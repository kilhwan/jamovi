[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "JAMOVI로 배우는 통계학",
    "section": "",
    "text": "역자 서문\n이 책은 Danielle J. Navarro와 David R. Foxcroft가 지은 Learning Statistics with jamovi: A Tutorial for Beginners in Statistical Analysis (2025년 1월 1일 판)을 우리말로 번역한 것입니다.\n역자는 R로 통계분석하는 과목을 여러 해 동안 강의하였습니다. R은 공개 SW로 자유롭게 사용할 수 있고 강력한 통계분석 도구이지만, 프로그래밍에 익숙하지 않은 학생들은 종종 초기 진입장벽을 느끼기도 합니다. 다양한 배경의 학생들에게 통계분석을 더 쉽게 강의할 수 있는 방법을 고민하던 차에, jamovi와 Danielle J. Navarro와 David R. Foxcroft의 책을 발견하게 되었습니다.\njamovi는 공개 SW이며 R을 기반으로 구현되었지만, SPSS 같이 그래픽 사용자 인터페이스를 채택하고 있어서 초심자가 비교적 쉽게 통계분석을 시작할 수 있습니다. 물론 통계분석의 다양한 기법과 옵션이 왜 필요하고, 복잡한 분석 결과를 어떻게 해석해야 하는지를 아는 것은 편리한 사용자 인터페이스와는 별개의 문제이고, 통계분석 과목에서 하나씩 배워나가야 할 쉽지 않은 내용들입니다. 그러나 일단 몇 번의 클릭만으로 통계분석 결과를 얻을 수 있다는 점은, 명령어 기반 통계분석 도구에 비해 초심자가 느끼는 심리적 진입장벽을 낮춰줍니다.\n이 책은 심리학을 전공하는 학부생들을 위한 통계 입문서이지만, 심리학에 특화된 내용보다는 사회과학 전반에서 활용되는 통계분석의 이론과 실습을 다루고 있기 때문에 다른 사회과학 전공이나 경영학 등을 전공하는 학부생들을 위해 사용되어도 손색이 없습니다.\n되도록이면 원문의 내용과 체계를 최대한 유지하여 번역하도록 노력하였습니다. 원문과 번역본이 크게 차이가 나는 부분은 세 가지 입니다. 첫째는, 원문에서는 각주로 처리된 수학적 설명의 일부분을 본문으로 옮겼습니다. 원문에서는 수학적 설명의 많은 부분을 각주로 처리하였습니다. 아마 수학 불안증을 가지는 독자들을 위한 배려일 거라 생각됩니다. 그러나 이런 부분 중 여러 내용이 수학적으로 그리 복잡하지 않았으며 본문의 다른 부분과 설명의 연관성이 높아서 각주가 아니라 본문에 있는 것이 오히려 이해하기 쉽다고 판단되었습니다. 이런 판단이 서는 곳은 각주를 모두 본문으로 처리하였습니다.\n두 번째로 다른 점은, 독자들이 jamovi를 실습하거나 본문의 내용을 이해하는데 도움이 될 것이라 생각되는 내용이 있으면 tip 형태의 별도의 글상자로 이러한 내용을 추가하였습니다. 별도의 글상자로 처리한 이유는 원문과 역자가 추가한 내용을 독자들이 쉽게 구분할 수 있게 하기 위해서입니다.\n세 번째로, jamovi의 한글화가 아직 불완전 하여 jamovi의 한글 인터페이스의 용어가 부적절한 곳이 많습니다. 대표적으로 test의 번역어로 ’검정’이라고 하는 것이 적절한 곳에 ’검증’이라고 한 것입니다. 이런 경우들이나 어떤 통계학 용어의 한글 용어가 여러 개 있는 경우에 역자가 각주를 단 곳이 있습니다. 이런 경우에는 각주의 시작 부분에 &lt;역주&gt;라는 표시를 두어 원저자의 각주와 구분할 수 있도록 하였습니다.\n이 책의 원본은 CC BY-SA 4.0 라이선스로 배포된 책입니다. 따라서 번역본인 이 책도 CC BY-SA 라이선스로 배포합니다. 이 책은 현재 번역 초안이라 할 수 있습니다. 이 책으로 강의를 하면서 더 매끄러운 번역이 될 수 있도록 문장이 조금씩 다듬어질 수 있으며, 새로운 실습이나 내용이 글상자로 추가될 수 있습니다.\n아무쪼록, 이 책이 통계분석의 이론과 실제의 세계에 입문하고자 하는 많은 분들에게 도움이 되기를 희망합니다.\n김길환\n2025년 2월 25일",
    "crumbs": [
      "역자 서문"
    ]
  },
  {
    "objectID": "index.html#역자-서문",
    "href": "index.html#역자-서문",
    "title": "JAMOVI로 배우는 통계학",
    "section": "",
    "text": "역자가 추가한 tip\n\n\n\n원문의 내용이 아니라 역자가 이해를 돕기 위해서 추가한 내용은 이러한 형태의 tip 글상자로 구분하였습니다.",
    "crumbs": [
      "역자 서문"
    ]
  },
  {
    "objectID": "index.html#원문-서문",
    "href": "index.html#원문-서문",
    "title": "JAMOVI로 배우는 통계학",
    "section": "원문 서문",
    "text": "원문 서문\n이 교재는 심리학, 보건 또는 사회 과학 전공의 학부생을 대상으로 하는 통계학 입문 수업의 내용을 다룹니다. 이 책에서는 jamovi를 시작하는 방법과 데이터 조작에 대해 소개합니다. 통계적 관점에서 보자면, 이 책은 기술 통계와 그래프 작성부터 시작하여, 확률 이론, 표본 추출 및 추정, 귀무 가설 검정에 대한 장으로 이어집니다. 이론을 소개한 후에는 분할표 분석, 상관분석, t-검정, 회귀분석, ANOVA, 요인분석을 다룹니다. 책의 마지막 부분에서는 베이즈 통계에 대해서도 간략히 언급합니다.\n이 책은 DJ Navarro(2018)의 Learning statistics with R: A tutorial for psychology students and other beginners (Version 0.6)를 각색한 것입니다. https://learningstatisticswithr.com/에서 원본을 확인할 수 있습니다.\n이 책의 jamovi 버전은 2018년에 첫 번째 버전(0.65)으로 출시되었습니다. 이후 0.70 및 0.75 버전이 오류 수정 및 추가 내용과 함께 발표되었으며, 초기 버전의 변경 사항에 대한 세부 정보는 0.75 버전 서문에서 확인할 수 있습니다: https://github.com/user-attachments/files/18124061/learning-statistics-with-jamovi-0.75.pdf.\n출시 이후 많은 사람들이 이 책의 인쇄본을 요청하였고, 이를 실현하면서 책과 자료의 오픈소스 특성을 유지하기 위해 영국 케임브리지의 Open Book Publishers와 협력하여 이 업데이트된 버전을 발간했습니다. Open Book Publishers는 영국에서 인문학 및 사회과학 분야의 학술 연구를 대상으로 한 선도적인 독립 오픈 액세스 출판사입니다. 이 출판사는 비영리, 수상 경력을 보유한, 학자들이 운영하는 기관으로, 고품질의 연구를 전 세계 독자들에게 무료로 제공하는 데 전념하고 있습니다.\n\n\n\n\n\n\nNote\n\n\n\n이 책의 영문 PDF 버전은 Open Book Publishers 웹사이트 (https://www.openbookpublishers.com/books/10.11647/obp.0333)에서 무료로 다운로드할 수 있습니다. 필요한 모든 데이터 파일은 jamovi의 추가 모듈을 통해 무료로 접근할 수 있으며, https://www.learnstatswithjamovi.com에서도 다운로드할 수 있습니다.\n\n\n오류를 발견하거나 제안 사항이 있다면 https://github.com/davidfoxcroft/lsj-book/issues에서 알려주시기 바랍니다.\nDavid Foxcroft\n2025년 1월 1일\n인용: Danielle J. Navarro와 David R. Foxcroft, Learning Statistics with jamovi: A Tutorial for Beginners in Statistical Analysis. 영국 케임브리지: Open Book Publishers, 2025, https://doi.org/10.11647/OBP.0333",
    "crumbs": [
      "역자 서문"
    ]
  },
  {
    "objectID": "01-Why-do-we-learn-statistics.html",
    "href": "01-Why-do-we-learn-statistics.html",
    "title": "1  왜 통계를 배워야 하는가",
    "section": "",
    "text": "1.1 통계학의 심리학적 관점\n많은 학생들에게 놀라운 사실이겠지만, 심리학 교육에서 통계는 꽤 중요한 부분을 차지합니다. 반면, 아무도 놀라지 않겠지만, 통계는 거의 모든 학생이 심리학 교육에서 좋아하는 부분이 아닙니다. 사실, 통계를 하는 것을 정말 좋아했다면 지금 심리학 수업이 아니라 통계학 수업을 듣고 있을 가능성이 높겠죠. 따라서 심리학에서 통계가 중요한 역할을 한다는 사실에 불만을 가진 학생들이 많다는 것은 놀라운 일이 아닙니다. 이런 상황을 고려할 때, 통계와 관련된 몇 가지 흔한 질문들에 답하면서 시작하는 것이 좋을 것 같네요.\n문제의 핵심은 통계라는 개념 그 자체와 관련이 있습니다. 통계란 무엇일까요? 통계는 왜 필요할까요? 그리고 왜 과학자들은 통계에 그렇게 집착할까요? 이 모든 질문은 곰곰이 생각해 보면 꽤 좋은 질문들입니다. 그래서 마지막 질문부터 시작해 보겠습니다. 과학자들은 왜 모든 것에 통계 검정을 적용하려고 할까요? 사실, 우리는 통계를 너무 자주 사용해서 왜 그렇게 하는지 설명하는 것을 잊곤 합니다. 과학자들, 특히 사회 과학자들 사이에서는 “통계 없이는 연구 결과를 신뢰할 수 없다”는 것이 일종의 신념처럼 되어 있습니다. 학부생들은 이런 상황에서 우리 모두가 완전히 제정신이 아닌 것처럼 느낄 수도 있습니다. 왜냐하면 아무도 아래와 같은 매우 단순한 질문에 답하려고 하지 않기 때문입니다:\n어떤 면에서는 이 질문이 단순해 보일 수 있지만, 대부분의 좋은 질문들이 단순해 보입니다. 이 질문에 대한 여러 훌륭한 답변이 있지만,2 제 생각에 가장 좋은 답변은 아주 단순합니다: 우리는 스스로를 충분히 신뢰하지 않기 때문입니다. 우리는 우리가 인간이라는 사실, 그리고 인간이 겪는 모든 편견, 유혹, 약점에 취약하다는 사실을 걱정합니다. 통계의 많은 부분은 기본적으로 이런 점을 방지하는 안전장치 역할을 합니다. “상식”을 사용해 증거를 평가하는 것은 직감, 언어적 논증, 그리고 인간의 이성을 사용해 올바른 답을 도출하는 것을 의미합니다. 하지만 대부분의 과학자들은 이러한 접근법이 효과적일 가능성이 낮다고 생각합니다.\n사실, 생각해보면 이것은 심리학적 질문처럼 들립니다. 심리학과에서 일하는 제가 이를 더 깊이 파고드는 것이 좋은 생각인 것 같습니다. “상식” 접근법이 정말로 신뢰할 만하다고 생각할 수 있을까요? 언어적 논증은 언어로 구성되어야 하고, 모든 언어는 편견을 가지고 있습니다. 어떤 개념들은 다른 것들보다 표현하기 더 어려운데, 그 이유가 반드시 그것이 틀려서가 아닙니다(예: 양자 전기역학은 훌륭한 이론이지만 말로 설명하기 어렵습니다). 우리의 “직감”은 과학적 문제를 해결하도록 설계된 것이 아니라, 일상적인 추론을 처리하도록 설계되었습니다. 그리고 생물학적 진화가 문화적 변화보다 느리다는 점을 고려하면, 우리는 이러한 직감이 우리가 사는 세상이 아닌 다른 세상의 문제들을 해결하도록 설계되었다고 인정해야 할 것 같습니다. 가장 근본적으로, 합리적으로 추론하기 위해서는 사람들이 “귀납법”을 사용해야 합니다. 즉, 현상의 즉각적인 증거를 넘어 현상을 일반화하는 현명한 추측을 해야 합니다. 여러분이 다양한 방해 요인에 영향을 받지 않고 이를 할 수 있다고 생각한다면, 제가 런던에 있는 다리를 팔아보겠습니다. 심지어 다음 절에서 보겠지만, 우리는 “추측이 필요 없는” 연역적 문제조차도 기존의 편견에 영향을 받지 않고 풀 수 없습니다.",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>왜 통계를 배워야 하는가</span>"
    ]
  },
  {
    "objectID": "01-Why-do-we-learn-statistics.html#통계학의-심리학적-관점",
    "href": "01-Why-do-we-learn-statistics.html#통계학의-심리학적-관점",
    "title": "1  왜 통계를 배워야 하는가",
    "section": "",
    "text": "왜 통계를 사용하는가? 과학자들은 단순히 상식 을 사용하지 않는 이유는 무엇인가?\n\n\n\n\n1.1.1 신념 편향의 저주\n사람들은 대체로 꽤 똑똑합니다. 우리는 이 행성을 공유하는 다른 종들보다 더 똑똑하죠(물론 이에 동의하지 않는 사람들도 있을 겁니다). 우리의 마음은 정말 놀라운 도구이며, 우리는 믿기 어려운 사고와 추론의 업적을 이룰 수 있는 것처럼 보입니다. 하지만 그렇다고 해서 우리가 완벽한 것은 아닙니다. 심리학자들이 수년간 보여준 여러 사실 중 하나는 중립적이고, 선입견에 흔들리지 않으며, 증거를 공정하게 평가하는 것을 정말로 어렵다는 점입니다. 이에 대한 좋은 예가 논리적 추론에서 나타나는 신념 편향 효과입니다. 사람들이 특정 주장이 논리적으로 타당한지(즉, 전제가 참이라면 결론도 참이 되는지) 판단하도록 요청받으면, 종종 결론의 신뢰성에 판단이 영향을 받게 됩니다. 심지어 그런 영향을 받지 않아야 할 때도 말이죠. 예를 들어, 다음은 결론이 신뢰할 만한 논리적으로 타당한 논증입니다.\n\n모든 담배는 비싸다 (전제 1)\n일부 중독성 물질은 싸다 (전제 2)\n따라서, 일부 중독성 물질은 담배가 아니다 (결론)\n\n다음은 결론이 신뢰할 만하지 않은 (논리적으로) 타당한 논증입니다:\n\n모든 중독성 물질은 비싸다 (전제 1)\n일부 담배는 싸다 (전제 2)\n따라서, 일부 담배는 중독성이 없다 (결론)\n\n논증 #2의 논리적 구조는 논증 #1의 구조와 동일하며, 둘 다 논리적으로 타당합니다. 하지만 두 번째 논증에서는 전제 1이 잘못되었을 가능성이 높으며, 그러므로 논증의 결론도 잘못되었을 가능성이 큽니다. 그러나 이는 논의의 핵심과는 무관합니다. 논증이 연역적으로 타당하다는 것은 결론이 전제에서 논리적으로 도출될 수 있다는 것을 의미합니다. 즉, 논리적으로 타당한 논증이 반드시 참된 진술을 포함할 필요는 없습니다.\n다음은 결론이 신뢰할 만한 논리적으로 타당하지 않은 논증입니다:\n\n모든 중독성 물질은 비싸다 (전제 1)\n일부 담배는 싸다 (전제 2)\n따라서, 일부 중독성 물질은 담배가 아니다 (결론)\n\n마지막으로, 결론이 신뢰할 만하지 않은 논리적으로 타당하지 않은 논증입니다:\n\n모든 담배는 비싸다 (전제 1)\n일부 중독성 물질은 싸다 (전제 2)\n따라서, 일부 담배는 중독성이 없다 (결론)\n\n이제, 사람들이 참과 거짓에 대한 기존 신념을 완전히 배제하고 순전히 논리적 근거에 따라 논증을 평가할 수 있다고 가정해 봅시다. 그렇다면, 타당한 논증은 100% 사람들이 타당하다고 판단하고, 비타당한 논증은 0%만이 타당하다고 판단해야 할 겁니다. 실험을 통해 이를 조사하면, Table 1.1 같은 데이터를 기대할 수 있습니다.\n\n\n\n\nTable 1.1. 논증의 타당성\n\n\n\n\n\n결론이 참처럼 느껴짐결론이 거짓처럼 느껴짐\n\n논증이 타당함100%가 \"타당함\"이라고 응답100%가 \"타당함\"이라고 응답\n\n논증이 타당하지 않음0%가 \"타당함\"이라고 응답0%가 \"타당함\"이라고 응답\n\n\n\n\n\n\n\n만약 심리학 데이터가 이와 같거나 이와 비슷한 결과를 보인다면, 우리의 직감을 그냥 믿어도 안전하다고 느낄 수 있을 겁니다. 즉, 과학자들이 데이터를 상식에 기반하여 평가하고 복잡한 통계는 신경 쓰지 않아도 괜찮을 겁니다. 하지만 여러분은 심리학 수업을 들었고, 아마도 이 이야기가 어디로 가는지 이미 짐작하고 있을 겁니다.\n고전적인 연구에서 Evans et al. (1983) 은 정확히 이 주제를 조사하는 실험을 진행했습니다. 그 결과, 기존 신념(즉, 믿음)이 데이터의 구조와 일치할 때는 모든 것이 예상대로 진행되었습니다(Table 1.2). 완벽하지는 않았지만, 꽤 좋은 결과였습니다. 그러나 결론의 진실성에 대한 우리의 직관적인 느낌이 논증의 논리적 구조와 충돌할 때는 어떤 일이 발생하는지 보십시오(Table 1.3).\n\n\n\n\nTable 1.2. 기존 신념과 논증의 타당성\n\n\n\n\n\n결론이 참처럼 느껴짐결론이 거짓처럼 느껴짐\n\n논증이 타당함92%가 \"타당함\"이라고 응답\n\n논증이 타당하지 않음8%가 \"타당함\"이라고 응답\n\n\n\n\n\n\n\n아, 이런. 그리 좋지 않은 결과입니다. 강력한 논증이 우리의 기존 신념과 충돌할 때, 사람들은 그것을 강력한 논증으로 인식하는 데 어려움을 겪습니다(사람들은 단 46%의 경우에만 그렇게 했습니다). 더 나쁜 것은, 우리의 기존 신념과 일치하는 약한 논증이 주어졌을 때, 거의 아무도 그 논증이 약하다는 것을 알아차리지 못했습니다(사람들은 92%의 경우에 이를 잘못 판단했습니다!).3\n\n\n\n\nTable 1.3. 직관과 논증의 타당성\n\n\n\n\n\n결론이 참처럼 느껴짐결론이 거짓처럼 느껴짐\n\n논증이 타당함92%가 \"타당함\"이라고 응답46%가 \"타당함\"이라고 응답\n\n논증이 타당하지 않음92%가 \"타당함\"이라고 응답8%가 \"타당함\"이라고 응답\n\n\n\n\n\n\n\n생각해보면, 이러한 데이터가 엄청나게 치명적인 것은 아닙니다. 전반적으로, 사람들은 기존 편향을 보완하는 데 있어서 무작위 선택보다 더 나은 결과를 보였습니다. 약 60%의 판단이 정확했으니까요(무작위적 선택에서는 50%를 기대할 수 있습니다). 그렇다 하더라도, 만약 여러분이 전문적인 “증거 평가자”라면, 누군가가 와서 여러분이 올바른 결정을 내릴 확률을 60%에서 (예를 들어) 95%로 향상시킬 수 있는 마법의 도구를 제공한다면, 아마도 그 제안을 받아들일 겁니다. 당연하죠. 다행히도, 우리는 실제로 이런 도구를 가지고 있습니다. 마법은 아니지만, 그것은 바로 통계입니다. 이것이 과학자들이 통계를 사랑하는 첫 번째 이유입니다. 우리는 “믿고 싶은 것을 믿기” 너무 쉽습니다. 따라서 “데이터를 믿고” 싶다면, 우리의 개인적인 편향을 통제하기 위해 약간의 도움을 받아야 합니다. 통계가 바로 그런 역할을 합니다. 통계는 우리가 정직할 수 있도록 도와줍니다.",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>왜 통계를 배워야 하는가</span>"
    ]
  },
  {
    "objectID": "01-Why-do-we-learn-statistics.html#심슨의-역설에-대한-교훈적-이야기",
    "href": "01-Why-do-we-learn-statistics.html#심슨의-역설에-대한-교훈적-이야기",
    "title": "1  왜 통계를 배워야 하는가",
    "section": "1.2 심슨의 역설에 대한 교훈적 이야기",
    "text": "1.2 심슨의 역설에 대한 교훈적 이야기\n다음은 (아마도!) 실제 이야기입니다. 1973년, 캘리포니아 대학교 버클리 캠퍼스는 대학원 과정에 학생들을 입학 과정의 문제에 대해 우려를 가지고 있었습니다. 특히, 문제가 되었던 것은 입학 과정에서의 성별 분포였습니다. (Table 1.4)\n\n\n\n\nTable 1.4. 성별에 따른 버클리 학생 입시 결과\n\n\n\n\n\n지원자 수합격률\n\n남성844244%\n\n여성432135%\n\n\n\n\n\n\n\n이로 인해 학교는 소송을 당할까 봐 걱정했습니다!4 약 13,000명의 지원자가 있었고, 남성과 여성의 입학률 차이가 9%에 이른다는 점은 단순한 우연으로 보기엔 너무 큰 차이였기 때문입니다. 꽤 설득력 있는 데이터죠, 그렇지 않나요? 그런데 만약 제가 이 데이터를 두고 사실은 여성을 약간 더 우대하는 약한 편향을 반영한다고 말한다면, 여러분은 제가 미쳤거나 성차별주의자라고 생각할지도 모릅니다.\n놀랍게도, 이 말이 어느 정도 사실입니다. 사람들이 입학 데이터를 더 자세히 살펴보았을 때, 다른 이야기가 나타났습니다(Bickel et al., 1975). 특히, 학과별 데이터를 살펴보았더니 대부분의 학과에서는 여성 지원자가 남성 지원자보다 약간 더 높은 입학률을 보였습니다. Table 1.5 는 가장 큰 6개 학과의 입학 결과를 보여줍니다(학과명은 개인 정보 보호를 위해 제거됨):\n\n\n\n\nTable 1.5. 버클리 6개 주요 학과에서의 성별에 따른 입시 결과\n\n\n\n\n\n남성여성\n\n학과지원자 수합격률지원자 수합격률\n\nA82562%10882%\n\nB56063%2568%\n\nC32537%59334%\n\nD41733%37535%\n\nE19128%39324%\n\nF2726%3417%\n\n\n\n\n\n\n\n놀랍게도, 대부분의 학과에서 여성의 입학률이 남성보다 더 높았습니다! 그런데도 대학 전체적으로는 여성의 입학률이 남성보다 낮았습니다. 어떻게 이런 일이 가능할까요? 어떻게 이 두 가지 진술이 동시에 사실일 수 있을까요?\n여기서 무슨 일이 일어나는지 설명해 보겠습니다. 먼저, 학과별 입학률이 서로 같지 않다는 점에 주목하세요. 일부 학과(A, B 등)는 자격을 갖춘 지원자를 높은 비율로 받아들이는 반면, 다른 학과(F 등)는 높은 자질을 가진 지원자조차 대부분 거부하는 경향이 있었습니다. 위의 6개 학과를 보면, 학과 A가 가장 관대했고, 그다음으로 B, C, D, E, F 순서였습니다. 이제 남성과 여성이 지원한 학과를 비교해 보겠습니다. 남성 지원자 수가 많은 학과를 순위로 매기면 A&gt;B&gt;D&gt;C&gt;F&gt;E(쉬운 학과가 굵게 표시됨) 순서입니다. 대체로 남성은 입학률이 높은 학과에 지원하는 경향이 있었습니다.\n이와 비교해 여성 지원자들의 분포를 보면 순위는 C&gt;E&gt;D&gt;F&gt;A&gt;B로 나타납니다. 즉, 이 데이터는 여성 지원자들이 “더 어려운” 학과에 지원하는 경향이 있다는 점을 시사합니다. 사실, Figure 1.1 을 보면 이러한 경향이 체계적이고 상당히 뚜렷하다는 것을 알 수 있습니다. 이러한 효과를 심슨의 역설(Simpson’s paradox)이라고 합니다. 이는 흔한 일은 아니지만 실제로 발생하며, 대부분의 사람들은 처음 접했을 때 매우 놀라고, 심지어는 믿지 않으려고 합니다. 그러나 이는 분명히 존재합니다. 이 현상에는 매우 미묘한 통계적 교훈이 숨어 있지만, 저는 이를 통해 훨씬 중요한 점을 강조하고 싶습니다. 어떤 것을 연구한다는 것은 어렵고, 복잡한 데이터의 구석구석에는 미묘하고 직관에 반하는 함정들이 도사리고 있다는 것입니다. 이것이 과학자들이 통계를 사랑하고, 연구 방법론을 가르치는 두 번째 이유입니다. 과학적 탐구는 어렵고, 진실은 때때로 교묘히 숨겨져 있습니다.\n\n\n\n\n\n\n\n\nFigure 1.1. 1973년 버클리 대학 입학 데이터. 이 그림은 적어도 한 명 이상의 여성 지원자가 있었던 85개 학과의 입학률을 여성 지원자의 비율에 따라 나타낸 것입니다. 이 플롯은 Bickel et al. (1975) 의 그림 1을 다시 그린 것입니다. 원은 지원자가 40명 이상인 학과를 나타내며, 원의 크기는 지원자 수에 비례합니다. 십자가는 지원자가 40명 미만인 학과를 나타냅니다.\n\n\n\n\n\n\n\n\n\n\n\n심슨의 역설이란\n\n\n\n심슨의 역설(Simpson’s Paradox)은 영국의 통계학자 에드워드 H. 심슨(Edward H. Simpson)이 1951년에 처음 공식적으로 논문에서 언급한 통계적 현상에서 이름을 따왔습니다. 그러나 이 현상 자체는 심슨 이전에도 알려져 있었고, 19세기 후반부터 여러 통계학자들에 의해 비공식적으로 논의되었습니다. 예를 들어, 1899년과 1903년에 Karl Pearson과 Udny Yule이 유사한 현상을 연구한 바 있습니다.\n심슨의 연구는 “The Interpretation of Interaction in Contingency Tables”라는 논문에서 소개되었으며, 조건부 확률 및 독립성 문제를 다룰 때 발생할 수 있는 역설적 결과를 정리한 내용이 포함되어 있었습니다. 이후, 이 현상은 1970년대에 심슨의 이름을 따서 “Simpson’s Paradox”로 널리 알려지게 되었고, 다양한 학문 분야에서 중요한 개념으로 자리 잡았습니다.\nSimpson’s Paradox는 데이터의 하위 그룹을 분석할 때와 전체 데이터를 분석할 때 결과가 모순되거나 반대되는 현상을 말합니다. 이를 통해 조건부 관계나 인과 관계를 잘못 해석할 위험성을 강조합니다.\n예를 들어: 1. 전체 데이터를 보면 A가 B보다 더 나은 결과를 보이는 것처럼 보이지만, 2. 데이터를 그룹(예: 성별, 연령대)으로 나누면 B가 A보다 나아 보이는 경우가 발생할 수 있습니다.\nSimpson’s Paradox는 데이터 분석 시 그룹별 차이와 전체 데이터를 분리하여 해석해야 한다는 중요성을 알려줍니다. 단순히 숫자만 보고 결론을 내리기보다, 데이터를 맥락 속에서 이해하고 조심스럽게 해석해야 합니다.\n\n\n이 주제를 완전히 마무리하기 전에 연구 방법론 수업에서 종종 간과되는 또 다른 중요한 점을 언급하고 싶습니다. 통계는 문제의 일부만 해결할 뿐입니다. 처음에는 버클리의 입학 과정이 여성 지원자에게 불공정할 수 있다는 우려에서 시작했습니다. “집계된” 데이터를 보면 대학이 여성을 차별하는 것처럼 보였지만, 데이터를 “분해”하여 각 학과의 개별적인 행동을 보면 실제로 학과들은 오히려 여성을 약간 더 우대하는 편향을 보였습니다. 전체 입학률에서 나타난 성별 편향은 여성이 더 어려운 학과를 선택하는 경향에서 비롯된 것입니다. 법적 관점에서 보면, 이는 아마도 대학의 입학 과정에 문제가 없다는 것을 의미할 것입니다. 대학원 입학은 개별 학과 수준에서 결정되며, 그렇게 해야 할 충분한 이유가 있습니다. 개별 학과 수준에서의 결정은 거의 편향이 없습니다(학과별로 나타난 약한 여성 우대 편향은 작고 일관되지 않습니다). 대학이 사람들이 지원할 학과를 통제할 수 없고, 결정이 학과 수준에서 이루어지므로 이러한 선택에서 발생하는 편향에 대해 책임질 수는 없습니다.\n제가 앞서 다소 가볍게 한 언급의 근거가 바로 이것이었지만, 이것이 이야기의 전부는 아닙니다, 그렇죠? 사회학적, 심리학적 관점에서 본다면, 왜 성별에 따른 지원 학과의 차이가 이렇게 큰지를 물어보고 싶을 것입니다. 왜 남성은 공학에, 여성은 영어학과에 더 자주 지원할까요? 그리고 왜 여성 지원자가 많은 학과는 입학률이 낮고, 남성 지원자가 많은 학과는 입학률이 높은 경우가 많은 걸까요? 각 학과가 편향이 없더라도 이것이 여전히 성별 편향을 반영하는 것은 아닐까요? 아마도 그렇습니다. 가령 남성은 “이공계”를 선호하고 여성은 “인문학”을 선호한다고 가정해 봅시다. 그리고 인문학 학과의 입학률이 낮은 이유가 정부가 인문학을 지원하지 않기 때문이라고 한다면요(예를 들어, 박사 과정 자리는 종종 정부가 자금을 지원하는 연구 프로젝트와 연계됩니다). 이것이 성별 편향일까요, 아니면 인문학의 가치를 간과한 관점일까요? 만약 정부 고위층에서 인문학 자금을 삭감하면서 “인문학은 쓸모없는 여성스러운 것”이라고 생각했다면, 이는 명백히 성별 편향처럼 보입니다. 이러한 것은 통계의 영역에 포함되지 않지만, 연구 프로젝트에서는 중요합니다. 만약 미묘한 성별 편향의 구조적 영향을 전체적으로 조사하고 싶다면, 집계된 데이터와 분해된 데이터를 모두 살펴보는 것이 좋을 것입니다. 버클리 자체의 의사 결정 과정을 알고 싶다면 분해된 데이터에만 관심을 가질 가능성이 높습니다.\n요컨대, 통계만으로는 많은 중요한 질문에 답할 수는 없으나, 질문들에 대한 답변은 데이터를 어떻게 분석하고 해석하느냐에 크게 영향을 받을 것입니다. 이것이 통계를 데이터로 부터 무언가를 배우기 위한 도구로 생각해야 하는 이유입니다. 그 이상도 이하도 아닙니다. 통계는 강력한 도구이지만, 신중한 사고를 대체할 수는 없습니다.",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>왜 통계를 배워야 하는가</span>"
    ]
  },
  {
    "objectID": "01-Why-do-we-learn-statistics.html#심리학에서의-통계",
    "href": "01-Why-do-we-learn-statistics.html#심리학에서의-통계",
    "title": "1  왜 통계를 배워야 하는가",
    "section": "1.3 심리학에서의 통계",
    "text": "1.3 심리학에서의 통계\n위 논의가 과학이 왜 통계에 그렇게 집중하는지를 설명하는 데 도움이 되었길 바랍니다. 하지만 심리학에서 통계가 어떤 역할을 하는지, 그리고 왜 심리학 수업에서 항상 통계에 많은 강의를 할애하는지에 대해 여전히 많은 질문이 있을 것 같습니다. 그래서 여기 몇 가지 질문에 대한 답변을 시도해 보겠습니다.\n\n왜 심리학에서 통계를 그렇게 많이 다루나요?\n\n솔직히 말하자면, 여러 가지 이유가 있는데, 그중 일부는 다른 것보다 더 타당합니다. 가장 중요한 이유는 심리학이 통계 과학이라는 점입니다. 제가 말하려는 것은 심리학이 연구하는 “대상”이 사람이라는 사실입니다. 진짜로 복잡하고, 놀랍도록 혼란스럽고, 때로는 화나게 하는 방식으로 예측 불가능한 사람들 말이죠. 물리학의 “대상”은 전자 같은 객체를 포함하며, 물리학에서도 여러 복잡한 문제가 발생하지만, 전자는 스스로 생각하지 않습니다. 전자는 의견을 갖고 있지 않으며, 이상하고 자의적 방식으로 서로 다르지 않고, 실험 도중에 지루해하거나 실험자에게 화를 내면서 데이터 세트를 일부러 망치려 하지도 않습니다(제가 그런 적이 있다는 건 아닙니다!). 근본적으로 심리학은 물리학보다 더 어렵습니다.5 그래서 우리는 물리학자보다 통계에 더 능숙해야 한다는 이유로 통계를 가르칩니다. 물리학에서는 종종 “만약 실험에 통계가 필요하다면, 더 나은 실험을 했어야 했다”라는 말이 사용됩니다. 그들은 연구 대상이 사회과학자들이 직면하는 방대한 혼돈에 비해 터무니없이 단순하기 때문에 이런 말을 할 수 있는 사치를 누릴 수 있는 것입니다. 심리학뿐만 아니라 대부분의 사회과학도 통계에 크게 의존합니다. 이는 우리가 실험을 잘 못해서가 아니라, 해결하기 더 어려운 문제를 선택했기 때문입니다. 여러분이 통계를 배우는 이유는 정말로 필요하기 때문입니다.\n\n다른 사람이 통계를 대신해줄 수는 없나요?\n\n어느 정도는 가능하지만, 완전히 그럴 수는 없습니다. 심리학을 하기 위해 완전히 훈련된 통계학자가 될 필요는 없지만, 일정 수준의 통계 능력을 갖춰야 합니다. 제가 보기에, 모든 심리학 연구자가 기본적인 통계를 다룰 줄 알아야 하는 세 가지 이유가 있습니다:\n\n첫째, 기본적인 이유입니다: 통계는 연구 설계와 깊이 얽혀 있습니다. 심리학 연구를 잘 설계하고 싶다면, 최소한 통계의 기본은 이해해야 합니다.\n둘째, 심리학적 연구를 잘하려면 심리학 문헌을 이해해야 하겠죠? 하지만 심리학 문헌의 거의 모든 논문은 통계 분석 결과를 보고합니다. 그러므로 심리학을 제대로 이해하려면 다른 사람들이 데이터로 무엇을 했는지 이해할 수 있어야 하고, 이는 일정 수준의 통계 지식을 요구합니다.\n셋째, 모든 통계를 다른 사람에게 의존하는 데에는 큰 실용적인 문제가 있습니다: 통계 분석은 비용이 많이 듭니다. 만약 지루할 때 호주 정부의 대학 등록금을 찾아보신다면, 흥미로운 점을 발견할 수 있을 겁니다: 통계학은 “국가 우선” 카테고리로 지정되어 있어서 다른 학문 영역보다 등록금이 훨씬 낮습니다. 이는 통계학자들이 크게 부족하기 때문입니다. 따라서 심리학 연구자로서의 관점에서 보면, 수요와 공급의 법칙이 여러분에게 유리하게 작용하지 않는다는 가혹한 현실에 직면하게 됩니다! 결과적으로 심리학 연구를 하고자 하는 현실적인 상황에서는, 잔인한 사실은 통계학자를 고용할 돈이 부족하다는 것입니다. 그러므로 경제적인 이유로 스스로 자립해야 할 필요가 있습니다.\n\n이러한 이유들 중 많은 부분은 연구자들뿐만 아니라 일반적인 상황에도 적용됩니다. 실무 심리학자가 되어 학문 분야를 따라가고 싶다면, 과학적 문헌을 읽을 수 있는 것이 도움이 됩니다. 이 문헌들은 통계에 크게 의존하니까요.\n\n저는 직업, 연구 또는 임상 작업에 관심이 없어요. 통계가 필요할까요?\n\n이제 저를 놀리시는군요. 그래도, 통계는 여러분에게도 중요할 거라고 생각합니다. 통계는 모든 사람에게 중요합니다. 우리는 21세기에 살고 있고, 데이터는 어디에나 존재합니다. 솔직히 말해서, 요즘 세상에서 기본적인 통계 지식은 거의 생존 도구에 가깝습니다! 이것이 바로 다음 섹션에서 다룰 주제입니다.",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>왜 통계를 배워야 하는가</span>"
    ]
  },
  {
    "objectID": "01-Why-do-we-learn-statistics.html#일상생활에서의-통계",
    "href": "01-Why-do-we-learn-statistics.html#일상생활에서의-통계",
    "title": "1  왜 통계를 배워야 하는가",
    "section": "1.4 일상생활에서의 통계",
    "text": "1.4 일상생활에서의 통계\n\n우리는 정보의 홍수 속에서 살아가고 있지만,\n지식의 기근에 허덕이고 있다.\n– 다양한 저자들, 아마도 John Naisbitt가 원작자\n\n제가 강의 노트를 작성하기 시작했을 때, ABC 뉴스 웹사이트에 게시된 최근 기사 20개를 살펴봤습니다. 그중 8개는 통계 주제를 다루고 있었고, 그중 6개는 오류를 포함하고 있었습니다. 가장 흔한 오류는 기준선 데이터를 보고하지 않은 것이었습니다(예: 기사에서 상황 X에 있는 사람 중 5%가 특성 Y를 가지고 있다고 언급하면서, 이 특성이 다른 사람들에게 얼마나 흔한지에 대해서는 말하지 않음). 여기서 제가 강조하고 싶은 것은 기자들이 통계를 잘 못 다룬다는 점이 아니라(물론 거의 항상 그렇긴 하지만), 기본적인 통계 지식이 다른 사람이 실수를 하거나 심지어 거짓말을 하고 있는지 판단하는 데 매우 유용하다는 점입니다. 사실, 통계 지식을 가지면 신문이나 인터넷에 훨씬 더 자주 화가 나는 일이 생기게 됩니다. 좋은 예는 Chapter 4 의 Section 4.1.5 에서 확인할 수 있습니다. 이 책의 후속 버전에서는 이와 관련된 일화들을 더 많이 포함하려고 노력할 것입니다.",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>왜 통계를 배워야 하는가</span>"
    ]
  },
  {
    "objectID": "01-Why-do-we-learn-statistics.html#연구-방법에는-통계-이상의-것이-있다",
    "href": "01-Why-do-we-learn-statistics.html#연구-방법에는-통계-이상의-것이-있다",
    "title": "1  왜 통계를 배워야 하는가",
    "section": "1.5 연구 방법에는 통계 이상의 것이 있다",
    "text": "1.5 연구 방법에는 통계 이상의 것이 있다\n지금까지 제가 언급한 대부분은 통계에 관한 것이었기 때문에, 통계만이 제가 관심 있는 전부라고 생각할 수도 있습니다. 사실 그렇게 생각해도 크게 틀리지는 않습니다. 하지만 연구 방법론은 통계보다 더 넓은 개념입니다. 그래서 대부분의 연구 방법론 수업에서는 연구 설계의 실제적인 측면, 특히 사람을 대상으로 연구할 때 마주치는 문제와 관련된 주제를 다룹니다. 그러나 학생들의 두려움 중 약 99%는 통계 부분과 관련이 있기 때문에, 이 논의에서는 통계에 초점을 맞췄고, 통계가 중요하며 두려워할 필요가 없다는 것을 설득하려고 노력했습니다. 그럼에도 불구하고, 연구 방법론의 입문 수업에서는 통계를 많이 다루는 것이 일반적입니다. 이는 (대개) 강사가 악의적인 사람이기 때문이 아닙니다. 사실은 그 반대입니다. 입문 수업이 통계에 많은 시간을 할애하는 이유는 다른 연구 방법론 훈련보다 통계가 더 먼저 필요하기 때문입니다. 왜냐하면, 다른 수업의 거의 모든 과제가 다른 연구 방법론 도구보다 통계 훈련에 더 크게 의존하기 때문입니다. 학부 과제에서 연구를 처음부터 끝까지 직접 설계하도록 요구하는 경우는 드물지만(이 경우 연구 설계에 대한 많은 지식이 필요함), 다른 사람이 설계한 연구에서 수집된 데이터를 분석하고 해석하도록 요구하는 과제는 흔합니다(이 경우 통계 지식이 필요함). 이런 점에서, 여러분이 다른 수업에서 성공적으로 과제를 수행할 수 있도록 돕는 관점에서 통계는 더 시급합니다.\n그러나 “시급함”과 “중요함”은 다르다는 점을 유념하세요. 둘 다 중요합니다. 저는 연구 설계가 데이터 분석만큼 중요하다는 점을 강조하고 싶습니다. 이 책에서도 연구 설계에 대해 어느 정도 다룹니다. 하지만 통계는 일종의 보편성을 가지고 있으며, 심리학 및 사회 연구 대부분에 유용한 핵심 도구 세트를 제공합니다. 반면, 연구 방법론은 그리 보편적이지 않습니다. 모두가 생각해야 할 일반적인 원칙은 있지만, 연구 설계의 많은 부분은 개별적이고 여러분이 참여하고자 하는 연구 분야에 따라 다릅니다.\n\n\n\n\nBickel, P. J., Hammel, E. A., & O’Connell, J. W. (1975). Sex bias in graduate admissions: Data from Berkeley. Science, 187, 398–404. https://doi.org/10.1126/science.187.4175.398\n\n\nEvans, J. St. B. T., Barston, J. L., & Pollard, P. (1983). On the conflict between logic and belief in syllogistic reasoning. Memory and Cognition, 11, 295–306. https://doi.org/10.3758/BF03196976",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>왜 통계를 배워야 하는가</span>"
    ]
  },
  {
    "objectID": "01-Why-do-we-learn-statistics.html#footnotes",
    "href": "01-Why-do-we-learn-statistics.html#footnotes",
    "title": "1  왜 통계를 배워야 하는가",
    "section": "",
    "text": "이 인용문은 오든의 1946년 시 어느 리라 아래: 시대를 위한 반동적 조항에서 나온 것으로, 하버드 대학교 졸업식 연설의 일부였습니다. 이 시의 역사는 꽤 흥미로운데, 이에 대한 애덤 커시(Adam Kirsch)의 분석을 하버드 매거진에서 확인할 수 있습니다. https://www.harvardmagazine.com/2007/11/a-poets-warning.html↩︎\n과학자에게 상식이 부족하다는 제안도 포함됩니다.↩︎\n제가 더 냉소적일 때는 이 사실만으로도 인터넷에서 읽는 내용의 95%를 설명할 수 있다고 느낍니다.↩︎\n이전 버전의 이 노트에서는 실제로 소송을 당했다고 잘못 언급했었습니다. 하지만 이는 사실이 아닙니다. 이에 대한 훌륭한 해설이 Alex Reinhart의 글에 나와 있습니다: https://www.refsmmat.com/posts/2016-05-08-simpsons-paradox-berkeley.html. Wilfried Van Hirtum께 감사드립니다.↩︎\n이것이 물리학이 심리학보다 약간 더 발전한 과학으로 간주되는 이유일지도 모릅니다.↩︎",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>왜 통계를 배워야 하는가</span>"
    ]
  },
  {
    "objectID": "02-A-brief-introduction-to-research-design.html",
    "href": "02-A-brief-introduction-to-research-design.html",
    "title": "2  연구 설계에 대한 간략한 소개",
    "section": "",
    "text": "2.1 심리학적 측정에 대한 소개\n데이터 수집을 측정의 일종으로 생각할 수 있다는 것을 먼저 이해해야 합니다. 즉, 여기서 우리가 하려고 하는 것은 인간의 행동이나 마음에 관한 어떤 것을 측정하려는 것입니다. 그렇다면 “측정”이란 무엇을 의미할까요?",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연구 설계에 대한 간략한 소개</span>"
    ]
  },
  {
    "objectID": "02-A-brief-introduction-to-research-design.html#sec-Introduction-to-psychological-measurement",
    "href": "02-A-brief-introduction-to-research-design.html#sec-Introduction-to-psychological-measurement",
    "title": "2  연구 설계에 대한 간략한 소개",
    "section": "",
    "text": "2.1.1 심리학적 측정에 대한 몇 가지 생각\n측정 자체는 미묘한 개념이지만, 기본적으로는 “무언가”에 숫자, 라벨, 또는 잘 정의된 설명을 할당하는 방법을 찾는 것입니다. 따라서 다음과 같은 항목들은 심리학적 측정으로 간주될 수 있습니다:\n\n내 나이는 33살이다.\n\n나는 앤초비를 좋아 하지 않는다.\n\n내 염색체 성별은 남성이다.\n\n내 자기 인식 성별은 여성이다.\n\n위의 간단한 목록에서, 굵게 표시된 부분은 “측정 대상”이고, 이탤릭체 부분은 “측정값”입니다. 사실 이를 조금 더 확장하여, 각 경우에 나올 수 있는 가능한 측정값의 집합을 생각해 볼 수 있습니다:\n\n내 나이(단위: 연)는 0, 1, 2, 3… 등의 값을 가질 수 있습니다. 나이의 상한선은 조금 모호하지만, 실질적으로는 150 정도가 최대치라고 안전하게 말할 수 있습니다. 왜냐하면 지금까지 그 이상 산 사람은 없기 때문입니다.\n내가 앤초비를 좋아하는지 물었을 때, 좋아한다, 좋아하지 않는다, 별 의견이 없다, 가끔 좋아한다고 대답할 수 있습니다.\n내 염색체 성별은 거의 확실히 남성(\\(XY\\)) 또는 여성(\\(XX\\))이겠지만, 다른 가능성도 있습니다. 예를 들어 클라인펠터 증후군(\\(XXY\\))일 수도 있는데, 이는 여성보다는 남성에 더 가깝습니다. 다른 가능성도 있을 수 있습니다.\n내 자기 인식 성별 역시 남성 또는 여성일 가능성이 크지만, 염색체 성별과 일치하지 않을 수도 있습니다. 나는 또한 둘 다 아니다라고 정체성을 선택하거나, 트랜스젠더라고 명시적으로 표현할 수도 있습니다.\n\n보시다시피, 어떤 경우(예: 나이)에는 가능한 측정값의 집합이 꽤 명확한 것처럼 보이는 반면, 다른 경우에는 조금 복잡해집니다. 하지만 심지어 나이의 경우에도 이것은 매우 미묘한 문제입니다. 예를 들어 위의 예에서는 나이를 연 단위로 측정해도 괜찮다고 가정했지만, 발달 심리학자라면 이는 너무 조잡한 방법일 것입니다. 그래서 나이를 종종 연도와 월 단위로 측정합니다(예: “2;11”은 2년 11개월을 의미함). 신생아를 연구하고 있다면, 나이를 출생 후 일수 또는 심지어 출생 후 시간수로 측정할 수도 있습니다. 즉, 허용 가능한 측정값을 지정하는 방식이 중요합니다.\n조금 더 자세히 살펴보면, “나이”라는 개념 자체가 그렇게 정확하지 않다는 것도 깨달을 수 있습니다. 일반적으로 우리가 “나이”라고 말할 때는 암묵적으로 “출생 후 경과 시간”을 의미합니다. 그러나 이것이 항상 적합한 방식은 아닙니다. 예를 들어 신생아의 안구 운동 제어 방식에 관심이 있다면, “출생”이 유일하게 중요한 기준점이 아닐 수도 있습니다. 만약 앨리스라는 아기가 출산 예정보다 3주 일찍 태어나고 비앙카라는 아기가 1주 늦게 태어났다면, 우리가 “출생 후 2시간”에 이들을 만났을 때 둘이 “동갑”이라고 말하는 것이 정말 의미가 있을까요? 사회적 관습에 따르면 출생은 일상생활에서 나이를 말할 때 기준점으로 사용하며, 이는 개인이 독립적 존재로 작동한 시간의 양을 정의합니다. 하지만 과학적 관점에서는 그것만이 중요한 것은 아닙니다. 인간의 생물학을 생각할 때 우리는 수정 이후로 성장하고 성숙해 온 유기체로 볼 수 있으며, 이 관점에서 보면 앨리스와 비앙카는 전혀 같은 나이가 아닙니다. 따라서 “나이”라는 개념을 두 가지 방식으로 정의할 수 있습니다: 수정 이후 경과 시간과 출생 이후 경과 시간. 성인과 관련된 연구에서는 큰 차이가 없겠지만, 신생아와 관련된 연구에서는 차이가 있을 수 있습니다.\n이 문제들을 넘어, 방법론의 문제가 있습니다. 누군가의 나이를 알아내기 위해 어떤 “측정 방법”을 사용할 것인가? 여기에도 여러 가지 방법이 있습니다:\n\n“당신의 나이가 몇 살입니까?”라고 직접 물어볼 수 있습니다. 자기 보고(self-report)는 빠르고 저렴하며 간단합니다. 하지만 질문을 이해할 나이에 도달한 사람에게만 효과적이며, 일부 사람들은 나이에 대해 거짓말을 할 수도 있습니다.\n부모에게 “당신의 아이는 몇 살입니까?”라고 물어볼 수 있습니다. 이 방법은 빠르고, 아이를 대상으로 할 때는 부모가 거의 항상 주변에 있기 때문에 어렵지 않습니다. 그러나 “수정 이후 나이”를 알고 싶다면 이런 방법은 잘 적용되지 않을 것입니다. 많은 부모가 수정 시점을 정확히 알지 못하기 때문입니다. 이 경우 산부인과 의사와 같은 다른 전문가가 필요할 수 있습니다.\n공식 기록(예: 출생 증명서나 사망 증명서)을 확인할 수도 있습니다. 이 방법은 시간과 노력이 많이 들지만 유용할 때도 있습니다(예: 대상이 이미 사망한 경우).\n\n\n\n2.1.2 조작화: 측정 정의하기\n이전 절에서 논의된 모든 아이디어는 조작화(operationalisation) 개념과 관련이 있습니다. 이 개념을 좀 더 정확히 설명하면, 조작화란 의미는 있지만 다소 모호한 개념을 정확한 측정으로 전환하는 과정입니다. 조작화 과정에는 여러 가지 요소가 포함될 수 있습니다:\n\n측정 대상에 대해 명확히 정의하기. 예를 들어, “나이”는 연구의 맥락에서 “출생 이후 경과 시간”을 의미합니까, 아니면 “수정 이후 경과 시간”을 의미합니까?\n측정 방법 결정하기. 나이를 측정하기 위해 자기 보고를 사용할 것입니까, 부모에게 물어볼 것입니까, 아니면 공식 기록을 확인할 것입니까? 자기 보고를 사용하는 경우 질문은 어떻게 표현할 것입니까?\n측정값이 취할 수 있는 허용 가능한 값의 집합 정의하기. 이 값은 항상 숫자일 필요는 없지만, 숫자일 경우가 많습니다. 나이를 측정할 때는 값이 숫자이지만, 어떤 숫자가 허용되는지 신중히 생각해야 합니다. 나이를 연 단위로 측정할 것입니까, 연도와 월 단위로 측정할 것입니까, 아니면 일 단위 또는 시간 단위로 측정할 것입니까? 다른 유형의 측정(예: 성별)의 경우 값이 숫자가 아닙니다. 하지만 이 경우에도 허용되는 값을 신중히 고려해야 합니다. 사람들이 자신의 성별을 자기 보고하도록 요청할 때, 선택 가능한 옵션으로 “남성”과 “여성”만 제공하는 것이 충분합니까? “기타” 옵션이 필요합니까? 아니면 특정 옵션을 제공하지 않고 사람들이 자신의 말로 자유롭게 답하도록 해야 합니까? 그리고 가능한 답변 범위를 모든 언어적 응답으로 확장하였다면, 답변을 어떤 방식으로 해석할 것입니까?\n\n조작화는 까다로운 작업이며, “유일하고 참된 방법”이 있는 것은 아닙니다. “나이”나 “성별”이라는 비공식적인 개념을 공식적인 측정값으로 조작화하는 방식은 측정이 사용되는 목적에 따라 달라집니다. 당신의 관심 분야의 과학자 커뮤니티에는 조작화를 하는 방법에 대해 꽤 확립된 아이디어가 있는 경우가 많습니다. 즉, 조작화는 사례별로 신중히 고려해야 하고 개별 연구 프로젝트에 특정된 많은 문제들이 있지만, 그럼에도 불구하고, 조직화 과정에는 꽤 일반적인 측면이 있습니다.\n앞으로 나아가기 전에 용어를 명확히 하고, 하나의 새로운 용어를 소개하려 합니다. 다음은 서로 밀접하게 연관된 네 가지 개념입니다:\n\n이론적 구성개념(theoretical construct): 측정하려고 하는 대상입니다. 예를 들어 “나이”, “성별”, “의견”과 같은 것입니다. 이론적 구성개념은 직접적으로 관찰할 수 없으며, 종종 약간 모호합니다.\n\n측정(measure): 측정은 관측을 수행하기 위해 사용하는 방법이나 도구를 의미합니다. 설문 조사에서의 질문, 행동 관찰, 또는 뇌 스캔 등이 이에 해당할 수 있습니다.\n\n조작화(operationalisation): 조작화란 측정과 이론적 구성개념 간의 논리적 연결을 의미하거나, 이론적 구성개념으로부터 측정을 도출하는 과정을 의미합니다.\n\n변수(Variable): 마지막으로 새로운 용어입니다. 변수란, 실제 세계의 어떤 것을 측정했을 때 얻게 되는 결과물입니다. 즉, 변수는 데이터셋에서 우리가 얻게 되는 실제 “데이터”입니다.\n\n실제로 과학자들조차도 이러한 개념들 사이의 차이를 흐리게 사용하는 경우가 많지만, 차이를 이해하는 것이 매우 유용합니다.\n\n\n\n\n\n\n이론적 구성개념이란?\n\n\n\n이론적 구성개념(theoretical construct)이란 학문이나 이론적 틀 안에서 정의된 개념으로, 관찰이나 측정이 직접적으로 가능하지 않은 추상적인 아이디어를 말합니다. 이러한 개념은 특정 현상이나 과정을 설명하거나 이해하기 위해 사용되며, 주로 심리학, 사회학, 경제학, 교육학 등 다양한 학문 분야에서 활용됩니다.\n이론적 구성개념에는 다음과 같은 특징이 있습니다.\n\n추상성: 이론적 구성개념은 구체적인 물리적 실체가 아니라, 관찰 가능한 현상을 설명하기 위해 만들어진 이론적 개념입니다.\n\n예: “지능(intelligence)”, “스트레스(stress)”, “사회적 자본(social capital)”.\n\n간접 측정: 이러한 개념은 직접적으로 측정할 수 없기 때문에, 측정 도구(예: 설문지, 테스트)나 지표(예: 행동, 반응)를 통해 간접적으로 평가됩니다.\n\n예: “스트레스”는 호르몬 수준, 심박수, 자기보고 설문 등을 통해 간접적으로 측정될 수 있습니다.\n\n이론적 맥락에서 중요: 이론적 구성개념은 특정 이론 내에서 그 의미와 역할이 정의됩니다. 이는 연구자가 현상을 설명하거나 예측하는 데 있어 필수적인 도구입니다.\n\n이론적 구성개념은 다양한 분야에서 사용됩니다.\n\n심리학:\n\n“자아존중감(self-esteem)”은 개인이 자기 자신을 어떻게 평가하는지를 나타내는 이론적 구성개념입니다.\n이를 직접 측정할 수 없기 때문에 설문지나 행동 관찰을 통해 평가합니다.\n\n사회학:\n\n“사회적 계층(social class)”은 개인이나 집단이 사회적, 경제적, 문화적 지위와 관련된 위치를 설명하기 위한 구성개념입니다.\n\n경제학:\n\n“효용(utility)”은 소비자가 특정 상품이나 서비스를 통해 얻는 만족감을 설명하는 개념으로, 직접 관찰할 수 없으나 소비자의 선택 행동을 통해 추론합니다.\n\n\n이론적 구성개념은 복잡한 현상을 이해하고 설명하는 데 필수적인 개념적 틀을 제공합니다. 그러나 동일한 문제에 대한 이론적 구성개념을 정의하고 측정하는 방식은 연구자의 접근법이나 이론적 배경에 따라 달라질 수 있습니다. 따라서 연구에서 이론적 구성개념을 명확히 정의하고, 이를 측정하기 위한 방법론을 신중히 설계하는 것이 중요합니다.\n\n\n\n\n\n\n\n\n조작화란?\n\n\n\n조작화(operationalization)란 연구에서 이론적 구성개념을 관찰 가능하고 측정 가능한 변수로 변환하는 과정을 말합니다. 이 과정을 통해 추상적인 개념을 구체화하여 데이터 수집과 분석이 가능해집니다.\n조작화가 필요한 이유는 다음과 같습니다.\n\n추상적 개념을 측정 가능하게: 이론적 개념(예: 스트레스, 지능, 행복)은 직접적으로 관찰할 수 없기 때문에, 이를 측정 가능한 형태로 정의해야 합니다.\n연구의 타당성과 신뢰성: 조작화를 통해 연구자가 동일한 개념을 일관성 있게 측정할 수 있도록 보장합니다.\n명확한 정의 제공: 연구의 재현 가능성을 높이고, 개념에 대한 모호성을 줄이는 데 기여합니다.\n\n조작화는 다음과 같은 과정을 거쳐 수행됩니다.\n\n이론적 개념 정의\n\n연구의 주요 개념을 명확히 정의합니다.\n\n예: “스트레스”를 “개인이 일상적인 요구에 대처하는 데 어려움을 느끼는 심리적 상태”로 정의.\n\n개념의 구성 요소 식별\n\n개념을 구성하는 주요 요소를 파악합니다.\n\n예: 스트레스 → “심리적 상태”, “생리적 반응”, “행동적 변화”.\n\n측정 가능한 변수로 전환\n\n각 구성 요소를 관찰하거나 측정할 수 있는 구체적인 방식으로 정의합니다.\n\n예:\n\n심리적 상태 → 설문지(자기보고식 스트레스 척도).\n생리적 반응 → 심박수, 혈압.\n행동적 변화 → 업무 결근 횟수, 사회적 상호작용 감소.\n\n\n측정 도구 개발\n\n설문지, 테스트, 행동 관찰, 실험 장비 등을 활용하여 데이터를 수집할 수 있도록 도구를 만듭니다.\n\n예: 스트레스 측정을 위해 코헨(Cohen)의 스트레스 척도를 사용.\n\n파일럿 테스트 및 수정\n\n개발된 측정 방법이 적절한지 소규모 파일럿 테스트를 통해 확인하고, 필요한 경우 조정합니다.\n\n\n이론적 구성개념을 측정할 수 있는 변수로 조작화할 때 다음 사항에 유의하여야 합니다.\n\n타당성: 조작화된 변수가 실제로 이론적 개념을 제대로 반영하고 있는가?\n신뢰성: 동일한 방법으로 반복 측정했을 때 일관된 결과가 나오는가?\n\n명확성: 다른 연구자들도 동일한 조작화 방식을 이해하고 재현할 수 있는가?\n\n조작화는 연구의 품질과 결과 해석에 중대한 영향을 미치므로 신중하게 설계되고 검증되어야 합니다.",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연구 설계에 대한 간략한 소개</span>"
    ]
  },
  {
    "objectID": "02-A-brief-introduction-to-research-design.html#sec-Scales-of-measurement",
    "href": "02-A-brief-introduction-to-research-design.html#sec-Scales-of-measurement",
    "title": "2  연구 설계에 대한 간략한 소개",
    "section": "2.2 측정 척도",
    "text": "2.2 측정 척도\n앞서 언급한 것처럼, 심리학적 측정의 결과는 변수라고 합니다. 그러나 모든 변수가 질적으로 동일한 유형을 가지는 것은 아니며, 따라서 변수의 유형을 이해하는 것이 유용합니다. 이를 구분하는 데 매우 유용한 개념이 측정 척도(Scales of measurement)입니다.\n\n2.2.1 명목 척도 (Nominal scale)\n명목 척도 변수(때로는 범주형(Categorical) 변수라고도 함)는 서로 다른 가능한 값들 간에 특정한 관계가 없는 변수를 말합니다. 이러한 변수에서는 어떤 것이 다른 것보다 “더 크다”거나 “더 낫다”고 말할 수 없으며, 평균을 내는 것도 전혀 의미가 없습니다. 이에 대한 고전적인 예로는 “눈동자 색”이 있습니다. 눈동자 색은 파란색, 녹색, 갈색 등 여러 가능성이 있지만, 그중 어느 것도 다른 것보다 “더 크다”거나 “더 낫다”고 말할 수 없습니다. 따라서 “평균 눈동자 색”에 대해 이야기하는 것은 매우 이상하게 느껴질 것입니다. 마찬가지로, 성별도 명목 척도에 속합니다. 남성이 여성보다 더 낫거나 나쁘다고 할 수 없습니다. 또한 “평균 성별”에 대해 이야기하는 것도 말이 되지 않습니다. 요컨대, 명목 척도 변수는 서로 다른 가능한 값들이 다르다는 점 외에는 말할 수 있는 것이 없는 변수입니다. 그것이 전부입니다.\n이를 조금 더 자세히 살펴봅시다. 내가 사람들의 출퇴근 방법에 대해 연구를 한다고 가정해 보겠습니다. 내가 측정해야 할 변수 중 하나는 사람들이 출근할 때 사용하는 교통수단일 것입니다. 이 “통근 유형” 변수는 다음과 같은 여러 가능성을 가질 수 있습니다: “기차”, “버스”, “자동차”, “자전거”. 여기서는 이 네 가지가 유일한 가능성이라고 가정합시다. 그런 다음, 내가 100명에게 오늘 출근할 때 어떤 방법을 사용했는지 물어보았다고 상상해 봅시다. 결과는 다음과 같을 수 있습니다(Table 2.1).\n\n\n\n\nTable 2.1. 오늘 100명은 어떻게 출근했나요?\n\n\n\n\n\n교통수단사람 수\n\n(1) 기차12\n\n(2) 버스30\n\n(3) 자동차48\n\n(4) 자전거10\n\n\n\n\n\n\n\n그래서, 평균 통근 유형은 무엇일까요? 당연히 여기서 답은 없습니다. 이것은 어리석은 질문입니다. 당신은 자동차로 이동한 것이 가장 인기 있는 방법이며, 기차로 이동한 것이 가장 빈도가 낮은 방법이라고 말할 수 있을 것입니다. 하지만 그게 전부입니다. 마찬가지로, 내가 옵션들을 나열한 순서는 별로 흥미롭지 않다는 점에 주목하십시오. 나는 데이터를 Table 2.2 같이 표시하도록 선택할 수도 있었습니다. 그리고 이는 아무것도 실제로 바꾸지 않습니다.\n\n\n\n\nTable 2.2. 오늘 100명은 어떻게 출근했나요? - 다른 표현\n\n\n\n\n\n교통수단사람 수\n\n(3) 자동차48\n\n(1) 기차12\n\n(4) 자전거10\n\n(2) 버스30\n\n\n\n\n\n\n\n\n\n2.2.2 서열 척도 (Ordinal scale)\n서열 척도 변수는 명목 척도 변수보다는 조금 더 구조화되어 있지만, 그 차이는 크지 않습니다. 서열 척도 변수는 다양한 가능한 값들 간에 자연스럽고 의미 있는 순서를 부여할 수 있는 변수이지만, 그 외에는 할 수 있는 것이 없습니다. 서열 척도의 일반적인 예는 “경주에서의 순위”입니다. 1등으로 결승점을 통과한 사람이 2등보다 더 빨랐다는 것은 알 수 있지만, 얼마나 더 빨랐는지는 알 수 없습니다. 따라서 우리는 1등 &gt; 2등이고, 2등 &gt; 3등이라는 것은 알지만, 1등과 2등 간의 차이가 2등과 3등 간의 차이보다 훨씬 더 클 수도 있습니다.\n심리학적으로 다 흥미로운 예를 들어봅시다. 기후 변화에 대한 사람들의 태도에 관심이 있다고 가정해 보겠습니다. 사람들이 자신의 신념에 가장 근접한 다음 네 가지 진술 중 하나를 선택하도록 요청했다고 합시다:\n\n온도 상승은 인간 활동 때문에 일어난다.\n\n온도 상승은 있지만, 이유는 알 수 없다.\n\n온도 상승은 있지만, 인간 때문은 아니다.\n\n온도는 상승하지 않고 있다.\n\n이 네 가지 진술은 “현재 과학과의 일치 정도”라는 관점에서 자연스러운 순서를 가지고 있다는 점을 알 수 있습니다. 진술 1은 과학과 매우 잘 일치하며, 진술 2는 적당히 일치하고, 진술 3은 그다지 일치하지 않으며, 진술 4는 현재 과학과 강하게 대치됩니다. 따라서, 내가 관심 있는 내용(사람들이 과학을 어느 정도 지지하는지)에 따라, 항목들을 1 &gt; 2 &gt; 3 &gt; 4로 순서화할 수 있습니다. 이 순서가 존재하기 때문에, 다음과 같이 옵션을 나열하는 것은 매우 이상할 것입니다.\n\n온도 상승은 있지만, 인간 때문은 아니다.\n\n온도 상승은 인간 활동 때문에 일어난다.\n\n온도는 상승하지 않고 있다.\n\n온도 상승은 있지만, 이유는 알 수 없다.\n\n왜냐하면 이 질문의 자연스러운 “구조”를 위반하는 것처럼 보이기 때문입니다.\n100명에게 이 질문을 하고, Table 2.3 같은 결과를 얻었다고 가정해 봅시다.\n\n\n\n\nTable 2.3. 기후 변화에 대한 태도\n\n\n\n\n\n응답수\n\n(1) 기온 상승은 인간 활동 때문51\n\n(2) 기온 상승 원인을 알 수 없음20\n\n(3) 기온 상승은 인간 때문이 아님10\n\n(4) 기온이 상승하지 않음19\n\n\n\n\n\n\n\n이 데이터를 분석할 때, (1), (2), (3)을 함께 묶어서 100명 중 81명이 적어도 부분적으로 과학을 지지했다고 말하는 것이 합리적일 것입니다. 또한, (2), (3), (4)를 묶어서 100명 중 49명이 적어도 일부는 과학적 관점과 불일치를 나타냈다고 말하는 것도 합리적입니다. 하지만 (1), (2), (4)를 묶어서 100명 중 90명이 무엇을 말했다고 하는 것은 완전히 이상합니다. 이 응답들을 함께 묶을 수 있는 합리적인 근거가 전혀 없기 때문입니다.\n이와 같이, 이 항목들의 자연스러운 순서를 이용해 의미 있는 그룹화를 구성할 수는 있지만, 평균을 낼 수는 없습니다. 예를 들어, 여기서 질문에 대한 “평균” 응답은 1.97입니다. 이것이 무슨 의미인지 설명해 줄 수 있다면 좋겠지만, 제게는 전혀 말이 안 되는 것처럼 보입니다!\n\n\n2.2.3 구간 척도 (Interval scale)\n명목 척도와 서열 척도 변수와 달리, 구간 척도2와 비율 척도 변수는 수치 값이 진정으로 의미를 가집니다. 구간 척도 변수의 경우, 숫자 사이의 차이는 해석 가능하지만, 변수에 “자연스러운” 0 값은 없습니다. 구간 척도 변수의 좋은 예는 섭씨 온도입니다. 예를 들어, 어제 온도가 15°C였고 오늘 온도가 18°C라면, 이 두 온도 간의 3°C 차이는 진정한 의미를 가집니다. 또한, 7°C와 10°C 간의 3°C 차이와 정확히 동일합니다. 요컨대, 구간 척도 변수에서는 덧셈과 뺄셈이 의미가 있습니다.3\n그러나 0°C는 “온도가 전혀 없다”는 의미가 아닙니다. 실제로는 “물이 얼기 시작하는 온도”를 의미하며, 이는 다소 임의적입니다. 결과적으로 온도를 곱하거나 나누는 것은 무의미합니다. 20°C가 10°C의 두 배라고 말하는 것은 잘못된 것이며, 20°C가 -10°C의 음의 두 배라고 주장하는 것도 이상하고 무의미합니다.\n좀 더 심리학적인 예를 보겠습니다. 예를 들어, 신입 대학생들의 태도가 시간에 따라 어떻게 변했는지 살펴보고 싶다고 가정해 봅시다. 당연히, 각 학생이 입학한 연도를 기록하고 싶을 것입니다. 이 변수는 구간 척도입니다. 2003년에 입학한 학생은 2008년에 입학한 학생보다 5년 먼저 입학했습니다. 그러나 2008을 2003으로 나누고 “두 번째 학생이 첫 번째 학생보다 1.0024배 늦게 입학했다”고 말하는 것은 완전히 어리석은 일입니다. 전혀 말이 되지 않습니다.\n\n\n2.2.4 비율 척도 (Ratio scale)\n마지막으로 고려할 변수 유형은 비율 척도 변수로, 여기서 0은 실제로 “없음”을 의미하며 곱셈과 나눗셈도 가능합니다. 심리학에서 비율 척도의 좋은 예는 반응 시간(RT)입니다. 많은 과제에서, 사람이 문제를 해결하거나 질문에 답하는 데 걸리는 시간을 기록하는 것이 일반적이며, 이는 과제가 얼마나 어려운지를 나타내는 지표입니다. 예를 들어, Alan이 질문에 2.3초가 걸렸고 Ben이 3.1초가 걸렸다고 가정해 봅시다. 구간 척도 변수와 마찬가지로, 여기서 덧셈과 뺄셈은 의미가 있습니다. Ben은 실제로 Alan보다 3.1 - 2.3 = 0.8초 더 걸렸습니다. 그러나 곱셈과 나눗셈도 의미가 있습니다. Ben은 Alan보다 3.1/2.3 = 1.35배 더 오래 걸렸습니다. 비율 척도 변수(RT)에서 “0초”는 실제로 “아무런 시간이 걸리지 않음”을 의미하기 때문입니다.\n\n\n2.2.5 연속형 변수와 이산형 변수\n변수의 종류와 관련하여 알아야 할 또 다른 구분은 연속형 변수와 이산형 변수의 차이입니다. 이는 다음과 같이 정의됩니다:\n\n연속형 변수는 어떠한 두 값 사이에도 항상 또 다른 값을 논리적으로 가질 수 있는 변수입니다.\n\n이산형 변수는 사실상 연속형 변수가 아닌 변수로, 두 값 사이에 중간값이 존재하지 않는 경우가 있습니다.\n\n이 정의는 다소 추상적으로 보일 수 있지만, 예시를 보면 매우 간단합니다. 예를 들어, 반응 시간(response time)은 연속형 변수입니다. Alan이 3.1초, Ben이 2.3초 걸렸다면, Cameron이 3.0초를 기록했다면 그의 반응 시간은 두 사람의 중간값에 해당합니다. 또한 David가 3.031초 걸렸다면 그의 반응 시간은 Cameron과 Alan 사이에 위치합니다. 실질적으로 이 정도로 정확히 측정할 수 없을지라도, 원칙적으로는 가능합니다. 따라서 반응 시간은 연속형 변수로 간주됩니다.\n\n\n\n\nTable 2.4. 측정 척도와 이산/연속 구분의 관계. 체크 표시가 있는 셀은 가능한 경우를 표현.\n\n\n\n\n\n연속형이산형\n\n명목\\( \\checkmark \\)\n\n서열\\( \\checkmark \\)\n\n구간\\( \\checkmark \\)\\( \\checkmark \\)\n\n비율\\( \\checkmark \\)\\( \\checkmark \\)\n\n\n\n\n\n\n\n이산형 변수는 이 규칙이 위배되는 경우입니다. 예를 들어, 명목 척도 변수는 항상 이산형입니다. 기차와 자전거 사이에 엄밀한 수학적 방식으로 “중간값”에 해당하는 이동 수단이 존재하지 않습니다. 따라서 이동 수단 유형은 이산형입니다. 마찬가지로 서열 척도 변수도 항상 이산형입니다. “2등”은 “1등”과 “3등” 사이에 위치하지만, 논리적으로 “1등”과 “2등” 사이에 어떤 것이 존재할 수는 없습니다. 한편, 구간 척도 및 비율 척도 변수는 연속형이거나 이산형일 수 있습니다. 위에서 본 것처럼, 반응 시간(비율 척도 변수)은 연속형입니다. 섭씨 온도(구간 척도 변수)도 연속형입니다. 그러나 학교에 입학한 연도(구간 척도 변수)는 이산형입니다. 2002년과 2003년 사이의 연도는 존재하지 않습니다. 또 다른 예로, 진위형(true-or-false) 테스트에서 맞힌 질문 수(비율 척도 변수)는 이산형입니다. 진위형 질문에서 “부분적으로 정답”이라는 것은 없으므로 5/10과 6/10 사이에 값이 없습니다. Table 2.4 는 측정 척도와 이산/연속 구분의 관계를 요약한 것입니다. 체크 표시가 있는 셀은 가능한 경우를 나타냅니다. 이 점을 강조하는 이유는 (a) 일부 교과서가 이 부분에서 잘못된 정보를 제공하며, (b) 사람들이 “이산형 변수”라는 말을 “명목 척도 변수”라는 의미로 종종 잘못 사용하기 때문입니다. 이는 매우 유감스러운 일입니다.\n\n\n2.2.6 복잡성에 대한 고려\n이러한 말을 들으면 충격을 받으리라는 것을 알고있지만, 실제로 현실은 이와 같은 단순한 분류 방식보다 훨씬 더 복잡합니다. 현실에서 대부분의 변수는 이러한 깔끔한 범주에 잘 맞지 않으며, 측정 척도를 엄격한 규칙처럼 취급하지 않도록 주의해야 합니다. 이들은 단지 가이드라인일 뿐으로, 상황에 따라 변수를 다르게 취급해야 하는 경우를 고려하도록 돕기 위한 것입니다.\n대표적인 심리학적 측정 도구의 한 가지 예를 들어보겠습니다. 바로 리커트 척도(Likert scale)입니다. 리커트 척도는 모든 설문 조사 설계에서 기본적으로 사용하는 도구입니다. 여러분은 이미 수백 번, 아니 수천 번 이러한 척도를 경험했을 것이며, 아마도 직접 사용해본 적도 있을 것입니다. 다음과 같은 설문 질문이 있다고 가정해 봅시다:\n\n“모든 해적은 정말 멋지다”라는 진술에 대한 귀하의 의견을 가장 잘 나타내는 항목을 선택하세요.\n\n참가자에게 제공되는 옵션은 다음과 같습니다:\n\n강력히 동의하지 않는다\n\n동의하지 않는다\n\n동의도 반대도 하지 않는다\n\n동의한다\n\n강력히 동의한다\n\n이 항목들은 5점 리커트 척도의 예로, 사람들에게 몇 가지(이 경우 5가지)의 명확하게 순서화된 선택지 중 하나를 선택하도록 요청합니다. 각 선택지에는 일반적으로 텍스트로 된 설명이 주어집니다. 그러나 모든 항목이 명시적으로 설명될 필요는 없습니다. 예를 들어, 다음은 5점 리커트 척도의 또 다른 예입니다:\n\n강력히 동의하지 않는다\n\n\n\n\n강력히 동의한다\n\n리커트 척도는 매우 유용하지만 제한적인 도구입니다. 이러한 리커트 척도는 어떤 유형의 변수일까요? 명백히 이산형 변수입니다. 2.5라는 응답을 줄 수는 없기 때문입니다. 또한 명목 척도도 아닙니다. 항목들이 순서화되어 있기 때문입니다. 그리고 비율 척도도 아닙니다. 자연적인 영점(zero point)이 존재하지 않기 때문입니다.\n그렇다면 서열 척도일까요, 아니면 구간 척도일까요? 한 가지 주장은 “강력히 동의”와 “동의” 사이의 차이가 “동의”와 “동의도 반대도 하지 않음” 사이의 차이와 동일하다고 증명할 수 없다는 점입니다. 실제로 일상생활에서는 이 차이가 전혀 같지 않다는 것이 명확합니다. 따라서 리커트 척도를 서열 변수로 취급해야 한다고 주장할 수 있습니다. 그러나 실질적으로 대부분의 참가자는 “1에서 5까지의 척도”를 상당히 진지하게 받아들이는 경향이 있으며, 다섯 가지 응답 옵션 간의 차이가 서로 비슷하다고 생각하는 경우가 많습니다. 따라서 많은 연구자는 리커트 척도 데이터를 구간 척도로 취급합니다.4 엄밀히 말하면 구간 척도가 아니지만, 실제로는 구간 척도에 가깝기 때문에 준-구간 척도(quasi-interval scale)로 간주됩니다.\n\n\n\n\n\n\n리커트 척도란\n\n\n\n리커트 척도(Likert Scale)는 1932년에 미국의 사회학자 Rensis Likert가 개발한 심리학적 측정 도구입니다. 주로 설문조사나 연구에서 사람들의 태도, 의견, 신념 등을 측정하기 위해 사용됩니다. 이 척도는 응답자가 특정 진술에 대해 얼마나 동의하거나 반대하는지에 대한 정도를 평가하는 방법입니다.\n리커트 척도의 특징은 다음과 같습니다:\n\n응답자의 태도 측정: 이 척도는 사람들의 태도나 의견을 정량적으로 파악할 수 있게 도와줍니다. 예를 들어, “이 제품은 매우 좋다”는 진술에 대해 응답자가 어느 정도 동의하는지를 평가할 수 있습니다.\n단계적 반응: 리커트 척도는 보통 5점이나 7점의 응답 범위로 구성됩니다. 예를 들어, 5점 척도는 “전혀 동의하지 않는다”, “동의하지 않는다”, “중립적이다”, “동의한다”, “매우 동의한다”와 같은 선택지를 제공합니다.\n데이터 분석 용이: 리커트 척도는 객관적인 데이터를 수집할 수 있어 통계적 분석에 적합하며, 응답자의 태도나 선호도를 이해하는 데 유용합니다.\n\n리커트 척도는 심리학, 사회학, 마케팅 연구 등 다양한 분야에서 광범위하게 사용되고 있습니다.",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연구 설계에 대한 간략한 소개</span>"
    ]
  },
  {
    "objectID": "02-A-brief-introduction-to-research-design.html#sec-Assessing-the-reliability-of-a-measurement",
    "href": "02-A-brief-introduction-to-research-design.html#sec-Assessing-the-reliability-of-a-measurement",
    "title": "2  연구 설계에 대한 간략한 소개",
    "section": "2.3 측정의 신뢰도를 평가하기",
    "text": "2.3 측정의 신뢰도를 평가하기\n지금까지 이론적 구성개념을 조작화하여 심리학적 측정을 생성하는 방법에 대해 간략히 살펴보았습니다. 또한 심리학적 측정을 적용하여 다양한 유형의 변수를 얻을 수 있다는 점을 보았습니다. 이제는 다음과 같은 명백한 질문을 다뤄야 할 시점입니다: 측정이 과연 유효한가? 이 질문은 두 가지 관련 개념인 신뢰도(reliability)와 타당도(validity) 측면에서 논의할 수 있습니다. 간단히 말해, 신뢰도는 얼마나 정밀하게(precisely) 측정하고 있는지를 나타내며, 타당도는 측정이 얼마나 정확한지(accurate)를 말합니다. 이 섹션에서는 신뢰도에 대해 논의하고, 타당도에 대해서는 Section 2.6 절에서 다루겠습니다.\n신뢰도는 사실 매우 간단한 개념입니다. 이는 측정의 반복 가능성 또는 일관성을 나타냅니다. 예를 들어, “체중계”를 사용하여 내 체중을 측정하는 것은 매우 신뢰도가 높습니다. 체중계에 여러 번 올라갔다 내려와도 항상 동일한 값을 제공합니다. 반면, “어머니께 내 지능을 물어보는” 것은 신뢰도가 매우 낮습니다. 어떤 날에는 내가 “좀 멍청하다”고 하고, 다른 날에는 내가 “완전히 바보 같다”고 합니다. 이러한 신뢰도 개념은 측정이 정확한지 여부(즉, 타당도)와는 다릅니다. 예를 들어, 감자 자루를 들고 체중계에 올라갔다 내려갔다 해도 여전히 동일한 값을 제공합니다. 그러나 이 매우 신뢰성 높은 값은 내 실제 체중과 일치하지 않기 때문에 정확하지 않습니다. 기술적으로 이는 신뢰성이 높지만 타당하지 않은 측정입니다. 반대로, 어머니의 지능 추정치는 다소 신뢰도가 낮더라도 사실일 수 있습니다. 어쩌면 내가 정말로 똑똑하지 않을 수도 있습니다. 따라서 어머니의 지능 추정치가 날마다 크게 변동하더라도 본질적으로 정확할 수 있습니다. 그러나 어머니의 추정치가 지나치게 신뢰도가 낮으면 그녀의 여러 주장 중 어떤 것이 실제로 맞는지를 알아내기가 매우 어려워집니다. 어느 정도까지는, 신뢰도가 매우 낮은 측정치는 실제로는 타당하지 않게 되는 경향이 있습니다. 그래서 많은 사람들은 신뢰도가 타당성을 보장하기 위한 필요 조건-충분 조건은 아니지만-이라 말합니다.\n신뢰도와 타당도의 구분을 명확히 이해했다면, 이제 신뢰도를 측정할 수 있는 다양한 방법에 대해 생각해 봅시다:\n\n검사-재검사 신뢰도(Test-retest reliability): 이는 시간에 따른 일관성과 관련이 있습니다. 측정을 나중에 반복했을 때 동일한 결과가 나오는가?\n\n평가자 간 신뢰도(Inter-rater reliability): 이는 사람 사이의 일관성과 관련이 있습니다. 다른 사람이 동일한 측정을 반복했을 때도(예: 어머니가 아니라 다른 사람이 나의 지능을 평가) 동일한 결과를 산출하는가?\n\n평행 형식 신뢰도(Parallel forms reliability): 이론적으로 동등한 측정을 사용했을 때 동일한 결과를 제공하는가? 예를 들어, 다른 체중계를 사용했을 때 동일한 체중이 나오는가?\n\n내적 일관성 신뢰도(Internal consistency reliability): 측정이 여러 가지 부분으로 구성되어 있고(예: 성격 설문조사 결과는 여러 질문에 걸쳐 합산됨), 이러한 개별 부분이 유사한 결과를 제공하는 경향이 있는가? 이 특정 신뢰도의 형태는 Section 15.5 에서 더 자세히 살펴보겠습니다.\n\n모든 측정이 모든 형태의 신뢰도를 가져야 하는 것은 아닙니다. 예를 들어, 교육 평가를 하나의 측정 방식으로 생각할 수 있습니다. 제가 가르치는 과목인 Computational Cognitive Science의 평가는 연구, 시험 그리고 기타 요소로 구성되어 있습니다. 이 평가 전체는 의도적으로 서로 다른 측면을 측정하도록 설계되었기 때문에 내적 일관성이 낮습니다. 하지만 시험 자체는 동일한 것을 측정하도록 설계된 몇 가지 질문을 포함하고 있으며, 이러한 질문들은 대체로 비슷한 결과를 제공합니다. 따라서 시험 자체는 내적 일관성이 비교적 높습니다. 이것이 바로 바람직한 형태입니다. 동일한 것을 측정하고자 할 때에만 측정의 신뢰도를 요구해야 합니다!",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연구 설계에 대한 간략한 소개</span>"
    ]
  },
  {
    "objectID": "02-A-brief-introduction-to-research-design.html#변수의-역할-예측-변수와-결과-변수",
    "href": "02-A-brief-introduction-to-research-design.html#변수의-역할-예측-변수와-결과-변수",
    "title": "2  연구 설계에 대한 간략한 소개",
    "section": "2.4 변수의 “역할”: 예측 변수와 결과 변수",
    "text": "2.4 변수의 “역할”: 예측 변수와 결과 변수\n변수에 대해 이야기를 마치기 전에 마지막으로 설명해야 할 용어가 있습니다. 일반적으로 연구를 수행할 때 여러 가지 변수를 다루게 됩니다. 데이터를 분석할 때는 보통 몇몇 변수를 사용해 다른 변수를 설명하려고 합니다. 여기서 “설명하는 역할”과 “설명받는 역할”을 명확히 구분하는 것이 중요합니다. 이 개념을 지금부터 명확히 해둡시다. 우선, 변수를 설명하기 위해 수학 기호를 사용하는 데 익숙해져야 합니다. 이는 앞으로 여러 번 사용될 것이기 때문입니다. “설명받는” 변수를 \\(Y\\)로 나타내고, “설명하는” 변수는 \\(X_1, X_2\\) 등으로 나타냅시다.\n분석을 수행할 때, \\(X\\)와 \\(Y\\)는 서로 다른 역할을 하기 때문에 다른 이름으로 불립니다. 전통적으로 사용되는 이름은 독립 변수(independent variable; IV)와 종속 변수(dependent variable; DV)입니다. 독립 변수(IV)는 설명에 사용되는 변수(\\(X\\))이고, 종속 변수(DV)는 설명받는 변수(\\(Y\\))입니다. 이러한 이름은 다음과 같은 논리에 기반합니다: 만약 \\(X\\)와 \\(Y\\) 사이에 실제로 관계가 있다면, \\(Y\\)는 \\(X\\)에 “의존”한다고 말할 수 있습니다. 또한, 연구가 “적절히” 설계되었다면 \\(X\\)는 다른 어떤 것에도 의존하지 않습니다. 하지만 개인적으로는 이러한 이름이 별로라고 생각합니다. 기억하기 어렵고 다음과 같은 이유로 오해의 소지가 있습니다: (a) 독립 변수는 실제로 “모든 것에서 독립적”이지 않고, (b) 관계가 없다면 종속 변수는 독립 변수에 의존하지 않습니다. 사실, IV와 DV라는 이름이 별로라는 데 동의하는 사람이 많기 때문에, 더 매력적인 대체 용어가 많이 존재합니다. 이 책에서는 예측 변수(predictors)와 결과 변수(outcomes)라는 용어를 사용하겠습니다. 여기서의 아이디어는 \\(X\\) (예측 변수)를 사용해 \\(Y\\) (결과 변수)에 대한 추측을 하려는 것입니다.5 이 내용은 Table 2.5 에 요약되어 있습니다.\n\n\n\n\nTable 2.5. 변수 구분\n\n\n\n\n\n변수의 역할전통적인 이름현대적 이름\n\n\"설명되어야 하는 것\"종속변수 (DV)결과변수\n\n\"설명하는 것\"독립변수 (IV)예측변수",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연구 설계에 대한 간략한 소개</span>"
    ]
  },
  {
    "objectID": "02-A-brief-introduction-to-research-design.html#실험-연구와-비실험-연구",
    "href": "02-A-brief-introduction-to-research-design.html#실험-연구와-비실험-연구",
    "title": "2  연구 설계에 대한 간략한 소개",
    "section": "2.5 실험 연구와 비실험 연구",
    "text": "2.5 실험 연구와 비실험 연구\n연구를 수행할 때 알아두어야 할 중요한 구분 중 하나는 “실험 연구”와 “비실험 연구”의 구분입니다. 이 구분은 연구자가 연구 참여자와 연구에서 발생하는 사건에 대해 어느 정도로 통제권을 가지는지에 따라 나뉩니다.\n\n2.5.1 실험 연구\n실험 연구의 핵심 특징은 연구자가 연구의 모든 측면, 특히, 참여자가 실험 동안 무엇을 경험할지 등을 통제한다는 점입니다. 연구자는 예측 변수(IV)를 조작하거나 변화시키며 결과 변수(DV)는 자연스럽게 변화하도록 둡니다. 여기서의 목적은 예측 변수(IV)를 의도적으로 변화시켜 결과 변수에 어떤 인과적 영향을 미치는지 확인하는 것입니다. 또한, 예측 변수가 아닌 다른 요소들이 결과에 영향을 미치지 않도록 모든 것을 일정하게 유지하거나 균형을 맞추는 방식으로 설정합니다. 실제로는 결과에 영향을 미칠 수 있는 모든 요소를 생각해내고 이를 일정하게 유지하는 것은 거의 불가능합니다. 이를 해결하기 위한 표준적인 방법은 랜덤화(randomization)입니다. 즉, 사람들을 무작위로 다른 그룹에 배정하고 각 그룹에 다른 처치를 제공하는 것입니다(즉, 예측 변수에 다른 값을 할당). 랜덤화는 그룹 간의 체계적인 차이를 최소화(완전히 제거하지는 않음)하는 역할을 합니다. 이에 대해서는 나중에 더 자세히 다루겠습니다.\n간단하고 완전히 비현실적이며 극도로 비윤리적인 예를 들어봅시다. 흡연이 폐암을 유발하는지 알아보고 싶다고 가정해봅시다. 이를 알아보는 한 가지 방법은 흡연자와 비흡연자를 찾아 흡연자가 더 높은 폐암 발병률을 보이는지 확인하는 것입니다. 하지만 이는 적절한 실험이 아닙니다. 왜냐하면 연구자가 흡연자가 누구인지, 비흡연자가 누구인지에 대해 크게 통제할 수 없기 때문입니다. 이는 매우 중요한 문제입니다. 예를 들어, 담배를 선택하는 사람들이 대체로 나쁜 식단을 가지고 있거나 석면 광산에서 일할 가능성이 높을 수도 있습니다. 요점은 흡연자 그룹과 비흡연자 그룹이 흡연이라는 요소만이 아니라 여러 가지 면에서 차이가 있을 수 있다는 것입니다. 따라서 흡연자가 더 높은 폐암 발병률을 보인다고 해도, 그것이 흡연 자체가 아닌 다른 원인일 가능성이 있습니다. 기술적으로 이러한 다른 요인들(예: 식단)을 교란 요인(confounders; confounding factors)이라고 부릅니다. 이에 대해서는 잠시 후에 다룰 것입니다.\n반면, 적절한 실험은 어떻게 보일까요? 우리가 문제로 여기는 것은 흡연자와 비흡연자가 여러 면에서 다를 수 있다는 것이었습니다. 윤리적 고려를 하지 않는다면 이에 대한 해결책은 흡연 여부를 통제하는 것입니다. 구체적으로, 젊은 비흡연자를 두 그룹으로 무작위로 나누고, 절반에게 흡연을 강요하면 그룹 간의 차이가 흡연 여부 외에는 거의 없게 됩니다. 그렇게 하여 흡연 그룹이 비흡연 그룹보다 높은 폐암 발병률을 보인다면, (a) 흡연이 폐암을 유발한다는 것과 (b) 우리가 살인자라는 것을 확신할 수 있을 것입니다.\n\n\n2.5.2 비실험 연구\n비실험적 연구는 “연구자가 실험에서만큼 많은 통제를 할 수 없는 모든 연구”를 포괄하는 광범위한 용어입니다. 과학자들은 일반적으로 통제를 선호하지만, 앞의 예에서 설명했듯이 통제를 얻을 수 없거나 통제를 시도해서는 안 되는 상황도 많습니다. 예를 들어, 사람들이 암에 걸리는지 알아보기 위해 흡연을 강요하는 것은 명백히 비윤리적일 뿐만 아니라 거의 확실히 범죄에 해당합니다. 이는 실험적 통제를 시도해서는 안 되는 상황의 좋은 예입니다.\n하지만 이러한 문제 외에도 다른 이유들이 있습니다. 윤리적 문제를 떠나서도, 우리의 “흡연 실험”에는 몇 가지 다른 문제가 있습니다. 예를 들어, 제가 사람들에게 “흡연자가 되도록 강요”해야 한다고 제안했을 때, 이는 비흡연자 표본으로 시작한 후 그들에게 흡연자가 되도록 강제하는 것을 의미했습니다. 이것은 악당 과학자가 좋아할 만한 강력하고 사악한 실험 설계처럼 들릴 수 있지만, 실제 세계에서 효과를 조사하기 위한 적절한 방법은 아닐 수 있습니다. 예를 들어, 흡연이 사람들에게 폐암을 유발하는 것은 나쁜 식습관을 가진 경우에만 해당한다고 가정해 보겠습니다. 그렇다면 보통 흡연을 하는 사람들은 나쁜 식습관을 가지고 있을 가능성이 높을 것입니다. 하지만 우리의 실험에서 “흡연자”는 “자연적” 흡연자가 아닙니다(즉, 비흡연자를 흡연자로 강제했지만, 그들은 흡연자들이 일반적으로 가지는 다른 특성을 가지지 않았습니다). 따라서 그들은 더 나은 식습관을 가지고 있을 가능성이 높습니다. 이런 상황에서는 그들이 폐암에 걸리지 않을 것이며, 우리의 실험은 실패할 것입니다. 왜냐하면 이는 “자연적” 세계의 구조를 위반했기 때문입니다(이 기술적인 용어는 “인위적 결과(artefactual result)”라고 합니다).\n비실험적 연구의 두 가지 유형 간의 차이를 구분할 가치가 있습니다. 그것은 준실험적 연구와 사례 연구의 차이입니다. 앞에서 논의한 예, 즉 흡연 여부를 통제하지 않고 흡연자와 비흡연자 간의 폐암 발병률을 조사하려고 했던 예는 준실험적 설계에 해당합니다. 이는 실험과 동일하지만, 예측 변수(IV)를 통제하지 않는다는 점이 다릅니다. 우리는 여전히 통계를 사용하여 결과를 분석할 수 있지만, 훨씬 더 신중하고 조심스럽게 접근해야 합니다.\n대안적인 접근법인 사례 연구는 하나 또는 소수의 사례에 대한 매우 상세한 설명을 제공하는 것을 목표로 합니다. 일반적으로 사례 연구의 결과를 통계적으로 분석할 수 없으며, 몇 가지 고립된 예시를 바탕으로 “일반적인 사람들”에 대한 일반적인 결론을 도출하기는 어렵습니다. 그러나 사례 연구는 특정 상황에서 매우 유용합니다. 첫째, 다른 대안이 없는 상황이 있습니다. 신경심리학은 이러한 문제를 자주 겪습니다. 특정 뇌 영역에 손상을 입은 많은 사람들을 찾을 수 없을 때, 할 수 있는 유일한 일은 그 사례들을 가능한 한 자세하고 신중하게 묘사하는 것입니다. 하지만 사례 연구에는 실제로 몇 가지 이점도 있습니다. 연구할 사람이 적기 때문에 각 사례에서 작용하는 특정 요인을 이해하기 위해 많은 시간과 노력을 들일 수 있습니다. 이는 매우 가치 있는 일입니다. 따라서 사례 연구는 실험 및 준실험 설계에서 사용되는 통계적 접근 방식을 보완할 수 있습니다. 이 책에서는 사례 연구에 대해 많이 다루지는 않겠지만, 사례 연구는 여전히 매우 가치 있는 도구입니다!",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연구 설계에 대한 간략한 소개</span>"
    ]
  },
  {
    "objectID": "02-A-brief-introduction-to-research-design.html#sec-assessing-the-validity-of-a-study",
    "href": "02-A-brief-introduction-to-research-design.html#sec-assessing-the-validity-of-a-study",
    "title": "2  연구 설계에 대한 간략한 소개",
    "section": "2.6 연구의 타당성 평가하기",
    "text": "2.6 연구의 타당성 평가하기\n과학자가 무엇보다도 가장 바라는 것은 자신의 연구가 “타당하다(valid)”는 것입니다. 타당성(validity)이라는 개념은 매우 간단합니다. 연구 결과를 신뢰할 수 있는가? 신뢰할 수 없다면 그 연구는 타당하지 않습니다. 하지만 이렇게 간단히 말하는 것과는 달리, 실질적으로 타당성을 확인하는 것은 신뢰도를 확인하는 것보다 훨씬 어렵습니다. 그리고 솔직히 말해서, 타당성이 실제로 무엇인지를 명확히 합의한 정의는 존재하지 않습니다. 사실, 여러 가지 다른 종류의 타당성이 있으며, 각각 고유한 문제를 제기합니다. 그리고 모든 연구에 모든 형태의 타당성이 관련되는 것은 아닙니다. 여기서는 다섯 가지 다른 유형의 타당성에 대해 이야기할 것입니다:\n\n내적 타당성(Internal validity)\n\n외적 타당성(External validity)\n\n구성 타당성(Construct validity)\n\n표면 타당성(Face validity)\n\n생태학적 타당성(Ecological validity)\n\n우선, 중요한 것이 무엇인지에 대한 간단한 안내입니다.\n(1) 내적 타당성과 외적 타당성이 가장 중요합니다. 이는 연구가 실제로 작동하는지를 직접적으로 다루기 때문입니다.\n(2) 구성 타당성은 당신이 측정하려는 것을 제대로 측정하고 있는지를 묻습니다.\n(3) 표면 타당성은 “외관”에 대해 신경을 쓰는 경우에만 중요한데, 아주 중요한 요소는 아닙니다.\n(4) 생태학적 타당성은 표면 타당성의 특별한 사례로, 특정 유형의 외관에 대한 관심과 관련이 있습니다.\n\n2.6.1 내적 타당성(Internal validity)\n내적 타당성은 변수들 간의 인과 관계에 대한 올바른 결론을 도출할 수 있는 정도를 말합니다. “내적”이라는 말은 연구 “내부”의 것들 사이의 관계를 지칭하기 때문에 붙여졌습니다. 간단한 예를 들어 이 개념을 설명해 보겠습니다.\n대학 교육이 글쓰기 능력을 향상시키는지 알아보고 싶다고 가정해 봅시다. 이를 위해, 1학년 학생 그룹을 모집하여 1000단어의 에세이를 작성하게 하고, 맞춤법 및 문법 오류의 개수를 세어 봅니다. 그런 다음, 더 많은 대학 교육을 받은 3학년 학생들을 대상으로 동일한 실험을 반복합니다. 그리고 3학년 학생들이 더 적은 오류를 냈다고 가정합시다. 그래서 당신은 대학 교육이 글쓰기 능력을 향상시킨다고 결론을 내립니다. 맞나요?\n문제는 이 실험의 주요 결함이 3학년 학생들이 나이가 더 많고 글을 쓴 경험이 더 많다는 점입니다. 따라서 인과 관계를 확실히 아는 것이 어렵습니다. 나이가 많은 사람들이 글을 더 잘 쓰는 것일까요? 아니면 글쓰기 경험이 많은 사람들이 더 잘 쓰는 것일까요? 아니면 더 많은 교육을 받은 사람들이 더 잘 쓰는 것일까요? 위의 어느 요인이 3학년 학생들의 더 나은 성과의 진정한 원인일까요? 나이? 글쓰기 경험? 교육? 이를 정확히 알 수는 없습니다. 이는 내적 타당성이 실패한 사례입니다. 연구가 서로 다른 변수들 사이의 인과 관계를 제대로 구분하지 못했기 때문입니다.\n\n\n2.6.2 외적 타당성\n외적 타당성은 연구 결과의 일반화 가능성 또는 적용 가능성과 관련이 있습니다. 즉, 연구에서 관찰된 결과 패턴이 “현실 세계”에서도 동일하게 나타날 것으로 예상되는 정도를 의미합니다. 좀 더 구체적으로 말하자면, 심리학에서 수행하는 모든 연구는 비교적 특정한 질문이나 과제를 포함하며, 특정한 환경에서 이루어지고, 특정한 하위 그룹(아쉽게도 종종 대학생들!)에서 모집된 참여자를 포함합니다. 따라서, 연구의 결과가 연구에 참여한 사람들과 상황을 넘어서서 일반화되거나 적용되지 않는다면, 이는 외적 타당성이 부족하다는 것을 의미합니다.\n이 문제의 대표적인 예는 심리학 연구의 상당수가 학부 심리학 학생들을 참여자로 사용한다는 사실입니다. 하지만 연구자들이 관심을 두는 것은 심리학 학생들만이 아닙니다. 연구자들은 일반 대중에 대해 관심을 가집니다. 이러한 상황에서, 심리학 학생들만을 참여자로 사용하는 연구는 외적 타당성이 부족할 위험을 항상 안고 있습니다. 즉, 심리학 학생들에게 어떤 “특별한” 점이 있어서 이들이 일반 대중과 관련된 면에서 다르다면, 외적 타당성에 대한 우려가 생길 수 있습니다.\n그렇다고 해서 심리학 학생들만을 사용한 연구가 반드시 외적 타당성에 문제가 있다는 것을 의미하지 않습니다. 이는 나중에 다시 이야기하겠지만, 매우 흔한 오해이기 때문에 여기에서 언급하고자 합니다. 연구의 외적 타당성은 다음 두 가지 조건에서 위협받을 수 있습니다:\n(a) 참여자를 모집한 모집단이 매우 좁은 범위일 경우(예: 심리학 학생),\n(b) 샘플링된 좁은 모집단이 연구하려는 심리학적 현상과 관련된 면에서 일반 모집단과 체계적으로 다를 경우.\n여기서 강조된 부분은 많은 사람들이 종종 잊어버리는 핵심입니다. 심리학 학부생들이 일반 모집단과 여러 면에서 다르다는 것은 사실입니다. 따라서 심리학 학생들만을 대상으로 한 연구에 외적 타당성 문제가 있을 수 있습니다. 하지만 이러한 차이점이 연구 중인 현상과 관련이 없다면, 걱정할 필요가 없습니다. 이를 구체적으로 설명하기 위해 두 가지 극단적인 예를 들어보겠습니다:\n\n“대중의 심리치료에 대한 태도”를 측정하고자 하는데, 모든 참여자가 심리학 학생이라면, 이 연구는 거의 확실히 외적 타당성 문제가 있을 것입니다.\n\n시각적 착시의 효과를 측정하려고 하고, 모든 참여자가 심리학 학생이라면, 이 연구는 외적 타당성 문제가 있을 가능성이 적습니다.\n\n지난 몇 단락에서 주로 참여자 선택에 초점을 맞췄지만(이는 모두가 가장 걱정하는 큰 문제이기 때문에), 외적 타당성이 더 넓은 개념이라는 점을 기억할 가치가 있습니다. 연구 유형에 따라 외적 타당성을 위협할 수 있는 다른 예들도 있습니다:\n\n사람들이 “심리학 설문지”에 답변하는 방식이 실제 삶에서의 행동을 반영하지 않을 수 있습니다.\n\n“인간 학습”에 대한 실험실에서의 실험이 사람들이 현실에서 마주치는 학습 문제와 다른 구조를 가질 수 있습니다.\n\n\n\n2.6.3 구성 타당성\n구성 타당성은 기본적으로 당신이 측정하려는 것을 실제로 측정하고 있는지에 대한 질문입니다. 측정이 올바른 이론적 구성개념을 실제로 측정하고 있다면 구성 타당성이 좋다고 할 수 있고, 그렇지 않다면 구성 타당성이 나쁘다고 할 수 있습니다. 아주 단순한(하지만 우스꽝스러운) 예를 들어보겠습니다. 제가 대학생들이 시험에서 부정행위를 하는 비율을 조사하려고 한다고 가정해봅시다. 이를 측정하기 위해 부정행위를 한 학생들에게 강의실에서 일어서라고 요청한 후, 그들을 세는 방법을 사용한다고 합시다. 300명의 학생이 있는 수업에서 아무도 부정행위를 했다고 주장하지 않는다면, 저는 제 수업에서 부정행위를 한 학생 비율이 0%라고 결론을 내립니다.\n이것이 명백히 우스꽝스러운 예라는 것은 분명합니다. 하지만 이 예의 요점은 깊은 방법론적 문제를 제기하려는 것이 아니라 구성 타당성이 무엇인지를 설명하려는 것입니다. 이 측정에서의 문제는 제가 “부정행위를 한 사람의 비율”을 측정하려 했지만 실제로는 “부정행위를 자백할 만큼 어리석거나, 부정행위를 했다고 거짓 자백할 정도로 괴짜인 사람의 비율”을 측정했다는 점입니다. 분명히 이 둘은 동일하지 않습니다! 그래서 제 연구는 실패했으며, 이는 제 측정이 매우 낮은 구성 타당성을 가지고 있기 때문입니다.\n\n\n2.6.4 표면 타당성\n표면 타당성은 단순히 어떤 측정이 “겉보기”에 그 목적을 달성하고 있는 것처럼 보이는지 여부를 말합니다. 그 이상도 이하도 아닙니다. 예를 들어, 제가 지능 테스트를 설계했는데 사람들이 그것을 보고 “아니, 이 테스트는 지능을 측정하지 않는 것 같아”라고 말한다면, 그 측정은 표면 타당성이 부족한 것입니다. 아주 간단합니다.\n분명히 표면 타당성은 순수한 과학적 관점에서 볼 때 그렇게 중요하지 않습니다. 결국, 우리가 신경 써야 하는 것은 측정이 실제로 그 목적을 달성하는지 여부이지, 그것이 겉보기에 그 목적을 달성하는지 여부가 아닙니다. 따라서 일반적으로 표면 타당성에 크게 신경 쓰지 않습니다. 그럼에도 불구하고, 표면 타당성 개념은 세 가지 실용적인 목적에서 유용합니다:\n\n가끔은 경험 많은 과학자가 특정 측정이 작동하지 않을 것이라는 “직감”을 가질 때가 있습니다. 이런 종류의 직감은 엄밀한 증거적 가치를 가지지는 않지만, 주의 깊게 살펴볼 가치가 있는 경우가 많습니다. 사람들이 명확히 설명할 수는 없지만 어떤 지식을 가지고 있을 때, 왜 그런지 명확히 말할 수 없어도 꺼림직한 무언가가 있을 수 있습니다. 즉, 신뢰할 만한 사람이 당신의 연구의 표면 타당성을 비판한다면, 연구 설계에 문제가 있는지 생각해보는 시간을 가지는 것이 좋습니다. 하지만 특별히 우려할 이유를 찾지 못한다면, 표면 타당성은 그다지 중요하지 않으므로 걱정할 필요는 없습니다.\n종종 (매우 자주), 전혀 정보를 갖추지 못한 사람들이 당신의 연구가 형편없다고 “직감”으로 판단할 때가 있습니다. 그리고 그들은 이를 인터넷 같은 곳에서 비판합니다. 자세히 보면, 이러한 비판은 실제로 연구의 “겉보기”에만 초점이 맞춰져 있고, 더 깊은 측면에는 집중하지 않는 경우가 많습니다. 이럴 때 표면 타당성 개념은 그들에게 비판의 근거를 더 명확히 제시해야 한다고 부드럽게 설명하는 데 유용합니다.\n앞의 점을 확장하자면, 훈련받지 않은 사람들의 신념이 중요한 경우(예: 정책 입안자들에게 무언가를 설득해야 하는 응용 연구에서 자주 발생), 표면 타당성에 신경을 써야 합니다. 왜냐하면, 당신이 원하든 원하지 않든, 많은 사람들이 표면 타당성을 실제 타당성의 대리 지표로 사용할 것이기 때문입니다. 예를 들어, 정부가 과학적 심리학에 기반해 법을 바꾸게 하려면, 연구가 “실제로” 얼마나 좋은가는 중요하지 않을 수 있습니다. 연구에 표면 타당성이 부족하다면 정치인들이 이를 무시할 가능성이 큽니다. 물론, 정책이 종종 사실보다 외형에 더 의존한다는 것은 다소 불공정하지만, 현실은 그렇습니다.\n\n\n\n2.6.5 생태학적 타당성\n생태학적 타당성은 외적 타당성과 비슷한 개념이지만, 덜 중요한 개념입니다. 생태학적 타당성은 연구의 전체 설정이 조사 중인 실제 상황을 얼마나 가깝게 모방하는지를 나타냅니다. 어떤 의미에서 생태학적 타당성은 표면 타당성의 일종입니다. 연구가 “올바르게 보이는지”에 초점이 맞춰져 있지만, 약간 더 엄격한 기준이 적용됩니다. 생태학적으로 타당하기 위해서는 연구가 특정 방식으로 “올바르게 보이는” 것이 중요합니다. 생태학적 타당성 개념은 생태학적 타당성이 높은 연구가 외적 타당성이 높을 가능성이 더 크다는 직관에서 비롯되었습니다. 물론, 이것이 외적 타당성을 보장하지는 않습니다. 하지만 생태학적 타당성은 연구가 외적 타당성을 갖추었는지 확인하는 것보다 훨씬 더 쉽게 확인할 수 있다는 장점이 있습니다.\n단순한 예로, 목격자 신원 확인 연구를 들 수 있습니다. 대부분의 이 연구는 대학 환경에서 진행되며, 대개 간단한 얼굴 목록을 보여주는 방식으로 이루어지며, 줄 세워진 사람 중에서 범죄자를 식별하는 전형적인 신원 대조 방식과는 다릅니다. 실험에서는 “범죄자”를 본 후 “신원 대조”에서 용의자를 식별하도록 요청받기까지의 시간도 실제보다는 대개 더 짧습니다. “범죄”는 실제가 아니기 때문에 목격자가 겁먹을 가능성도 없고, 경찰관이 없기 때문에 압박감을 느낄 가능성도 줄어듭니다. 이러한 요인들은 연구가 생태학적 타당성을 결여한다는 것을 의미합니다. 그러나 이것이 외적 타당성도 부족하다는 것을 의미할 수도, 의미하지 않을 수도 있습니다.",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연구 설계에 대한 간략한 소개</span>"
    ]
  },
  {
    "objectID": "02-A-brief-introduction-to-research-design.html#교란-요인-인위적-결과물-그리고-타당성에-대한-위협",
    "href": "02-A-brief-introduction-to-research-design.html#교란-요인-인위적-결과물-그리고-타당성에-대한-위협",
    "title": "2  연구 설계에 대한 간략한 소개",
    "section": "2.7 교란 요인, 인위적 결과물, 그리고 타당성에 대한 위협",
    "text": "2.7 교란 요인, 인위적 결과물, 그리고 타당성에 대한 위협\n일반적인 관점에서 타당성 문제를 바라보면, 우리가 가장 주의해야 하는 두 가지는 교란 요인(confounders)와 인위적 결과물(artefacts)입니다. 이 두 가지 용어는 다음과 같이 정의됩니다:\n\n교란 요인: 교란 요인이란 종종 측정되지 않은 부가적인 변수로6 *예측 변수와 결과 변수 모두와 관련이 있는** 경우를 말합니다. 교란 요인의 존재는 연구의 내적 타당성을 위협합니다. 왜냐하면 예측 변수가 결과를 야기하는 것인지, 아니면 교란 요인이 결과를 야기하는 것인지 알 수 없기 때문입니다.\n인위적 결과물: 어떤 결과가 연구에서 테스트된 특정 상황에서만 성립한다면, 그 결과는 “인위적”(artefactual)이라고 합니다. 결과가 인위적일 가능성은 연구의 외적 타당성을 위협합니다. 이는 연구 결과를 관심 있는 실제 모집단에 일반화하거나 적용할 수 없을 가능성을 제기하기 때문입니다.\n\n일반적으로, 교란 요인은 비실험적 연구에서 더 큰 골칫거리입니다. 왜냐하면, 비실험적 연구는 본질적으로 “적절한 실험”이 아니기 때문입니다. 정의상, 많은 요소를 통제하지 않은 상태로 두기 때문에 연구에 교란 요인이 존재할 가능성이 큽니다. 반면, 실험적 연구는 교란 요인에 덜 취약합니다. 연구 과정에서 더 많은 것을 통제할수록, 교란 요인이 결과에 영향을 미치는 것을 더 효과적으로 막을 수 있습니다. 예를 들어, 무작위 할당을 통해 교란 요인이 각 그룹에 무작위로, 그리고 고르게 분배됩니다.\n하지만 모든 일에는 장단점이 있습니다. 인위적 결과물을 고려하기 시작하면 상황은 정반대가 됩니다. 대부분의 경우, 인위적 결과물은 비실험적 연구보다 실험적 연구에서 더 큰 문제로 나타납니다. 이를 이해하기 위해, 많은 연구가 비실험적으로 수행되는 이유를 생각해 보면 도움이 됩니다. 연구자들이 하고자 하는 일은 인간 행동을 보다 자연스러운 맥락에서 조사하는 것이기 때문입니다. 보다 실제 세계에 가까운 맥락에서 작업하면 실험적 통제력을 잃게 되어(교란 요인에 취약하게 됨) 인위적 결과물이 발생할 가능성이 줄어듭니다. 다시 말해, 심리학을 “자연 환경”에서 벗어나 실험실로 가져오게 되면(실험적 통제를 얻기 위해 보통 그렇게 해야 하지만), 원래 연구하려던 것과는 다른 무언가를 의도치 않게 연구하게 될 위험이 항상 존재합니다.\n하지만 주의하세요. 위의 내용은 단지 대략적인 가이드일 뿐입니다. 실험에서도 교란 요인이 존재할 수 있으며, 비실험적 연구에서도 인위적 결과물이 나타날 수 있습니다. 이는 실험자나 연구자의 실수 등 다양한 이유로 발생할 수 있습니다. 실제로는 모든 것을 미리 완벽히 고려하는 것이 매우 어렵고, 뛰어난 연구자들도 실수를 합니다.\n거의 모든 타당성에 대한 위협은 교란 요인이나 인위적 결과물로 설명될 수 있지만, 이 두 가지는 꽤 모호한 개념입니다. 따라서 가장 흔히 나타나는 몇 가지 예를 살펴보겠습니다.\n\n2.7.1 역사 효과\n역사 효과(history effects)는 연구 중 특정 사건이 발생하여 결과 측정치에 영향을 미칠 가능성을 의미합니다. 예를 들어, 사전 테스트와 사후 테스트 사이에 어떤 일이 발생할 수 있습니다. 또는 참가자 23번과 24번을 테스트하는 사이에 어떤 일이 발생할 수도 있습니다. 또는 과거의 연구 논문을 검토할 때, 당시에는 타당했지만 시간이 지나면서 세상이 변해 그 결론이 더 이상 신뢰할 수 없게 되었을 수도 있습니다. 역사 효과의 예는 다음과 같습니다:\n\n당신은 사람들이 위험과 불확실성에 대해 어떻게 생각하는지에 관심이 있습니다. 데이터를 2010년 12월에 수집하기 시작했지만, 참가자를 모집하고 데이터를 수집하는 데 시간이 걸려 2011년 2월에도 새로운 사람들을 테스트하고 있습니다. 하지만 2011년 1월에 퀸즐랜드(Queensland) 홍수가 발생하여 수십억 달러의 피해를 입히고 많은 사람들이 사망했습니다. 2011년 2월에 테스트된 사람들은 2010년 12월에 테스트된 사람들과는 상당히 다른 위험 대처 방식을 보였습니다. 어느 쪽이 참가자들의 “진정한” 신념을 반영한 것일까요? 아마 둘 다 일 것입니다. 퀸즐랜드 홍수는 분명히 호주 대중의 신념을 변화시켰지만, 아마도 일시적으로만 그랬을 것입니다. 여기서 중요한 점은 2011년 2월에 테스트된 사람들의 “역사”가 2010년 12월에 테스트된 사람들과 상당히 다르다는 것입니다.\n당신은 새로운 항불안 약물의 심리적 효과를 테스트하고 있습니다. 먼저 약물을 투여하기 전 불안 수준을 측정합니다(예: 자기보고 및 생리학적 측정). 그런 다음 약물을 투여한 후 동일한 측정을 수행합니다. 하지만 그 사이에, 연구실이 로스앤젤레스에 있기 때문에 지진이 발생하여 참가자들의 불안 수준이 증가합니다.\n\n\n\n2.7.2 성숙 효과\n역사 효과와 마찬가지로, 성숙 효과(maturation effects)는 본질적으로 시간의 흐름에 따른 변화를 다룹니다. 그러나 성숙 효과는 특정 사건에 대한 반응이 아니라, 사람들이 시간이 지남에 따라 스스로 변화하는 것과 관련이 있습니다. 우리는 나이를 먹고, 피곤해지고, 지루해지기도 합니다. 성숙 효과의 예는 다음과 같습니다:\n\n발달 심리학 연구를 수행할 때, 어린이는 매우 빠르게 성장한다는 점을 인식해야 합니다. 예를 들어, 3세 아동의 어휘력에 특정 교육적 기법이 도움이 되는지 알아보려고 한다고 가정해 봅시다. 이때 알아야 할 한 가지는 그 연령대 아동의 어휘력은 그 자체로 매우 빠르게(하루에 여러 단어) 증가한다는 것입니다. 성숙 효과를 고려하지 않고 연구를 설계하면, 당신의 교육적 기법이 효과가 있는지 여부를 알 수 없게 됩니다.\n실험실에서 매우 긴 실험(예: 3시간 동안 지속되는 실험)을 실행할 때, 참가자들이 지루해지거나 피곤해질 가능성이 매우 높습니다. 이러한 성숙 효과는 실험의 다른 모든 상황과 무관하게 참가자들의 성과를 저하시킬 것입니다.\n\n\n\n2.7.3 반복 측정 효과\n반복 측정 효과는 중요한 역사 효과 유형 중 하나입니다. 예를 들어, 어떤 심리적 구성개념(예: 불안)을 두 번 측정하려 한다고 가정해 봅시다. 여기서 우려되는 한 가지는 첫 번째 측정이 두 번째 측정에 영향을 미칠 가능성입니다. 즉, 두 번째 측정에 영향을 미치는 “사건”이 첫 번째 측정 자체인 경우입니다! 이는 드물지 않은 상황입니다. 몇 가지 예는 다음과 같습니다:\n\n학습과 연습: 예를 들어, 1차보다 2차 측정에서 “지능”이 높아 보이는 이유는 참가자들이 첫 번째 테스트 세션 동안 “지능 테스트 스타일” 질문을 해결하는 일반적인 규칙을 학습했기 때문일 수 있습니다.\n테스트 상황에 대한 익숙함: 예를 들어, 1차 측정에서는 사람들이 긴장하여 성과가 떨어질 수 있습니다. 하지만 첫 번째 테스트 상황을 경험한 후에는 테스트가 어떻게 진행되는지 알기 때문에 긴장이 많이 풀릴 수 있습니다.\n테스트로 인한 부수적인 변화: 예를 들어, 기분을 평가하는 설문지가 지루하다면, 2차 측정에서의 기분 평가가 1차의 지루한 측정 때문에 “지루함”으로 기울 가능성이 높아집니다.\n\n\n\n2.7.4 선택 편향\n선택 편향(selection bias)은 꽤 넓은 의미를 가진 용어입니다. 예를 들어, 두 그룹의 참가자를 대상으로 실험을 진행한다고 가정해 봅시다. 각 그룹에는 다른 “처치”가 주어지며, 다른 처치가 서로 다른 결과를 초래하는지 보고자 합니다. 하지만 최선을 다했음에도 불구하고, 그룹 간에 성별 불균형이 발생했다고 가정합시다(예: 그룹 A는 여성 80%, 그룹 B는 여성 50%). 이런 일이 절대 일어나지 않을 것처럼 보이지만, 실제로는 충분히 가능한 상황입니다. 이는 선택 편향의 한 예로, 두 그룹에 “선택된” 사람들이 무작위 선택이 되지 않아서 서로 다른 특성을 가진 경우입니다. 만약 이러한 특성 중 하나가 연구의 결과와 관련된 것으로 밝혀진다면(예: 처치가 남성보다 여성에게 더 효과적이라면), 큰 문제가 발생할 수 있습니다.\n\n\n2.7.5 차별적 탈락\n탈락 효과를 고려할 때, 두 가지 다른 유형을 구분하는 것이 때로는 유용합니다. 첫 번째는 동질적 탈락(homogeneous attrition)으로, 탈락 효과가 모든 그룹, 처치 또는 조건에서 동일한 경우를 말합니다. 위에서 든 예에서는, 실험의 모든 조건에서 쉽게 지루해하는 참가자들이 대체로 동일한 비율로 탈락했다면, 이 탈락은 동질적입니다. 일반적으로, 동질적 탈락의 주요 효과는 표본이 대표성을 잃게 된다는 것입니다. 따라서 가장 큰 우려는 결과의 일반화 가능성이 감소한다는 것입니다. 다시 말해, 외적 타당성이 손실됩니다.\n두 번째 유형은 이질적 탈락(heterogeneous attrition)으로, 탈락 효과가 서로 다른 그룹에서 다르게 나타나는 경우입니다. 보통 차별적 탈락(differential attrition)이라고 더 자주 불리며, 이는 연구 자체로 인해 발생하는 일종의 선택 편향입니다. 가령, 심리학의 역사에서 처음으로 완벽히 균형 잡힌 대표적인 표본을 찾았다고 가정합시다. 저는 이 완벽한 표본을 대상으로 “엄청 길고 지루한 실험”을 실행하기 시작합니다. 하지만 제 연구가 너무 길고 지루하기 때문에 많은 사람들이 탈락하기 시작합니다. 이를 막을 수는 없습니다. 참가자들은 어떤 실험이든, 어떤 이유에서든, 언제든 중단할 권리가 있으며, 연구자로서 우리는 참가자들에게 이러한 권리가 있음을 상기시킬 도덕적(그리고 전문적) 의무가 있습니다. 따라서 “엄청 길고 지루한 실험”에서 탈락률이 매우 높다고 가정해 봅시다. 이 탈락이 무작위일 가능성은 얼마나 될까요? 답: 0입니다. 남아 있는 사람들은 거의 확실히 더 성실하고, 지루함에 대한 내성이 더 강한 사람들이었을 것입니다. (예를 들어) 성실성이 제가 관심을 두는 심리적 현상과 관련이 있다면, 이러한 탈락은 제 결과의 타당성을 감소시킬 수 있습니다.\n다른 예를 들어봅시다. 제가 두 가지 조건으로 실험을 설계했다고 가정합니다. “처치”(treatment) 집단에서는 실험자가 참가자를 모욕한 뒤 복종을 측정하기 위한 설문지를 제공합니다. “통제”(control) 집단에서는 실험자가 별다른 의미 없는 잡담을 한 뒤 설문지를 제공합니다. 이 연구의 의심스러운 과학적 가치와 윤리적 문제는 논외로 하고, 여기서 어떤 문제가 발생할 수 있을지 생각해 봅시다. 일반적으로, 누군가가 제 얼굴 앞에서 저를 모욕한다면, 저는 훨씬 덜 협조적이 됩니다. 따라서 처치 집단에서 통제 집단보다 훨씬 더 많은 사람들이 탈락할 가능성이 큽니다. 그리고 이 탈락은 무작위가 아닐 것입니다. 가장 탈락할 가능성이 높은 사람들은 실험을 복종적으로 끝까지 수행하는 것의 중요성에 별로 관심이 없는 사람들일 것입니다. 따라서 가장 반항적이고 복종하지 않는 사람들이 처치 집단에서는 탈락하고, 통제 집단에서는 탈락하지 않는다면, 우리는 교란 변수를 도입하게 됩니다. 처치 집단에서 설문지를 실제로 작성한 사람들은 이미 통제 집단의 사람들보다 더 성실하고 순종적일 가능성이 높았습니다. 요컨대, 이 연구에서 사람들을 모욕하는 것은 그들을 더 복종적으로 만드는 것이 아니라, 더 복종하지 않는 사람들이 실험을 떠나게 만드는 것입니다! 이 실험의 내적 타당성은 완전히 손상됩니다.\n\n\n\n\n\n\n처치 집단과 통제 집단\n\n\n\n실험에서 처치 집단(treatment group)과 통제 집단(control group)은 연구자가 특정 변수의 효과를 평가하기 위해 설정하는 두 가지 주요 집단입니다. 이 두 집단의 차이는 연구의 신뢰성과 타당성을 확보하는 데 핵심적인 역할을 합니다.\n처치 집단은 다음과 같은 의미를 가지고 있습니다.\n\n연구자가 특정한 처치나 조작(예측 변수의 효과)을 가하는 집단입니다.\n\n연구에서 조작된 처치가 결과 변수에 미치는 영향을 관찰하기 위해 필요합니다.\n\n예: 새로운 약물을 투여받는 환자, 새로운 학습법을 적용받는 학생\n\n통제 집단은 다음과 같은 의미를 가지고 있습니다.\n\n처치를 받지 않거나, 처치와 유사하지만 중립적인 조건을 받는 집단입니다.\n\n처치의 효과를 비교할 기준선을 제공하여 처치의 순수한 효과를 평가할 수 있도록 합니다.\n\n종종 위약(placebo)이나 기존의 표준 치료(standard treatment)를 받습니다.\n예: 약물 연구에서 가짜 약을 받는 그룹, 기존 학습법을 사용하는 학생\n\n처치 집단과 통제 집단의 차이를 표로 정리하면 다음과 같습니다.\n\n\n\n구분\n처치 집단\n통제 집단\n\n\n\n\n예측변수 적용\n적용됨\n적용되지 않음 (또는 중립적 처치)\n\n\n목적\n독립변수의 효과 관찰\n비교 기준 제공\n\n\n예시\n새로운 약물 투여\n위약(placebo) 투여\n\n\n\n실험에서 왜 두 집단이 필요할까요? 그 이유는 다음과 같습니다.\n\n비교를 통해 효과 확인: 두 집단의 결과를 비교함으로써 예측 변수(처치)의 효과를 명확히 구분할 수 있습니다.\n외부 요인의 통제: 통제 집단이 없으면 결과 변수의 변화가 처치 때문인지, 아니면 외부 요인 때문인지 알기 어렵습니다.\n\n예: 시간이 지남에 따라 자연적으로 발생하는 변화와 처치로 인한 변화를 구분.\n\n내적 타당성 보장: 실험 결과가 처치에 의한 것임을 확신할 수 있습니다.\n\n처치 집단과 통제 집단을 구성할 때의 주의 사항은 다음과 같습니다.\n\n랜덤화: 참가자를 무작위로 배정하여 두 집단 간의 차이를 최소화합니다.\n\n동질성 유지: 처치 집단과 통제 집단이 처치 외의 모든 조건에서 동일하도록 설정합니다.\n\n위약 효과 고려: 통제 집단에 가짜 처치를 제공하여 심리적 요인의 영향을 배제합니다.\n\n이와 같은 실험 설계는 연구의 신뢰도를 높이고, 얻어진 결과를 기반으로 신뢰할 수 있는 결론을 도출하는 데 필수적입니다.\n\n\n\n\n2.7.6 무응답 편향 (Non-response bias)\n무응답 편향은 선택 편향(selection bias) 및 차별적 탈락(differential attrition)과 밀접한 관련이 있습니다. 이 문제의 가장 간단한 버전은 다음과 같습니다. 설문지를 1000명에게 발송했지만, 그중 300명만 응답했다고 가정해 봅시다. 응답한 300명은 거의 확실히 무작위 하위 표본(random subsample)이 아닐 것입니다. 설문에 응답하는 사람들은 응답하지 않는 사람들과 체계적으로 다릅니다. 따라서 응답한 300명을 기반으로 전체 모집단으로 일반화하려고 할 때 문제가 발생합니다. 그러나 무응답 편향 문제는 이보다 더 일반적입니다. 예를 들어, 응답한 300명 중 일부가 설문지의 모든 질문에 응답하지 않았다고 가정합시다. 만약 80명이 특정 질문에 응답하지 않았다면, 이게 문제가 될까요? 답은 항상 그렇듯이 “아마도”입니다. 응답하지 않은 질문이 설문지의 마지막 페이지에 있었고, 80개의 설문지가 마지막 페이지가 없는 상태로 반환되었다면, 누락된 데이터는 큰 문제가 아닐 가능성이 높습니다. 아마도 페이지가 단순히 떨어졌을 것입니다. 하지만 80명이 응답하지 않은 질문이 설문지에서 가장 논쟁적이거나 개인적인 질문이었다면, 거의 확실히 문제가 발생합니다. 본질적으로, 이것은 결측치 문제(missing data problem)로 불립니다. 만약 결측치가 무작위로 “결측된” 것이라면 큰 문제가 아닙니다. 하지만 체계적으로 결측된 경우라면 큰 문제가 될 수 있습니다.\n\n\n2.7.7 평균 회귀 (Regression to the mean)\n평균 회귀는 어떤 척도의 극단적인 값을 가진 표본을 선택하는 상황에서 나타납니다. 변수가 자연적인 변동을 가지므로, 이후 측정을 할 때는 순전히 우연적 효과만으로 이후의 측정값이 처음보다 덜 극단적으로 나타날 가능성이 높습니다.\n예를 들어 보겠습니다. 저는 심리학 교육이 매우 똑똑한 아이들에게 부정적인 영향을 미치는지 알아보고 싶습니다. 이를 위해, 고등학교 성적이 가장 우수한 심리학 1학년 학생 20명을 찾아 이들이 대학에서 얼마나 잘하고 있는지를 살펴봅니다. 그 결과, 이들은 평균보다 훨씬 잘하고 있지만, 고등학교에서 반에서 최고였던 것과는 달리 대학에서는 최고가 아닙니다. 이것은 무엇을 의미할까요? 첫 번째로 떠오르는 생각은 심리학 수업이 그 학생들에게 부정적인 영향을 미쳤다는 것일 수 있습니다. 하지만 그럴 가능성도 있지만, 더 가능성이 높은 것은 이것이 “평균 회귀”의 한 예라는 것입니다. 이를 이해하기 위해, 반에서 최고 성적을 받으려면 어떤 조건이 필요한지 생각해 봅시다. 큰 반에서는 매우 똑똑한 사람들이 많이 있을 것입니다. 최고 성적을 받으려면 매우 똑똑하고, 열심히 공부해야 하며, 약간의 운도 따라야 합니다. 시험에서 자신의 기질에 맞는 질문이 나오고, 멍청한 실수를 피해야 하죠(누구나 가끔 그런 실수를 합니다). 문제는 개인의 지능과 노력은 이전 수업에서 다음 수업으로 전달되지만, 운은 그렇지 않다는 점입니다. 고등학교에서 운이 좋았던 사람들이 대학에서 운이 좋을 가능성은 적습니다. 이것이 바로 “운”의 정의입니다. 결과적으로, 첫 번째 측정에서 극단적인 값을 보인 사람들(예: 상위 20명)을 선택하면, 노력, 기술, 운이 모두 고려된 기준으로 표본을 선택하게 됩니다. 그러나 두 번째 측정(대학)에서는 운이 이전처럼 작용하지 않으므로 이들의 점수는 약간 낮아져 다른 사람들과 가까워집니다. 이것이 평균 회귀입니다.\n평균 회귀는 놀랍도록 흔합니다. 예를 들어, 매우 키가 큰 부모의 자녀는 평균보다 키가 크지만 부모만큼 크지는 않을 가능성이 높습니다. 반대로 매우 키가 작은 부모의 자녀는 키가 작겠지만 부모보다 조금 더 클 가능성이 높습니다. 또한 이는 매우 미묘할 수 있습니다. 예를 들어, 사람들이 부정적인 피드백을 긍정적인 피드백보다 더 잘 학습한다는 연구가 있었습니다. 이를 보여주기 위해, 사람들이 잘했을 때는 긍정적인 피드백을 주고, 잘못했을 때는 부정적인 피드백을 주는 방식으로 실험이 진행되었습니다. 그 결과, 긍정적인 피드백 후에는 성과가 나빠지고, 부정적인 피드백 후에는 성과가 좋아지는 경향이 나타났습니다. 하지만 여기에 선택 편향(selection bias)이 존재합니다! 사람들이 매우 잘했을 때는 “높은” 성과를 보이는 표본을 선택한 셈이므로 평균 회귀로 인해 다음 시도에서 성과가 떨어질 가능성이 있습니다. 마찬가지로, 나쁜 결과 이후에는 사람들이 저절로 나아질 가능성이 높습니다. 부정적인 피드백의 명백한 우월성은 평균 회귀로 인해 발생한 인위적인 결과입니다(자세한 논의는 Kahneman & Tversky (1973) 참고).\n\n\n2.7.8 실험자 편향 (Experimenter bias)\n실험자 편향은 여러 형태로 나타날 수 있습니다. 기본 아이디어는 실험자가 의도와는 다르게 실험 결과에 영향을 미칠 수 있다는 것입니다. 이는 실험자가 참가자에게 “정답”이나 “원하는 행동”을 미묘하게 전달하기 때문입니다. 일반적으로, 이는 실험자가 참가자에게 없는 특별한 지식을 가지고 있을 때 발생합니다. 예를 들어, 질문에 대한 정답을 알고 있거나, 참가자가 속한 조건에서 예상되는 성과 패턴을 알고 있는 경우입니다. 이와 관련된 고전적 사례는 1907년의 “영리한 한스(Clever Hans)” 사건입니다 (Pfungst, 1911). 한스는 읽기와 계산 같은 인간의 지능적인 능력을 보여주는 말로 유명했습니다. 하지만 심리학자들이 그의 행동을 더 면밀히 조사한 결과, 한스가 수학을 할 줄 아는 것이 아니라, 주변의 인간 관찰자들의 행동에 반응한 것임이 밝혀졌습니다. 한스는 사람들이 숫자를 셀 줄 안다는 사실을 이용해, 사람들이 행동을 바꿀 때 자신의 행동을 변화시키는 법을 배운 것이었습니다.\n실험자 편향 문제를 해결하는 일반적인 방법은 이중 눈가림 연구(double-blind study)를 수행하는 것입니다. 이 방법에서는 실험자와 참가자 모두 참가자가 속한 조건이나 원하는 행동을 알지 못하도록 합니다. 이는 문제를 해결하는 매우 좋은 방법이지만, 완벽한 해결책은 아니며 실행하기도 쉽지 않습니다. 예를 들어, 제가 이중 눈가림 연구를 설계하려면 제 박사과정 학생 중 한 명(실험에 대해 아무것도 모르는 사람)에게 연구를 진행하게 할 수 있습니다. 이 방식은 충분할 것처럼 보입니다. 모든 세부 사항(예: 질문의 정답, 조건에 따른 참가자 배정)을 알고 있는 유일한 사람인 제가 참가자와 상호작용하지 않고, 사람들과 대화하는 사람(박사과정 학생)은 아무것도 모릅니다. 그러나 현실적으로 이 마지막 부분이 진실이 아닐 가능성이 높습니다. 박사과정 학생이 연구를 효과적으로 진행하려면 연구자인 제가 그들에게 브리핑을 해야 하기 때문입니다. 게다가 그 학생은 저를 알고, 제가 사람과 심리에 대해 가진 일반적인 신념(예: 저는 심리학자들이 평가하는 것보다 인간이 훨씬 똑똑하다고 생각함)을 조금은 알고 있을 것입니다. 이 모든 결과로 인해 실험자가 제가 가진 기대치를 약간이라도 알게 되는 것을 완전히 피하는 것은 거의 불가능합니다. 그리고 약간의 지식도 영향을 미칠 수 있습니다. 예를 들어, 실험자가 실수로 참가자들이 이 과제에서 잘할 것이라는 기대를 전달했다고 가정해 봅시다. 이는 “피그말리온 효과”(Pygmalion effect)로 알려져 있으며, 사람들이 큰 기대를 받으면 그 기대에 부응하려고 노력하는 경향이 있습니다. 반대로 실패를 예상하면 사람들은 실패를 하게 됩니다. 다시 말해, 기대가 자기충족적 예언(self-fulfilling prophecy)이 되는 것입니다.\n\n\n\n\n\n\n피그말리온 효과와 자기충족적 예언\n\n\n\n피그말리온 효과(pygmalion effect)는 타인의 기대가 개인의 행동과 성과에 긍정적인 영향을 미치는 현상을 말합니다. 이는 심리학과 교육학에서 중요한 개념으로, 특히 리더나 교사가 구성원이나 학생에게 가지는 높은 기대가 그들의 실제 성과를 향상시키는 데 영향을 줄 수 있음을 설명합니다.\n이름은 그리스 신화의 피그말리온(Pygmalion)에서 유래했으며, 조각가 피그말리온이 자신이 만든 조각상에 강한 애정을 가지자 조각상이 실제 사람으로 변했다는 이야기에서 따왔습니다. 1968년 로젠탈(Robert Rosenthal)과 제이콥슨(Lenore Jacobson)이 학교 실험에서 교사의 기대가 학생들의 학업 성취에 영향을 미친다는 것을 실증하면서 널리 알려졌습니다.\n피그말리온 효과가 발생하는 기제는 다음과 같습니다.\n\n높은 기대를 받는 사람은 자신의 잠재력을 더 잘 발휘하려는 동기를 갖게 됩니다.\n기대는 의사소통, 피드백, 행동 방식 등을 통해 간접적으로 전달됩니다.\n긍정적인 순환: 높은 기대 → 더 많은 지원과 관심 → 더 높은 성과.\n\n자기 충족적 예언(Self-fulfilling Prophecy)은 어떤 예언이나 믿음이 그 자체로 행동에 영향을 미쳐 결과적으로 예언이 현실이 되는 현상을 말합니다.\n자기 충족적 예언이 실현되는 과정은 다음과 같습니다.\n\n초기 믿음/예언: 특정 상황이나 사람에 대해 어떤 기대나 예측을 가집니다.\n\n행동 변화: 이 믿음이 행동에 영향을 미칩니다.\n\n결과 실현: 행동의 결과로 예언이 현실이 됩니다.\n\n자기 충족적 예언의 예는 다음과 같습니다.\n\n긍정적 사례: “나는 시험을 잘 볼 거야”라는 믿음이 공부의 동기를 높이고, 실제로 높은 성적을 얻게 됨.\n\n부정적 사례: “나는 잘 못할 거야”라는 믿음이 행동을 위축시키고 실제로 실패를 초래함.\n\n피그말리온 효과와 자기 충족적 실현의 차이는 다음과 같습니다.\n\n피그말리온 효과는 타인의 긍정적 기대가 개인의 행동과 성과를 변화시키는 예시입니다.\n\n자기 충족적 실현은 자신의 믿음이나 타인의 기대가 행동을 통해 예언을 현실로 만드는 더 일반적인 개념입니다.\n\n정리하자면, 피그말리온 효과과 타인의 기대가 개인에게 영향을 미쳐 성과를 높인다면, 자기 충족적 실현은 믿음이나 예언이 행동에 영향을 주어 스스로 현실이 되는 것을 의미합니다.\n이 둘은 모두 기대와 행동의 상호작용을 강조하며, 긍정적 또는 부정적인 결과를 낳을 수 있다는 점에서 중요합니다.\n\n\n\n\n2.7.9 요구 효과와 반응성\n실험자 편향에 대해 이야기할 때는 실험자의 지식이나 실험에 대한 기대가 참가자에게 전달되어 이로 인해 사람들이 행동을 바꾸는 것에 대한 우려를 다룹니다 (Rosenthal, 1966). 그러나 이를 막는다 하더라도, 참가자들이 자신이 심리학 연구의 일환이라는 사실을 인식하지 못하도록 만드는 것은 거의 불가능합니다. 누군가가 자신을 관찰하거나 연구하고 있다는 사실만으로도 행동에 상당한 영향을 미칠 수 있습니다. 이를 일반적으로 반응성(reactivity) 또는 요구 효과(demand effects)라고 합니다.7 이러한 기본 아이디어는 호손 효과(Hawthorne effect)로 잘 알려져 있습니다. 이는 연구가 자신에게 초점을 맞춘다는 사실로 인해 사람들이 자신의 수행을 변경하는 현상을 의미합니다. 이 효과는 시카고 외곽의 “호손 워크스”(Hawthorne Works) 공장에서 진행된 연구에서 비롯된 이름입니다(자세한 내용은 Adair (1984) 참조). 1920년대의 이 연구는 공장 조명이 노동자 생산성에 미치는 영향을 조사했지만, 중요한 점은 조명 변화 때문이 아니라 노동자들이 자신들이 연구되고 있다는 사실을 인지했기 때문에 행동 변화가 일어났다는 것입니다.\n사람들이 실험의 일환이라는 사실만으로도 행동이 어떻게 바뀔 수 있는지에 대해 조금 더 구체적으로 살펴보려면, 사회심리학자의 관점에서 실험 중 사람들이 현실 세계에서와는 다른 역할을 맡게 되는 몇 가지 방식을 생각해 보면 도움이 됩니다:\n\n착한 참가자는 연구자에게 지나치게 협조적이려고 합니다. 그는 실험자의 가설을 파악하고 이를 확인하려고 노력합니다.\n부정적인 참가자는 좋은 참가자와 정확히 반대입니다. 그는 연구나 가설을 어떤 방식으로든 파괴하거나 무너뜨리려고 합니다.\n충실한 참가자는 지나치게 순종적입니다. 그는 현실적인 상황에서라면 했을지도 모를 행동에 상관없이 지침을 완벽히 따르려고 합니다.\n불안한 참가자는 실험이나 연구를 받는 것에 대해 긴장하여 그의 행동이 매우 부자연스럽거나 과도하게 사회적으로 바람직한 방향으로 변합니다.\n\n\n\n\n\n\n\n호손 효과란?\n\n\n\n호손 효과(Hawthorne Effect)는 사람들이 자신이 관찰되고 있다는 사실을 인식할 때 행동이 변화하는 현상을 말합니다. 이는 연구나 실험 과정에서 피실험자가 관찰 대상임을 알고 있을 때, 그들의 자연스러운 행동이 달라질 수 있음을 보여줍니다.\n호손 효과는 1920년대와 1930년대에 미국 일리노이주 시카고 근처에 위치한 웨스턴 일렉트릭(Western Electric)의 호손 공장(Hawthorne Works)에서 진행된 연구에서 처음 관찰되었습니다.\n이 연구는 하버드 대학교의 연구진, 특히 엘튼 메이오(Elton Mayo)와 그의 동료들에 의해 주도되었습니다. 이 연구의 목적은 작업 환경(예: 조명 밝기, 휴식 시간)이 생산성에 미치는 영향을 조사하는 것이었습니다.\n그런데 조사 결과, 조명을 밝게 하거나 어둡게 하는 등 작업 환경을 변화시켰을 때 생산성이 증가했지만, 환경을 원래대로 돌려도 생산성은 여전히 높게 유지되는 것을 관찰하였습니다. 마찬가지로 릴레이 조립 실험에서, 휴식 시간 등의 근무 조건을 변화시켰을 때, 어떠한 방식의 변화에도 생선이 증가하였습니다. 이러한 결과의 원인을 알기 위해 연구자들은 참여자에 대한 인터뷰를 수행하였는데, 환경 변화 그 자체보다는 관찰되고 있다는 인식과 연구자들의 관심이 참여자들의 생산성 증가를 유발하였음을 발견하게 되었습니다.\n호손 효과는 인간 행동이 단순히 물리적 조건만으로 설명될 수 없으며, 심리적·사회적 요인도 중요한 역할을 한다는 점을 강조했습니다. 이후 호손 효과는 조직행동론과 산업심리학의 발전에 기여했습니다.\n\n\n\n\n2.7.10 플라시보 효과\n플라시보 효과(placebo effect)는 요구 효과의 특정 유형으로, 우리가 많이 우려하는 부분입니다. 이는 치료를 받고 있다는 사실만으로도 결과가 개선되는 상황을 가리킵니다. 고전적인 예는 임상 시험에서 찾아볼 수 있습니다. 화학적으로 전혀 작용하지 않는 약물을 사람들에게 투여하고 그것이 질병을 치료하는 약물이라고 말하면, 치료를 전혀 받지 않은 사람들보다 상태가 더 빠르게 좋아지는 경향이 있습니다. 즉, 약물 자체가 아니라 치료를 받고 있다는 믿음이 향상된 결과를 가져옵니다.\n그러나 현재 의학에서는 진정한 플라시보 효과는 매우 드물다고 여겨지며, 과거에 플라시보 효과로 간주되었던 대부분의 것들은 자연 치유(어떤 사람들은 스스로 나아집니다), 평균 회귀(regression to the mean), 그리고 연구 설계의 다른 유연적 효과들의 조합이라는 의견이 일반적입니다. 심리학적으로 흥미로운 점은, 플라시보 효과에 대한 가장 강력한 증거들은 통증 치료에서 환자에 의해 보고된 플라시보의 효과에서 발견된다는 점입니다(Hróbjartsson & Gøtzsche, 2010).\n\n\n2.7.11 상황, 측정 및 하위 집단 효과\n이 용어들은 어느 정도 “외적 타당성에 대한 모든 기타 위협”을 포괄하는 개념으로 볼 수 있습니다. 이는 연구 참가자를 모집하는 데 사용된 하위 집단의 선택, 연구를 진행하는 장소, 시간, 방식(데이터 수집 담당자를 포함하여) 및 측정 도구의 선택이 결과에 영향을 미칠 수 있다는 점을 나타냅니다. 구체적으로 말하면, 이러한 요소들이 결과에 영향을 미쳐 더 광범위한 사람들, 장소, 측정에서는 일반화되지 않을 가능성이 있다는 우려를 의미합니다.\n\n\n2.7.12 사기, 기만 및 자기 기만\n\n누군가의 급여가 무언가를 이해하지 않는 데 달려 있다면, 그에게 그것을 이해시키는 것은 어렵다.\n– 업턴 싱클레어(Upton Sinclair)\n\n마지막으로 언급하고 싶은 것이 하나 있습니다. 연구의 타당성을 평가하는 데 있어 교과서들이 흔히 다루는 내용을 읽다 보면, 연구자가 정직하다는 가정을 하고 있다는 점을 알게 됩니다. 저는 이 점이 우습다고 생각합니다. 대다수의 과학자들은 정직하지만, 적어도 제 경험에 따르면 일부는 그렇지 않습니다.8 그뿐만 아니라, 앞서 언급했듯이 과학자들도 신념 편향(belief bias)에 면역되어 있지 않습니다. 연구자는 스스로 잘못된 것을 믿도록 자기 기만에 빠질 수 있으며, 이로 인해 미묘하게 결함이 있는 연구를 수행하고, 연구 결과를 작성할 때 그러한 결함을 숨길 수도 있습니다. 따라서 노골적인 사기의 가능성(아마도 가능성이 낮겠지만)을 고려해야 할 뿐만 아니라, 의도치 않게 “편향된” 연구일 가능성(아마도 꽤 흔하겠지만)을 고려해야 합니다. 몇 가지 표준적인 교과서를 열어 보았지만, 이 문제에 대한 논의는 거의 찾아볼 수 없었습니다. 그래서 제가 직접 이러한 문제들이 발생할 수 있는 몇 가지 방식을 정리해 보았습니다.\n\n데이터 조작(data fabrication): 때로는 연구자들이 데이터를 아예 조작하기도 합니다. 이는 때로 “선의”로 이루어지기도 합니다. 예를 들어, 연구자는 조작된 데이터가 진실을 반영한다고 믿으며, 실제 데이터의 “약간 정리된(cleaned up)” 버전일 수도 있다고 생각합니다. 다른 경우에는, 조작이 의도적이고 악의적으로 이루어지기도 합니다. 데이터 조작이 의심되거나 밝혀진 많이 회자된 사례로는 연구 데이터를 조작했다고 여겨지는 심리학자 시릴 버트(Cyril Burt), MMR 백신과 자폐증 간의 연관성을 주장하며 데이터를 조작했다고 비난받은 앤드루 웨이크필드(Andrew Wakefield), 줄기세포 연구 데이터를 조작한 황우석 등이 있습니다.\n속임수(hoaxes): 속임수는 데이터 조작과 많은 유사점을 가지지만, 의도된 목적에서 다릅니다. 속임수는 종종 농담으로서 많은 경우 결국 사실이 들어나도록 의도되기도 합니다. 이러한 속임수의 목적은 종종 특정 사람이나 분야를 불신하게 만드는 것입니다. 역사적으로 잘 알려진 과학적 속임수들(예: 필트다운인(Piltdown man))이 있었고, 일부는 특정 연구 분야를 불신하게 하려는 의도적인 시도였습니다(예: 소칼 사건(Sokal affair)).\n\n\n\n\n\n\n\n필트다운인 사건이라\n\n\n\n필트다운인(Piltdown Man) 사건은 1912년 영국 필트다운 지역에서 발견된 가짜 화석이 약 40년 동안 인류 진화의 중요한 증거로 오인된 사기 사건입니다. 아마추어 고고학자 찰스 도슨을 중심으로 발견된 이 화석은 두개골 조각과 원숭이와 유사한 아래턱뼈로 구성되어 있었고, 인간과 유인원의 진화 사이에 존재했던 잃어버린 연결고리로 여겨졌습니다. 당시 과학계는 이 발견이 인류 진화 연구의 획기적인 전환점이라고 믿었으나, 1949년 불소 흡수 테스트와 이후의 검증을 통해 이 화석이 현대 인간의 두개골과 오랑우탄의 아래턱뼈를 조작하여 만든 가짜라는 사실이 밝혀졌습니다.\n이 사건은 과학적 검증의 중요성과 편향된 사고가 학문적 오류로 이어질 수 있음을 보여주는 사례로 자리 잡았습니다. Piltdown Man은 영국 중심의 인류 진화 이론을 강화하려는 의도로 조작된 것으로 추정되며, 과학계에 신뢰의 손상을 초래했지만 이후 연구 방법론의 발전을 촉진하는 계기가 되었습니다.\n\n\n\n\n\n\n\n\n소칼 사건이란?\n\n\n\n소칼 사건(Sokal Affair)은 1996년 물리학자 앨런 소칼이 고의적으로 가짜 논문을 작성해 학술 출판의 허점을 폭로한 사건입니다. 소칼은 과학적 개념을 왜곡된 방식으로 사용하며, 실제로는 근거가 없는 주장과 모호하고 난해한 표현들로 논문을 작성했습니다. 그는 포스트모더니즘 철학의 용어와 문체를 따라 작성한 논문에서 양자 중력이라는 과학적 주제를 철학적·사회적 담론과 억지로 연결하는 방식으로 내용을 구성했습니다. 이러한 논문은 논리적 일관성이 부족했음에도, 편집자들이 듣고 싶어할 내용으로 꾸며져 포스트모던 학술지 Social Text에 게재되었습니다.\n논문 출판 후 소칼은 이를 의도적인 장난이었음을 폭로하며, 학술 출판에서 동료 평가나 검증 없이 논문이 실릴 수 있다는 문제를 지적했습니다. 이 사건은 과학적 엄밀성과 학술 담론의 질을 점검하는 계기가 되었으며, 포스트모더니즘 철학의 과학적 상대주의와 학문적 신뢰성에 대한 논쟁을 촉발했습니다. 또한 학술 출판 과정에서 비판적 검토의 중요성을 강조하며, 학문의 질적 개선을 요구하는 목소리를 높였습니다.\n\n\n\n데이터 오보(data misrepresentation): 사기가 헤드라인을 차지하는 경우가 많지만, 제 경험으로는 데이터가 오보되는 경우가 훨씬 더 일반적입니다. 여기서 말하는 것은 신문에서 잘못 보도하는 경우를 말하는 것이 아닙니다(신문은 거의 항상 잘못 보도합니다). 제가 말하는 것은, 종종 데이터가 연구자가 생각하는 것을 실제로 말해주지 않는 경우입니다. 이는 거의 항상 고의적인 부정직함 때문이 아니라 데이터 분석의 미숙함 때문이라고 생각됩니다. 예를 들어, 이 책의 초반에 논의한 심슨의 역설(Simpson’s paradox)을 떠올려보세요. 사람들이 어떤 형태로든 “집계된(aggregated)” 데이터를 제시하는 경우가 흔하고, 직접 데이터를 더 깊이 파고들어보면 집계된 데이터와 분해된(disaggregated) 데이터가 다른 이야기를 전하는 경우가 있습니다. 또는 특정 데이터가 불편한 이야기를 전달하기 때문에 연구자가 해당 변수에 대해 언급하지 않기로 선택했을 수도 있습니다. 이러한 변형된 사례들은 많고, 대부분 탐지하기 어렵습니다.\n연구 설계 오류(study “misdesign”): 이 문제는 다소 미묘합니다. 기본적으로, 연구자가 본질적인 결함이 있는 연구를 설계하고, 논문에 그러한 결함을 전혀 보고하지 않는 경우를 말합니다. 보고된 데이터는 완전히 실제 데이터이고 정확히 분석되었지만, 사실은 잘못된 방식으로 구성된 연구에서 나온 것입니다. 연구자가 특정 효과를 찾고 싶어 하며, 연구를 그러한 효과를 (인위적으로) 쉽게 관찰할 수 있는 방식으로 설계한 경우입니다. 이를 은밀히 수행하려면, 실험 참가자들이 “해야 할 일”을 명백히 알 수 있도록 실험을 설계하고, 반응성을 이용하는 것입니다. 실험 결과를 작성할 때, 이러한 사기는 독자들에게 명백히 드러나지 않습니다. 실험 맥락에서 참가자에게 명확했던 것이 논문을 읽는 사람에게는 명확하지 않을 수 있습니다. 지금까지 설명한 내용으로는 연구 설계 오류가 항상 사기로 보일 수 있지만, 아마도 의도적으로 수행되는 경우도 있지만 제 경험상 더 큰 문제는 의도되지 않은 설계 오류입니다. 연구자가 특정 믿음을 가지고 있다 보니, 연구가 내재된 결함을 가지게 되었고, 그 결함이 논문으로 작성될 때 마법처럼 사라지는 것입니다.\n데이터 마이닝(data mining)과 사후 가설(post hoc hypothesising): 연구 결과를 왜곡하는 또 다른 방법은 이른바 “데이터 마이닝”을 하는 것입니다(통계 분석에서 “갈림길의 정원(garden of forking paths)”의 일부로 이에 대해 더 광범위하게 논의한 Gelman and Loken, 2014를 참조하세요). 나중에 더 자세히 다루겠지만, 데이터를 여러 방식으로 분석하다 보면 결국 “진짜” 효과처럼 보이는, 그러나 실제로는 아닌 무언가를 발견하게 됩니다. 이것이 바로 데이터 마이닝입니다. 데이터 분석이 몇 주씩 걸리던 시절에는 드물었지만, 요즘은 강력한 통계 소프트웨어를 모든 컴퓨터에서 사용할 수 있게 되면서 매우 흔해졌습니다. 데이터 마이닝 그 자체는 “잘못된” 것은 아니지만, 이를 많이 할수록 위험은 커집니다. 진짜 문제는 인정을 하지 않는 데이터 마이닝(unacknowledged data mining)이며, 이는 매우 흔할 것으로 보입니다. 연구자가 가능한 모든 분석을 시도한 뒤, 성공한 하나를 찾아내고, 마치 그것이 처음부터 유일하게 수행한 분석인 것처럼 가장하는 것입니다. 심지어 데이터를 본 후 가설을 “발명”하여 데이터 마이닝을 은폐하는 경우도 많습니다. 명확히 하자면, 데이터를 본 뒤 자신의 믿음을 바꾸거나 새로운 “사후(post hoc)” 가설을 사용해 데이터를 다시 분석하는 것은 잘못된 것이 아닙니다. 그러나 문제는 자신이 그렇게 했음을 인정하지 않는 것입니다. 이를 인정하면 다른 연구자들이 해당 행동을 고려할 수 있지만, 그렇지 않으면 고려할 수 없게 되고, 이는 기만적입니다. 나쁘죠!\n\n\n\n\n\n\n\n통계 분석에서 ’Garden of Forking Paths’란?\n\n\n\n“Garden of Forking Paths”는 통계 분석에서 연구자가 데이터를 해석하거나 분석하는 과정에서 수많은 선택지를 만나게 되는 상황을 비유적으로 표현한 용어입니다. 이 개념은 2014년 심리학자 앤드루 젤먼(Andrew Gelman)과 에릭 로카넬라(Eric Loken)가 제시한 것으로, 실험 결과와 통계적 유의성이 실제보다 과장되거나 잘못 해석될 수 있는 원인을 설명하기 위해 사용되었습니다.\n이 표현은 아르헨티나 작가 호르헤 루이스 보르헤스의 소설 The Garden of Forking Paths에서 영감을 받았으며, 연구 과정에서 수많은 가능성의 갈림길이 존재한다는 점을 강조합니다.\n\n연구자는 실험 설계, 변수 선택, 데이터 전처리, 통계 분석 방법 등에서 다양한 선택을 내릴 수 있습니다.\n\n이러한 선택지 중 어느 길을 택하느냐에 따라 결과는 크게 달라질 수 있으며, 연구자들이 무의식적으로나 의도적으로 특정 결과를 유리하게 만드는 선택을 할 가능성이 있습니다.\n\n이는 명시적으로 다수의 가설을 검토하지 않았더라도, 암묵적으로 다양한 경로를 탐색한 것과 같은 효과를 낳아 p-value와 같은 통계적 유의성이 왜곡될 위험을 초래합니다.\n\n예를 들어 연구자는 연구과정에서 다음과 같은 선택을 할 수 있습니다.\n\n데이터 수집 후의 선택: 연구자가 실험 데이터를 분석하며 변수를 포함하거나 제외하거나, 특정 하위 그룹을 분석에서 포함시키거나 제외하는 등의 다양한 선택을 할 수 있습니다. 이러한 모든 선택은 결과에 영향을 미칠 수 있습니다.\n분석 방법의 사후 선택: 동일한 데이터를 사용하더라도 다양한 통계 기법(예: t-검정, 회귀 분석)을 사용할 수 있으며, 특정 방법이 유의미한 결과를 낳을 때까지 여러 방법을 시도할 가능성이 있습니다.\n발견적 탐색: 연구자가 명확한 가설 없이 데이터를 탐색하며 흥미로운 패턴을 찾고 이를 연구 결과로 발표하는 경우, 통계적 유의성이 진정한 결과가 아니라 우연히 발생한 것일 수 있습니다.\n\n“Garden of Forking Paths”는 연구자가 의도적으로 p-value를 조작하는 p-hacking과는 다릅니다. 여기서는 연구자가 명시적으로 조작하지 않아도, 선택 과정에서 자연스럽게 유의미해 보이는 결과가 도출될 수 있습니다. 이 현상은 연구 결과의 신뢰성과 재현성을 저하시켜, 특히 심리학과 같은 사회과학 분야에서 재현성 위기의 원인 중 하나로 지목됩니다.\n이러한 문제의 해결책으로 다음 방법들이 제안되고 있습니다.\n\n사전 등록(Pre-registration): 연구 설계와 가설, 분석 방법을 사전에 명시적으로 등록하면, 분석 중 경로를 변경하는 것을 방지할 수 있습니다.\n베이즈 통계 사용: 베이즈적 접근은 데이터 분석에서 사전 확률(prior probability)을 고려하기 때문에, 데이터에서 우연히 발견된 결과를 과대평가할 위험을 줄일 수 있습니다.\n전체 데이터 공개: 연구 데이터와 분석 코드를 공개하여 연구자의 선택이 결과에 미친 영향을 투명하게 보여줍니다.\n\n\n\n\n출판 편향(publication bias)과 자기 검열(self-censoring): 마지막으로, 널리 퍼진 편향 중 하나는 부정적인 결과를 “보고하지 않는” 것입니다. 이를 막는 것은 거의 불가능합니다. 학술지는 제출된 모든 논문을 출판하지 않습니다. “무언가를 발견한” 논문을 선호합니다. 예를 들어, 20명의 연구자가 인간이 피네간의 경야(Finnegans Wake)를 읽으면 정신이 이상해지는지 여부를 실험했는데, 그중 19명이 그렇지 않다는 결과를 얻었다고 합시다. 이 중 어떤 연구가 출판될 것 같습니까? 당연히 피네간의 경야가 정신 이상을 초래한다고 주장한 한 가지 연구일 것입니다.9 이것이 바로 출판 편향의 예입니다. 효과를 발견하지 못한 19개의 연구가 출판되지 않았기 때문에 순진한 독자는 그것들이 존재했다는 사실을 전혀 알 수 없습니다. 더 나쁜 것은, 대부분의 연구자가 이 편향을 “내면화”하여 스스로 연구를 검열한다는 점입니다. 부정적인 결과가 출판되지 않을 것을 알기 때문에, 애초에 시도조차 하지 않습니다. 제 친구 중 한 명은 “출판할 수 있는 실험 하나당 실패한 실험이 10개는 있다”고 말합니다. 그녀의 말이 맞습니다. 문제는, 그 실험들 중 일부(아마도 대부분)는 단순한 이유로 실패한 것이지만(예: 실수로 무언가를 잘못했을 때), 다른 일부는 진정한 “무효(null)” 결과일 수 있다는 점입니다. 그리고 “무효” 결과인지 단순 실패인지 구별하는 것은 종종 어렵습니다. 좋은 시작점은 Ioannidis (2005) 의 논문, 왜 대부분의 연구 결과는 거짓인가라는 제목의 우울한 글입니다. 또한, 심리학에서 이러한 현상이 실제로 발생한다는 통계적 증거를 제시한 Kühberger et al. (2014) 의 연구도 참고해 보세요.\n\n\n\n\n\n\n\n피네간의 경야\n\n\n\n피네간의 경야(Finnegans Wake)는 제임스 조이스가 1939년에 발표한 실험적이고 난해한 소설로, 꿈속에서 펼쳐지는 이야기를 통해 죽음과 재생, 순환이라는 주제를 탐구합니다. 전통적인 줄거리나 서사 구조를 따르지 않고, 다언어적 글쓰기와 언어유희, 신화적 상징으로 가득 차 있어 독자는 무한한 해석의 가능성을 마주하게 됩니다. 작품은 순환적 구조를 가지며 마지막 문장이 첫 문장과 연결되어 영원한 반복을 상징합니다.\n이 소설은 모더니즘 문학의 정점으로 평가되며, 언어와 서사 형식에 대한 혁신적 실험을 보여줍니다. 난해한 텍스트는 독창성과 함께 독자들에게 도전 과제를 던지며, 후대 문학과 예술에 깊은 영향을 미쳤습니다. 제목은 아일랜드 민요 “Finnegan’s Wake”에서 유래되어 죽음과 재생의 주제를 반영하며, 작품의 본질을 상징적으로 드러냅니다.\n\n\n이 외에도 생각해볼 문제가 아마 더 많을 것입니다. 하지만 이 정도로 시작하면 충분할 것입니다. 제가 정말로 강조하고 싶은 점은, 현실 세계의 과학은 실제 인간들에 의해 수행된다는 명백한 진실입니다. 그리고 다른 모든 사람이 정직하고 공정하다고 자동으로 가정하는 것은 가장 순진한 사람들만이 하는 일입니다. 실제 과학자들은 보통 그렇게 순진하지 않습니다. 하지만 세상은 우리가 그렇다고 생각하는 것을 좋아하며, 우리가 작성한 교과서는 그러한 고정관념을 강화하는 경향이 있습니다.",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연구 설계에 대한 간략한 소개</span>"
    ]
  },
  {
    "objectID": "02-A-brief-introduction-to-research-design.html#요약",
    "href": "02-A-brief-introduction-to-research-design.html#요약",
    "title": "2  연구 설계에 대한 간략한 소개",
    "section": "2.8 요약",
    "text": "2.8 요약\n이 장은 심리학 연구 방법에 대한 포괄적인 논의를 제공하기 위한 것이 아닙니다. 이 주제에 대해 충분히 논의하려면 이 책만큼 긴 또 다른 책이 필요할 것입니다. 그러나 실제로 통계와 연구 설계는 매우 밀접하게 얽혀 있기 때문에 몇 가지 주요 주제를 논의하는 것은 매우 유용합니다. 이 장에서 저는 다음 주제들을 간략히 다루었습니다.\n\n심리학적 측정에 대한 소개: 이론적 구성개념을 조작화한다는 것의 의미는 무엇인가요? 변수를 사용하고 측정을 한다는 것은 무엇을 의미할까요?\n측정 척도와 변수 유형: 여기에는 두 가지 구분이 있습니다. 이산 데이터와 연속 데이터의 차이, 그리고 네 가지 척도 유형(명목, 서열, 구간, 비율)의 차이가 있습니다.\n측정의 신뢰도를 평가하기: 동일한 대상을 두 번 측정한다면 동일한 결과를 기대해야 할까요? 이러한 기대는 측정이 신뢰할 수 있을 때만 가능합니다. 그런데 “동일한” 것을 측정한다고 말하는 것은 무엇을 의미할까요? 그래서 우리는 다양한 유형의 신뢰성에 대한 숙고가 필요합니다. 이들을 꼭 기억하세요.\n변수의 “역할”: 예측 변수와 결과 변수: 변수는 분석에서 어떤 역할을 합니까? 예측 변수와 결과 변수의 차이를 기억할 수 있나요? 종속 변수와 독립 변수는요?\n실험 연구와 비실험 연구의 설계: 실험이 실험인 이유는 무엇인가요? 그것은 멋진 흰색 실험복인가요, 아니면 연구자가 변수에 대해 통제력을 가진다는 점인가요?\n연구의 타당성 평가하기: 연구가 당신이 측정하기를 원하는 것을 제대로 측정하고 있습니까? 이것이 잘못될 수 있을까요? 이러한 논의는 단지 내 상상일까요, 아니면 연구가 잘못될 수 있는 실질적인 가능성의 긴 나열일까요?\n\n이 모든 것을 통해 연구 설계가 연구 방법론의 중요한 부분이라는 점이 분명해졌을 것입니다. 저는 이 장을 Campbell & Stanley (1963) 의 고전적인 책에서 가져왔지만, 연구 설계에 대한 교과서는 물론 많이 있습니다. 여러분이 좋아하는 검색 엔진을 몇 분만 사용해도 수십 권을 찾을 수 있을 것입니다.\n\n\n\n\nAdair, G. (1984). The hawthorne effect: A reconsideration of the methodological artifact. Journal of Applied Psychology, 69, 334–345. https://doi.org/10.1037/0021-9010.69.2.334\n\n\nCampbell, D. T., & Stanley, J. C. (1963). Experimental and quasi-experimental designs for research. Houghton Mifflin.\n\n\nHróbjartsson, A., & Gøtzsche, P. (2010). Placebo interventions for all clinical conditions. Cochrane Database of Systematic Reviews, 1. https://doi.org/10.1002/14651858.cd003974.pub3\n\n\nIoannidis, J. P. A. (2005). Why most published research findings are false. PLoS Med, 2(8), 697–701. https://doi.org/10.1371/journal.pmed.1004085\n\n\nKahneman, D., & Tversky, A. (1973). On the psychology of prediction. Psychological Review, 80, 237–251. https://doi.org/10.1037/h0034747\n\n\nKühberger, A., Fritz, A., & Scherndl, T. (2014). Publication bias in psychology: A diagnosis based on the correlation between effect size and sample size. Public Library of Science One, 9, 1–8. https://doi.org/10.1371/journal.pone.0105825\n\n\nPfungst, O. (1911). Clever hans (the horse of mr. Von osten): A contribution to experimental animal and human psychology (C. L. Rahn, Trans.). Henry Holt.\n\n\nRosenthal, R. (1966). Experimenter effects in behavioral research. Appleton.\n\n\nStevens, S. S. (1946). On the theory of scales of measurement. Science, 103, 677–680. https://doi.org/10.1126/science.103.2684.677",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연구 설계에 대한 간략한 소개</span>"
    ]
  },
  {
    "objectID": "02-A-brief-introduction-to-research-design.html#footnotes",
    "href": "02-A-brief-introduction-to-research-design.html#footnotes",
    "title": "2  연구 설계에 대한 간략한 소개",
    "section": "",
    "text": "1938년 제1회 인도 통계학회에서의 회장 연설. 출처: https://en.wikiquote.org/wiki/Ronald_Fisher↩︎\n&lt;역주&gt; 구간 척도를 간격 척도라고도 합니다.↩︎\n물리학 지식이 더 풍부한 독자들로부터 들은 바에 따르면, 온도는 엄밀히 말하면 구간 척도가 아닙니다. 물체를 3°C만큼 데우는 데 필요한 에너지는 현재 온도에 따라 달라지기 때문입니다. 따라서 물리학자들이 관심을 가지는 관점에서는, 온도는 구간 척도가 아닙니다. 그러나 이 예는 여전히 적절하고, 불편한 진실은 무시하겠습니다.↩︎\n아, 심리학이란… 명확한 답을 얻기 힘들죠!↩︎\n하지만 짜증나게도 이와 관련하여 사용되는 용어가 정말 많습니다. 모두 나열할 필요는 없겠지만, 제가 “결과 변수”라고 부른 것을 “반응 변수(response variable)”라고 부르는 경우도 있다는 점만 언급하겠습니다. 이런 용어 혼란은 정말 흔합니다.↩︎\n교란 요인이 “측정되지 않았다”고 말한 이유는, 측정했다면 교란 요인을 다루기 위한 고급 통계 기법을 사용할 수 있기 때문입니다. 교란 요인 문제를 해결하기 위한 통계적 솔루션이 존재하기 때문에, 우리가 측정하고 다룬 교란 요인을 “공변량”(covariate)이라고 부르기도 합니다. 공변량을 다루는 것은 더 고급 주제이지만, 이러한 기법이 존재한다는 것을 아는 것만으로도 위안을 줄 수 있으므로 간략히 언급해 보았습니다.↩︎\n&lt;역주&gt; 요구 특성(demand characteristics)이라고도 합니다.↩︎\n일부 사람들은 정직하지 않다면 진정한 과학자가 아니라고 주장할 수도 있습니다. 이 말에는 어느 정도 진실이 담겨 있을지 모르지만, 이는 교묘한 말장난에 불과합니다(“진정한 스코틀랜드인” 오류를 찾아보세요). 사실은 과학자처럼 고용되어 과학의 외형을 갖춘 일을 하지만 완전히 부정직한 사람들이 많다는 점입니다. 그들을 과학자가 아니라고 말하며 존재를 부정하는 것은 혼란스러운 사고일 뿐입니다.↩︎\n분명한 사실은, 피네간의 경야를 읽어볼 생각을 하는 사람은 애초에 제정신이 아니라는 점입니다.↩︎",
    "crumbs": [
      "시작하며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>연구 설계에 대한 간략한 소개</span>"
    ]
  },
  {
    "objectID": "03-Getting-started-with-jamovi.html",
    "href": "03-Getting-started-with-jamovi.html",
    "title": "3  jamovi 시작하기",
    "section": "",
    "text": "3.1 jamovi 설치하기\n좋습니다. 이제 홍보는 그만하고 시작해 봅시다. 다른 모든 소프트웨어와 마찬가지로, jamovi를 사용하려면 “컴퓨터”에 설치해야 합니다. 컴퓨터란 멋진 일들을 하고, 무료 조랑말도 제공하는 마법 상자 같은 것입니다. 아니면, 이런 설명은 iPad 마케팅 캠페인과 컴퓨터를 혼동했을 수도 있겠네요. 어쨌든, jamovi는 온라인에서 무료로 배포되며 https://www.jamovi.org/에서 다운로드할 수 있습니다.\n페이지 상단의 “Download”라는 제목 아래, Windows 사용자, Mac 사용자, Linux 사용자를 위한 별도의 링크를 볼 수 있습니다. 관련 링크를 클릭하면 온라인 설명이 꽤 직관적임을 알 수 있습니다. 이 글을 쓰는 시점에서 jamovi의 현재 버전은 2.3이지만, 보통 몇 달마다 업데이트가 이루어지므로 여러분이 사용하는 버전은 더 최신일 가능성이 높습니다.3",
    "crumbs": [
      "jamovi 소개",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>jamovi 시작하기</span>"
    ]
  },
  {
    "objectID": "03-Getting-started-with-jamovi.html#jamovi-설치하기",
    "href": "03-Getting-started-with-jamovi.html#jamovi-설치하기",
    "title": "3  jamovi 시작하기",
    "section": "",
    "text": "실습: jamovi 내려받아 설치하기\n\n\n\n2025년 1월 28일 현재 jamovi의 홈페이제에 접속하면 ‘jamovi Cloud’와 ’jamovi Desktop’ 버전이 나타납니다. 이 책에서는 jamovi를 컴퓨터에 직접 설치하는 jamovi Desktop 버전을 기준으로 설명합니다.\n\n\n\n\n\n\n\n\n\n‘jamovi Desktop’을 클릭하면 운영체제 별로 jamovi를 다운로드 받을 수 있는 페이지가 나타납니다. 접속 시점에 안정 버전(’solid’)과 가장 최신 버전(‘current’)를 다운로드 받을 수 있습니다. 소프트웨어의 버그를 탐색하는 것을 주저하지 않거나 꼭 필요한 기능이 최신 버전에만 제공되는 경우가 아니라면 안정 버전(‘solid’)를 클릭하여 다운로드 받을 것을 권장합니다.\n\n\n\n\n\n\n\n\n\n다운로드 받은 파일을 실행하면 설치할 것인지 묻는데, ’Install’을 선택하면 설치가 진행됩니다. 설치가 완료되면 ’Finish’를 클릭하여 설치를 종료합니다.\n\n\n\n3.1.1 jamovi 시작하기\n어떤 운영체제를 사용하든 jamovi를 실행하고 시작할 시간입니다. jamovi를 처음 시작하면 Figure 3.1 같은 사용자 인터페이스가 나타납니다.\n\n\n\n\n\n\n\n\nFigure 3.1. jamovi 시작 화면!\n\n\n\n\n\n왼쪽에는 스프레드시트 뷰가 있고, 오른쪽에는 통계 분석 결과가 표시되는 영역이 있습니다. 가운데에는 이 두 영역을 나누는 막대가 있으며, 이를 왼쪽 또는 오른쪽으로 드래그하여 크기를 조정할 수 있습니다.\n\n\n\n\n\n\n실습: jamovi에서 한글 설정하기\n\n\n\njamovi를 설치한 후 실행하면 메뉴가 영문으로 나오는데, 한글 메뉴가 나오도록 설정해 봅시다.\n\njamovi의 상단의 오른쪽 상단의 애플리케이션 메뉴(점 세 개로 표시됨)을 선택합니다.\n애플리케이션 메뉴의 ‘Language’ 드롭다운 상자에서 ’한국어’를 선택합니다. 그러면 언어 설정을 변경하려면 jamovi를 재시작해야 한다는 안내 상자가 나타납니다. 확인을 클릭합니다.\n\n\n\n\n\n\n\n\n\n\n\njamovi를 껐다가 다시 시작하면 다음처럼 한글로 메뉴가 나타납니다.\n\n\n\n\n\n\n\n\n\n\n\n\njamovi 스프레드시트에 다른 스프레드시트 소프트웨어처럼 직접 값을 입력할 수 있습니다. 또는 CSV(.csv) 형식의 기존 데이터 세트를 jamovi에서 열 수 있습니다. 뿐만 아니라 SPSS, SAS, STATA, JASP 파일도 jamovi로 직접 쉽게 가져올 수 있습니다. 파일을 열려면 왼쪽 상단의 ‘파일’4 탭(세 개의 가로선으로 표시됨)을 선택하고, ’열기’를 선택한 다음, ’데이터 라이브러리’에서 예제 파일이나, ’이 컴퓨터’에서 ’탐색’에 표시된 목록에서 컴퓨터에 저장된 파일 중 원하는 것을 선택하면 됩니다.\n\n\n\n\n\n\n실습: 예제 파일 열기\n\n\n\njamovi가 제공하는 Tooth Growth라는 예제 파일을 열어 봅시다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 선택합니다.\n목록에서 ’Tooth Growth’를 클릭합니다.\n\n\n\n\n\n\n\n\n\n\n그러면 다음과 왼쪽 스프레드시트 뷰에 다음과 같이 3 개의 열로 구성된 데이터 세트가 표시될 것입니다. 이 데이터는 비타민 C를 제공하는 방식과 복용량에 따라 기니피그의 치아 모세포의 길이가 어떻게 달라지는를 실험한 데이터입니다.\n\n‘len’: 치아 모세포의 길이\n‘supp’: 보충 유형 (VC: 비타민 C vs. OJ: 오렌지 주스)\n‘dose’: 비타민 C 복용량 (mg/일)",
    "crumbs": [
      "jamovi 소개",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>jamovi 시작하기</span>"
    ]
  },
  {
    "objectID": "03-Getting-started-with-jamovi.html#분석",
    "href": "03-Getting-started-with-jamovi.html#분석",
    "title": "3  jamovi 시작하기",
    "section": "3.2 분석",
    "text": "3.2 분석\n분석은 상단에 있는 ‘분석’ 리본 또는 메뉴에서 선택할 수 있습니다. 특정 분석을 선택하면 해당 분석의 ’옵션 패널’이 왼쪽에 표시되며, 여기에서 다양한 변수를 분석의 각 부분에 할당하고 다양한 옵션을 선택할 수 있습니다. 동시에, 분석 결과는 오른쪽 ’결과 패널’에 표시되며, 옵션을 변경할 때마다 분석 결과가 실시간으로 업데이트됩니다.\n분석 설정을 올바르게 완료했다면, 옵션 패널의 오른쪽 상단에 있는 화살표를 클릭하여 옵션 패널을 닫을 수 있습니다. 나중에 이 옵션으로 돌아가고 싶다면, 생성된 결과를 클릭하면 됩니다. 이렇게 하면 여러분(또는 동료)이 이전에 만든 분석으로 언제든지 돌아갈 수 있습니다.\n더 이상 특정 분석이 필요 없다고 판단되면, 결과 패널의 컨텍스트 메뉴를 사용하여 분석을 제거할 수 있습니다. 분석 결과를 오른쪽 클릭하면 메뉴가 나타나며, 여기에서 ’Analysis’를 선택한 다음 ’Remove’를 선택하면 분석을 제거할 수 있습니다. 하지만 이에 대한 자세한 내용은 나중에 다룰 것입니다. 우선 스프레드시트 뷰를 좀 더 자세히 살펴봅시다.\n\n\n\n\n\n\n실습: 데이터 탐색\n\n\n\njamovi가 제공하는 Tooth Growth라는 예제 데이터를 탐색해 봅시다.\n\n‘분석’-‘기술통계’-’기술통계’를 선택합니다.\n왼편에 나타나는 기술통계 옵션 패널에서 다음을 수행합니다.\n\n\n‘len’ 변수를 선택하여 ‘변수’ 상자에 할당합니다.\n그러면 오른편의 결과 패널에 다음과 같이 ‘len’ 변수의 평균, 중앙값, 표준편차 등의 통계량이 계산됩니다.\n\n\n\n\n\n\n\n\n\n\n\n치아 모세포 길이(‘len’)이 복용량(‘dose’)에 영향을 받는지를 확인하기 위하여 왼쪽 패널에서 다음을 수행합니다.\n\n\n‘dose’ 변수를 ‘split by’ 상자에 할당합니다.\n그러면 ‘len’이 ’dose’ 값 별로 분해되어 통계량이 계산됩니다.\n너무나 많은 통계량이 제시되어 번잡한 느낌입니다. 하단의 ’통계’를 클릭하여 ’사례’와 ’평균’을 제외하고 다른 통계량은 체크를 해제합니다.\n복용량 별 치아 모세포의 평균을 살펴보면 복용량이 많을수록 평균이 커지는 경향을 확인할 수 있습니다.\n\n\n\n\n\n\n\n\n\n\n\n복용량에 따른 치아 모세포의 길이의 분포를 확인하기 위하여 상자 그래프를 그려봅시다.\n\n\n왼편 패널 아래의 ’도표’를 선택하면 그릴 수 있는 도표가 나타납니다.\n’히스토그램’을 선택하여 복용량 별로 치아 모세포 길이의 히스토그램을 그려봅니다.\n\n\n\n\n\n\n\n\n\n\n\n왼편의 옵션 패널의 화살표를 클릭하여 옵션 패널을 닫습니다.",
    "crumbs": [
      "jamovi 소개",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>jamovi 시작하기</span>"
    ]
  },
  {
    "objectID": "03-Getting-started-with-jamovi.html#스프레드시트",
    "href": "03-Getting-started-with-jamovi.html#스프레드시트",
    "title": "3  jamovi 시작하기",
    "section": "3.3 스프레드시트",
    "text": "3.3 스프레드시트\njamovi에서 데이터는 스프레드시트로 표현되며, 각 열은 ‘변수’를, 각 행은 ’사례(case)’ 또는 ’참가자(participant)’를 나타냅니다.\n\n3.3.1 변수(Variables)\njamovi에서 가장 일반적으로 사용되는 변수는 ’데이터 변수(Data variables)’입니다. 이러한 변수는 데이터 파일에서 로드되거나 사용자가 ’직접 입력’한 데이터를 단순히 포함합니다. 데이터 변수는 여러 측정 수준 중 하나를 가질 수 있습니다(Figure 3.2).\n\n\n\n\n\n\n\n\nFigure 3.2. 측정 수준\n\n\n\n\n\n이 측정 수준은 변수 열 헤더의 기호로 표시됩니다. 아이디 변수 유형은 분석에 사용하지 않을 식별자를 나타내는 변수에 사용됩니다. 예를 들어, 사람의 이름이나 참여자 ID가 이에 해당합니다. ID 변수 유형을 지정하면 매우 큰 데이터 세트를 다룰 때 처리 성능이 향상될 수 있습니다.\n\n명목형(Nominal) 또는 명명척도 변수는 텍스트 레이블로 구성된 범주형 변수입니다. 예를 들어, ‘male’과 ’female’ 값을 가질 수 있는 ‘gender’라는 열은 명목형 변수입니다. 사람의 이름도 명목형 변수에 해당합니다. 명목형 변수는 숫자 값도 가질 수 있습니다. 이는 범주가 텍스트 대신 숫자로 코딩된 데이터를 가져올 때 가장 자주 사용됩니다. 예를 들어, 데이터 세트의 한 열이 남성을 나타내는 값으로 1, 여성을 나타내는 값으로 2를 사용할 수 있습니다. 변수 편집기를 사용하면 이러한 값에 ’사람이 읽을 수 있는(human-readable)’ 레이블을 추가할 수 있습니다(이 부분은 이후에 자세히 설명합니다).\n서열형(Ordinal) 또는 서열척도 변수는 명목형 변수와 비슷하지만, 값에 특정 순서가 있습니다. 예를 들어, 리커트 척도에서 3은 ‘매우 동의’, -3은 ’매우 반대’를 나타냅니다.\n연속형(Continuous) 변수 또는 연속변수는 연속 척도 상에 존재하는 변수입니다. 키나 몸무게가 그 예입니다. 이는 ‘구간(Interval)’ 또는 ’비율(Ratio) 척도’라고도 합니다.\n\n추가적으로, 변수는 데이터 유형이 ‘텍스트(Text)’, ‘정수(Integer)’, 또는 ’소수(Decimal)’인지 지정할 수 있습니다.\n빈 스프레드시트에서 값을 입력하기 시작하면, 입력한 데이터에 따라 변수 유형이 자동으로 변경됩니다. 이를 통해 어떤 변수 유형이 어떤 데이터와 적합한지 감을 잡을 수 있습니다. 마찬가지로, 데이터 파일을 열면 jamovi는 각 열의 데이터를 기반으로 변수 유형을 추정하려고 합니다. 그러나 이 자동 접근 방식이 항상 정확하지는 않으므로 변수 편집기를 사용하여 변수 유형을 수동으로 지정해야 할 수도 있습니다.\n변수 편집기는 데이터 탭에서 ‘Setup’을 선택하거나 변수 열 헤더를 더블 클릭하여 열 수 있습니다. 변수 편집기를 통해 변수 이름, 변수 유형, 수준의 순서, 각 수준에 표시되는 레이블을 변경할 수 있습니다. 변경 사항은 오른쪽 상단의 ’체크 표시(tick)’를 클릭하여 적용할 수 있습니다. 변수 편집기는 ’Hide’ 화살표를 클릭하여 닫을 수 있습니다.\n새 변수를 데이터 세트에 삽입하거나 추가하려면 데이터 리본의 ‘Add’ 버튼을 사용합니다. ‘Add’ 버튼을 통해 계산된 변수(computed variable)도 추가할 수 있습니다.\n\n\n\n\n\n\n실습: 변수 설정\n\n\n\njamovi가 제공하는 Tooth Growth라는 예제 데이터의 변수가 어떻게 설정되어 있는지 확인해 봅시다.\n\n‘len’ 열의 헤더를 더블클릭합니다. 그러면 다음처럼 데이터 변수를 설정하는 패널이 상단에 나타납니다.\n\n\n변수의 ‘척도 유형(measurement type)’은 ’연속변수(continuous)’\n‘데이터 유형(data type)’은 ’소수(decimal)’\n연속변수이므로 측정 수준(levels)은 정의되지 않습니다.\n\n\n\n\n\n\n\n\n\n\n\n‘supp’ 열의 헤더를 더블클릭하거나 상단의 데이터 변수 패널에서 오른쪽 화살표를 클릭합니다. 그러면 ‘supp’ 데이터 변수를 설정하는 패널이 나타납니다.\n\n\n변수의 ‘척도 유형(measurement type)’은 ’명목척도(nominal)’\n‘데이터 유형(Data type)’은 ’텍스트(text)’\n측정 수준(levels)은 OJ와 VC로 설정되어 있습니다.\n\n\n\n\n\n\n\n\n\n\n\n상단의 데이터 변수 패널에서 위 화살표를 클릭하여 변수 패널을 숨기도록 합시다.\n\n\n\n\n\n3.3.2 계산 변수(Computed Variables)\n계산 변수는 다른 변수를 연산하여 값을 얻는 변수입니다. 계산 변수는 로그 변환, z-점수, 합산 점수, 역채점(negative scoring), 평균 등 다양한 용도로 사용될 수 있습니다.\n계산 변수는 데이터(Data) 탭에서 ‘추가(Add)’ 버튼을 사용하여 데이터 세트에 추가할 수 있습니다. 이를 클릭하면 수식을 지정할 수 있는 수식 상자가 나타납니다. 일반적인 산술 연산자가 사용 가능합니다. 다음은 몇 가지 수식 예제입니다:\nA + B\nLOG10(len)\nMEAN(A, B)\n(len - VMEAN(len)) / VSTDEV(len)\n이 예제는 각각 A와 B의 합, len의 로그(밑 10) 변환, A와 B의 평균, 그리고 변수 len의 z-점수를 계산한 것입니다.5 Figure 3.3 은 len 변수의 z-점수로 계산된 새로운 변수를 보여줍니다(예제 데이터 세트 ‘Tooth Growth’ 사용).\n\n\n\n\n\n\n실습: 계산 변수 추가\n\n\n\njamovi가 제공하는 Tooth Growth라는 예제 데이터에서 ‘len’ 변수를 z-점수화한 ’zscore-len’라는 변수를 추가해 봅시다.\n\n‘데이터’-‘추가’-‘다중 계산 변수’-‘추가(Append)’ 메뉴를 클릭하여 데이터의 맨 마지막 열에 새로운 계산 변수를 추가합니다.\n추가된 열의 헤더를 더블클릭하여 ‘다중 계산 변수(computed variable)’ 패널이 상단에 나타나도록 합니다.\n‘다중 계산 변수’ 패널의 맨 위의 입력 상자에 ’zscore-len’이라는 변수 이름을 입력합니다.\n‘다중 계산 변수’ 패널의 오른쪽 아래의 수식 입력 상자(= 표시가 있는 입력 상자)에 다음 수식을 입력합니다. (변수와 함수 이름은 대소문자를 구분합니다.)\n\n(len -VMEAN(len)) / VSTDEV(len)\n\n입력이 완료되었으면 ‘다중 계산 변수’ 패널의 위 화살표를 클릭하여 패널을 숨깁니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.3. dose의 z-점수로 계산된 새 변수\n\n\n\n\n\n\n3.3.2.1 V-함수\nJamovi에는 이미 여러 가지 함수가 준비되어 있으며, 이는 \\(f_x\\)로 표시된 드롭다운 상자에서 사용할 수 있습니다. 여러 함수는 쌍으로 나타나며, 하나는 V로 접두어가 붙고 다른 하나는 그렇지 않습니다. V 함수는 변수 전체에 대해 계산을 수행하는 반면, 비-V 함수는 행별로 계산을 수행합니다. 예를 들어, MEAN(A, B)는 각 행에 대해 A와 B의 평균을 계산합니다. 반면, VMEAN(A)는 A의 모든 값에 대한 평균을 계산합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.3 복사 및 붙여넣기\nJamovi는 미국심리학회(APA) 형식으로 잘 형식화된 표와 매력적인 그래프를 생성합니다. 이 결과를 Word 문서에 붙여넣거나, 동료에게 이메일로 공유하는 등 복사 및 붙여넣기를 할 수 있는 기능이 유용할 때가 많습니다. 결과를 복사하려면, 관심 있는 객체를 마우스 오른쪽 버튼으로 클릭한 다음, 메뉴에서 복사하고자 하는 범위를 선택합니다. 메뉴를 통해 이미지만 복사하거나 전체 분석을 복사할 수 있습니다. ’복사(Copy)’를 선택하면 콘텐츠가 클립보드에 복사되며, 이를 일반적인 방법으로 다른 프로그램에 붙여넣을 수 있습니다. 이후 분석을 진행하면서 이를 연습해 볼 기회가 있을 것입니다.\n\n\n3.3.4 구문 모드(Syntax mode)\nJamovi는 ‘R 구문 모드(R Syntax mode)’도 제공합니다.6 이 모드에서는 Jamovi가 각 분석에 대해 \\(R\\) 코드를 생성합니다. 구문 모드로 전환하려면 Jamovi의 오른쪽 상단에 있는 ’애플리케이션(Application)’ 메뉴(세로로 배열된 세 개의 점 버튼)를 선택하고, 거기에서 ‘구문모드(Syntax mode)’ 확인란을 클릭하십시오. 구문 모드를 끄려면 이 확인란을 다시 클릭하면 됩니다.\n구문 모드에서는 분석이 이전과 동일하게 작동하지만, 이제 \\(R\\) 구문과 \\(R\\) 세션에서 나타나는 “ASCII 출력”을 생성합니다. Jamovi의 모든 결과와 마찬가지로, 이러한 항목(특히 \\(R\\) 구문 포함)을 마우스 오른쪽 버튼으로 클릭하여 복사 및 붙여넣기 할 수 있습니다. 예를 들어, 이를 \\(R\\) 세션에 붙여넣을 수 있습니다. 다만, 제공되는 \\(R\\) 구문에는 데이터 가져오기 단계가 포함되어 있지 않으며, 이는 \\(R\\)에서 수동으로 수행해야 합니다. \\(R\\)에서 데이터를 가져오는 방법에 대한 많은 자료가 있으니 관심이 있다면 인터넷 검색을 통해 이러한 자료를 참고해 보시길 권장합니다.",
    "crumbs": [
      "jamovi 소개",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>jamovi 시작하기</span>"
    ]
  },
  {
    "objectID": "03-Getting-started-with-jamovi.html#jamovi로-데이터-가져오기",
    "href": "03-Getting-started-with-jamovi.html#jamovi로-데이터-가져오기",
    "title": "3  jamovi 시작하기",
    "section": "3.4 jamovi로 데이터 가져오기",
    "text": "3.4 jamovi로 데이터 가져오기\n데이터 분석을 수행할 때 사용할 가능성이 높은 파일 형식은 여러 가지가 있지만, 이 책의 관점에서 특히 중요한 두 가지가 있습니다:\n\njamovi 파일은 .omv 파일 확장자를 가진 파일입니다. 이는 jamovi가 데이터를 저장하고, 변수 및 분석을 관리하는 표준 파일 형식입니다.\nCSV(comma seprated values) 파일은 .csv 파일 확장자를 가진 파일입니다. 이러한 파일은 일반적인 텍스트 파일로, 여러 소프트웨어에서 열 수 있습니다. 데이터가 단순하기 때문에 사람들이 데이터를 CSV 파일로 저장하는 경우가 흔합니다.\n\n그 외에도 jamovi로 가져올 수 있는 다양한 데이터 파일 형식이 있습니다. 예를 들어, Microsoft Excel 스프레드시트(.xls 파일)나 SPSS 또는 SAS 같은 다른 통계 소프트웨어의 고유 파일 형식을 열 수도 있습니다. 어떤 파일 형식을 사용하든 jamovi 데이터 세트 및 분석을 위한 전용 폴더를 만들고, 이를 정기적으로 백업하는 것이 좋습니다.\n\n3.4.1 CSV 파일에서 데이터 가져오기\n많이 사용되는 데이터 형식 중 하나는 CSV 파일입니다. 이러한 파일은 단순한 텍스트 파일로, 기본적으로 데이터를 테이블 형태로 저장합니다. Figure 3.4 에 CSV 파일의 예를 볼 수 있습니다. 예로 든 booksales.csv 파일에는 한 달 동안의 책 판매 데이터를 나타내는 행이 있습니다. 첫 번째 행은 실제 데이터가 아니라 변수 이름이 들어 있습니다.\n\n\n\n\n\n\n\n\nFigure 3.4. booksales.csv 데이터 파일. 왼쪽에서는 스프레드시트 프로그램으로 파일을 열었으며, 이는 파일이 기본적으로 테이블 형식임을 보여줍니다. 오른쪽에서는 동일한 파일을 일반 텍스트 편집기(TextEdit)로 열었으며, 파일이 쉼표로 구분된 형식으로 저장되어 있음을 보여줍니다.\n\n\n\n\n\njamovi에서 CSV 파일을 여는 것은 간단합니다. 왼쪽 상단 메뉴(세 개의 평행선 버튼)에서 ‘열기’를 선택하고, 컴퓨터에 저장된 CSV 파일 위치를 찾아봅니다. Mac에서는 일반적인 Finder 창이 나타날 것이며, Windows에서는 Explorer 창이 표시됩니다. Mac에서 보이는 예는 Figure 3.5 에 나와 있습니다. 자신의 컴퓨터에 익숙하다는 가정하에, 가져오고 싶은 CSV 파일을 찾는 데 문제가 없을 것입니다! 원하는 파일을 찾은 다음, ’열기’ 버튼을 클릭하세요.\n\n\n\n\n\n\n\n\nFigure 3.5. Mac에서 jamovi가 가져올 CSV 파일을 선택하도록 요청하는 대화 상자. Mac 사용자는 이를 즉시 인식할 수 있으며, 이는 파일을 찾을 때 Mac이 일반적으로 사용하는 방식입니다. Windows 사용자는 이와 다르게, Windows의 일반적인 Explorer 창이 나타날 것입니다.\n\n\n\n\n\n데이터가 올바르게 가져오려면 다음 사항을 확인하여야 합니다:\n\n헤더(Heading): 파일의 첫 번째 행이 각 변수의 이름을 포함한 ‘헤더’ 행인가요? booksales.csv 파일에는 헤더가 있으므로, 이 경우는 “예”입니다.\n\n소수점(Decimal): 소수점을 지정하는 데 어떤 문자가 사용되나요? 영어권 국가에서는 거의 항상 마침표(.)를 사용합니다. 하지만 이는 보편적이지 않으며, 유럽의 많은 국가에서는 쉼표를 사용합니다.\n\n인용부호(Quote): 텍스트 블록을 나타내는 데 어떤 문자가 사용되나요? 일반적으로 큰따옴표(“)를 사용하며, booksales.csv 파일도 그렇습니다.\n\n\n\n\n\n\n\n실습: CSV 파일 열기\n\n\n\n\n다음 링크에서 booksales.csv 파일을 다운로드 받는다.\n\n\n\nDownload booksales.csv\n\n\n\nbooksales.csv 파일을 Excel 등의 스프레드시트 프로그램으로 열어 본다.\nbooksales.csv 파일을 메모장 등의 텍스트 편집기로 열어 본다.\n‘파일’-‘열기’-‘이 컴퓨터’-’탐색’을 메뉴를 선택한다.\n탐색기에서 booksales.csv 파일을 찾아서 연다.",
    "crumbs": [
      "jamovi 소개",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>jamovi 시작하기</span>"
    ]
  },
  {
    "objectID": "03-Getting-started-with-jamovi.html#다양한-형식의-데이터-파일-가져오기",
    "href": "03-Getting-started-with-jamovi.html#다양한-형식의-데이터-파일-가져오기",
    "title": "3  jamovi 시작하기",
    "section": "3.5 다양한 형식의 데이터 파일 가져오기",
    "text": "3.5 다양한 형식의 데이터 파일 가져오기\n이 책에서는 데이터가 jamovi의 .omv 파일이나 “적절히” 형식화된 csv 파일로 저장되어 있다고 가정했습니다. 그러나 실제로는 이러한 가정이 항상 현실적이지는 않으므로, 여러분이 마주칠 수 있는 다른 가능성들에 대해 이야기해 보겠습니다.\n\n3.5.1 텍스트 파일에서 데이터 불러오기\n데이터가 텍스트 파일로 저장되어 있지만 제대로 된 CSV 형식이 아닐 경우에도, jamovi가 파일을 열 수 있는 가능성이 꽤 큽니다. 그냥 시도해 보고 되는지 확인해 보면 됩니다. 하지만 때로는 데이터 파일에서 몇 가지 형식을 수정해야 할 수도 있습니다. 제가 자주 수정해야 했던 사항은 다음과 같습니다:\n\n헤더(header): CSV 파일로 데이터를 저장할 때 첫 번째 행이 데이터가 아닌 열 이름을 포함하는 경우가 많습니다. 만약 그렇지 않다면 Open Office나 Excel 같은 스프레드시트 프로그램에서 CSV 파일을 열어 헤더 행을 수동으로 추가하는 것이 좋습니다.\n\n구분자(sep): “쉼표로 구분된 값”이라는 이름처럼, CSV 파일의 각 행의 값은 보통 쉼표로 구분됩니다. 하지만 이러한 규칙이 항상 지켜지지는 않습니다. 예를 들어, 유럽에서는 소수점을 쉼표(,)로 표기하는 경우가 많아 쉼표 대신 세미콜론(;)을 구분자로 사용하는 경우가 있습니다. 때로는 탭(TAB) 문자도 사용됩니다.\n\n인용부호(quote): CSV 파일에서는 텍스트 데이터를 위해 인용 문자를 포함하는 것이 관례입니다. 예를 들어, booksales.csv 파일에서 볼 수 있듯이, 보통 큰따옴표(“)를 사용하여 텍스트 데이터를 감싸줍니다. 하지만 어떤 경우에는 인용 문자가 전혀 없거나, 대신 작은따옴표(’)가 사용되기도 합니다.\n\n건너뛰기(skip): CSV 파일의 처음 몇 행이 실제 데이터와 관련이 없는 경우가 종종 있습니다. 이러한 행은 데이터 출처에 대한 요약 정보를 제공하거나 기술 정보를 포함할 수 있습니다.\n\n결측값(missing values): 종종 결측값이 포함된 데이터를 받게 됩니다. 표의 일부 항목이 비어 있는 경우 특별한 값으로 결측값을 표시해야 합니다. 기본적으로 jamovi는 숫자와 텍스트 데이터 모두에 대해 결측값으로 99를 가정합니다.7 따라서 CSV 파일의 모든 결측값을 jamovi에 파일을 열거나 가져오기 전에 99(또는 -9999 등 선택한 값)로 대체해야 합니다. jamovi에서 파일을 열거나 가져오면, 모든 결측값이 jamovi 스프레드시트 뷰에서 빈 셀이나 회색 셀로 변환됩니다. ‘데이터’-‘설정’(Data - Setup) 메뉴에서 각 변수의 결측값을 변경할 수도 있습니다.\n\n\n\n3.5.2 SPSS(및 기타 통계 패키지)에서 데이터 불러오기\n지금가지 설명한 명령어가 이 책에서 다룰 데이터 파일에 대한 주요 내용입니다. 하지만 실제로는 더 많은 가능성이 있습니다. 예를 들어, 다른 통계 프로그램에서 데이터를 읽어와야 할 수도 있습니다. SPSS는 심리학에서 가장 널리 사용되는 통계 패키지이기 때문에, jamovi가 SPSS 데이터 파일(.sav 확장자)도 가져올 수 있다는 점을 언급할 가치가 있습니다. CSV 파일을 여는 방법과 동일한 절차를 따르되, 이번에는 가져오고자 하는 .sav 파일을 선택하면 됩니다. SPSS 파일의 경우, SPSS에서 “시스템 결측값”으로 간주되는 모든 값은 jamovi에서도 결측값으로 간주합니다. 하지만 SPSS 파일을 가져올 때 ’기본 결측값(Default missings)’은 예상대로 작동하지 않을 수 있습니다. 따라서 추가적인 단계가 필요할 수 있습니다: SPSS 파일을 jamovi로 가져온 후 CSV 파일로 내보낸 다음 jamovi에서 다시 여는 것입니다.8\nSPSS 관련 내용은 이것으로 충분합니다. 그 외 통계 소프트웨어에 대해 말하자면, jamovi는 SAS 및 STATA 파일도 직접 열거나 가져올 수 있습니다.\n\n\n3.5.3 Excel 파일 불러오기\nExcel 파일은 또 다른 문제를 제기합니다. 독점 데이터 형식으로 데이터를 보내지 말라고 여러 해 동안 부탁해 왔음에도 불구하고 여전히 많은 Excel 파일을 받습니다. Excel 파일을 처리하는 방법은 먼저 Excel 또는 Excel 파일을 처리할 수 있는 다른 스프레드시트 프로그램에서 파일을 열고, 데이터를 CSV 파일로 내보낸 후 jamovi에서 CSV 파일을 열거나 가져오는 것입니다.",
    "crumbs": [
      "jamovi 소개",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>jamovi 시작하기</span>"
    ]
  },
  {
    "objectID": "03-Getting-started-with-jamovi.html#sec-Changing-data-from-one-level-to-another",
    "href": "03-Getting-started-with-jamovi.html#sec-Changing-data-from-one-level-to-another",
    "title": "3  jamovi 시작하기",
    "section": "3.6 변수 유형 변경하기",
    "text": "3.6 변수 유형 변경하기\n가끔 변수를 다른 유형으로 변경해야 할 때가 있습니다. 이는 여러 가지 이유로 발생할 수 있습니다. 파일에서 데이터를 가져올 때 잘못된 형식으로 가져올 수 있습니다. 숫자가 명목(nominal) 텍스트 형식으로, 날짜가 텍스트 형식으로 읽힐 수도 있습니다. 참여자 ID 값이 연속형(continuous)으로 읽히거나 명목값이 서열(ordinal) 또는 연속형으로 읽힐 수도 있습니다. 변수를 한 측정 유형에서 다른 유형으로 변환해야 할 경우가 있을 것입니다. 이를 올바른 용어로 표현하자면, 변수를 형변환(coerce)하여 다른 유형으로 변경하는 것입니다.\n이전에 다양한 변수 유형을 지정하는 방법을 살펴봤습니다. 변수를 다른 측정 유형으로 변경하려면 jamovi 데이터 뷰에서 해당 변수의 측정 유형을 클릭하여 연속형(continuous), 서열(ordinal), 명목(nominal) 중에서 원하는 유형을 선택하면 됩니다.\n\n\n\n\n\n\n실습: CSV 파일 열기\n\n\n\nbooksales.csv 파일을 jamovi로 열면 다음처럼 모든 변수들이 명목형으로 되어 있을 것입니다.\n\n\n\n\n\n\n\n\n\n서점의 운영 일자인 ’Days’와 서점의 매울 ’Sales’는 연속변수이고, 재고 수준인 Stock.Levels는 순서형 척도입니다. 그러므로 이 세 변수의 척도 유형을 수정해 봅시다.\n\n‘Days’ 열을 더블클릭하여 ‘데이터 변수’ 패널을 연다. 그리고 ’척도 유형’을 ’연속변수’로 수정한다.\n‘Sales’ 열을 더블클릭하여 ‘데이터 변수’ 패널을 연다. 그리고 ’척도 유형’을 ’연속변수’로 수정한다.\n‘Stock.Level’ 열을 더블클릭하여 ‘데이터 변수’ 패널을 연다. 그리고 ’척도 유형’을 ’서열척도’로 수정한다. 그리고 out, low, high 순으로 순서를 변경한다.\n\n그러면 변수의 헤더의 아이콘이 다음처럼 바뀔 것이다.",
    "crumbs": [
      "jamovi 소개",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>jamovi 시작하기</span>"
    ]
  },
  {
    "objectID": "03-Getting-started-with-jamovi.html#jamovi에-추가-모듈-설치하기",
    "href": "03-Getting-started-with-jamovi.html#jamovi에-추가-모듈-설치하기",
    "title": "3  jamovi 시작하기",
    "section": "3.7 jamovi에 추가 모듈 설치하기",
    "text": "3.7 jamovi에 추가 모듈 설치하기\njamovi의 정말 멋진 기능 중 하나는 jamovi 라이브러리에서 추가 모듈을 설치할 수 있다는 점입니다. 이 추가 모듈은 jamovi 사용자와 개발자가 제작한 소프트웨어 애드온으로, 기본 jamovi 프로그램의 기능을 넘어서는 고급 분석을 수행할 수 있습니다.\n추가 모듈을 설치하려면 jamovi 창의 오른쪽 상단에 있는 큰 \\(+\\) 버튼을 클릭하고, “자모비 라이브러리(jamovi-library)”를 선택한 후 사용할 수 있는 다양한 추가 모듈을 찾아보세요. 원하는 모듈을 선택한 다음 설치하면 됩니다. 설치된 새 모듈은 “분석(Analyses)” 메뉴에서 액세스할 수 있습니다. 유용한 추가 모듈로는 “scatr”(“Descriptives” 아래 추가), \\(R_j\\), 그리고 물론 이 책의 데이터 파일인 “lsj-data”가 포함됩니다(Figure 3.6 참조).\n\n\n\n\n\n\n\n\nFigure 3.6. jamovi에서 추가 모듈 설치하기\n\n\n\n\n\n\n\n\n\n\n\nTip 3.1. 실습: 추가 모듈 설치하기\n\n\n\n\n오른편 상단의 + ’모듈’을 클릭한 후, ’자모비 라이브러리’를 선택합니다.\n‘설치됨’ 탭을 선택하여 현재 설치된 모듈을 확인합니다.\n‘사용가능’ 탭을 선택하여 설치 가능한 모듈을 확인합니다.\n검색 상자에서 “lsj”를 입력하여 “lsj-data” 모듈을 찾은 후, ’설치’를 클릭합니다.\n\n\n\n\n\n\n\n\n\n\n\n‘설치됨’ 탭에 가서 추가한 모듈이 잘 설치되었는지 확인합니다.\n위 화살표를 클릭하여 모듈 설치 패널에서 나옵니다.",
    "crumbs": [
      "jamovi 소개",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>jamovi 시작하기</span>"
    ]
  },
  {
    "objectID": "03-Getting-started-with-jamovi.html#jamovi-종료하기",
    "href": "03-Getting-started-with-jamovi.html#jamovi-종료하기",
    "title": "3  jamovi 시작하기",
    "section": "3.8 jamovi 종료하기",
    "text": "3.8 jamovi 종료하기\n이 장에서 마지막으로 다룰 내용은 jamovi를 종료하는 방법입니다. 어렵지 않습니다. 다른 프로그램을 닫는 방식과 동일하게 프로그램을 닫으면 됩니다. 하지만 종료 전에 작업을 저장하는 것이 좋습니다! 여기에는 데이터 세트 변경 사항 저장과 실행한 분석 저장이라는 두 가지 부분이 포함됩니다.\n데이터 세트의 변경 사항은 새로운 데이터 세트로 저장하는 것이 좋습니다. 이렇게 하면 항상 원본 데이터로 돌아갈 수 있습니다. jamovi에서 변경 사항을 저장하려면 기본 jamovi 메뉴(왼쪽 상단의 가로선 세 개 버튼)에서 ‘Export’…’Data’를 선택하고 변경된 데이터 세트에 새 파일 이름을 지정하세요.\n또는 변경된 데이터와 수행한 분석 모두를 jamovi 파일로 저장할 수도 있습니다. 이를 위해 기본 jamovi 메뉴에서 ’다른 이름으로 저장하기(Save as)’를 선택하고 ’jamovi 파일(.omv)’의 파일 이름을 입력하세요. 나중에 파일을 찾을 수 있는 위치에 저장하세요. 저는 일반적으로 특정 데이터 세트와 분석을 위한 새 폴더를 만듭니다.\n\n\n\n\n\n\n실습: jamovi 파일 저장하기\n\n\n\nTooth Growth 파일을 jamovi 파일(.omv) 형식으로 저장해 봅시다.\n\n‘파일’-’다른 이름으로 저장’을 클릭합니다.\n’탐색’을 선택하여 저장할 폴더와 파일이름을 지정합니다.\n\n\n‘문서’ 폴더에 ‘Tooth Growth.omv’ 파일로 저장해 봅시다.\n\n\njamovi를 종료한 후, ‘문서’ 폴더에 파일이 생성되었는지 확인해 봅니다.\n저장된 파일을 더블클릭하여 jamovi로 다시 읽어서 모든 내용이 제대로 저장되어 있는지 확인해 봅니다.",
    "crumbs": [
      "jamovi 소개",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>jamovi 시작하기</span>"
    ]
  },
  {
    "objectID": "03-Getting-started-with-jamovi.html#요약",
    "href": "03-Getting-started-with-jamovi.html#요약",
    "title": "3  jamovi 시작하기",
    "section": "3.9 요약",
    "text": "3.9 요약\n초보자에게 새로운 통계 소프트웨어 프로그램을 가르치는 모든 책은 대체로 동일한 주제를 비슷한 순서로 다룹니다. 이 책도 예외는 아니며, 기존 방식에 따라 이번 장에서는 다음 주제를 다뤘습니다:\n\njamovi 설치하기: jamovi를 다운로드하고 설치한 후 실행해 보았습니다.\n\n분석: jamovi에서 분석이 이루어지고 결과가 표시되는 부분을 간단히 살펴봤지만, 자세한 내용은 책의 뒷부분으로 미뤄두었습니다.\n\n스프레드시트: jamovi의 스프레드시트 부분을 살펴보았고, 다양한 변수 유형과 새 계산 변수를 만드는 방법을 학습하였습니다.\n\njamovi로 데이터 가져오기: jamovi로 데이터 파일을 불러오는 방법을 살펴보았습니다.\n\n다양한 형식의 데이터 파일 가져오기: 다양한 파일 형식에서 데이터를 불러오는 방법을 알아보았습니다.\n\n변수 유형 변경하기: 때로는 변수를 한 유형에서 다른 유형으로 형변환해야 할 때가 있다는 것을 배웠습니다.\n\njamovi에 추가 모듈 설치하기: jamovi 커뮤니티에서 제공하는 추가 모듈을 설치하면 jamovi의 기능을 확장할 수 있습니다.\n\njamovi 종료하기: jamovi를 종료하기 전에 데이터 세트와 분석을 저장하는 좋은 습관에 대해 알아보았습니다.\n\n아직 데이터 분석에 많이 가까워지지는 못했습니다. 아마 다음 장에서 조금 더 가까워질 수 있을 것입니다!",
    "crumbs": [
      "jamovi 소개",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>jamovi 시작하기</span>"
    ]
  },
  {
    "objectID": "03-Getting-started-with-jamovi.html#footnotes",
    "href": "03-Getting-started-with-jamovi.html#footnotes",
    "title": "3  jamovi 시작하기",
    "section": "",
    "text": "출처: Dismal Light (1968).↩︎\n이 책을 처음 집필한 2018년 8월 당시 기준입니다. 이후 버전에서는 업데이트된 jamovi 버전을 사용할 것입니다.↩︎\njamovi는 자주 업데이트되지만, 이 책에서 다룰 작업에는 별다른 영향을 미치지 않습니다. 사실 이 책을 쓰는 동안 여러 번 업그레이드했지만, 책의 내용에는 거의 차이가 없었습니다.↩︎\njamovi 인터페이스에서 라벨, 명령, 옵션, 출력 등을 지칭할 때는 작은 따옴표를 사용할 것입니다.↩︎\n이후 버전의 jamovi에는 z-점수를 계산하는 사전 정의된 ‘Z’ 함수가 있어 훨씬 더 쉽게 사용할 수 있습니다!↩︎\n\\(R\\)은 강력한 통계 프로그래밍 언어입니다. 사실, Jamovi는 \\(R\\) 엔진 위에 구축된 사용자 친화적인 인터페이스일 뿐입니다.↩︎\njamovi에서 결측값의 기본값은 오른쪽 상단 애플리케이션 메뉴(세로 점 3개)에서 변경할 수 있습니다. 단, 이는 데이터 파일을 가져올 때에만 작동합니다. 데이터 세트의 기본 결측값은 변수와 관련된 유효한 숫자가 아니어야 하며, 예를 들어 -9999는 유효한 값일 가능성이 낮으므로 사용할 수 있습니다.↩︎\n이는 약간의 임시방편이긴 하지만 작동하며, 아마도 나중 버전의 jamovi에서 수정될 것입니다.↩︎",
    "crumbs": [
      "jamovi 소개",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>jamovi 시작하기</span>"
    ]
  },
  {
    "objectID": "04-Descriptive-statistics.html",
    "href": "04-Descriptive-statistics.html",
    "title": "4  기술 통계량",
    "section": "",
    "text": "4.1 중심 경향 측정\n데이터의 히스토그램을 그려보는 것은(Figure 4.2 참고) 데이터가 전달하려는 “요점”을 효과적으로 전달하는 훌륭한 방법입니다. 그러나 데이터를 몇 가지 간단한 “요약” 통계량으 압축하는 것도 매우 유용할 때가 많습니다. 대부분의 상황에서 가장 먼저 계산하고 싶은 것은 중심 경향 측정값입니다. 즉, 데이터의 “평균” 또는 “중간” 값이 어디에 있는지 알고자 하는 것입니다. 가장 흔히 사용되는 세 가지 측정값은 평균(mean), 중앙값(median), 최빈값(mode)입니다. 각 척도를 차례로 설명한 뒤, 각 척도가 유용한 상황에 대해 논의하겠습니다.",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>기술 통계량</span>"
    ]
  },
  {
    "objectID": "04-Descriptive-statistics.html#중심-경향-측정",
    "href": "04-Descriptive-statistics.html#중심-경향-측정",
    "title": "4  기술 통계량",
    "section": "",
    "text": "4.1.1 평균(mean)\n평균(mean)은 우리가 잘 알고 있는 그 평균값입니다. 모든 값을 더한 다음 값의 개수로 나누면 됩니다. 예를 들어, 첫 다섯 개의 AFL 승리 점수 차가 56, 31, 56, 8, 32라면, 평균은 다음과 같이 계산됩니다:\n\\[\\frac{56 + 31 + 56 + 8 + 32}{5} = \\frac{183}{5} = 36.60\\]\n물론, 이런 평균의 정의는 누구에게나 익숙한 개념일 것입니다. 평균은 일상생활에서 자주 사용되기 때문에 별로 새로울 것이 없습니다.\n평균 개념이 이미 잘 알려져 있기 때문에, 이번 기회에 통계학에서 사용하는 수학적 표기법을 소개하고 jamovi에서 이 계산을 어떻게 하는지 논의하겠습니다.\n먼저, \\(N\\)이라는 표기법을 소개합니다. 이는 우리가 평균을 계산하려는 관측값의 개수를 나타냅니다(이 경우 \\(N = 5\\)). 다음으로, 개별 관측값에 레이블을 붙일 필요가 있습니다. 관습적으로 \\(X\\)를 사용하며, 첨자를 사용하여 특정 관측값을 나타냅니다. 예를 들어, 첫 번째 관측값은 \\(X_1\\), 두 번째는 \\(X_2\\), 마지막은 \\(X_N\\)으로 나타냅니다. 즉, i번째 관측값은 \\(X_i\\)로 나타냅니다.\nTable 4.1 은 afl.margins 변수에 있는 5개의 관측값과 해당 관측값을 나타내는 수학적 기호 및 실제 값을 정리한 표입니다.\n\n\n\n\nTable 4.1. afl.margins 변수의 관측값\n\n\n\n\n\n관찰기호관찰된 값\n\n게임 1 승리 마진\\( X_1 \\)56점\n\n게임 2 승리 마진\\( X_2 \\)31점\n\n게임 3 승리 마진\\( X_3 \\)56점\n\n게임 4 승리 마진\\( X_4 \\)8점\n\n게임 5 승리 마진\\( X_5 \\)32점\n\n\n\n\n\n\n\n이제 평균을 수식으로 표현해보겠습니다. 전통적으로 평균은 \\(\\bar{X}\\)로 나타냅니다. 평균 계산은 다음과 같은 수식으로 표현할 수 있습니다:\n\\[\\bar{X}=\\frac{X_1 + X_2 ... + X_{N-1} + X_{N}}{N}\\]\n이 수식은 정확하지만 너무 길기 때문에, 합(sum) 기호 \\(\\sum\\)을 사용해 이를 간략화합니다. 예를 들어, 첫 다섯 개의 관측값을 더하려면 \\(X_1 + X_2 + X_3 + X_4 + X_5\\)로 길게 쓸 수도 있지만, 합 기호를 사용하여 다음과 같이 간략히 쓸 수 있습니다:\n\\[\\sum_{i=1}^{5} X_i\\]\n이는 문자 그대로 읽으면 “i가 1에서 5까지의 모든 값에 대해 \\(X_i\\)를 더한 합”으로 해석됩니다. 이를 통해 평균 수식을 간단히 다음과 같이 쓸 수 있습니다:\n\\[\\bar{X}=\\frac{1}{N}\\sum_{i=1}^{N}X_i\\]\n사실 이런 수학적 표기법은 평균 개념을 명확히 설명하는 데 크게 도움되지 않습니다. 이는 단순히 “모든 값을 더한 뒤, 전체 항목 수로 나눈다”라는 말을 수학적으로 표현한 것뿐입니다. 하지만 이러한 세부사항을 설명한 이유는 이 책에서 사용하는 표기법(\\(\\bar{X}\\), \\(\\sum\\), \\(X_i\\), \\(N\\))에 대한 이해를 돕기 위해서입니다. 이러한 기호는 책 전반에서 자주 사용되므로, 이를 읽고 이해할 수 있어야 합니다.\n\n\n4.1.2 jamovi에서 평균 계산하기\n이제 수학적 개념을 배웠으니, 컴퓨터를 사용해 계산하는 방법을 알아보겠습니다. 관측값이 많아지면 컴퓨터를 사용하는 것이 훨씬 더 간편합니다. jamovi를 사용해 평균을 계산하려면, 먼저 ‘기술통계(Exploration)’ 메뉴를 클릭한 뒤 ‘기술통계(Descriptives)’를 선택합니다. 그런 다음 왼쪽 ’기술통계’ 패널에서 afl.margins 변수를 선택하고 ‘오른쪽 화살표’를 클릭하여 ’변수(Variables)’ 상자로 이동시킵니다. 이 작업을 하면 오른쪽 결과 패널에 선택된 변수에 대한 기본 기술 통계량이 표로 나타납니다(Figure 4.3 참고).\n\n\n\n\n\n\n\n\nFigure 4.3. AFL 2010 시즌의 승리 점수 차(afl.margins 변수)의 기본 기술 통계\n\n\n\n\n\nFigure 4.3 에서 볼 수 있듯이, afl.margins 변수의 평균값은 35.30입니다. 제공된 정보에는 총 관측값 수(N=176), 결측값(없음), 중앙값, 최소값 및 최대값도 포함되어 있습니다.\n\n\n4.1.3 중앙값 (Median)\n중심 경향을 나타내는 두 번째 측정값은 중앙값(median)입니다. 중앙값은 평균보다 설명하기 훨씬 간단합니다. 관측값 집합의 중앙값은 단순히 “가운데 값”입니다. 예를 들어, 첫 다섯 번의 AFL 경기 점수 차가 \\(56\\), \\(31\\), \\(56\\), \\(8\\), \\(32\\)였다고 가정해 봅시다. 중앙값을 찾으려면 이 숫자들을 오름차순으로 정렬합니다: 8, 31, 32, 56, 56.\n이 정렬된 목록에서 가운데 값인 32가 중앙값이라는 것을 쉽게 알 수 있습니다(더 명확히 보이도록 굵게 표시했습니다). 간단하죠? 그런데 만약 첫 6개의 경기 결과를 분석하고 싶다면 어떻게 해야 할까요? 여섯 번째 경기의 점수 차가 14점이었다고 하면, 정렬된 목록은 다음과 같습니다: 8, 14, 31, 32, 56, 56.\n여기서는 가운데 값이 두 개(31과 32)가 됩니다. 중앙값은 이 두 숫자의 평균으로 정의되므로, 중앙값은 \\(31.5\\)입니다. 이처럼 값이 많아지면 손으로 계산하는 것은 매우 번거롭습니다. 실제로는 데이터를 정렬하고 중간 값을 찾는 대신, 컴퓨터를 이용하여 계산을 합니다. 예를 들어, jamovi는 afl.margins 변수에 대해 중앙값을 \\(30.50\\)으로 계산해 주었습니다(Figure 4.3 참고).\n\n\n4.1.4 평균과 중앙값: 차이는 무엇일까요?\n평균과 중앙값을 계산하는 방법을 아는 것만으로는 충분하지 않습니다. 각 측정값이 데이터에 어떤 의미를 가지며, 언제 각각을 사용하는 것이 적합한지 이해해야 합니다. 이 차이를 Figure 4.4 에서 확인할 수 있습니다. 평균은 데이터 집합의 “무게중심”이고, 중앙값은 데이터의 “중간값”입니다. 어떤 것을 사용할지는 데이터의 종류와 분석 목표에 따라 달라집니다. 대략적인 가이드라인은 다음과 같습니다:\n\n명목척도(Nominal Scale) 변수인 경우, 평균이나 중앙값을 사용하는 것은 적절하지 않습니다. 평균과 중앙값 모두 변수에 할당된 숫자가 의미가 있어야 하기 때문입니다. 숫자 체계가 임의적이라면 [최빈값(Mode)]을 사용하는 것이 더 나을 수 있습니다.\n서열척도(Ordinal Scale) 변수인 경우, 중앙값이 평균보다 적합합니다. 중앙값은 데이터의 순서 정보(즉, 어떤 값이 더 큰지)에만 의존하며, 구체적인 숫자에는 의존하지 않으므로 서열척도 데이터에 적합합니다. 반면, 평균은 관측값에 할당된 구체적인 숫자 값을 사용하기 때문에 서열척도 데이터에는 적합하지 않습니다.\n구간척도(Interval Scale)나 비율척도(Ratio Scale) 변수인 경우, 평균과 중앙값 모두 일반적으로 사용 가능합니다. 어떤 것을 선택할지는 분석 목표에 따라 다릅니다. 평균은 데이터의 모든 정보를 활용하는 장점이 있지만(데이터가 많지 않을 때 유용), 극단적인 값에 매우 민감합니다.\n\n이 마지막 점을 조금 더 확장해 봅시다. 히스토그램이 비대칭일 때(예: 왜도와 첨도 참고), 평균과 중앙값 사이에는 체계적인 차이가 생깁니다. 이를 Figure 4.4 에서 확인할 수 있습니다. 중앙값(오른쪽)은 히스토그램의 “본체”에 더 가까운 위치에 있는 반면, 평균(왼쪽)은 “꼬리”(극단값이 있는 쪽)로 끌려갑니다.\n구체적인 예를 들어보겠습니다. Bob(소득 $50,000), Kate(소득 $60,000), Jane(소득 $65,000)이 한 테이블에 앉아 있다고 가정합니다. 이때 테이블의 평균 소득은 $58,333이고, 중앙값은 $60,000입니다. 여기에 Bill(소득 $100,000,000)이 합류하면, 평균 소득은 $25,043,750으로 급증하지만 중앙값은 $62,500으로만 증가합니다. 테이블의 전체 소득 규모를 분석하려면 평균이 적절할 수 있습니다. 하지만 테이블에서 “전형적인 소득”을 알고 싶다면 중앙값이 더 적합한 선택이 될 것입니다.\n\n\n\n\n\n\n\n\nFigure 4.4. 평균과 중앙값 해석의 차이를 보여주는 그림. 평균은 데이터 집합의 무게중심입니다. 데이터 히스토그램이 단단한 물체라고 가정하면, 시소처럼 균형을 잡을 수 있는 지점이 평균입니다. 반면, 중앙값은 데이터 집합의 중간에 위치한 관측값으로, 절반의 관측값이 그보다 작고 나머지 절반이 그보다 큽니다.\n\n\n\n\n\n\n\n\n\n\n\n실습: 어느 마을의 가구 소득의 평균과 중앙값\n\n\n\n5 가구가 살고 있는 마을을 생각해 보자. 각각의 가구의 연소득은 1, 2, 3, 4, 5억이다. 그러면 이 마을의 평균 소득과 중위 소득(중앙값)은 얼마일까? jamovi를 이용하여 구해 보자.\n\n‘파일’-’새로운’을 메뉴에서 선택하여 새로운 스프레드시트 화면을 만듭니다.\nA 열에 마을의 가구 소득 1, 2, 3, 4, 5를 차례로 입력합니다.\nA 열을 더블클릭하여 변수명을 ’소득’으로, ’척도 유형’을 ’연속변수’로, ’데이터 유형’을 ’소수’로 바꿉니다. 그리고 위 화살표를 클릭하여 스프레드시트로 돌아옵니다.\n\n\n\n\n\n\n\n\n\n\n\n‘기술통계’-‘기술통계’ 메뉴를 선택합니다. 그리고는 ‘소득’을 ’변수’ 상자에 넣습니다. 평균과 중앙값을 확인해 봅니다.\n이 마을에 연간 100 억을 버는 부자 가구가 이사왔다고 하죠. 그러면 이 마을의 가구 소득의 평균과 중앙값은 어떻게 바뀔까요?\n스프레드시트로 돌아가서 ‘소득’ 열의 데이터를 ‘B’ 열에 복사합니다. 그리고 ‘B’ 열의 마지막에 100을 입력합니다.\nB 열을 더블클릭하여 변수명을 ’이사 후 소득’으로, ’척도 유형’을 ’연속변수’로, ’데이터 유형’을 ’소수’로 바꿉니다. 그리고 위 화살표를 클릭하여 스프레드시트로 돌아옵니다.\n‘기술통계’-‘기술통계’ 메뉴를 선택합니다. 그리고는 ‘이사 후 소득’을 ’변수’ 상자에 넣습니다. 평균과 중앙값을 확인해 봅니다.\n’이사 후 소득’의 평균과 중앙값을 이전 ’소득’의 평균과 중앙값과 비교해 봅시다. 중앙값은 크게 변하지 않았는데, 평균은 6 배 이상 차이 나는 것을 볼 수 있습니다. 왜 이런 결과가 나왔을까요?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.1.5 실제 사례\n평균과 중앙값의 차이에 주의를 기울여야 하는 이유를 실제 사례에서 살펴봅시다. 제가 자주 기자들이 과학 및 통계 지식이 부족하다고 비판하곤 하지만, 잘한 점은 인정해야겠죠. 여기 Michael Janda가 2010년 9월 24일 ABC 뉴스 웹사이트에 게재한 훌륭한 기사2가 있습니다.\n\n지난 몇 주 동안 Commonwealth Bank의 고위 임원들은 호주의 주택가격과 소득 대비 가격 비율을 호주와 비슷한 국가들과 비교하는 발표 자료를 가지고 세계 곳곳을 다녔다. “주택 구입 여건은 지난 5~6년 동안 사실상 정체 상태였습니다,” 라고 CommSec의 수석 이코노미스트 Craig James는 말했다.\n\n지난 몇 년 동안 호주 주택 시장에서 벌어진 상황을 조금이라도 알고 있는 사람, 특히 주택담보대출을 갚고 있거나, 대출을 원하거나, 임대료를 내는 사람들에게는 이런 주장은 매우 놀라운 소식일 것입니다. 다시 기사로 돌아가 봅시다.\n\nCBA는 그래프, 숫자, 국제 비교를 통해 자사가 생각하는 주택시장 비관론자들과 전쟁을 벌였습니다. 발표 자료에서 은행은 호주의 주택가격이 소득에 비해 상대적으로 비싸다는 주장을 반박하며, 주요 도시에서 소득 대비 주택가격의 비율이 5.6이고 전국적으로는 4.3이라고 주장하고 있습니다. 또한 샌프란시스코와 뉴욕의 비율은 7, 오클랜드는 6.7, 밴쿠버는 9.3이라고 덧붙입니다.\n\n매우 좋은 소식처럼 들리네요! 하지만 기사는 이어서 다음과 같은 관찰을 덧붙입니다.\n\n많은 분석가들은 은행이 오도된 수치와 비교를 사용하고 있다고 말합니다. CBA 발표 자료의 4페이지의 그래프와 표의 출처 정보를 읽어보면 국제 비교와 관련된 추가적인 출처로 Demographia가 있다는 것을 알 수 있습니다. 하지만 Commonwealth Bank가 Demographia의 호주의 소득 대비 주택가격 비율을 분석에 사용했다면, 5.6이나 4.3이 아닌 9에 가까운 수치를 얻었을 것입니다.\n\n음… 꽤 심각한 불일치군요. 한쪽에서는 9라고 말하고, 다른 쪽에서는 4~5라고 말합니다. 그러면 둘의 중간쯤으로 타협하고 진실이 그 사이 어딘가에 있다고 말해야 할까요? 절대 아닙니다! 이것은 정답과 오답이 명확히 존재하는 상황입니다. Demographia가 옳고, Commonwealth Bank는 틀렸습니다.\n\nCommonwealth Bank의 소득 대비 주택가격 수치에서 명백한 문제는 소득의 평균과 주택 가격의 중앙값을 비교했다는 점입니다(반면 Demographia의 수치는 소득 중앙값과 주택가격 중앙값을 비교했습니다). 중앙값은 중간 지점으로, 극단적인 값들을 효과적으로 제거합니다. 이는 평균 소득과 자산 가격이 호주의 최고 소득자들를 포함하기 때문에 일반적으로 더 높게 나타나는 이유입니다. 다시 말해, Commonwealth Bank의 수치는 Ralph Norris의 수백만 달러 급여는 소득 측면에서 포함하지만, 그의 (아마도) 매우 비싼 집은 부동산 가격 수치에서 제외하여, 중간 소득 호주인들의 소득 대비 주택가격 비율을 과소평가한 것입니다.\n\n더 잘 설명할 방법이 없군요. Demographia가 계산한 방식이 맞습니다. 은행의 방식은 틀렸습니다. 그러면 왜 Commonwealth Bank처럼 정량적 데이터를 매우 세련되게 다루는 조직이 이런 초보적인 실수를 저질렀을까요? 그들의 생각을 들여다볼 특별한 통찰력은 없으니 확실히 말할 수는 없습니다. 하지만 기사는 다음과 같은 사실을 언급하는데, 이것이 관련이 있을 수도 있겠죠:\n\n호주에서 가장 큰 주택 대출 기관인 Commonwealth Bank는 주택 가격 상승에 가장 큰 이해관계를 가지고 있습니다. 이 은행은 주택 담보 대출뿐만 아니라 많은 소규모 비즈니스 대출을 담보로 하여 호주 주택의 상당 부분을 사실상 소유하고 있습니다.\n\n오, 이런.\n\n\n4.1.6 최빈값 (Mode)\n표본의 최빈값은 매우 간단합니다. 이는 가장 자주 나타나는 값을 의미합니다. AFL 데이터를 활용해 최빈값을 설명해 보겠습니다. 누가 가장 많은 결승전에 출전했는지 알아봅시다. aflsmall finalists 파일을 열어 afl.finalists 변수(Figure 4.5 참고)를 살펴보세요.\n\n\n\n\n\n\n\n\nFigure 4.5. aflsmall_finalists.csv 파일에 저장된 변수들을 보여주는 jamovi 화면 캡처\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.6. afl.finalists 변수에 대한 빈도표를 보여주는 jamovi 화면 캡처\n\n\n\n\n\n이 변수에는 1987년부터 2010년까지 열린 총 200번의 결승전에서 출전한 400개 팀 이름이 포함되어 있습니다. 우리는 이 400개의 항목을 모두 읽고 각 팀 이름이 리스트에서 등장한 횟수를 세어 빈도표를 만들 수 있습니다. 하지만, 이는 단조롭고 지루한 작업입니다. 이런 작업은 컴퓨터가 잘 처리하죠. 따라서 jamovi를 사용해 이를 처리해 보겠습니다. ‘기술통계’-‘기술통계’ 메뉴에서 ’빈도분포표(Frequency tables)’라고 표시된 작은 체크박스를 클릭하면 Figure 4.6 같은 결과를 얻을 수 있습니다.\n이제 빈도표를 보면, 우리가 가진 24년간의 데이터에서 Geelong이 다른 팀들보다 결승전에 더 많이 출전했다는 것을 알 수 있습니다. 따라서 afl.finalists 데이터의 최빈값은 “Geelong”입니다. Geelong은 1987년부터 2010년까지 총 39번의 결승전에 출전하며 최다 기록을 세웠습니다. 또한, ‘기술통계’ 표에는 평균(mean), 중앙값(median), 최소값(minimum), 최대값(maximum)에 대한 결과가 계산되지 않았다는 점도 주목할 만합니다. afl.finalists 변수가 명목형 텍스트 변수이기 때문이며, 이러한 값들을 계산하는 것은 의미가 없습니다.\n최빈값에 대해 한 가지 더 언급하자면, 최빈값은 명목형 데이터에서 주로 계산됩니다. 이는 평균과 중앙값이 이러한 변수에 대해 유용하지 않기 때문입니다. 하지만, 서열척도, 구간척도 또는 비율척도 변수에서도 최빈값이 필요한 상황이 있을 수 있습니다. 예를 들어, afl.margins 변수로 돌아가 봅시다. 이 변수는 명백히 비율척도 변수입니다(명확하지 않다면 Section 2.2 를 다시 읽어보세요). 대부분의 상황에서는 평균이나 중앙값이 중심 경향을 나타내는 데 적합합니다. 하지만 다음과 같은 시나리오를 생각해 보세요. 친구가 무작위로 선택한 풋볼 경기의 정확한 승리 점수 차를 맞추면 $50을 받고, 틀리면 $1을 잃는 내기를 제안합니다. “거의 맞힌” 경우에 대한 위로 상금은 없습니다. 정확히 맞춰야 합니다. 이 경우 평균과 중앙값은 전혀 도움이 되지 않으며, 최빈값을 기반으로 베팅해야 합니다.\njamovi에서 afl.margins 변수의 최빈값을 계산하려면 해당 데이터 세트로 돌아가 ‘기술통계’-‘기술통계’ 화면으로 이동하세요. ‘통계’ 섹션을 확장하고 ‘최빈값’이라고 표시된 체크박스를 클릭하면 ’기술통계’ 표에 최빈값이 표시됩니다(Figure 4.7 참고). 2010년 데이터에 따르면 3점 차를 선택하는 것이 가장 적합한 베팅이라고 제안합니다.\n\n\n\n\n\n\n\n\nFigure 4.7. afl.margins 변수에 대한 최빈값을 보여주는 jamovi 화면 캡처",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>기술 통계량</span>"
    ]
  },
  {
    "objectID": "04-Descriptive-statistics.html#sec-Measures-of-variability",
    "href": "04-Descriptive-statistics.html#sec-Measures-of-variability",
    "title": "4  기술 통계량",
    "section": "4.2 변동성 측정",
    "text": "4.2 변동성 측정\n지금까지 논의한 통계는 모두 중심 경향(central tendency)과 관련이 있었습니다. 즉, 데이터의 “가운데”나 “인기 있는” 값을 설명하는 데 초점이 있었습니다. 그러나 중심 경향만이 우리가 계산하고자 하는 요약 통계량이 아닙니다. 우리가 정말로 알고 싶은 또 다른 중요한 정보는 데이터의 변동성(variability)입니다. 즉, 데이터가 얼마나 “퍼져” 있는지, 관측값들이 평균(mean) 또는 중앙값(median)으로부터 얼마나 “멀리” 떨어져 있는지를 측정하는 것입니다. 여기서는 데이터를 구간척도(interval scale) 또는 비율척도(ratio scale)라고 가정하고, 계속해서 afl.margins 데이터를 사용할 것입니다. 이 데이터를 통해 다양한 변동성 측정 방법을 살펴보며, 각각의 장단점을 논의하겠습니다.\n\n4.2.1 범위\n범위(range)는 매우 간단합니다. 최대값에서 최소값을 뺀 값입니다. AFL 승리 점수 차 데이터에서 최대값은 116이고 최소값은 0입니다. 범위는 “변동성”을 정량화하는 가장 간단한 방법이지만, 가장 취약한 방법 중 하나이기도 합니다. 평균에 대한 논의에서 보았듯이, 요약 통계량은 강건성(robust)을 가져야 합니다. 즉, 데이터에 몇 개의 극단적인 특이치(outliers)가 있더라도 통계가 과도하게 영향을 받지 않아야 합니다. 예를 들어, 다음과 같은 극단값을 포함하는 변수를 고려해 봅시다.\n-100, 2, 3, 4, 5, 6, 7, 8, 9, 10\n이 경우, 범위는 110이지만 극단값을 제거하면 범위는 단 8에 불과합니다. 따라서 범위는 특이치에 강건하지 않습니다.\n\n\n4.2.2 사분범위\n사분범위(interquartile range, IQR)는 범위와 비슷하지만, 최대값과 최소값 간의 차이가 아니라, 25번째 백분위수(25th percentile)와 75번째 백분위수(75th percentile) 간의 차이를 계산합니다. 데이터의 10번째 백분위수(percentile)는 데이터의 10%가 그 값보다 작은 수중 가장 작은 수입니다. 사실, 이미 이 개념을 접했습니다. 데이터의 중앙값은 50번째 백분위수입니다! jamovi에서는 ‘기술통계’-‘기술통계’-‘통계’ 화면에서 ‘백분위’ 체크박스를 클릭하여 25번째, 50번째, 75번째 백분위수를 쉽게 확인할 수 있습니다.\nFigure 4.8 을 보면 50번째 백분위수가 중앙값과 동일하다는 것을 알 수 있습니다. 그리고 \\(50.50 - 12.75 = 37.75\\)라는 계산을 통해, 2010년 AFL 승리 점수 차 데이터의 사분범위가 37.75임을 알 수 있습니다. 범위를 해석하는 것은 쉽지만, 사분범위를 해석하는 것은 조금 더 어렵습니다. 사분범위를 가장 간단하게 생각하는 방법은 다음과 같습니다. 사분범위는 데이터의 “중간 부분의 절반”이 차지하는 범위입니다. 즉, 데이터의 4분의 1은 25번째 백분위수 아래에 있고, 또 다른 4분의 1은 75번째 백분위수 위에 있습니다. 나머지 “중간 부분의 절반”의 데이터는 이 두 값 사이에 위치합니다. 사분범위는 이 중간 절반의 범위를 나타냅니다.\n\n\n\n\n\n\n\n\nFigure 4.8. afl.margins 변수의 사분위수를 보여주는 jamovi 화면 캡처\n\n\n\n\n\n\n\n4.2.3 평균 절대 편차 (Mean absolute deviation)\n앞서 살펴본 범위와 사분범위는 모두 데이터의 백분위수를 통해 변동성을 측정하는 방법에 의존합니다. 그러나 이것이 변동성을 생각하는 유일한 방법은 아닙니다. 또 다른 접근법은 의미 있는 기준점(일반적으로 평균 또는 중앙값)을 선택하고, 이 기준점에서의 “전형적인” 편차를 보고하는 것입니다. 여기서 “전형적인” 편차란 무엇을 의미할까요? 일반적으로 편차의 평균(mean) 또는 중앙값(median)을 의미합니다. 실질적으로, 이는 두 가지 다른 측정값을 생성합니다. 하나는 (평균에서의) “평균 절대 편차”(mean absolute deviation)이고, 다른 하나는 (중앙값에서의) “중앙 절대 편차”(median absolute deviation)입니다. 통계학에서는 중앙값을 기준으로 한 측정값이 더 많이 사용되며 더 우수한 것으로 여겨지는 것 같습니다. 그러나 심리학에서는 평균을 기준으로 한 측정값이 가끔 사용됩니다. 이 섹션에서는 첫 번째에 대해 논의하고, 두 번째는 이후에 다루겠습니다.\n이전 문단이 다소 추상적으로 들렸다면, 평균 절대 편차를 조금 더 천천히 살펴보겠습니다. 이 측정값의 유용한 점은 이름이 실제 계산 방법을 그대로 설명한다는 점입니다. AFL 승리 점수 차 데이터를 다시 생각해 봅시다. 우선 5개의 경기만 있다고 가정하고, 승리 점수 차가 56, 31, 56, 8, 32라고 해봅시다. 이 계산은 기준점(여기서는 평균)을 기준으로 한 편차를 살펴보는 것에 의존하므로, 먼저 평균 \\(\\bar{X}\\)를 계산해야 합니다. 이 5개의 관측값에 대한 평균은 \\(\\bar{X} = 36.6\\)입니다. 다음으로 각 관측값 \\(X_i\\)를 편차 점수로 변환합니다. 편차 점수는 관측값 \\(X_i\\)와 평균 \\(\\bar{X}\\) 간의 차이, 즉, \\(X_i - \\bar{X}\\)를 계산하면 됩니다. 예를 들어, 첫 번째 관측값의 경우 \\(56 - 36.6 = 19.4\\)가 됩니다. 이 과정은 간단합니다.\n다음 단계는 이러한 편차를 절대값으로 변환하는 것입니다. 음수 값을 양수로 변환하면 됩니다. 수학적으로, \\(-3\\)의 절대값은 \\(\\mid -3 \\mid\\)로 표시되며, \\(\\mid -3 \\mid = 3\\)이 됩니다. 여기서 절대값을 사용하는 이유는 값이 평균보다 높은지 낮은지가 아니라, 평균과 얼마나 가까운지가 중요하기 때문입니다. 이 과정을 명확히 하기 위해 Table 4.2 에 모든 계산 과정을 나타내었습니다.\n\n\n\n\nTable 4.2. 변동성 측정\n\n\n\n\n\n일상언어기호값평균으로부터의 편차절대 편차\n\n기호:\\(i\\)\\(X_i\\)\\(X_i - \\bar{X} \\)\\( \\mid X_i - \\bar{X} \\mid \\)\n\n15619.419.4\n\n231-5.65.6\n\n35619.419.4\n\n48-28.628.6\n\n532-4.64.6\n\n\n\n\n\n\n\n이제 데이터 세트의 모든 관측값에 대한 절대 편차 점수를 계산했으므로, 이 점수들의 평균을 계산하면 됩니다. 계산은 다음과 같습니다: \\[\\frac{19.4 + 5.6 + 19.4 + 28.6 + 4.6}{5} = 15.52\\]\n이로써 계산이 완료되었습니다. 이 다섯 개 점수의 평균 절대 편차는 15.52입니다.\n이 작은 예제에 대한 계산은 여기서 끝났지만, 몇 가지 더 논의할 내용이 있습니다. 첫째, 올바른 수학적 공식을 작성해야 합니다. 그러나 “평균 절대 편차”(mean absolute deviation)와 “중앙 절대 편차”(median absolute deviation)는 동일한 약어(MAD)를 가지므로 약간의 혼동이 있을 수 있습니다. 따라서 평균 절대 편차를 지칭하기 위해 AAD(average absolute deviation)라는 약어를 사용할 것입니다. 이를 바탕으로 우리가 계산한 내용을 설명하는 공식은 다음과 같습니다: \\[AAD(X) =\\frac{1}{N} \\sum_{i=1}^{N} \\mid X_i - \\bar{X} \\mid = 15.52\\]\n\n\n4.2.4 분산\n평균 절대 편차는 유용한 지표이지만, 가장 좋은 변동성 측도는 아닙니다. 수학적으로는 절대 편차 대신 제곱 편차를 사용하는 것이 더 바람직한 이유가 있습니다. 제곱 편차를 사용하면 분산(variance)이라는 측도를 얻게 되는데, 이는 무시할 수 없는 많은 훌륭한 통계적 속성을 가지고 있습니다.3 그러나 심리학적으로는 큰 단점이 있어 이에 대해 잠시 후 강조할 예정입니다. 데이터 집합 \\(X\\)의 분산은 종종 Var(\\(X\\))로 표기되지만, 보통 \\(s^2\\)로 나타냅니다(이 표기의 이유는 곧 명확해질 것입니다).\n관측값에서 분산을 계산하기 위해 사용하는 공식은 다음과 같습니다:\n\\[VAR(X) = \\frac{1}{N} \\sum_{i=1}^{N} ( X_i - \\bar{X} )^2\\]\n이는 평균 절대 편차를 계산할 때 사용한 공식과 기본적으로 동일하지만, “절대 편차” 대신 “제곱 편차”를 사용한다는 점이 다릅니다. 이 때문에 분산을 “평균 제곱 편차(mean square deviation)”라고 부르기도 합니다.\n이제 기본 개념을 이해했으니, 구체적인 예제를 살펴보겠습니다. 다시 한 번 AFL 경기 첫 5경기를 데이터로 사용해 봅시다. 이전과 동일한 방법으로 접근하면, Table 4.3 에 나타난 정보를 얻게 됩니다.\n\n\n\n\nTable 4.3. AFL 첫 5 경기의 변동성 측도\n\n\n\n\n\n일상언어수학값평균으로부터의 편차편차의 제곱\n\n기호:\\(i\\)\\(X_i\\)\\(X_i - \\bar{X} \\)\\( ( X_i - \\bar{X} )^2 \\)\n\n15619.4376.36\n\n231-5.631.36\n\n35619.4376.36\n\n48-28.6817.96\n\n532-4.621.16\n\n\n\n\n\n\n\n마지막 열에는 제곱 편차가 모두 있으므로, 이 값을 평균 내기만 하면 됩니다. 계산기를 사용해 직접 계산하면 분산이 \\(324.64\\)임을 알 수 있습니다. 여기서 분산 \\(324.64\\)가 실제로 무엇을 의미하는지는 잠시 신경 쓰지 마세요. 대신, jamovi에서 이 계산을 수행하는 방법을 알아보겠습니다. 이를 통해 매우 이상한 점을 발견할 것입니다. jamovi의 새로운 세션을 시작하려면 왼쪽 상단의 메뉴 버튼(가로 세 줄)을 클릭하고 ‘새로운’를 선택하세요. 이제 afl.margins 데이터 세트에서 첫 5개의 값(56, 31, 56, 8, 32)을 A 열에 입력하세요. 변수 유형을 ’연속변수’로 변경하고 ’기술통계’에서 ’분산’ 체크박스를 클릭하면 우리가 계산한 값(\\(324.64\\))과 동일한 분산 값이 나올까요? 아니, 전혀 다른 값(\\(405.80\\))이 나옵니다(Figure 4.9 참고).\n\n\n\n\n\n\n\n\nFigure 4.9. AFL 첫 5개 값의 분산을 보여주는 jamovi 스크린샷\n\n\n\n\n\n이거 이상하네요. jamovi가 오류를 일으킨 걸까요? 사실, 그렇지 않습니다.4 jamovi는 잘못된 계산을 하는 것이 아닙니다. jamovi가 하는 일을 설명하는 것은 간단하지만, 왜 그런 방식을 선택했는지를 설명하는 것은 조금 더 까다롭습니다. 우선 “무엇을” 하고 있는지부터 시작해 보겠습니다. jamovi는 위에서 설명한 공식 대신 약간 다른 공식을 사용하고 있습니다. 제곱 편차를 평균하는 데이터 개수 \\(N\\) 대신 \\(N - 1\\)로 제곱 편차를 나눕니다.\n[추가 기술적 세부사항[^04-descriptive-statistics-8]]\n즉, jamovi가 사용하는 공식은 다음과 같습니다:\n\\[\\frac{1}{N-1} \\sum_{i=1}^{N} ( X_i - \\bar{X} )^2\\]\n이것이 jamovi가 분산에 대해 “무엇을” 하고 있는지에 대한 대답입니다. 진짜 질문은 왜 jamovi가 \\(N - 1\\)로 나누고 \\(N\\)으로 나누지 않는가입니다. 결국, 분산은 평균 제곱 편차여야 하므로 \\(N\\)으로 나눠야 하지 않을까요? 맞습니다, 그렇게 해야 합니다. 하지만, Chapter 8 에서 논의할 예정이듯이, “표본을 설명”하는 것과 “표본이 나온 모집단을 추정”하는 것 사이에는 미묘한 차이가 있습니다. 지금까지는 이 차이가 중요하지 않았습니다. 표본을 설명하든 모집단을 추론하든 평균은 동일한 방식으로 계산됩니다. 그러나 분산, 표준 편차, 기타 여러 측도는 그렇지 않습니다.\n처음에 설명한 방식(즉, 실제 평균을 계산하므로 \\(N\\)으로 나누는 것)은 표본의 분산을 계산하려는 의도를 전제로 합니다. 하지만 대부분의 경우, 여러분은 표본 자체보다는 표본이 세상에 대해 알려주는 것에 더 관심이 있습니다. 그렇다면 여러분은 “표본 통계”를 계산하는 것에서 “모집단 모수”를 추정하는 개념으로 전환하고 있는 것입니다. 그러나 이는 다소 앞서가는 이야기입니다. 지금은 jamovi가 제대로 하고 있다고 믿고, 나중에 Chapter 8 에서 이에 대해 다시 논의하겠습니다.\n마지막으로 한 가지 더 있습니다. 이 절은 마치 추리소설처럼 진행되었습니다. 분산 계산 방법을 보여주고, jamovi의 “\\(N - 1\\)”이라는 이상한 계산 방법을 설명하고, 그 이유를 암시했지만, 가장 중요한 점을 언급하지 않았습니다. 분산을 어떻게 해석해야 할까요? 기술 통계는 결국 어떤 것을 요약하여 설명하기 위한 것이며, 현재로서는 분산이 단순히 난해한 숫자처럼 보입니다. 안타깝게도, 분산에 대한 인간 친화적인 해석을 소개하지 않은 이유는 그것이 사실상 존재하지 않기 때문입니다. 이것이 분산의 가장 심각한 문제입니다. 분산은 변동성을 나타내는 기본적인 양이라는 수학적 속성은 우아하지만, 실제로 인간과 소통하기에는 완전히 쓸모가 없습니다. 분산은 원래 변수의 관점에서 보면 해석이 완전히 불가능한 물건입니다. 모든 숫자가 제곱되었기 때문에 더 이상 원래의 의미를 갖지 않게 됩니다. 이는 큰 문제입니다. 예를 들어, Table 4.3 에 따르면 경기 1의 마진은 “평균 마진보다 376.36 포인트 제곱만큼 높았다”고 나와 있습니다. 이것은 실제로 들리는 그대로 어리석은 말입니다. 따라서 분산 \\(324.64\\)를 계산했을 때도 우리는 같은 상황에 처하게 됩니다. 저는 수많은 풋볼 경기를 보았지만, “포인트 제곱”에 대해 말하는 사람은 본 적이 없습니다. 이는 실제 측정 단위가 아니며, 분산이 이 난해한 단위로 표현되기 때문에 인간의 해석에서는 전혀 의미가 없습니다.\n\n\n4.2.5 표준편차\n자, 이제 분산을 사용하는 것이 설명되지는 않았지만 수학적으로 유용한 특성들 때문이라고 가정해 봅시다. 하지만, 당신은 로봇이 아니라 인간이기 때문에 데이터 자체의 단위(예: 점수 마진이지 점수 마진의 제곱은 아님)로 표현된 측정을 원할 것입니다. 이 문제를 어떻게 해결할 수 있을까요? 해결책은 명확합니다! 표준편차(standard deviation), 즉 “평균 제곱근 편차(root mean squared deviation)”를 사용하면 됩니다. 이는 분산에 제곱근을 취한 값입니다. 이 방법은 문제를 깔끔하게 해결합니다. “324.68 포인트 제곱의 분산”이 무엇을 의미하는지 아무도 알 수 없지만, “18.01 포인트의 표준편차”는 데이터의 원래 단위로 표현되기 때문에 훨씬 이해하기 쉽습니다. 표본 데이터의 표준편차는 일반적으로 \\(s\\)로 표시되지만, 때로는 “sd”나 “std dev.”라는 표현도 사용됩니다.\n표준편차는 분산의 제곱근이므로, 공식을 보면 놀라지 않을 것입니다:\n\\[s=\\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} ( X_i - \\bar{X} )^2 }\\]\njamovi에서 ‘표준편차’ 체크박스는 ‘분산’ 체크박스 바로 위에 있습니다. 이를 체크하면 표준편차 값으로 \\(26.07\\)을 얻습니다.\n하지만, 분산에서 이미 살펴본 것처럼, jamovi가 실제로 계산하는 방식은 위 공식과 약간 다릅니다. 분산에서 보았던 것처럼 jamovi는 \\(N\\)이 아닌 \\(N - 1\\)로 나누는 방식을 사용합니다.\n이 새로운 값을 \\(\\hat{\\sigma}\\) (시그마 햇)이라고 부르며, 그 공식은 다음과 같습니다:\n\\[\\hat{\\sigma}=\\sqrt{\\frac{1}{N-1} \\sum_{i=1}^{N} ( X_i - \\bar{X} )^2}\\]\n표준편차를 해석하는 것은 조금 더 복잡합니다. 표준편차는 분산에서 유도되며, 분산은 인간에게 직관적으로 이해하기 어려운 값이기 때문에, 표준편차 역시 단순히 해석하기는 어렵습니다. 그래서 대부분의 경우 우리는 간단한 경험적 규칙에 의존합니다. 일반적으로, 평균에서 1 표준편차 이내에 데이터의 68%가 포함되고, 2 표준편차 이내에 95%, 3 표준편차 이내에 99.7%가 포함된다고 예상할 수 있습니다. 이 규칙은 대부분의 경우 잘 맞지만, 정확하지는 않습니다. 이는 히스토그램이 대칭적이고 “종 모양”이라는 가정을 기반으로 계산됩니다. Figure 4.2 에서 볼 수 있듯이, AFL 승리 마진 데이터의 히스토그램은 이 가정에 완전히 부합하지는 않습니다. 그럼에도 불구하고 이 규칙은 대략적으로 맞습니다. 실제로, afl.margins 데이터의 65.3%가 평균에서 1 표준편차 이내에 포함됩니다. 이는 Figure 4.10 에서 시각적으로 나타나 있습니다.\n\n\n\n\n\n\n\n\nFigure 4.10. AFL 승리 마진 데이터의 표준편차를 나타내는 그림. 히스토그램의 음영 처리된 막대는 평균에서 1 표준편차 범위 내에 포함된 데이터를 나타냅니다. 이 경우, 데이터 세트의 65.3%가 이 범위 내에 포함되며, 이는 본문에서 논의한 약 68% 규칙과 일치합니다.\n\n\n\n\n\n\n\n4.2.6 어떤 측정값을 사용해야 할까?\n데이터 변동성을 나타내는 여러 측정값을 살펴보았습니다: 범위(range), IQR(사분범위), 평균 절대 편차(mean absolute deviation), 분산(variance), 표준편차(standard deviation)의 장단점도 살펴보았습니다. 각 측정값에 대해 배운 내용을 요약해 봅시다.\n\n범위(range): 데이터의 전체 범위를 얄려줍니다. 특이치(outlier)에 매우 민감하며, 데이터의 극단값에 특별히 관심이 있을 때를 제외하면 자주 사용되지 않습니다.\n\n사분범위(IQR): 데이터의 “중간 부분 절반”이 어디에 위치하는지 알려줍니다. 특이치에 상당히 강건하며, 중앙값과 잘 어울립니다. 많이 사용됩니다.\n\n평균 절대 편차(mean absolute deviation): 관측값들이 평균에서 “평균적으로” 얼마나 떨어져 있는지를 알려줍니다. 해석이 매우 직관적이지만, 통계학자들이 표준편차를 더 선호하는 몇 가지 이유가 있습니다(여기에서는 논의되지 않음). 가끔 사용되지만 흔하지는 않습니다.\n\n분산(variance): 평균으로부터의 제곱 편차에 대한 평균을 계산합니다. 수학적으로 우아하며, 평균 중심의 변동성을 설명하는 “올바른” 방법일 수 있습니다. 하지만 원래 데이터와 같은 단위를 사용하지 않기 때문에 해석이 완전히 불가능합니다. 수학적 도구로는 거의 항상 사용되지만, 일반적으로는 대다수의 통계 도구에서 눈에 보이지 않는 방식으로 사용됩니다.\n\n표준편차(standard deviation): 분산의 제곱근입니다. 수학적으로 꽤 우아하며, 데이터와 동일한 단위로 표현되므로 해석하기 쉽습니다. 평균이 중심 경향성의 척도일 때 기본적으로 사용됩니다. 변동성을 나타내는 가장 인기 있는 측정값입니다.\n\n결론적으로, IQR과 표준편차는 데이터 변동성을 보고할 때 가장 흔히 사용되는 두 가지 측정값입니다. 하지만 다른 측정값들이 사용되는 상황도 있습니다. 이 책에서 모든 측정값을 설명한 이유는 이들 대부분을 어디선가 접할 가능성이 크기 때문입니다.",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>기술 통계량</span>"
    ]
  },
  {
    "objectID": "04-Descriptive-statistics.html#왜도와-첨도",
    "href": "04-Descriptive-statistics.html#왜도와-첨도",
    "title": "4  기술 통계량",
    "section": "4.3 왜도와 첨도",
    "text": "4.3 왜도와 첨도\n심리학 문헌에서 가끔 보고되는 기술 통계량에는 두 가지가 더 있습니다. 바로 왜도(skew)와 첨도(kurtosis)입니다. 실무적으로는 우리가 논의했던 중심 경향과 변동성 측정치만큼 자주 사용되지는 않습니다. 왜도는 상당히 중요해서 꽤 자주 언급되지만, 저는 지금까지 과학 논문에서 첨도를 보고한 사례를 한 번도 본 적이 없습니다.\n\n\n\n\n\n\n\n\nFigure 4.11. 왜도의 시각적 예시. 왼쪽에는 음의 왜도를 가진 데이터 세트, 가운데는 왜도가 없는 데이터 세트, 오른쪽에는 양의 왜도를 가진 데이터 세트가 있습니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.12. 첨도의 시각적 예시. 왼쪽에는 편첨도(platykurtic) 분포(첨도 = -0.95)가 있으며, 꼬리가 얇거나 평평한 분포를 의미합니다. 가운데는 중첨도(mesokurtic) 분포(첨도 = 거의 0)로 꼬리가 얇거나 두껍지 않습니다. 오른쪽에는 첨첨도(leptokurtic) 분포(첨도 = 2.12)가 있으며, 꼬리가 두꺼운 분포를 나타냅니다. 첨도는 정규 곡선(검은 선)을 기준으로 측정됩니다.\n\n\n\n\n\n더 흥미로운 주제이기 때문에 왜도(skewness)부터 시작해 봅시다. 왜도는 기본적으로 분포의 비대칭성을 측정하는 지표이며, 이를 가장 쉽게 설명하는 방법은 그림을 그려보는 것입니다. Figure 4.11 에 나타난 바와 같이, 데이터에 극단적으로 작은 값이 많고 (즉, 왼쪽 꼬리가 “더 길고”) 극단적으로 큰 값이 적다면(왼쪽 그래프) 데이터를 음의 왜도를 보인다고 합니다. 반대로, 극단적으로 큰 값이 더 많다면(오른쪽 그래프) 데이터를 양의 왜도를 보인다고 합니다. 즉, 평균보다 훨씬 큰 값이 상대적으로 많으면 분포가 양의 왜도를 가지며 오른쪽 꼬리가 길어집니다. 음의 왜도는 그 반대입니다. 대칭 분포는 왜도가 0입니다. 양의 왜도를 가지는 분포의 왜도 값은 양수이고, 음의 왜도를 가지는 분포는 음수입니다.\n데이터 세트의 왜도를 계산하는 한 가지 공식은 다음과 같습니다:\n\\[skewness(X)=\\frac{1}{N \\hat{\\sigma}^3} \\sum_{i=1}^{N} ( X_i - \\bar{X})^3\\]\n여기서 \\(N\\)은 관측값의 수, \\(\\bar{X}\\)는 표본 평균, \\(\\hat{\\sigma}\\)는 표준편차(\\(N - 1\\)로 나눈 버전)입니다.\njamovi를 사용하면 왜도를 쉽게 계산할 수 있습니다. 이는 ‘기술통계’-‘기술통계’-’통계’의 옵션 체크 박스에서 ’왜도’를 체크합니다. afl.margins 변수의 경우, 왜도값은 \\(0.780\\)입니다. 왜도 추정값을 왜도의 표준오차로 나누면 데이터가 얼마나 치우쳐져 있는지 나타낼 수 있습니다. 특히 작은 표본(N \\(&lt;\\) 50)에서는, 이 값이 2 이하라면 데이터가 크게 치우치지 않았다고 보고, 2 이상이라면 데이터가 치우쳐 분포되어 일부 통계 분석이 어려울 가능성이 있다고 간주할 수 있습니다. 하지만 이 해석에 대한 명확한 합의는 없습니다. 그럼에도, AFL 승리 마진 데이터는 다소간 치우쳐 있음을 나타냅니다(\\(\\frac{0.780}{0.183} = 4.262\\)).\n마지막으로, 실무에서는 매우 드물게 언급되지만 첨도(kurtosis)가 있습니다. 첨도는 단순히 분포 꼬리가 얼마나 얇거나 두꺼운지를 나타내는 지표입니다. Figure 4.12 에 설명된 바와 같이, 관례적으로 정규 곡선(검은 선)은 첨도 0을 가지며, 첨도는 이 곡선을 기준으로 평가됩니다. 그림에서 왼쪽 데이터는 분포가 평평하고 꼬리가 얇아서 첨도가 음수이며 이를 편첨도(platykurtic)라고 부릅니다. 오른쪽 데이터는 꼬리가 두꺼운 분포로 첨도가 양수이며 이를 첨첨도(leptokurtic)라고 합니다. 가운데 데이터는 꼬리가 얇거나 두껍지 않아서 중첨도(mesokurtic)이고 첨도가 0입니다. 이 내용은 Table 4.4 에 요약되어 있습니다.\n\n\n\n\nTable 4.4. 첨도를 나타내는 얇은 꼬리부터 두꺼운 꼬리까지\n\n\n\n\n\n일상언어비공식 용어첨도 값\n\n\\(\\text{``}\\)꼬리가 너무 얇음\\(\\text{''}\\)편첨도 (platykurtic)음수\n\n\\(\\text{``}\\)꼬리가 보통\\(\\text{''}\\)중첨도 (mesokurtic)0\n\n\\(\\text{``}\\)꼬리가 너무 두꺼움\\(\\text{''}\\)첨첨도 (leptokurtic)양수\n\n\n\n\n\n\n\n첨도의 공식은 분산 및 왜도 공식을 연상시키며, 제곱 편차를 사용하는 분산과 세제곱 편차를 사용하는 왜도와 달리 네제곱 편차를 사용합니다.\n\\[kurtosis(X)=\\frac{1}{N \\hat{\\sigma}^4} \\sum_{i=1}^{N} ( X_i - \\bar{X} )^4 - 3\\]\n“-3” 부분은 정규 곡선이 첨도 0을 가지도록 하기 위해 통계학자들이 추가한 부분입니다. 공식 끝에 “-3”을 붙이는 것이 조금 이상해 보일 수 있지만, 이를 이렇게 하는 데는 타당한 수학적 이유가 있습니다.\n우리에게 중요한 점은, jamovi에 첨도를 계산할 수 있는 체크 박스가 있으며, 이는 왜도 체크 박스 바로 아래에 있습니다. afl.margins는 첨도 \\(0.101\\)과 표준 오차 \\(0.364\\)를 제공합니다. 이는 AFL 승리 마진 데이터는 작은 첨도를 가지고 있어서 큰 문제가 없음을 의미합니다.",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>기술 통계량</span>"
    ]
  },
  {
    "objectID": "04-Descriptive-statistics.html#집단으로-나누어-기술통계량-구하기",
    "href": "04-Descriptive-statistics.html#집단으로-나누어-기술통계량-구하기",
    "title": "4  기술 통계량",
    "section": "4.4 집단으로 나누어 기술통계량 구하기",
    "text": "4.4 집단으로 나누어 기술통계량 구하기\n집단(을 나누는) 변수에 따라 집단을 나누어 기술통계량을 살펴봐야 할 때가 많습니다. jamovi에서는 이를 비교적 간단히 수행할 수 있습니다. 예를 들어, 특정 임상 시험 데이터에서 치료 유형 별로 나누어 기술통계량을 확이해 보고 싶다고 해봅시다. 설명을 위해 새로운 데이터 세트를 사용해 봅시다. 이 데이터는 clinicaltrial.csv 파일에 저장되어 있으며, 나중에 Chapter 13에서 많이 사용될 것입니다(해당 장의 시작 부분에서 데이터에 대한 전체 설명을 찾을 수 있습니다). 이를 로드하여 무엇이 있는지 확인해 봅시다 (Figure 4.13).\n\n\n\n\n\n\n실습: Clinical Trial 데이터 불러오기\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전에 이 폴더를 사용하여 이미 선택되어 있을 수 있습니다.\n데이터 라이브러 목록에서 ’Clinical Trial’을 선택합니다. 그러면 Figure 4.13 같은 데이터가 스프레드시트 뷰에 나타납니다.\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.13. clinicaltrial.csv 파일에 저장된 변수를 보여주는 jamovi의 스크린샷\n\n\n\n\n\n이 데이터에는 세 가지 약물이 있었던 것으로 보입니다: 플라시보, “anxifree”라는 약물, 그리고 “joyzepam”이라는 약물입니다. 각 약물은 6명에게 투여되었습니다. 또한, 9명은 인지행동치료(cognitive behavioral therapy; CBT)를 받았고, 9명은 이러한 심리 치료를 받지 않았습니다. 그리고 mood.gain 변수의 ‘기술통계’ 결과를 보면 대부분의 사람들이 기분 향상을 보였다는 것을 알 수 있습니다(\\(mean = 0.88\\)). 하지만 이 척도의 구체적인 의미를 알 수 없으므로 그 이상의 해석은 어렵습니다. 그래도 나름 의미 있는 정보를 얻은 것 같네요.\n이제 다른 기술통계량도 살펴보겠습니다. 이번에는 치료 유형별로 나누어서 살펴보겠습니다. jamovi에서 ‘통계’ 옵션에서 표준 편차(Std. deviation), 왜도(Skewness) 및 첨도(Kurtosis)를 선택합니다. 동시에 therapy 변수를 ‘Split by’ 상자로 이동하면 Figure 4.14 같은 결과를 얻을 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 4.14. 치료 유형별로 나뉜 기술통계를 보여주는 jamovi의 스크린샷\n\n\n\n\n\n집단 변수가 여러 개인 경우는 어떻게 해야 할까요? 예를 들어 약물과 치료의 모든 가능한 조합에 따라 평균 기분 향상을 살펴보고 싶다고 합시다. 이를 위해 ‘Split by’ 상자에 drug 변수를 추가하면 됩니다. 매우 간단합니다. 다만, 너무 세분화하면 각 조합에 데이터가 충분하지 않아 의미 있는 계산을 수행할 수 없을 수도 있습니다. 이 경우 jamovi는 ‘NaN’ 또는 ’Inf’와 같은 메시지로 이를 알려줍니다.5",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>기술 통계량</span>"
    ]
  },
  {
    "objectID": "04-Descriptive-statistics.html#sec-Standard-scores",
    "href": "04-Descriptive-statistics.html#sec-Standard-scores",
    "title": "4  기술 통계량",
    "section": "4.5 표준 점수",
    "text": "4.5 표준 점수\n제 친구가 “짜증 정도”를 측정하기 위해 새로운 설문지를 만들고 있다고 가정해 봅시다. 이 설문은 짜증나는 방식으로 대답할 수 있는 50개의 질문으로 구성되어 있습니다. 대규모 표본(가령 약 백만 명)을 대상으로 했을 때, 데이터는 대체로 정규 분포를 따르며 평균 짜증 점수는 50개의 질문 중 17개를 짜증스럽게 답한 것으로 나타났고, 표준 편차는 5였습니다. 반면, 제가 이 설문을 했을 때 50개 중 35개를 짜증스럽게 대답했습니다. 그렇다면 저는 얼마나 짜증이 난 건가요?\n하나의 접근 방식은 \\(\\frac{35}{50}\\)로 계산하여 제가 “70% 짜증났다”고 표현하는 것입니다. 하지만, 이 방식은 약간 이상합니다. 질문의 표현 방식이 달라지면 사람들이 다르게 답할 수도 있어서 전체적인 답변의 분포가 달라질 수 있기 때문입니다. 따라서 이 설문을 기준으로 저는 70% 짜증났다는 것은 그리 유익한 진술이 아닙니다.\n이 문제를 해결하는 더 간단한 방법은 저의 짜증을 다른 사람들과 비교하는 것입니다. 놀랍게도, 제 친구의 백만 명 표본 중 저처럼 짜증난 사람은 단 159명뿐이었습니다. 이는 제가 상위 0.016%에 속한다는 것을 의미하며, 이런 방식이 원시 데이터를 해석하는 것보다 훨씬 이해하기 쉽습니다. 제 짜증을 인간의 전체 짜증 분포를 기준으로 설명해야 한다는 아이디어는 표준화라는 개념을 정성적으로 설명하고 있습니다. 제가 방금 한 것처럼 모든 것을 백분위로 설명하는 방식도 하나의 방법입니다. 그러나 이런 방식에는 문제가 있습니다. “정상에 서면 외로워진다”는 말처럼, 제 친구가 1,000명의 표본만 수집했다고 가정해 보겠습니다(새로운 설문지를 테스트하기에는 여전히 꽤 큰 표본입니다). 이 경우 평균은 50개 중 16개를 짜증스럽게 답한 것으로 나타나고, 표준 편차는 5였습니다. 그러나 이 표본에는 저처럼 짜증난 사람은 거의 없을 가능성이 큽니다. (그러므로 저를 백분율로 표현할 수도 없습니다.)\n하지만, 이것으로 모든 것이 끝난 것이 아닙니다. 다른 접근 방법으로 제 짜증 점수를 표준 점수(standard score), 또는 \\(z\\)-점수로 변환하는 것입니다. 표준 점수는 제가 얻은 짜증 점수가 평균에서 얼마나 많은 표준 편차만큼 떨어져 있는지를 나타냅니다. 이를 수식으로 표현하자면 다음과 같습니다:\n\\[\\text{표준 점수} = \\frac{\\text{원점수} - \\text{평균}}{\\text{표준 편차}}\\]\n실제 수학으로는, \\(z\\)-점수 공식은 다음과 같습니다:\n\\[z_i =\\frac{X_i - \\bar{X}}{\\hat{\\sigma}}\\]\n따라서, 다시 짜증 데이터로 돌아가면 제 원점수를 표준화된 짜증 점수로 변환할 수 있습니다: \\[z =\\frac{35 - 17}{5} = 3.6\\]\n이 값을 해석하기 위해, Section 4.2.5에서 언급했던 대략적인 기준을 기억하는 게 도움이 됩니다. 평균에서 3 표준 편차 내에 대략적으로 99.7%의 값이 분포된다고 했습니다. 따라서 제 짜증 점수가 \\(z\\)-점수 3.6에 해당한다는 것은 제가 매우 짜증이 난 상태라는 것을 의미합니다. 사실, 이는 제가 전체 사람 중 99.98%보다 더 짜증났다는 것을 나타냅니다. 딱 맞는 설명이네요.\n표준 점수는 단순히 원점수를 더 큰 집단과 비교하여 해석할 수 있도록 도와줄 뿐만 아니라(이를 통해 임의 적인 척도에서 측정된 변수를 표준적인 방식으로 이해할 수 있음), 또 다른 유용한 기능이 있습니다. 표준 점수는 원점수로는 비교할 수 없는 상황에서 서로 비교할 수 있도록 해줍니다. 예를 들어, 제 친구가 또 다른 설문을 가지고 있는데, 이는 24개 항목으로 구성된 외향성(extraversion)을 측정하는 설문입니다. 이 설문의 전체 평균은 13이고, 표준 편차는 4입니다. 제가 이 설문에서 받은 점수는 단 2점이었습니다. 아시다시피, 외향성 설문에서 받은 원점수 2와 짜증 설문에서 받은 원점수 35를 서로 비교하는 것은 말이 되지 않습니다. 두 변수의 원점수는 근본적으로 서로 다른 의미를 가지고 있기 때문에 이는 마치 사과와 오렌지를 비교하는 것과 같습니다.\n그렇다면 표준 점수는 어떨까요? 이 경우는 조금 다릅니다. 표준 점수를 계산하면 다음과 같은 값을 얻게 됩니다:\n\n짜증 점수: \\((z = \\frac{(35-17)}{5}=3.6)\\)\n외향성 점수: \\((z = \\frac{(2-13)}{4}=-2.75)\\)\n\n이 두 숫자는 서로 비교할 수 있습니다.6 저는 대부분의 사람들보다 외향적이지 않으며(\\(z = -2.75\\)), 대부분의 사람들보다 훨씬 더 짜증이나 있습니다(\\(z=3.6\\)). 하지만 짜증과 외향성의 비정상적 정도를 비교해 보면, 짜증이 더 극단적이라는 것을 알 수 있습니다. 왜냐하면 \\(3.6\\)이 \\(2.75\\)보다 더 큰 숫자이기 때문입니다. 각 표준 점수는 특정 관찰치가 해당 모집단 내에서 어디에 위치하는지에 대한 진술이기 때문에, 완전히 다른 척도의 변수들 사이에도 표준 점수를 비교할 수 있습니다.",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>기술 통계량</span>"
    ]
  },
  {
    "objectID": "04-Descriptive-statistics.html#요약",
    "href": "04-Descriptive-statistics.html#요약",
    "title": "4  기술 통계량",
    "section": "4.6 요약",
    "text": "4.6 요약\n실제 데이터를 분석할 때 가장 먼저 해야 할 일 중 하나는 기본적인 기술통계량을 계산하는 것입니다. 기술통계는 추론 통계보다 훨씬 간단히 이해할 수 있으므로, 다른 모든 통계 교재와 마찬가지로 이 책도 기술통계로 시작했습니다. 이 장에서는 다음과 같은 주제들을 다뤘습니다:\n\n중심 경향 측정: 중심 경향 측정은 데이터의 중심이 어디에 위치해 있는지를 알려줍니다. 문헌에서 일반적으로 보고되는 세 가지 측정치는 평균(mean), 중앙값(median), 최빈값(mode)입니다.\n변동성 측정: 반대로 변동성 측정은 데이터가 얼마나 “퍼져 있는지”를 알려줍니다. 주요 측정치는 범위(range), 표준편차(standard deviation), 사분범위(interquartile range)입니다.\n왜도와 첨도: 변수의 분포의 비대칭성(왜도)과 얇거나 두꺼운 꼬리를 가진 분포(첨도)를 살펴보았습니다.\n집단으로 나누어 기술통계량 구하기: 이 책은 jamovi에서 데이터 분석을 수행하는 데 중점을 두고 있기 때문에, 다양한 하위 집단에 대해 기술통계량을 계산하는 방법에 대해 논의하였습니다.\n표준 점수: \\(z\\)-점수는 약간 독특한 성격을 가집니다. 이는 완전한 기술통계량도 아니고 완전한 추론 통계도 아닙니다. 이 절을 반드시 이해하세요. 나중에 이 개념을 다시 만나게 될 것입니다.\n\n다음 장에서는 데이터를 시각화하는 방법을 논의하겠습니다! 모두가 예쁜 그림을 좋아하죠, 그렇죠? 하지만 그 전에 중요한 점을 강조하며 마무리하고자 합니다. 통계학의 전통적인 첫 강의에서는 기술통계에 대해서 비교적 짧은 시간(대개 한두 강의)만을 할애합니다. 대부분의 시간은 추론 통계에 할애되며, 이는 어려운 부분이기 때문입니다. 이것은 이해할 만하지만, 좋은 기술통계 분석의 실질적이고 일상적인 중요성을 간과하게 만드는 경향이 있습니다.",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>기술 통계량</span>"
    ]
  },
  {
    "objectID": "04-Descriptive-statistics.html#footnotes",
    "href": "04-Descriptive-statistics.html#footnotes",
    "title": "4  기술 통계량",
    "section": "",
    "text": "비호주인을 위한 참고: AFL은 호주식 풋볼 대회입니다. 이 섹션을 이해하는 데 호주식 풋볼에 대한 지식은 필요하지 않습니다.↩︎\nwww.abc.net.au/news/2010-09-24/housing-bubble-debate-boils-over/2273406↩︎\n훌륭한 통계적 특성 중 한 가지만 짧게 언급하겠습니다. 분산은 가산적입니다. 이것이 의미하는 바는 다음과 같습니다. \\(X\\)와 \\(Y\\)라는 두 변수가 있고, 이들의 분산이 각각 \\(Var(X)\\)와 \\(Var(Y)\\)라고 합시다. 이제 \\(Z = X + Y\\)라는 새로운 변수를 정의한다고 가정합니다. 이 경우 \\(Z\\)의 분산은 \\(Var(X) + Var(Y)\\)와 같습니다. 이는 매우 유용한 속성이지만, 이 섹션에서 다루는 다른 측도들에는 해당되지 않습니다. (역주: 이러한 성질이 성립하려면 \\(X\\)와 \\(Y\\)의 상관계수가 0이어야 합니다.)↩︎\n세 번째 질문을 제외할 수 있는 경우에만 해당합니다.↩︎\njamovi가 숫자를 비일상적인 방식으로 표현하는 경우도 있습니다. 숫자가 매우 작거나 매우 큰 경우, jamovi는 숫자를 지수 형태로 전환합니다. 예를 들어, 6.51e-4는 소수점을 왼쪽으로 4자리 이동한 0.000651을 의미합니다. (역주: \\(6.51 \\times 10^{-4}\\)을 의미한다.) 반대로 6.51e+4라면 소수점을 오른쪽으로 이동하여 65,100.00이 됩니다. (역주: \\(6.51 \\times 10^{4}\\)을 의미한다.) 일반적으로 매우 작거나 큰 숫자에만 이런 방식이 사용됩니다. 예: 6.51e-16 (이는 일반적인 방식으로 작성하기에는 너무 번거롭습니다).↩︎\n그러나 주의가 필요합니다. 변수 A의 1 표준 편차가 변수 B의 1 표준 편차와 동일한 “종류”의 것을 의미하지 않을 수도 있습니다. 두 변수의 \\(z\\)-점수를 비교하는 것이 의미가 있는지를 판단할 때는 상식적 판단이 필요합니다.↩︎",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>기술 통계량</span>"
    ]
  },
  {
    "objectID": "05-Drawing-graphs.html",
    "href": "05-Drawing-graphs.html",
    "title": "5  그래프 그리기",
    "section": "",
    "text": "5.1 히스토그램\n가장 기본이라 할 수 있는 히스토그램부터 시작해 보겠습니다. 히스토그램은 데이터를 시각화하는 가장 간단하고 유용한 방법 중 하나입니다. 히스토그램은 구간척도 또는 비율척도 변수(예: Chapter 4 에서 다룬 afl.margins 데이터)를 사용할 때 가장 적절하며, 해당 변수에 대한 인상을 전체적으로 파악하는 데 유용합니다. 여러분 대부분은 히스토그램이 어떻게 작동하는지 알고 있을 것입니다. 그러나 설명의 완전성을 위해 간략히 설명하도록 하겠습니다. 먼저 가능한 값을 여러 개의 구간(빈, bin)으로 나누고, 각 구간에 속하는 관측값의 개수를 계산합니다. 이 개수를 해당 구간의 빈도 또는 밀도라고 하며, 이를 세로 막대로 표시됩니다. 예를 들어 AFL 승리 마진 데이터에서는 승리 마진이 10점 미만인 경기가 33경기 있었으며, 이는 앞서 Chapter 4 에서 보여준 Figure 4.2 의 왼쪽 끝 막대의 높이로 나타납니다. 이 그래프들은 R의 고급 플로팅 패키지를 사용하여 생성되었으며, 현재 jamovi의 기능을 넘어서는 수준입니다. 그러나 jamovi에서도 유사한 결과를 쉽게 얻을 수 있습니다. jamovi에서 히스토그램을 그리는 방법은 간단합니다. ‘기술통계’-‘기술 통계’에서 ’도표’ 옵션을 열고, ‘히스토그램’ 체크 박스를 클릭하면 됩니다. Figure 5.2 에 나와 있듯이 jamovi는 기본적으로 y축을 ’밀도(density)’로, x축을 변수명으로 축 이름을 붙입니다. 구간(빈, bins)의 크기와 개수는 자동으로 선택되며, Figure 4.2 와 달리 y축에 스케일이나 개수 정보가 표시되지 않습니다. 그러나 이 점은 크게 중요하지 않습니다. 우리가 궁극적으로 관심을 가지는 것은 분포의 형태에 대한 전반적인 인상입니다. 데이터가 정규 분포를 따르는지, 왜도가 있는지, 첨도가 높은지 등을 처음으로 파악하는 데 히스토그램이 유용합니다.\nFigure 5.2. jamovi 화면에서 히스토그램 체크 박스를 선택한 모습\njamovi에서 제공하는 추가 기능 중 하나는 ‘밀도(Density)’ 곡선을 플로팅하는 기능입니다. 이는 ‘도표’ 옵션에서 ‘밀도’ 체크 박스를 클릭하고 ‘히스토그램’ 체크 박스를 해제하면 가능합니다. 이를 통해 얻은 결과가 Figure 5.3 에 표시되어 있습니다. 밀도 도표 연속적인 구간 또는 시간 동안 데이터 분포를 시각화하는 그래프입니다. 이는 커널 스무딩(kernel smoothing)을 사용하여 값을 플로팅하는 히스토그램의 변형으로, 노이즈를 줄이고 보다 부드러운 분포를 보여줍니다. 밀도 도표의 봉우리(peak)는 특정 구간에서 값들이 집중된 곳을 나타냅니다.\n밀도 도표가 히스토그램보다 가지는 장점 중 하나는, 구간(빈)의 개수에 의해 영향을 받지 않는다는 점입니다. 예를 들어, 4개의 구간으로 만든 히스토그램은 20개의 구간을 가진 히스토그램에 비해 분포 형태를 충분히 구별하기 어렵습니다. 하지만 밀도 도표는 이러한 문제가 없습니다.\nFigure 5.3. jamovi에서 afl.margins 변수의 밀도 도표\n이 그래프를 보고서에 포함할 수 있는 수준의 프레젠테이션 그래픽으로 만들려면 상당한 정리가 필요하겠지만, 데이터의 특성을 설명하는 데는 충분히 유용합니다. 사실, 히스토그램이나 밀도 도표의 가장 큰 장점은 데이터의 전체적인 분포를 보여준다는 것입니다. 이를 통해 데이터의 모습에 대한 좋은 직관을 얻을 수 있습니다.\n그러나 히스토그램의 단점도 있습니다. 다른 그래프 유형과 달리 20~30개의 히스토그램을 하나의 이미지에 담는 것은 쉽지 않으며, 지나치게 많은 정보를 포함하면 독자를 어리둥절하게 만들 수 있습니다. 또한, 만약 데이터가 명목척도(nominal scale)라면, 히스토그램은 쓸모가 없습니다.",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>그래프 그리기</span>"
    ]
  },
  {
    "objectID": "05-Drawing-graphs.html#sec-Histograms",
    "href": "05-Drawing-graphs.html#sec-Histograms",
    "title": "5  그래프 그리기",
    "section": "",
    "text": "실습: 히스토그램과 밀도도표 그리기\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리에서 ’AFL Margins’를 선택합니다. 그러면 Figure 4.1 같은 데이터가 스프레드시트 뷰에 나타납니다.\n‘기술통계’-’기술통계’를 선택합니다.\n왼편의 ‘기술통계’ 패널에서 afl.margins를 ‘변수’ 상자에 넣습니다.\n‘도표’ 옵션에서 ’히스토그램’을 체크 합니다. 그러면 Figure 5.2 그래프와 같은 히스토그램이 오른편 결과 패널에 나타납니다.\n‘도표’ 옵션에서 ’히스토그램’과 ’밀도’를 체크합니다. 그러면 그래프와 같이 히스토그램 위에 밀도 그래프가 겹쳐 그려져서 오른편 결과 패널에 나타납니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n커널 확률 밀도: 확률 밀도 추정하기\n\n\n\n커널 확률 밀도(Kernel Density Estimation; KDE)는 확률 밀도 함수(PDF, Probability Density Function)를 추정하는 방법이다. 즉, 히스토그램처럼 데이터를 구간별로 나누어 개수를 세는 것이 아니라, 각 데이터 포인트를 기준으로 연속적인 확률 밀도를 추정하는 방식이다.\nKDE는 각 데이터 포인트에 커널 함수(Kernel Function)를 적용하여 확률 밀도를 추정한다. 일반적으로 가우시안(정규분포) 커널을 사용하여 각 데이터 포인트를 중심으로 부드러운 곡선을 생성한다. 그리고는 여러 개의 커널을 합쳐서 전체적인 분포를 나타낸다. 히스토그램보다 부드러운 분포를 얻을 수 있어 데이터의 실제 분포를 더 자연스럽게 표현할 수 있다.\n히스토드램과 커널 확률 밀도의 차이를 다음 표와 같이 정리할 수 있다.\n\n\n\n\n\n\n\n\n\n히스토그램\n커널 확률 밀도(KDE)\n\n\n\n\n형태\n막대그래프 형태로 표현됨\n부드러운 곡선 형태로 표현됨\n\n\n구간(bin) 영향\n구간 개수에 따라 그래프 모양이 달라짐\n구간(bin) 개념이 없고, 부드러운 분포 표현 가능\n\n\n데이터 표현\n특정 구간에 속하는 데이터 개수를 표현\n데이터 밀도를 부드러운 확률 분포 형태로 표현",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>그래프 그리기</span>"
    ]
  },
  {
    "objectID": "05-Drawing-graphs.html#박스도표",
    "href": "05-Drawing-graphs.html#박스도표",
    "title": "5  그래프 그리기",
    "section": "5.2 박스도표",
    "text": "5.2 박스도표\n히스토그램의 또 다른 대안으로 박스도표(Boxplot)(상자 그림이라고도 합니다)가 있으며, 때때로 “상자와 수염 도표(Box and Whiskers Plot)”라고도 불립니다. 히스토그램과 마찬가지로 박스도표는 구간척도 또는 비율척도 데이터를 다룰 때 가장 적합합니다. 박스도표는 데이터의 중앙값(median), 사분위 범위(interquartile range, IQR), 그리고 데이터의 전체 범위(range)를 간단하게 시각적으로 표현합니다. 이러한 정보를 비교적 간결하게 전달할 수 있기 때문에, 박스도표는 특히 데이터 분석의 탐색 단계에서 매우 인기 있는 통계 그래픽이 되었습니다. 이제 afl.margins 데이터를 예제로 사용하여 박스도표가 어떻게 작동하는지 살펴보겠습니다.\n박스도표의 형태를 가장 쉽게 설명하는 방법은 직접 그려보는 것입니다. jamovi에서 ‘박스도표’ 체크 박스를 클릭하면 Figure 5.4 에 나타난 그래프를 얻을 수 있습니다. jamovi는 가장 기본적인 박스도표를 그려줍니다.\n\n\n\n\n\n\n\n\nFigure 5.4. jamovi에서 그린 afl.margins 변수의 박스도표\n\n\n\n\n\n이 그래프를 해석하는 방법은 다음과 같습니다.\n\n상자 안의 굵은 선은 중앙값(median)을 나타냅니다.\n\n상자의 범위는 제1사분위수(25번째 백분위수)에서 제3사분위수(75번째 백분위수)까지를 포함합니다.\n\n“수염(whiskers)”은 특정한 범위를 초과하지 않는 가장 극단적인 데이터 지점을 나타냅니다.\n\n기본적으로 수염의 길이는 1.5배의 사분범위(1.5 × IQR)를 기준으로 결정됩니다.\n\n하한(lower boundary) = 25번째 백분위수 - (1.5 × IQR)\n\n상한(upper boundary) = 75번째 백분위수 + (1.5 × IQR)\n\n이 범위를 벗어난 값은 수염에 포함되지 않고 점 또는 원으로 표시되며, 이러한 점을 특이치(outlier)라고 부릅니다.\nafl.margins 데이터에서는 두 개의 값이 이 범위를 벗어나 특이치로 표시되었습니다. 이 상한값은 107이며, 데이터 스프레드시트를 확인해 보면 107을 초과하는 두 개의 데이터(행 번호가 46과 163인 사례)가 존재하는데, 이 값들이 특이치로 그래프에 점으로 표시된 것입니다.\n\n5.2.1 바이올린 도표\n전통적인 박스도표의 변형 중 하나가 바이올린 도표(Violin plot)입니다. 바이올린 도표는 박스도표와 유사하지만, 데이터의 다양한 값에서 커널 확률 밀도(kernel probability density)를 추가로 나타낸다는 점이 다릅니다. 일반적으로 바이올린 도표에는 데이터의 중앙값(median)을 나타내는 마커와 사분위 범위(interquartile range, IQR)를 표시하는 상자가 포함되며, 이는 표준 동일합니다.\njamovi에서는 ‘Violin’과 ’상자도표’ 체크 박스를 모두 선택하면 이와 같은 기능을 사용할 수 있습니다. Figure 5.5 에서는 ‘데이터’ 체크 박스도 활성화하여 개별 데이터 점을 그래프에 표시한 예시를 보여줍니다. 하지만 제 개인적인 의견으로는 이렇게 하면 그래프가 너무 복잡해질 수 있습니다. 그래프에서 명확함은 곧 단순함을 의미하므로, 실제 보고서나 발표에서는 단순한 박스도표를 사용하는 것이 더 나을 수도 있습니다.\n\n\n\n\n\n\n\n\nFigure 5.5. jamovi에서 그린 afl.margins 변수의 바이올린 도표, 박스도표와 데이터 점도 함께 표시됨\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.6. jamovi의 Split by 창을 보여주는 스크린샷\n\n\n\n\n\n\n\n5.2.2 여러 개의 박스도표 그리기\n마지막으로 한 가지 더 알아보자. 여러 개의 박스도표를 한 번에 그리고 싶다면 어떻게 해야 할까? 예를 들어, 2010년뿐만 아니라 1987년부터 2010년까지의 모든 연도에 대한 afl.margins 데이터를 각각 별도의 박스도표으로 나타내고 싶다고 하자. 이를 위해 가장 먼저 해야 할 일은 데이터를 찾는 것이다. 해당 데이터는 aflmarginbyyear.csv 파일에 저장되어 있다. 따라서, 이 파일을 jamovi에 불러와서 어떤 데이터가 들어 있는지 확인해 보자.\n파일을 확인해 보면, 꽤 큰 데이터 세트이라는 것을 알 수 있다. 이 데이터 세트에는 총 4,296개의 경기 기록과 우리가 관심 있는 변수가 포함되어 있다. 우리가 하고자 하는 것은 jamovi에서 margin 변수의 박스도표를 그리되, 연도별로 개별적으로 나타내는 것이다. 이를 위해서는 연도(year) 변수를 ‘Split by’ 박스로 이동하면 된다. Figure 5.6 에서처럼 설정하면 된다.\n그 결과는 Figure 5.7 에서 확인할 수 있다. 연도별로 나뉜 이 박스도표을 보면, 왜 때때로 히스토그램 대신 박스도표를 선택하는 것이 유용한지 알 수 있다. 연도별로 데이터가 어떻게 분포하는지 한눈에 파악할 수 있으며, 너무 많은 정보로 인해 압도되지도 않는다. 만약 같은 공간에 24개의 히스토그램을 억지로 넣으려 했다면 어땠을까? 독자가 유용한 정보를 얻을 가능성은 거의 없었을 것이다.\n\n\n\n\n\n\n\n\nFigure 5.7. jamovi에서 연도별 margin 변수에 대해 그린 여러 개의 박스도표\n\n\n\n\n\n\n\n\n\n\n\n실습: 데이터를 분리하여 박스도표 그리기\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’AFL Margins By Year’를 선택합니다.\n‘기술통계’-’기술통계’를 선택합니다.\n왼편의 ‘기술통계’ 패널에서 margins를 ‘변수’ 상자에 넣습니다. year를 ‘Split by’ 상자에 넣습니다.\n‘도표’ 옵션에서 ’박스도표’를 체크 합니다. 박스들이 많아서 특이치의 사례 레이블이 표시되면 번잡하므로 Label outliers의 체크를 해제합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.2.3 박스도표를 이용한 특이치 탐지\n박스도표는 자동으로 특정 범위를 벗어나는 관측값을 분리하여 jamovi에서는 점(dot)으로 표시해 줍니다. 이 때문에 사람들은 박스도표를 특이치(outlier) 탐지를 위한 비공식적인 방법으로 자주 활용합니다. 특이치는 다른 데이터들과 비교했을 때 “수상할 정도로” 먼 값들이다.\n예를 들어, margins 데이터에 대한 박스도표를 그렸는데, 그 결과가 Figure 5.8 과 같다고 하자. 두 개의 관측값에서 뭔가 이상한 점이 있다는 것이 분명하다. 두 경기에서 점수 차가 300점을 넘었던 것으로 보인다!1 하지만 이는 직관적으로 말이 되지 않는다. 이렇게 이상한 점이 발견되면, 데이터를 좀 더 면밀히 살펴보아야 한다.\njamovi에서는 이러한 의심스러운 관측값이 어떤 것인지 빠르게 찾아볼 수 있으며, 원시 데이터(raw data)로 돌아가 입력 오류가 있는지 확인할 수도 있다. 이를 수행하는 방법 중 하나는 jamovi에서 ‘박스도표’ 체크박스 옆의 옵션을 선택하여 특이치에 라벨(Label outliers)을 추가하는 것이다. 이렇게 하면 박스도표에서 특이치 옆에 행(row) 번호가 표시되므로, 해당 행을 찾아 극단적인 값을 확인할 수 있다.\n좀 더 유연한 방법은 특정 기준을 초과하는 값만 포함되도록 필터(filter)를 설정하는 것이다. 이번 예에서 기준값(threshold)을 300 이상으로 하면 특이치만 찾을 수 있으므로, 필터를 이 값으로 설정할 것이다. 먼저, jamovi의 데이터 창 상단의 ‘필터’ 버튼을 클릭한 다음 필터 입력란에 'margin &gt; 300'을 입력하면 된다. Figure 5.9 에서 설정 방법을 확인할 수 있다.\n\n\n\n\n\n\n\n\nFigure 5.8. 두 개의 매우 의심스러운 특이치를 보여주는 박스도표!\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.9. jamovi 필터 화면\n\n\n\n\n\n이 필터를 적용하면 스프레드시트 보기에서 필터를 통과한 관측값만 포함된 새로운 열(column)이 생성된다. 이러한 관측값을 빠르게 식별하는 한 가지 방법은 jamovi에서 ‘빈도표(Frequency table)’를 생성하는 것이다(메뉴: ‘기술통계’-‘기술통계’). 단, 빈도표를 만들려면 ID 변수가 명목형(nominal)이어야 한다.\nFigure 5.10 을 보면 margin이 300을 초과한 관측값의 ID가 176과 202임을 알 수 있다. 이런 경우, 원본 데이터로 돌아가 어떤 문제가 있었는지 확인하는 것이 좋다.\n\n\n\n\n\n\n\n\nFigure 5.10. ID 변수에 대한 빈도표, 두 개의 의심스러운 특이치(176과 202)를 표시\n\n\n\n\n\n일반적으로 이러한 특이치는 단순한 입력 오류(typo)일 가능성이 크다. 이 예제는 단순해 보일 수 있지만, 실제 데이터 분석에서는 매우 자주 발생하는 문제이다. 현실 세계의 데이터 세트은 많은 오류를 포함하고 있으며, 특히 사람이 직접 입력한 경우에는 더욱 그렇다. 사실, 데이터를 정리하는 과정 자체를 “데이터 정제(data cleaning)”라고 부르며, 이는 데이터 분석에서 상당한 시간을 차지한다. 이 과정에서는 오타(typo), 누락된 데이터(missing data), 기타 오류 등을 찾아내고 수정해야 한다.\n한편, 박스도표에서 특이치로 표시된 값이 있더라도, 이를 분석에서 제거할지 포함할지는 데이터의 특성과 분석 목적에 따라 다르다. 따라서, 항상 신중한 판단이 필요하다. 만약 특이치가 합리적으로 보인다면 유지하는 것이 맞을 수도 있다. 이와 관련된 주제는 Section 12.10 및 Chapter 12 에서 다시 다룰 예정이다.\n\n\n\n\n\n\n실습: 필터로 특이치 찾기\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’AFL Margins’를 선택합니다.\n‘기술통계’-’기술통계’를 선택합니다.\n왼편의 ‘기술통계’ 패널에서 afl.margins를 ‘변수’ 상자에 넣습니다.\n‘도표’ 옵션에서 ’박스도표’를 체크 합니다. 그러면 Figure 5.4 같은 박스도표가 표시됩니다.\n박스도표에 표시된 특이치를 살펴보기 위하여 ‘데이터’-’필터’를 선택합니다.\n=가 표시된 상자에 필터의 조건인 afl.margins &gt; 105를 기술합니다.\n\n\n\n\n\n\n\n\n\n\n\n‘행 필터’ 패널에서 위 화살표를 클릭하여 ‘행 필터’ 패널을 닫습니다. 그러면 스프레드시트 보기에서 ’필터1’이라는 열이 생성되어 필터의 조건에 맞는 행만 체크되고 나머지는 해제된 것을 확인합니다. 아울러 기술통계 결과도 필터의 조건만 맞는 행에 대해서만 기술통계량을 구한 것을 확인합니다.\n필터 조건을 만족하는 데이터만 보거나 필터 적용을 취소하려면 ‘데이터’-‘필터’ 메뉴를 선택하거나 ‘필터 1’ 열을 더블클릭하여 ‘행 필터’ 패널로 돌아갑니다.\n’행 필터’의 왼쪽의 눈 모양 아이콘을 클릭하여 ’필터 열 숨기기’를 합니다. 그러면 필터 조건을 만족하는 행만 표시됩니다.\n\n\n\n\n\n\n\n\n\n\n\n필터 적용을 해제하려면 ‘행 필터’ 패널의 오른편 상단의 ‘활성’을 해제하거나 아예 ’x’ 표시를 클릭하여 필터를 삭제할 수 있습니다. 그러면 스프레드시트와 분석의 결과 보기가 모두 원래 데이터를 기준으로 표현되는 것을 확인할 수 있습니다.",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>그래프 그리기</span>"
    ]
  },
  {
    "objectID": "05-Drawing-graphs.html#sec-Bar-graphs",
    "href": "05-Drawing-graphs.html#sec-Bar-graphs",
    "title": "5  그래프 그리기",
    "section": "5.3 막대도표",
    "text": "5.3 막대도표\n자주 사용하게 되는 또 다른 형태의 그래프는 막대도표(Bar graph)입니다. 이번에는 Section 4.1.6 에서 소개했던 afl.finalists 데이터 세트와 afl.finalists 변수를 사용해 보겠습니다. 이 데이터 세트가 포함하는 기간 동안 각 팀이 결승전에 출전한 횟수를 나타내는 막대 그래프를 그리고 싶습니다.\n팀이 많지만, 저는 특히 브리즈번(Brisbane), 칼튼(Carlton), 프리맨틀(Fremantle), 리치몬드(Richmond) 이 네 팀에 관심이 있습니다. 따라서 첫 번째 단계는 막대 그래프에 포함할 팀을 이 네 팀으로 제한하는 것입니다. jamovi에서 필터를 설정하는 것은 매우 간단하며, 이전에 사용했던 ‘필터’ 기능을 활용하면 됩니다.\n‘필터’ 화면을 열고 다음과 같이 정확히 입력하세요 (작은따옴표도 포함해야 합니다):\n\nafl.finalists \\(==\\) ‘Brisbane’ or afl.finalists \\(==\\) ‘Carlton’ or afl.finalists \\(==\\) ‘Fremantle’ or afl.finalists \\(==\\) ‘Richmond’ 2\n\n이렇게 설정하면 jamovi의 ‘데이터’ 보기에서 우리가 지정한 팀을 제외한 모든 값이 필터링됩니다. 다음으로 ‘기술통계’-‘기술통계’ 창을 열고 ‘막대도표’ 체크 박스를 선택하세요. (이때, afl.finalists 변수를 ‘변수’ 박스로 이동시켜 jamovi가 어떤 변수를 사용할지 알 수 있도록 해야 합니다.)\n그러면 Figure 5.11 같은 막대도표가 생성될 것입니다.\n\n\n\n\n\n\n\n\nFigure 5.11. 특정 네 개의 AFL 팀을 필터링한 후 jamovi에서 막대도표를 그린 결과",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>그래프 그리기</span>"
    ]
  },
  {
    "objectID": "05-Drawing-graphs.html#jamovi에서-이미지-파일-저장하기",
    "href": "05-Drawing-graphs.html#jamovi에서-이미지-파일-저장하기",
    "title": "5  그래프 그리기",
    "section": "5.4 jamovi에서 이미지 파일 저장하기",
    "text": "5.4 jamovi에서 이미지 파일 저장하기\n잠깐만요! jamovi에서 이렇게 멋진 그래프를 그릴 수 있다 해도, 저장해서 친구들에게 자랑하거나 과제나 논문에 포함할 수 없다면 무슨 의미가 있을까요?\n그래프를 저장하는 방법은 매우 간단합니다. 그래프 이미지에서 오른쪽 클릭한 후, ‘png’, ‘eps’, ‘svg’, ‘pdf’ 형식 중 하나로 내보내기(export)를 하면 됩니다. 이 형식들은 모두 깔끔한 품질의 이미지를 제공하므로, 친구들에게 공유하거나 과제 및 논문에 첨부하기에 적합합니다.",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>그래프 그리기</span>"
    ]
  },
  {
    "objectID": "05-Drawing-graphs.html#요약",
    "href": "05-Drawing-graphs.html#요약",
    "title": "5  그래프 그리기",
    "section": "5.5 요약",
    "text": "5.5 요약\n어쩌면 저는 단순한 사람일지도 모르지만, 저는 그림을 정말 좋아합니다. 새로운 과학 논문을 쓸 때마다 가장 먼저 하는 일 중 하나는 어떤 그림을 넣을지 고민하는 것입니다. 제 머릿속에서 논문이란 결국 이야기로 연결된 그림들의 연속일 뿐이며, 나머지는 단순한 장식에 불과합니다.\n제가 정말 하고 싶은 말은, 인간의 시각 시스템은 매우 강력한 데이터 분석 도구라는 것입니다. 적절한 정보를 제공하면 독자는 단시간에 엄청난 양의 지식을 얻을 수 있습니다. “백문이 불여일견”이라는 속담이 괜히 있는 것이 아니죠.\n이 점을 고려할 때, 저는 이 장이 책에서 가장 중요한 장 중 하나라고 생각합니다.\n이번 장에서 다룬 주요 내용은 다음과 같습니다:\n\n일반적인 그래프(Common plots): 이 장에서는 통계학자들이 자주 사용하는 표준 그래프에 대해 집중적으로 다루었습니다:\n\n히스토그램\n\n박스도표\n\n막대도표\n\n\njamovi에서 이미지 파일 저장하기에서는 생성한 그래프를 내보내는 방법도 함께 설명했습니다.\n\n마지막으로 한 가지 더 설명하고 싶은 것은, jamovi는 깔끔한 기본 그래프를 제공하지만, 현재 그래프를 직접 수정하는 기능은 없습니다. 만약 더 정교하고 강력한 그래픽 기능이 필요하다면, R의 그래픽 패키지들이 훨씬 강력한 도구가 될 수 있습니다. 특히, ggplot2 패키지는 가장 인기 있는 그래픽 시스템 중 하나이며, 이는 Wilkinson(2006)의 The Grammar of Graphics 이론을 바탕으로 만들어졌습니다. (ggplot2 공식 사이트를 참조하세요.) 하지만, ggplot2는 초보자에게 쉽지 않은 도구입니다. R에 대한 이해도가 충분해야 하며, 사용법을 익히는 데도 시간이 걸립니다. 그럼에도 불구하고, ggplot2를 배우는 것은 충분한 가치가 있습니다. 왜냐하면 훨씬 더 강력하고 깔끔한 그래픽을 제공하기 때문입니다.\n\n\n\n\n\n\nggplot2\n\n\n\nggplot2 그래픽 문법을 사용하여 자신만의 다양한 그래프를 그릴 수 있습니다. ggplot2에 입문할 수 있는 좋은 자료로 졸저 [R 프로그래밍의 ggplot2를 이용한 데이터 시각화] (https://kilhwan.github.io/rprogramming/ch-visualization.html) 장 등을 참조하면 좋습니다.",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>그래프 그리기</span>"
    ]
  },
  {
    "objectID": "05-Drawing-graphs.html#footnotes",
    "href": "05-Drawing-graphs.html#footnotes",
    "title": "5  그래프 그리기",
    "section": "",
    "text": "이 AFL Margins By Year 데이터 세트의 수정된 버전은 jamovi에서 직접 열거나 불러올 수 없다. 나는 단순히 데이터 세트에서 margin 값 몇 개를 300 이상으로 변경했을 뿐이다. 원하는 경우, 직접 동일한 방식으로 값을 수정할 수도 있다.↩︎\njamovi에서는 “\\(==\\)” 기호를 “일치(matches)”의 의미로 사용합니다.↩︎",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>그래프 그리기</span>"
    ]
  },
  {
    "objectID": "06-Pragmatic-matters.html",
    "href": "06-Pragmatic-matters.html",
    "title": "6  데이터 조작",
    "section": "",
    "text": "6.1 데이터를 표로 요약하기\n데이터를 분석할 때 가장 자주 수행하는 작업 중 하나는 빈도표(frequency table)를 작성하거나, 하나의 변수를 다른 변수와 교차 분석(crosstabulation)하는 것입니다. jamovi에서는 이러한 작업을 쉽게 수행할 수 있으며, 이 절에서 그 방법을 살펴보겠습니다.",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 조작</span>"
    ]
  },
  {
    "objectID": "06-Pragmatic-matters.html#sec-Tabulating-and-cross-tabulating-data",
    "href": "06-Pragmatic-matters.html#sec-Tabulating-and-cross-tabulating-data",
    "title": "6  데이터 조작",
    "section": "",
    "text": "6.1.1 단일 변수에 대한 표 만들기\n간단한 예제부터 시작해 봅시다.\n저는 어린 자녀를 둔 부모로서 자연스럽게 In the Night Garden 같은 TV 프로그램을 자주 보게 됩니다.\nnightgarden.csv 파일에는 제가 짧은 대화 일부를 기록해 둔 데이터가 있습니다.\n이 파일에는 우리가 주목할 만한 두 개의 변수, 즉 말한 사람(speaker)과 말한 내용(utterance)이 포함되어 있습니다.\n이 데이터 파일을 jamovi에서 열고, ‘스프레드시트(spreadsheet)’ 보기에서 데이터를 살펴보면 다음과 같은 형태로 표시됩니다:\n\n\n\n\n\n\n\n\nFigure 6.1. Night Garden 데이터\n\n\n\n\n\n이제 각 캐릭터가 프로그램에서 말한 단어 수를 세어 빈도표를 만드는 작업을 해보겠습니다.\njamovi의 ‘기술통계’ 창에는 ‘빈도분포표’ 체크박스가 있는데, 이를 사용하면 빈도를 쉽게 계산할 수 있습니다.\n그 결과는 Table 6.1 에서 볼 수 있습니다.\n\n\n\n\nTable 6.1. 발화자(speaker) 변수의 빈도표\n\n\n\n\n\n수준개수비율누적 비율\n\nmakka-pakka440\\(\\%\\)40\\(\\%\\)\n\ntombliboo220\\(\\%\\)60\\(\\%\\)\n\nupsy-daisy440\\(\\%\\)100\\(\\%\\)\n\n\n\n\n\n\n\n결과 창에 나타나는 첫 줄은 말한 사람을 나타내는 speaker 변수의 빈도표임을 알려줍니다.\n‘Levels’ 열에는 speaker 열에 있는 모든 말한 사람이 나열됩니다.\n‘Counts’ 열에는 각 말한 사람이 speaker 열에 몇 번 등장하는지 나타납니다.\n즉, 이 표는 단순한 빈도표(frequency table)입니다.\n\n\n6.1.2 두 변수에 대한 분할표 만들기\njamovi의 ‘빈도분포표’ 체크박스는 단일 변수에 대해서만 표를 생성합니다.\n그러나 두 개의 변수를 조합하여 빈도를 나타내는 교차표 또는 분할표(cross-tabulation, contingency table)를 만들 수도 있습니다. 예를 들어, 말한 사람(speaker)과 말한 내용(utterance)을 조합하여 각각의 말한 사람이 특정 내용을 몇 번 말했는지를 확인해 보겠습니다.\n이를 위해 jamovi에서 다음 분석을 수행합니다: ‘빈도’-‘분할표’-‘독립 표본’ 메뉴를 선택합니다. 그다음, speaker 변수를 ‘행’ 박스에, utterance 변수를 ‘열’ 박스에 설정한다.\n이렇게 하면 Figure 6.2 같은 분할표(Contingency Table)를 얻을 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 6.2. speaker와 utterance 변수에 대한 분할표\n\n\n\n\n\n표 아래에 “\\(\\chi^2\\) 테스트” 결과가 함께 표시되지만, 이는 Chapter 10 에서 다룰 예정이므로 지금은 신경 쓰지 않아도 됩니다.\n이 분할표는 단순한 빈도(counts) 정보를 제공합니다.\n예를 들어, 첫 번째 행, 두 번째 열의 값이 2인 것은 “Makka-Pakka”(첫 번째 행)가 “onk”(두 번째 열)를 두 번 말했다는 것을 의미합니다.\n\n\n6.1.3 분할표에 백분율 추가하기\nFigure 6.2 에 표시된 분할표는 원래 빈도(raw frequencies)만을 보여줍니다. 즉, 지정된 변수의 서로 다른 수준(levels)들의 조합에 대한 총 사례 수(counts)만을 나타냅니다.\n하지만, 종종 데이터를 빈도뿐만 아니라 백분율(percentages)로도 정리하고 싶을 때가 있습니다.\njamovi의 ‘분할표(Contingency Tables)’ 창에서 ‘칸’ 옵션을 선택하면 다양한 형식의의 백분율을 추가할 수 있습니다.\n우선, ‘행’ 체크박스를 선택하면, 출력 창의 분할표가 행 기준 백분율(row percentages)을 포함한 형태로 변경됩니다. 결과는 Figure 6.3 에서 볼 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 6.3. speaker와 utterance 변수에 대한 분할표 (행 기준 백분율 포함)\n\n\n\n\n\n이 표는 각 캐릭터가 말한 전체 내용 중 특정 내용이 차지하는 비율을 나타냅니다.\n예를 들어, “Makka-Pakka”가 말한 발화의 50%가 “pip”이며, 나머지 50%가 “onk”임을 보여줍니다.\n이를 열 기준 백분율(column percentages)과 비교해 보겠습니다.\n‘행’ 체크박스를 해제하고 ‘열(Column)’ 체크박스를 선택하면, 결과는 Figure 6.4 같이 변경됩니다.\n이 경우, 각 특정 utterance와 관련된 speaker의 비율을 나타냅니다.\n예를 들어, “ee”라는 말은 이 데이터에서 100%의 확률로 “Tombliboo”가 말한 것임을 보여줍니다.\n\n\n\n\n\n\n\n\nFigure 6.4. speaker와 utterance 변수에 대한 분할표 (열 기준 백분율 포함)\n\n\n\n\n\n\n\n\n\n\n\n실습: 분할표 만들기\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리에서 ’Night Garden’을 선택합니다. 그러면 Figure 6.1 같은 데이터가 스프레드시트 뷰에 나타납니다.\n‘기술통계’-’기술통계’를 선택합니다.\n‘기술통계’ 창에서 ‘speaker’를 ’변수’ 상자로 옮깁니다.\n‘빈도분포표’ 체크 박스를 체크합니다. 그러면 결과 창에 빈도표가 나타납니다.\n\n\n\n\n\n\n\n\n\n\n\n‘빈도’-‘분할표’-‘독립 표본’ 메뉴를 선택합니다.\n‘분할표’ 창에서 speaker 변수를 ‘행’ 박스로, utterance 변수를 ‘열’ 박스로 옮깁니다. 그러면 결과 창에 분할표가 나타납니다.\n‘칸’ 옵션을 선택하면 현재 ‘관찰 빈도’만 체크되어 있을 것입니다. ’비율’의 ’행’ 체크 상자을 체크하여 행 기준 백분율을 표시해 봅니다.\n\n\n\n\n\n\n\n\n\n\n\n‘비율’의 ’행’, ‘열’, ‘전체’ 등을 체크하거나 체크를 해제하며 어떠한 백분율이 나타나는지 관찰합니다. 이 때 행과 열의 전체 합이 어떻게 변하는지 주의 깊게 살펴 보십시오.",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 조작</span>"
    ]
  },
  {
    "objectID": "06-Pragmatic-matters.html#jamovi의-논리-표현식",
    "href": "06-Pragmatic-matters.html#jamovi의-논리-표현식",
    "title": "6  데이터 조작",
    "section": "6.2 jamovi의 논리 표현식",
    "text": "6.2 jamovi의 논리 표현식\njamovi에서 데이터 변환(data transformation)을 수행할 때 중요한 개념 중 하나는 논리값(logical value)입니다.\n논리값이란 어떤 것이 참(true)인지 거짓(false)인지에 대한 판단을 의미합니다.\njamovi에서 논리값은 매우 단순합니다. TRUE(참)와 FALSE(거짓) 두 가지뿐입니다. 비록 단순하지만, 논리값은 매우 유용한 개념입니다.\n그럼 어떻게 작동하는지 살펴보겠습니다.\n\n6.2.1 수학적 참과 거짓 평가하기\n조지 오웰(George Orwell)의 고전 1984에 나오는 전체주의 정당이 사용한 슬로건 중 하나는 “2 더하기 2는 5(Two plus two equals five)”였습니다.\n이는 가장 기본적인 진리조차 왜곡할 수 있을 때, 정치적 지배는 완성된다라는 개념을 내포하고 있습니다. 소설에서 주인공 윈스턴 스미스(Winston Smith)는 고문 끝에 결국 이 명제를 받아들이고 맙니다. 책에서는 이를 “인간은 무한히 조작될 수 있다”라고 표현합니다.\n하지만 저는 인간이 그렇게까지 조작될 수 있다고 생각하지 않으며2, 적어도 jamovi는 절대 그렇지 않습니다.\njamovi는 수학적 사실을 매우 엄격하게 판단합니다.\n예를 들어, jamovi에 \\(2 + 2\\)를 계산하도록 요청하면3,\n항상 같은 결과를 반환합니다. 그리고 그 답은 결코 5가 아닙니다!\n물론, 지금까지 jamovi는 단순히 계산을 수행했을 뿐입니다.\njamovi에게 \\(2 + 2 = 4\\)가 참인지 판단하도록 요청한 것은 아닙니다.\njamovi에게 명시적으로 참(True)인지 거짓(False)인지 판단하도록 하려면\n아래와 같은 명령을 사용할 수 있습니다.\n\\[2 + 2 == 4\\]\n여기서 사용된 == 기호는 “동등 연산자(equality operator)”라고 불립니다. 이 연산자는 jamovi에게 이 명제가 참인지 거짓인지 평가하라고 강제합니다.4 자, 이제 당의 슬로건에 대해 jamovi의 판단을 확인해 보겠습니다. jamovi의 ‘계산된 새 변수(Compute new variable)’ 창에서 아래 식을 입력해 보세요.\n\\[2 + 2 == 5\\]\n그럼, jamovi는 어떤 결과를 반환할까요? jamovi는 새로운 변수 열(column)에 FALSE 값을 출력할 것입니다. 즉, \\(2 + 2 = 5\\)는 거짓이다라고 확실하게 판단하는 것입니다.\n\n\n\n6.2.2 논리 연산\n앞에서 논리 연산이 어떻게 동작하는지 살펴보았습니다. 하지만 지금까지 본 것은 가장 단순한 예제였습니다. 논리 연산을 다른 연산 및 함수와 결합하여 더 복잡한 방식으로 사용할 수도 있습니다. 예를 들면 다음과 같습니다.\n\\[3 \\times 3 + 4 \\times 4 == 5 \\times 5\\]\n또는\n\\[SQRT(25) == 5\\]\n뿐만 아니라, Table 6.2 에서 볼 수 있듯이 기본적인 수학 개념과 관련된 여러 논리 연산자가 존재합니다. 이들은 비교적 직관적이므로 쉽게 이해할 수 있을 것입니다. 예를 들어, “작다(less than)” 연산자 &lt;는 왼쪽 숫자가 오른쪽 숫자보다 작은지 확인합니다. 만약 작은 경우 TRUE를 반환하며, 두 숫자가 같거나 오른쪽 숫자가 더 작으면 FALSE를 반환합니다.\n반면, “작거나 같다(less than or equal to)” 연산자 &lt;=는 왼쪽 숫자가 오른쪽 숫자보다 작거나 같은 경우 TRUE를 반환합니다. 이제 “크다(greater than)” 연산자 &gt;와 “크거나 같다(greater than or equal to)” 연산자 &gt;=가 어떤 역할을 하는지 충분히 짐작할 수 있을 것입니다!\n\n\n\n\nTable 6.2. 다양한 논리 연산자\n\n\n\n\n\n연산연산자예제 입력결과\n\n작다&lt;2 &lt; 3참\n\n작거나 같다&lt;=2 &lt;= 2참\n\n크다&gt;2 &gt; 3거짓\n\n크거나 같다&gt;=2 &gt;= 2참\n\n같다==2 == 3거짓\n\n같지 않다!=2 != 3참\n\n\n\n\n\n\n\n다음으로 살펴볼 논리 연산자는 “같지 않다(not equal to)” 연산자 !=입니다.\n이 연산자는 양쪽 값이 서로 다를 경우 TRUE를 반환합니다.\n즉, 2 + 2는 5와 같지 않으므로, jamovi는 TRUE를 반환할 것입니다.\n직접 실행해보세요.\n\\[2 + 2 \\text{ != } 5\\]\n하지만 아직 다 끝난 게 아닙니다! 알아두면 유용한 논리 연산자 세 개가 더 있습니다. Table 6.3 에서 볼 수 있는 “부정(not)” 연산자 !, “논리곱(and)” 연산자 and, “논리합(or)” 연산자 or입니다. 이들 연산자의 동작 방식은 이름에서 쉽게 유추할 수 있습니다.\n예를 들어, 다음 명제를 평가해 보겠습니다. “2 + 2 = 4 또는 2 + 2 = 5”. 이 문장은 참입니다. 왜냐하면 “논리합(or)” 연산자는 하나만 참이면 전체가 참이 되기 때문입니다.5\n\n\n\n\nTable 6.3. 추가적인 논리 연산자\n\n\n\n\n\n연산연산자예제 입력결과\n\n부정NOTNOT(1==1)거짓\n\n또는or(1==1) or (2==3)참\n\n그리고and(1==1) and (2==3)거짓\n\n\n\n\n\n\n\n반면, 다음 명제를 평가해보겠습니다. “2 + 2 = 4 그리고 2 + 2 = 5”. 이 문장은 거짓입니다. 왜냐하면 “논리곱(and)” 연산자는 모든 조건이 참일 때만 참을 반환하기 때문입니다. 이를 jamovi의 논리 연산식으로 표현하면 다음과 같습니다.\n\\[(2+2 == 4) \\text{ and } (2+2 == 5)\\]\n마지막으로, “부정(not)” 연산자는 간단하지만 설명하기 까다로운 개념입니다. 예를 들어, “2 + 2 = 5가 아니다”라는 명제를 평가해 보겠습니다. 이 문장은 참입니다. 왜냐하면 “2 + 2 = 5는 거짓이다”라는 말과 동일한 의미를 갖기 때문입니다. jamovi에서 이를 표현하는 방법은 다음과 같습니다.\n\\[NOT(2+2 == 5)\\]\n즉, 2+2 == 5가 FALSE이므로 NOT(2+2 == 5)는 TRUE가 됩니다. 결국, “거짓의 부정(not false)”은 “참(true)”이라는 논리적 사실을 확인한 것입니다. 현실에서는 흑백 논리가 항상 적용되지는 않지만, jamovi에서는 모든 것이 참(TRUE) 또는 거짓(FALSE) 중 하나로만 표현됩니다. 어떤 모호함도 허용되지 않습니다. 사실, 이번 예제에서는 NOT 연산자와 == 연산자를 따로 사용할 필요가 없었습니다. 그 대신 “같지 않다(not equal to)” 연산자 !=를 바로 사용할 수도 있었습니다.\n\\[2+2 \\text{ != } 5\\]\n\n\n6.2.3 논리 연산을 텍스트에 적용하기\n논리 연산자를 논리 데이터뿐만 아니라 텍스트에도 적용할 수 있다는 점을 간단히 설명하고자 합니다. 다만, jamovi가 이러한 연산을 해석하는 방식에 대해 조금 더 주의 깊게 이해해야 합니다. 이 절에서는 “같다(equal to)” 연산자 ==가 텍스트에 어떻게 적용되는지 다루겠습니다. 이는 가장 중요한 연산자이기 때문입니다. 당연히 “같지 않다(not equal to)” 연산자 !=는 ==의 정반대 결과를 반환하므로 내재적으로 함께 다루지만, !=의 사용 예시는 따로 제시하지 않겠습니다.\n자, 이제 어떻게 동작하는지 살펴봅시다. 한편으로는 매우 간단합니다. 예를 들어, jamovi에게 “cat”과 “dog”가 같은지 물어볼 수 있습니다.\n\n\"cat\" == \"dog\"\n\n이것은 거짓임이 너무나도 자명하며, jamovi도 이를 쉽게 판단할 수 있습니다. 마찬가지로, jamovi는 \"cat\"이 \"cat\"과 동일하다는 것도 인식합니다.\n\n\"cat\" == \"cat\"\n\n이 역시 예상한 대로입니다. 그러나 jamovi는 철자나 띄어쓰기 등에 관해서는 전혀 관대하지 않습니다. 즉, 두 문자열이 조금이라도 다르면 jamovi는 동일하지 않다고 판단합니다. 예를 들어, 다음과 같은 경우를 생각해봅시다.\n\n\" cat\" == \"cat\"\n\"cat\" == \"CAT\"\n\"cat\" == \"c a t\"\n\n이 모든 비교 연산은 FALSE를 반환합니다. jamovi는 공백이나 대소문자 차이까지도 정확히 구분하기 때문입니다.\n또한, jamovi에서는 &lt; 및 &gt; 연산자를 사용하여 알파벳 순서상 어떤 문자열이 먼저 오는지 판단할 수도 있습니다. 다만, 실제로는 단순한 알파벳 정렬보다 조금 더 복잡한 방식으로 동작합니다. 우선 간단한 예제부터 살펴봅시다.\n\n\"cat\" &lt; \"dog\"\n\njamovi에서 이 표현식은 TRUE로 평가됩니다. 이유는 \"cat\"이 \"dog\"보다 알파벳 순서상 먼저 오기 때문입니다. 반면, \"cat\"이 \"anteater\"보다 앞서는지 확인해보면 FALSE가 나옵니다. 여기까지는 사전(dictionary)에서 단어를 찾는 방식과 크게 다르지 않습니다.\n하지만 텍스트 데이터의 정렬 방식은 단순한 사전 순서보다 더 복잡합니다. 그렇다면 \"cat\"과 \"CAT\" 중에서 어떤 것이 먼저 올까요? 직접 실행해보세요.\n\n\"CAT\" &lt; \"cat\"\n\n이 표현식은 TRUE로 평가됩니다. 즉, jamovi는 대문자가 소문자보다 먼저 온다고 가정합니다. 여기까지는 꽤 직관적인 결과입니다. 그러나 jamovi는 모든 대문자가 모든 소문자보다 먼저 온다고 가정한다는 점이 흥미롭습니다. 예를 들어, \"anteater\" &lt; \"zebra\"는 TRUE이고, 대문자로 변환한 \"ANTEATER\" &lt; \"ZEBRA\" 역시 TRUE입니다. 그런데 다음과 같은 경우는 어떻게 될까요?\n\n\"anteater\" &lt; \"ZEBRA\"\n\n이 표현식은 FALSE로 평가됩니다. 즉, “anteater”가 “ZEBRA”보다 사전 순서상 앞선다고 볼 수 있지만, jamovi는 대문자를 더 우선시하기 때문에 “ZEBRA”가 더 먼저 온다고 판단합니다. 이러한 동작이 다소 직관적이지 않을 수 있습니다. 이러한 특성을 이해하는 데 도움이 되도록, jamovi가 텍스트 문자를 처리하는 순서를 Table 6.4 에 정리하였습니다.\n\n\n\n\nTable 6.4. jamovi가 처리하는 텍스트 문자 순서\n\n\n\n\n\n\\( \\text{!} \\)\\( \\text{``} \\)\\( \\# \\)\\( \\text{\\$} \\)\\( \\% \\)\\( \\& \\)\\( \\text{'} \\)\\( \\text{(} \\)\n\n\\( \\text{)} \\)\\( \\text{*} \\)\\( \\text{+} \\)\\( \\text{,} \\)\\( \\text{-} \\)\\( \\text{.} \\)\\( \\text{/} \\)0\n\n12345678\n\n9\\( \\text{:} \\)\\( \\text{;} \\)&lt;\\( \\text{=} \\)&gt;\\( \\text{?} \\)\\( \\text{@} \\)\n\nABCDEFGH\n\nIJKLMNOP\n\nQRSTUVWX\n\nYZ\\( \\text{[} \\)\\( \\backslash \\)\\( \\text{]} \\)\\( \\hat{} \\)\\( \\_ \\)\\( \\text{`} \\)\n\nabcdeghi\n\njklmnopq\n\nrstuvwxy\n\nz\\(\\text{\\{}\\)\\(\\text{|}\\)\\(\\text{\\}}\\)",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 조작</span>"
    ]
  },
  {
    "objectID": "06-Pragmatic-matters.html#sec-Transforming-and-recoding-a-variable",
    "href": "06-Pragmatic-matters.html#sec-Transforming-and-recoding-a-variable",
    "title": "6  데이터 조작",
    "section": "6.3 변수 변환 및 재코딩",
    "text": "6.3 변수 변환 및 재코딩\n실제 데이터 분석에서는 특정 변수가 원하는 형태와 정확히 일치하지 않는 경우가 많습니다. 예를 들어, 연속형 변수(예: 나이)를 몇 개의 범주(예: 젊은, 중년, 노년)로 나누는 것이 편리할 수 있습니다. 때로는 숫자 변수를 다른 숫자 변수로 변환해야 할 수도 있습니다(예: 원래 변수의 절댓값을 분석하고 싶을 때). 이 절에서는 jamovi에서 이러한 작업을 수행하는 몇 가지 핵심 방법을 설명하겠습니다.\n\n6.3.1 변환된 변수 생성하기\n첫 번째로 다룰 개념은 변환(transforming)입니다. 문자 그대로 해석하면 변수에 대한 모든 조작이 변환에 해당하지만, 실제로는 원래 변수에 간단한 수학적 함수를 적용하여 새로운 변수를 생성하는 경우를 의미합니다. 이렇게 하면 (a) 실제로 관심 있는 대상을 더 잘 설명할 수 있거나, (b) 수행하려는 통계 검정의 가정과 더 잘 부합하는 데이터를 만들 수 있습니다. 아직 통계 검정이나 그 가정에 대해 설명하지 않았으므로, 첫 번째 경우를 예제로 보여드리겠습니다.\n가령, 10명을 대상으로 다음과 같은 질문을 한 짧은 연구를 수행했다고 가정해 보겠습니다.\n\n“공룡은 멋지다”라는 주장에 대해 1(전혀 동의하지 않음)에서 7(매우 동의함)까지의 척도로 어느 정도 동의하시나요?\n\n이제 데이터를 불러와 확인해 보겠습니다. 데이터 파일 likert.omv에는 이 10명이 응답한 원본 Likert 척도 값이 포함된 단일 변수가 있습니다. 하지만 이를 자세히 생각해 보면, 현재 방식으로 응답을 표현하는 것이 최선이 아닙니다. 응답 척도를 대칭적으로 설정했으므로 척도의 중간값을 0(의견 없음)으로, 두 끝점을 “3(매우 동의함)” 및 “-3(매우 동의하지 않음)”으로 코딩하는 것이 더 적절합니다. 이렇게 데이터를 재코딩하면 실제로 우리가 응답을 해석하는 방식과 더 잘 맞아떨어집니다.\n이 변환은 매우 간단합니다. 원본 점수에서 4를 빼면 됩니다. jamovi에서는 새 변수를 계산하여 이를 수행할 수 있습니다. ‘데이터’-‘계산’ 버튼을 클릭하면 스프레드시트에 새로운 변수가 추가됩니다. 이 변수를 likert.centered라고 이름을 지정한 후, 수식 입력 상자에 다음과 같이 입력합니다(Figure 6.5 참조).\n\nlikert.raw - 4\n\n\n\n\n\n\n\n\n\nFigure 6.5. jamovi에서 새로 계산된 변수 생성하기\n\n\n\n\n\n이렇게 데이터를 변환하면 응답 강도(의견의 세기)와 응답 방향(찬성 또는 반대)을 별도로 분석할 수 있는 유용한 형식이 됩니다. 이를 위해 likert.centered 변수에 대해 두 가지 다른 변환을 수행할 수 있습니다. 먼저, 의견 강도를 나타내는 변수(opinion.strength)를 계산하려면 변환된 데이터의 절댓값을 구하면 됩니다(‘ABS’ 함수 사용).6\njamovi에서 ‘계산’ 버튼을 사용하여 새 변수를 만듭니다. 변수명을 ‘opinion.strength’로 설정한 후, ’수식’ 상자 옆의 fx 버튼을 클릭합니다. 여기에서 사용 가능한 ‘함수’ 및 ‘변수’ 목록이 나타납니다. ABS를 더블 클릭한 후 likert.centered'를 더블 클릭하면ABS(likert.centered)`라는 수식이 자동으로 입력되며, 새로운 변수가 생성됩니다(Figure 6.6 참조).\n\n\n\n\n\n\n\n\nFigure 6.6. \\(f_x\\) 버튼을 사용하여 함수 및 변수를 선택하는 방법\n\n\n\n\n\n다음으로, 의견의 방향만을 나타내는 변수를 만들고 강도의 영향을 배제하려면 변수의 “부호(sign)”를 계산해야 합니다. jamovi에서는 IF 함수를 사용하여 이를 수행할 수 있습니다. ‘계산’ 버튼을 사용하여 새 변수를 만들고, 변수명을 opinion.sign으로 지정한 후, 수식 입력 상자에 다음과 같이 입력합니다.\n\nIF(likert.centred \\(==\\) 0, 0, likert.centred / opinion.strength)\n\n이제 likert.centred 변수에서 음수 값은 -1, 양수 값은 1, 0은 그대로 유지됩니다.\n\n-1 1 -1 0 0 0 -1 1 1 1\n\nIF 명령의 동작을 살펴보겠습니다. jamovi에서 IF 문은 세 부분으로 구성됩니다: IF(조건, 참일 때 값, 거짓일 때 값). 첫 번째 부분은 논리 또는 수학적 표현식입니다. 여기서는 likert.centred == 0을 사용하여 likert.centred 값이 0인 경우를 판별했습니다. 두 번째 부분에서는 이 조건이 참일 경우 새 값을 지정합니다(즉, likert.centred 값이 0이면 0으로 유지). 마지막으로, 조건이 거짓인 경우(즉, likert.centred 값이 0이 아닐 경우) 수행할 연산을 입력합니다. 우리는 likert.centred를 opinion.strength로 나누어 -1 또는 +1을 계산했습니다.7\n이제 likert.raw 데이터를 변환한 세 개의 새로운 변수를 얻었습니다. 각각이 원본 데이터를 보다 유용한 형식으로 변환하는 데 기여합니다.",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 조작</span>"
    ]
  },
  {
    "objectID": "06-Pragmatic-matters.html#변수를-더-적은-개수의-이산-수준-또는-범주로-축소하기",
    "href": "06-Pragmatic-matters.html#변수를-더-적은-개수의-이산-수준-또는-범주로-축소하기",
    "title": "6  데이터 조작",
    "section": "6.4 변수를 더 적은 개수의 이산 수준 또는 범주로 축소하기",
    "text": "6.4 변수를 더 적은 개수의 이산 수준 또는 범주로 축소하기\n실제 분석에서 자주 접하는 작업 중 하나는 변수를 더 적은 개수의 이산 수준 또는 범주로 축소하는 문제입니다. 예를 들어, 한 사교 모임에서 사람들의 연령 분포를 살펴보고 싶다고 가정해 보겠습니다:\n\n60,58,24,26,34,42,31,30,33,2,9\n\n어떤 상황에서는 이러한 데이터를 소수의 범주로 그룹화하는 것이 유용할 수 있습니다. 예를 들어, 데이터를 다음 세 개의 넓은 범주로 그룹화할 수 있습니다: 어린 연령층 (0-20), 성인 (21-40), 고령층 (41-60). 이는 다소 거친 분류이며, 제가 붙인 라벨은 이 데이터의 문맥에서만 의미를 가집니다(예: 일반적으로 볼 때, 42세 사람이 자신을 “고령층”이라고 생각하지 않을 것입니다). 변수를 이런 식으로 분할하는 작업은 이미 사용한 jamovi의 IF 함수를 이용하여 쉽게 수행할 수 있습니다. 이번에는 중첩된 IF 문을 지정해야 하는데, 이는 단순히 첫 번째 논리 표현이 참이면 첫 번째 값을 삽입하고, 두 번째 논리 표현이 참이면 두 번째 값을 삽입하며, 세 번째 논리 표현이 참이면 세 번째 값을 삽입하는 방식입니다. 이를 다음과 같이 작성할 수 있습니다:\n\nIF(Age &gt;= 0 and Age &lt;= 20, 1, IF(Age &gt;= 21 and Age &lt;= 40, 2, IF(Age &gt;= 41 and Age &lt;= 60, 3 )))\n\n중첩이 발생할 때 세 개의 왼쪽 괄호가 사용되므로 전체 문장이 세 개의 오른쪽 괄호로 끝나야 오류 메시지가 발생하지 않습니다. 이 데이터 조작을 보여주는 jamovi 스크린샷과 이에 따른 빈도표는 Figure 6.7 에 나와 있습니다.\n연구 프로젝트의 맥락에서 생성된 범주가 의미가 있는지 시간을 들여 확인하는 것이 중요합니다. 만약 의미가 없다면, 해당 범주를 사용하는 데이터 분석 역시 의미가 없을 가능성이 큽니다. 저는 사람들이 (연속적이고 복잡한) 데이터를 몇 개의 (이산적이고 단순한) 범주로 나누고, 원본 데이터 대신 범주화된 데이터를 사용하여 분석을 수행하려는 경향이 강하다는 점을 자주 목격합니다.8 이것이 본질적으로 나쁜 아이디어라고 단언할 수는 없지만, 경우에 따라 상당히 심각한 단점이 있을 수 있으므로 신중할 필요가 있습니다.\n\n\n\n\n\n\n\n\nFigure 6.7. jamovi IF 함수를 사용하여 변수를 더 적은 개수의 이산 수준으로 축소하기\n\n\n\n\n\n\n\n\n\n\n\n실습: 수치형 변수를 범주형 변수로 만들기\n\n\n\n\n‘파일’-‘새로운’ 메뉴로 새로운 스프레드시트 창을 만듭니다.\n“A” 열을 더블클릭하여 열의 이름을 Age로 변경한다. 그리고 위 화살표를 클릭하여 스프레드시트로 돌아옵니다.\n다음 데이터를 Age 열에 차례로 입력합니다.\n\n\n60,58,24,26,34,42,31,30,33,2,9\n\n\n‘데이터’-’계산’을 클릭하여 새로운 계산 변수를 추가한다. (Figure 6.7 참조)\n\n\n변수 이름을 AgeCat이라고 한다.\n\\(f_x\\)를 클릭하여 IF를 선택한다. 그리고 다음이 IF()의 괄호 안에 기술되도록 한다.\n\n\nIF(Age &gt;= 0 and Age &lt;= 20, 1, IF(Age &gt;= 21 and Age &lt;= 40, 2, IF(Age &gt;= 41 and Age &lt;= 60, 3 )))\n\n\n‘분석’-‘기술통계’-‘기술통계’ 메뉴를 선택한다.\nAgeCat을 ‘변수’ 상자로 옮긴 후, ’빈도분포표’를 클릭한다. 그러면 결과 창에 나이대 별로 다음과 같은 빈도표가 나타난다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.4.1 여러 변수에 적용할 수 있는 변환 생성하기\n때때로 여러 변수에 동일한 변환을 적용해야 할 때가 있습니다. 예를 들어, 여러 설문 항목을 동일한 방식으로 다시 계산하거나 재코딩해야 할 경우가 있습니다. jamovi의 유용한 기능 중 하나는 ‘데이터’-‘변환’ 메뉴를 사용하여 변환을 생성하고 저장한 후 여러 변수에 적용할 수 있다는 것입니다. 앞서 살펴본 첫 번째 예제를 다시 사용하여, 10명의 사람이 응답한 원래 리커트 척도 데이터가 포함된 likert.omv 데이터 파일을 활용해 보겠습니다. 변환을 생성하고 저장한 후 여러 변수에 적용하려면, 먼저 스프레드시트 편집기에서 변환을 생성할 변수를 선택합니다. 이 예제에서는 likert.raw 변수를 선택합니다. 그런 다음 jamovi의 ‘데이터’ 리본에서 ‘변환’ 메뉴를 클릭하면 Figure 6.8 같은 화면이 나타납니다.\n\n\n\n\n\n\n\n\nFigure 6.8. jamovi의 변환 명령을 사용하여 새로운 변수 변환 생성하기\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.9. jamovi에서 변환을 지정하고 변환 1이라는 이름으로 저장하는 과정\n\n\n\n\n\n새 변수를 opinion.strength라고 명명한 후, ‘변환 사용’ 선택 상자를 클릭하고 ’새 변환 만들기…’를 선택합니다. 여기에서 변환을 생성하고 이름을 지정할 수 있습니다. 변환은 기본적으로 ’변환 1’이라는 이름이 자동으로 지정되지만 필요하면 변경할 수 있습니다. 그런 다음 함수 입력 상자에 ABS($source - 4)를 입력한 후 Enter 키를 누르면 변환이 생성되고 likert.raw 변수에 적용됩니다.\n주목할 점은 변수 라벨을 직접 사용하지 않고, 대신 $source를 사용했다는 것입니다. 이는 동일한 변환을 여러 변수에 적용할 수 있도록 하기 위함이며, jamovi에서는 변환할 원본 변수를 $source로 참조해야 합니다. 변환은 저장되며, 데이터 세트를 .omv 파일로 저장하면 언제든 다시 사용할 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 6.10. jamovi의 새로운 관측치(레코드) 추가 버튼을 사용하여 세 개의 연령 범주로 변환하기\n\n\n\n\n\n앞서 살펴본 사교 모임에서의 연령 분포 예제를 변환을 사용하여 다시 수행할 수도 있습니다. 시도해 보세요! 이전에 이 변수를 ‘younger’, ‘adult’, ‘older’의 세 그룹으로 분류한 바 있습니다. 이번에는 jamovi의 ’변환’ 창에서 ‘새로운 관측치(레코드) 추가’ 버튼을 사용하여 동일한 작업을 수행하겠습니다. 데이터 세트를 다시 불러오거나 새로 만들고, 새로운 변수 변환을 설정합니다. 변환된 변수를 ‘AgeCats’로 명명하고, 변환 이름은 ’Agegroupings’로 지정합니다. 그런 다음 함수 상자 옆에 있는 “\\(+\\)” 버튼을 클릭합니다. 이것이 ’새로운 관측치(레코드) 추가’ 버튼이며, Figure 6.10 에서 빨간색 화살표로 표시된 위치에 있습니다.\nFigure 6.10 의 변환을 재현하면 새로운 값이 스프레드시트 창에 나타날 것입니다. 또한, 생성된 연령 그룹 변환이 저장되므로 언제든 다시 적용할 수 있습니다. 물론 같은 데이터 세트 내에서 여러 개의 ‘Age’ 변수를 가질 가능성은 낮겠지만, jamovi에서 변환을 설정하는 방법을 익혔으므로 다른 유형의 변수에도 동일한 개념을 적용할 수 있습니다.\n이러한 변환을 사용할 수 있는 일반적인 시나리오는 설문 조사 척도가 여러 개의 문항(예: 20개 항목)으로 구성된 경우입니다. 원래 1에서 6까지 점수를 매겼던 문항들을 1에서 3까지 다시 코딩해야 하는 상황을 예로 들 수 있습니다. jamovi에서는 변환을 생성한 후 이를 반복 적용하여 모든 변수를 손쉽게 다시 코딩할 수 있습니다.",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 조작</span>"
    ]
  },
  {
    "objectID": "06-Pragmatic-matters.html#추가적인-수학-함수와-연산",
    "href": "06-Pragmatic-matters.html#추가적인-수학-함수와-연산",
    "title": "6  데이터 조작",
    "section": "6.5 추가적인 수학 함수와 연산",
    "text": "6.5 추가적인 수학 함수와 연산\n변수 변환 및 재코딩 절에서 변수 변환의 개념을 논의하면서, 데이터에 적용할 수 있는 많은 변환들이 비교적 간단한 수학 함수와 연산을 기반으로 한다는 점을 설명했습니다. 이번 절에서는 그 논의를 다시 살펴보고, 실제 데이터 분석에서 유용하게 사용될 수 있는 몇 가지 추가적인 수학 함수와 산술 연산을 소개하고자 합니다. Table 6.5 에서는 여기서 다루거나 이후에 언급할 다양한 수학 함수들을 간략하게 개괄하고 있습니다.9 물론, 이 표가 가능한 모든 기능을 포괄하는 것은 아니지만, 데이터 분석에서 자주 사용되며 jamovi에서 지원하는 함수들을 포함하고 있습니다.\n\n\n\n\nTable 6.5. 몇 가지 수학 연산자\n\n\n\n\n\n함수예제 입력결과\n\n제곱근SQRT(x)SQRT(25)5\n\n절대값ABS(x)ABS(-23)23\n\n로그 (밑 10)LOG10(x)LOG10(1000)3\n\n로그 (밑 e)LN(x)LN(1000)6.91\n\n지수EXP(x)EXP(6.908)1e+03\n\n박스-콕스 변환BOXCOX(x, lamda)BOXCOX(6.908, 3)110\n\n\n\n\n\n\n\n\n6.5.1 로그와 지수 함수\n앞서 언급한 것처럼, jamovi에는 다양한 수학 함수들이 내장되어 있으며, 모든 함수를 설명하거나 나열하는 것은 큰 의미가 없습니다. 대체로 이 책에서는 필수적인 함수들만 다루고자 하지만, 로그 함수와 지수 함수는 예외로 하고 싶습니다. 비록 이 책의 다른 부분에서는 필요하지 않지만, 보다 넓은 통계학 분야에서는 어디에나 등장하는 함수이기 때문입니다. 게다가 변수를 로그 변환(log-transform)하여 분석하는 것이 편리한 경우가 많습니다. 이 책의 독자들 중 상당수는 이미 로그 함수와 지수 함수를 접해본 적이 있을 것으로 생각되지만, 사회과학 통계 수업을 듣는 학생들 중에는 고등학교 이후로 로그를 접하지 못한 경우도 많기에 간략한 복습이 도움이 될 것입니다.\n로그와 지수를 이해하는 가장 쉬운 방법은 실제로 계산을 해보면서 다른 간단한 연산과의 관계를 살펴보는 것입니다. jamovi에서 특히 유용한 세 가지 함수, 즉 LN(), LOG10(), EXP() 함수에 대해 설명하겠습니다. 먼저 LOG10() 함수부터 살펴보죠. 이 함수는 “밑(base)이 10인 로그”를 계산합니다. 로그(logarithm) 를 이해하는 핵심은 로그가 거듭제곱의 “역연산(opposite operation)”이라는 점을 아는 것입니다. 구체적으로, 밑이 10인 로그는 10의 거듭제곱과 밀접한 관련이 있습니다. 예를 들어, 10의 세제곱이 1000이라는 사실을 수식으로 나타내면 다음과 같습니다:\n\\[10^3=1000\\]\n로그를 이해하는 핵심은 “10의 3제곱이 1000이다”라는 진술이 “1000을 밑이 10인 로그로 나타내면 3이다”라는 진술과 동등하다는 점을 인식하는 것입니다. 이를 수식으로 나타내면 다음과 같습니다:\n\\[\\log_{10}(1000)=3\\]\nLOG10() 함수가 10의 거듭제곱과 관련이 있다면, 다른 밑을 가지는 로그 함수도 존재할 것이라고 예상할 수 있습니다. 물론 그렇습니다. 사실, 10이라는 숫자는 수학적으로 특별할 것이 없습니다. 우리가 유용하게 사용하는 이유는 우리의 숫자 체계가 10진법을 기반으로 하기 때문이지만, 수학적으로는 10진법이 특별한 의미를 가지지는 않습니다. 예를 들어, 밑이 2인 로그(logarithm in base 2)도 계산할 수 있습니다.\n또한, 통계학에서 밑이 10이나 2보다 훨씬 더 자주 등장하는 로그가 있습니다. 바로 자연 로그(natural logarithm) 입니다. 자연 로그는 밑이 \\(e\\)인 로그를 의미합니다. 그렇다면 \\(e\\)가 무엇인지 설명해야겠네요.\n수학에서 중요한 수 중 하나인 \\(e\\)는 오일러 수(Euler’s number) 라고 불리며, 무한 소수로 표현되는 무리수(irrational number)입니다. \\(e\\)의 첫 몇 자리 숫자는 다음과 같습니다:\n\\[e \\approx 2.718282 \\]\n통계학에서는 \\(e\\)의 거듭제곱을 계산해야 하는 경우가 많습니다. 이 연산을 지수 함수(exponential function) 라고 하며, \\(e^x\\)는 흔히 \\(\\exp(x)\\)로 표기됩니다. 따라서 jamovi에는 지수 함수를 계산하는 EXP() 함수가 포함되어 있습니다.\n\\(e\\)가 통계학에서 자주 등장하는 만큼, 자연 로그(밑이 \\(e\\)인 로그)도 자주 나타납니다. 수학자들은 이를 \\(\\log_e(x)\\) 또는 \\(\\ln(x)\\)로 표기하며, jamovi에서도 같은 방식으로 작동합니다. 즉, LN() 함수는 자연 로그를 계산하는 함수입니다.\n이제 로그와 지수 함수에 대한 설명은 이 정도로 충분할 것 같습니다!",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 조작</span>"
    ]
  },
  {
    "objectID": "06-Pragmatic-matters.html#데이터의-부분-집합-추출하기",
    "href": "06-Pragmatic-matters.html#데이터의-부분-집합-추출하기",
    "title": "6  데이터 조작",
    "section": "6.6 데이터의 부분 집합 추출하기",
    "text": "6.6 데이터의 부분 집합 추출하기\n데이터 처리에서 매우 중요한 작업 중 하나는 특정 부분 집합을 추출하는 것입니다. 예를 들어, 특정 실험 조건의 데이터만 분석하고 싶을 수도 있고, 50세 이상의 사람들에 대한 데이터를 집중적으로 살펴보고 싶을 수도 있습니다. 이를 수행하기 위한 첫 번째 단계는 jamovi에서 원하는 관측치에 해당하는 데이터의 부분 집합을 필터링하는 것입니다.\n이 섹션에서는 nightgarden.csv 데이터 세트로 돌아가 보겠습니다. 이 장을 한 번에 읽고 있다면, 이미 이 데이터 세트를 jamovi 창에 불러온 상태일 것입니다. 이 섹션에서는 speaker와 utterance라는 두 변수를 중심으로 살펴보겠습니다. (이 변수들이 어떤 것인지 기억나지 않는다면 [데이터의 표와 교차표 만들기] 섹션을 참고하세요.) 이제 ‘makka-pakka’가 한 말만 추출하고 싶다고 가정해 보겠습니다. 이를 위해 jamovi에서 필터를 지정해야 합니다. 먼저, jamovi의 ’데이터’ 도구 모음에서 ‘필터’를 클릭하여 필터 창을 엽니다. 그런 다음, ’필터 1’ 텍스트 상자에서 ‘=’ 기호 옆에 다음과 같이 입력합니다(작은따옴표 포함):\n\nspeaker == ‘makka-pakka’\n\n\n\n\n\n\n\n\n\nFigure 6.11. jamovi의 필터 옵션을 사용하여 nightgarden 데이터의 부분 집합 만들기\n\n\n\n\n\n이 작업을 완료하면 스프레드시트 창에 ‘필터 1’이라는 새로운 열이 추가된 것을 볼 수 있습니다(Figure 6.11 참조). 여기에서 speaker가 ’makka-pakka’가 아니면 회색으로 표시되며(즉, 필터링됨), speaker가 ’makka-pakka’가 맞으면 초록색 체크 표시가 되어 필터링된 상태임을 나타냅니다. 이를 확인하려면 ’기술통계’-‘기술통계’ 창에서 speaker 변수에 대한 ’빈도분포표’를 실행하여 어떤 결과가 나오는지 확인해 보세요. 직접 시도해 보세요!\n이 간단한 예제에 이어, jamovi에서는 논리 표현식을 사용하여 보다 복잡한 필터를 만들 수도 있습니다. 예를 들어, utterance 값이 “pip” 또는 “oo”인 경우만 유지하고 싶다고 가정해 보겠습니다. 이 경우 ‘필터 1’ 텍스트 상자에서 ‘=’ 기호 옆에 다음과 같이 입력하면 됩니다:\n\nutterance == ‘pip’ or utterance == ‘oo’",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 조작</span>"
    ]
  },
  {
    "objectID": "06-Pragmatic-matters.html#요약",
    "href": "06-Pragmatic-matters.html#요약",
    "title": "6  데이터 조작",
    "section": "6.7 요약",
    "text": "6.7 요약\n이 장에는 특별한 일관성이 있는 내용이 아닙니다. 여러 유용한 주제와 팁을 한데 모은 내용이므로, 가장 적절한 마무리는 다음 목록을 다시 한번 반복하는 것입니다:\n\n데이터를 표로 요약하기.\njamovi의 논리 표현식.\n변수 변환 및 재코딩.\n추가적인 수학 함수와 연산.\n데이터의 부분 집합 추출하기.",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 조작</span>"
    ]
  },
  {
    "objectID": "06-Pragmatic-matters.html#footnotes",
    "href": "06-Pragmatic-matters.html#footnotes",
    "title": "6  데이터 조작",
    "section": "",
    "text": "이 인용문은 Home is the Hangman (1975)에서 나온 것이다.↩︎\n저는 10대 시절 “쿨해 보이려는” 시도가 실패한 것을 증거로 제시하겠습니다. 어떤 것은 애초에 불가능합니다.↩︎\njamovi의 ‘계산된 새 변수(Compute new variable)’ 화면에서 직접 확인할 수 있습니다. 다만, 모든 셀에서 \\(2 + 2\\)를 계산하는 것은 큰 의미가 없겠죠!↩︎\n= 연산자와 == 연산자는 완전히 다른 의미를 가집니다. 많은 프로그래밍 언어나 통계 프로그램에서도 =과 ==의 차이는 중요합니다. 사람들이 jamovi에서 논리 명령을 작성할 때 흔히 실수하는 부분이 =를 == 대신 사용하는 것입니다. 저도 10대 시절부터 여러 프로그래밍 언어를 다뤄왔지만, 여전히 이 실수를 종종 저지릅니다. 주의하세요!↩︎\njamovi의 흥미로운 특징이 있습니다. 간단한 논리 표현식(2 + 2 == 5 등)에서는 jamovi가 명확하게 ‘FALSE’ 또는 ‘TRUE’ 값을 출력합니다. 그러나 jamovi 내부적으로는 FALSE를 0, TRUE를 1로 저장합니다. 따라서 조금 더 복잡한 논리 표현식, 예를 들어 (2+2 == 4) or (2+2 == 5)을 평가하면, jamovi는 FALSE 또는 TRUE 대신 0 또는 1을 출력합니다.↩︎\n숫자의 절댓값은 부호와 관계없이 해당 숫자가 0에서 얼마나 떨어져 있는지를 나타냅니다.↩︎\n0을 0으로 유지하는 이유는 단순히 likert.centred / opinion.strength를 사용할 경우 수학적으로 0을 0으로 나눌 수 없기 때문입니다. 한번 시도해 보세요.↩︎\n만약 이 책을 더 읽고 이 섹션을 다시 읽고 있다면, 이에 대한 좋은 예는 Age를 예측 변수로 사용하여 회귀 분석을 실행하는 대신 AgeCats를 그룹 변수로 사용하여 ANOVA를 수행하는 경우일 것입니다. 이를 수행하는 데는 좋은 이유가 있을 수 있습니다. 예를 들어, Age와 결과 변수 간의 관계가 비선형적이며, 비선형 회귀를 실행하는 것이 어렵다고 느껴질 수 있습니다! 그러나 정말로 좋은 논리가 있는 경우가 아니라면, 그렇게 하지 않는 것이 좋습니다. 이는 다양한 문제를 초래할 수 있으며(예: 데이터가 정규성 가정을 위반할 가능성이 높음), 통계적 검정력도 상당히 손실될 수 있습니다.↩︎\nBox-Cox 함수에 대한 설명은 나중으로 미룹니다.↩︎",
    "crumbs": [
      "데이터 다루기",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>데이터 조작</span>"
    ]
  },
  {
    "objectID": "Prelude-Part-IV.html",
    "href": "Prelude-Part-IV.html",
    "title": "들어가며",
    "section": "",
    "text": "논리적 추론의 한계에 대하여\n이 인용문(https://www.bartleby.com/lit-hub/samuel-arthur-bent/duke-of-wellington/quote)은 시골을 가로지르는 마차 여행 중에 나온 말이다. 웰즐리와 그의 동행인 J. W. 크로커는 일종의 추측 게임을 하고 있었는데, 각각 언덕 너머에 무엇이 있을지를 예측하는 것이었다. 매번 웰즐리는 정답을 맞혔고, 크로커는 틀렸다. 수년 후, 누군가가 웰즐리에게 이 게임에 대해 묻자, 그는 “전쟁의 모든 기술은 언덕 너머에 무엇이 있는지를 파악하는 것이다”라고 설명했다. 사실, 전쟁만이 이런 성격을 가진 것은 아니다. 우리 삶 자체가 여러 형태의 추측 게임이며, 하루하루를 살아가는 데에도 우리는 적절한 추측을 해야 한다. 그러니 우리도 한 번 추측 게임을 해보자.\n가령, 당신과 내가 웰즐리와 크로커의 대결을 지켜보고 있고, 세 개의 언덕이 지나갈 때마다 다음 번 승자가 웰즐리일지 크로커일지를 예측해야 한다고 하자. 여기서 W는 웰즐리의 승리를, C는 크로커의 승리를 의미한다. 첫 세 개의 언덕이 지나간 후, 우리에게 주어진 데이터는 다음과 같다: \\(WWW\\)\n우리의 대화는 이렇게 진행된다:\n당신의 베팅이 적중했다. 세 개의 언덕이 더 지나갔고, 웰즐리가 모두 승리했다. 이제 우리의 점수는 1-0으로 당신이 앞서 있고, 데이터는 다음과 같이 정리된다: \\(WWW\\) \\(WWW\\). 나는 데이터를 세 개씩 묶어 정리했는데, 이렇게 하면 매 단계에서 우리가 이용했던 관찰 결과를 더 명확히 볼 수 있다. 이 새로운 데이터가 주어진 후, 우리의 대화는 이렇게 이어진다:\n이번에도 당신이 옳았고, 나는 틀렸다. 웰즐리는 다시 세 개의 언덕을 이겼고, 크로커와의 승부에서 9-0으로 앞서게 되었다. 이제 우리가 가진 데이터는 \\(WWW\\) \\(WWW\\) \\(WWW\\)가 되었다. 우리의 대화는 계속된다:\n웰즐리는 다시 세 개의 언덕을 연속으로 이겼다. 이제 웰즐리와 크로커의 점수는 12-0이 되었고, 우리 게임의 점수는 3-0이 되었다. 네 번째 라운드를 앞두고 우리의 데이터는 \\(WWW\\) \\(WWW\\) \\(WWW\\) \\(WWW\\)가 되었다. 대화는 계속된다:",
    "crumbs": [
      "통계 이론",
      "들어가며"
    ]
  },
  {
    "objectID": "Prelude-Part-IV.html#논리적-추론의-한계에-대하여",
    "href": "Prelude-Part-IV.html#논리적-추론의-한계에-대하여",
    "title": "들어가며",
    "section": "",
    "text": "전쟁의 모든 기술은 언덕 너머에 무엇이 있는지를 파악하는 것, 다시 말해 우리가 행하는 것에서 우리가 모르는 것을 배우는 것에 있다.\n– 아서 웰즐리, 제1대 웰링턴 공작\n\n\n\n\n\n당신: 세 번 연속으로 이겼다고 해서 큰 의미가 있는 건 아니지. 웰즐리가 크로커보다 이 게임을 더 잘할 수도 있겠지만, 단순히 운일 수도 있어. 그래도 나는 도박을 좋아하니까 웰즐리에게 걸겠어.\n\n\n나: 나도 세 번 연속 승리가 특별한 정보라고 보지는 않아. 웰즐리의 추측이 크로커보다 낫다고 볼 논리적인 이유도 없고. 이 단계에서는 베팅할 근거가 없다구. 미안, 난 패스할게.\n\n\n\n당신: 웰즐리가 여섯 번 연속으로 이겼어. 뭔가 수상한데? 아직 확신할 수는 없지만, 웰즐리가 다음 라운드도 이길 것 같아.\n\n\n나: 난 그렇게 생각하지 않아. 그래, 웰즐리가 여섯 번 연속 이겼다는 건 알겠지만, 그게 그가 일곱 번째도 이길 거라는 논리적 근거가 된다고는 보지 않아. 난 베팅하지 않을래.\n\n\n당신: 정말 그렇게 생각해? 좋아, 하지만 지난번에도 내 베팅이 맞았고, 난 내 선택이 괜찮다고 봐.\n\n\n\n당신: 이제는 너무 명백하지 않나? 웰즐리는 이 게임에서 훨씬 뛰어나. 우리 둘 다 다음 언덕도 웰즐리가 이길 거라고 생각하지?\n\n\n나: 그게 정말 논리적으로 증명된 걸까? 게임이 시작되기 전에는, 처음 10번의 결과에 대한 다양한 가능성이 있었고, 난 어떤 결과가 나올지 전혀 알지 못했어. \\(WWW\\) \\(WWW\\) \\(WWW\\) \\(W\\)도 가능했고, \\(WCC\\) \\(CWC\\) \\(WWC\\) \\(C\\)도 가능했고, \\(WWW\\) \\(WWW\\) \\(WWW\\) \\(C\\)도 가능했으며, 심지어 \\(CCC\\) \\(CCC\\) \\(CCC\\) \\(C\\)도 가능했지. 어떤 일이 일어날지 전혀 몰랐으니까, 난 이 모든 가능성을 똑같이 생각했을 거야. 너도 그렇게 생각했지, 그렇지 않아? 전혀 모른다는 건 그런 의미잖아.\n\n\n당신: 그랬던 것 같아.\n\n\n나: 그렇다면 달라진 게 뭐지? 우리가 시작할 때는 모든 가능성이 다 똑같이 타당하다고 생각했지만, 지금까지의 관찰 결과로 두 가지 가능성만을 남겨두었어: \\(WWW\\) \\(WWW\\) \\(WWW\\) \\(C\\) 또는 \\(WWW\\) \\(WWW\\) \\(WWW\\) \\(W\\). 지금까지의 증거가 이 두 가지를 제외한 나머지를 배제했지만, 그렇다고 이 두 가능성 사이에서 하나를 더 신뢰할 근거는 없잖아?\n\n\n당신: 맞아. 그런데 그래서 뭐?\n\n\n나: 처음 시작할 때 이 두 가지가 동등하게 가능하다고 생각했다면, 지금도 여전히 똑같은 가능성을 가지고 있다고 생각해야 해. 그러니 웰즐리가 9번 연속으로 이겼다는 게 놀랍기는 하지만, 그가 10번째도 이길 거라고 생각할 논리적 이유를 찾을 수가 없어. 난 여전히 베팅하지 않을래.\n\n\n당신: 네 말이 이해는 가. 하지만 난 여전히 웰즐리에게 걸겠어.\n\n\n\n당신: 또 맞췄어! 웰즐리가 세 번 더 이겼고, 나도 이겼어. 이제 인정하지? 내가 옳았다는 걸! 우리 이번에는 둘 다 웰즐리에게 베팅하는 거 맞지?\n\n\n나: 모르겠어. 여전히 지난 라운드와 똑같은 상황인 것 같아. 가능한 13개 언덕의 결과 중 아직 배제되지 않은 경우는 \\(WWW\\) \\(WWW\\) \\(WWW\\) \\(WWW\\) \\(C\\)와 \\(WWW\\) \\(WWW\\) \\(WWW\\) \\(WWW\\) \\(W\\)뿐이야. 게임이 시작될 때 모든 가능성이 동등하게 타당하다고 생각했다면, 지금도 이 두 가지는 동등하게 가능해야 하지 않아? 웰즐리가 대단한 연승을 하고 있다는 느낌은 들지만, 그 연승이 계속될 논리적 근거는 어디 있지?\n\n\n당신: 네 말은 억지스러워. 논리적 증거가 필요하면 우리 점수판을 보라고! 너는 논리적 분석을 했지만 지고 있어. 나는 그냥 상식에 의존했을 뿐인데 이기고 있잖아. 전략을 바꿔야 하는 거 아니야?\n\n\n나: 그건 일리가 있네. 하지만 여전히 네 전략이 더 낫다는 논리적 증거를 찾을 수가 없다구. 누군가 우리의 게임을 관찰하고 있다고 가정하면, 그들이 보는 데이터는 \\(YYY\\)가 될 거야. (역주: 당신(You)가 세 번 승리.) 논리적으로 보면, 이건 우리가 처음 웰즐리와 크로커를 지켜보던 상황과 다를 게 없다구. \\(WWW\\)가 웰즐리가 더 낫다는 증거가 될 수 없었다면, \\(YYY\\)만으로 네 전략이 더 낫다는 증거가 될 수 없지 않겠어?\n\n\n당신: 이제 보니, 너 좀 짜증 나는구나.\n\n\n나: 나는 그말에 대해서도 논리적 증거를 찾을 수가 없는데.",
    "crumbs": [
      "통계 이론",
      "들어가며"
    ]
  },
  {
    "objectID": "Prelude-Part-IV.html#가정-없이-학습하는-것은-신화이다",
    "href": "Prelude-Part-IV.html#가정-없이-학습하는-것은-신화이다",
    "title": "들어가며",
    "section": "가정 없이 학습하는 것은 신화이다",
    "text": "가정 없이 학습하는 것은 신화이다\n이 대화를 여러 가지 방식으로 분석할 수 있지만, 이 책은 심리학자를 위한 통계학 책이지 철학이나 논리 심리학 입문서가 아니므로 간략하게 설명하겠다.\n위에서 설명한 내용은 때때로 귀납의 수수께끼(riddle of induction)라고 불린다. 웰즐리가 12승 0패의 기록을 가지고 있다면 그가 13번째 게임에서도 이길 가능성이 높다고 생각하는 것이 매우 합리적일 수 있지만, 이에 대해 논리적으로 정당화하는 것은 쉽지 않다. 오히려, 아무리 답이 명백해 보여도, 논리적으로 정당화할 수 없는 어떤 가정을 하지 않고는 웰즐리에게 베팅하는 것은 불가능하다.\n귀납의 수수께끼는 철학자 데이비드 흄(David Hume)과 최근에는 넬슨 굿맨(Nelson Goodman)의 연구와 관련이 깊지만, 문학(루이스 캐럴(Lewis Carroll)이나 기계 학습(‘공짜 점심은 없다’(no free lunch) 정리)과 같은 다양한 분야에서도 이 문제가 등장한다. 우리가 알고 있는 것으로 모르는 것에 대해 알고자 노력한다는 것은 정말 이상한 일이다. 중요한 핵심은, 세상에 대해 무언가를 알고자 한다면 가정과 편향은 불가피하다는 것이다. 이러한 사실에서 우리는 벗어날 수 없다. 그것이 인간의 추론뿐만 아니라 통계적 추론에서도 마찬가지이다.\n대화에서 나는 인간으로서의 당신이 내린 매우 합리적인 추론을 비판하는 입장이었다. 그러나 당신이 의존한 상식적인 추론 방식은 통계학자가 사용하는 방식과 다르지 않다. 당신이 보여준 ‘상식적인’ 접근법은 사실 웰즐리와 크로커 사이에 어떤 실력 차이가 존재한다는 묵시적 가정에 기반을 둔 것이었고, 당신은 그 실력 차이가 얼마나 되는지를 파악하려 했다. 반면, 나의 ’논리적 분석’은 그 가정을 완전히 거부한 접근 방식이었다. 나는 단지 승패의 연속적인 흐름이 존재한다는 사실만 받아들였으며, 어떤 연속이 나타날지 모른다는 전제하에 추론을 진행했다. 대화 내내 나는 웰즐리-크로커 게임이 시작될 때 모든 논리적으로 가능한 데이터 세트가 동일한 가능성을 가진다고 주장했으며, 내가 나의 믿음을 수정하는 유일한 방식은 관찰된 사실과 모순되는 가능성들을 제거하는 것이었다.\n이 접근법만 놓고 보면 매우 합리적으로 들린다. 실제로 이는 훌륭한 연역적 추론의 특징처럼 보인다. 셜록 홈즈처럼, 나는 불가능한 것들을 제거함으로써 남은 것이 진실이기를 바랐다. 그러나 우리가 본 것처럼, 불가능한 것을 제거하는 것만으로는 미래에 대한 예측을 전혀 할 수 없었다.\n대화에서 내가 주장한 모든 논리는 자체적으로는 정확했다.\n하지만 가정을 전혀 하지 않는다면 어떤 예측도 할 수 없다는 것은 필연적인 결론이었다. 결국 나는 당신과의 게임에서 졌다. 왜냐하면 당신은 가정을 했고, 그 가정이 맞았기 때문이다. 실력은 실제로 존재하는 것이었고, 당신은 그것을 가정했기 때문에 웰즐리가 크로커보다 더 뛰어나다는 사실을 학습할 수 있었다. 만약 당신이 덜 합리적인 가정을 바탕으로 학습을 진행했다면, 게임에서 이기지 못했을 수도 있다.\n궁극적으로 여기서 두 가지 교훈을 얻을 수 있다. 첫째, 데이터를 통해 무언가를 배우고 싶다면 가정을 피할 수 없다는 것이다.\n둘째, 가정이 필수적이라는 사실을 깨닫는 순간, 올바른 가정을 설정하는 것이 중요해진다! 가정을 적게 사용하는 데이터 분석이 항상 더 나은 것은 아니다. 중요한 것은 그 가정이 데이터에 적절한지 여부이다. 이 책을 읽어 나가면서 특정 통계 기법이 기반으로 하는 가정과, 그 가정이 타당한지 확인하는 방법에 대해 자주 설명할 것이다.",
    "crumbs": [
      "통계 이론",
      "들어가며"
    ]
  },
  {
    "objectID": "07-Introduction-to-probability.html",
    "href": "07-Introduction-to-probability.html",
    "title": "7  확률이란?",
    "section": "",
    "text": "7.1 확률과 통계는 어떻게 다른가?\n확률 이론을 논의하기 전에, 확률과 통계의 관계에 대해 잠시 생각해 보는 것이 도움이 됩니다. 이 두 학문은 밀접하게 관련되어 있지만 동일하지는 않습니다. 확률 이론은 “가능성의 원리”입니다. 이는 다양한 유형의 사건이 얼마나 자주 발생할지를 알려주는 수학의 한 분야입니다. 예를 들어, 다음과 같은 질문들은 확률 이론을 사용하여 답할 수 있습니다:\n이 질문들은 모두 공통점을 가지고 있습니다. 각각의 경우에서 “세상에 대한 진실”은 이미 알려져 있으며, 질문은 그런 기지의 세상에서 “어떤 유형의 사건”이 발생할지에 대한 것입니다. 첫 번째 질문에서는 동전이 공정하다는 것을 알고 있으며, 따라서 개별 동전 던지기에서 앞면이 나올 확률이 50%라는 것도 압니다. 두 번째 질문에서는 주사위를 한 번 던졌을 때 6이 나올 확률이 1/6이라는 것을 알고 있습니다. 세 번째 질문에서는 카드 데크가 제대로 섞였다는 것을 알고 있습니다. 네 번째 질문에서는 복권이 특정한 규칙을 따른다는 것을 알고 있습니다. 요점은 확률론적 질문은 이미 알려진 모형에서 출발하며, 우리는 그 모형을 사용하여 계산을 수행한다는 것입니다. 이러한 모형은 매우 단순할 수도 있습니다. 예를 들어, 동전 던지기 예제에서는 다음과 같이 모형을 정의할 수 있습니다: \\[P(head)=0.5\\]\n이를 “앞면이 나올 확률은 0.5이다”라고 읽을 수 있습니다. 나중에 보겠지만, 백분율이 0%에서 100% 사이의 숫자인 것처럼, 확률도 0에서 1 사이의 숫자로 표현됩니다. 이 확률 모형을 사용하여 첫 번째 질문에 답할 때, 실제로는 어떤 일이 일어날지 정확히 알지는 못합니다. 질문에서처럼 10번 연속으로 앞면이 나올 수도 있습니다. 하지만 세 번만 앞면이 나올 수도 있습니다. 이것이 핵심입니다. 확률 이론에서는 모형이 이미 알려져 있지만, 데이터는 알려져 있지 않습니다.\n그렇다면 확률은 그렇다 치고, 통계는 무엇일까요? 통계적 질문은 반대 방향으로 작동합니다. 통계에서는 우리가 세상의 진실을 알지 못합니다. 우리가 가진 것은 오직 데이터뿐이며, 우리는 이 데이터를 통해 미지의 세상에 대한 진실을 알아내고자 합니다. 통계적 질문은 다음과 같은 형태를 띱니다:\n이번에는 우리가 가진 것은 오직 데이터뿐입니다. 내가 아는 것은 친구가 동전을 10번 던졌고, 그 결과가 모두 앞면이었다는 것입니다. 그리고 내가 알고 싶은 것은 실제로 공정한 동전인데 10번 연속 앞면이 나온 것인지, 아니면 내 친구가 나를 속이고 있는 것인지에 대한 것입니다. 내가 가진 데이터는 다음과 같습니다:\n그리고 내가 하려는 것은 어떤 “세상에 대한 모형”을 신뢰해야 하는지를 결정하는 것입니다. 만약 동전이 공정하다면, 내가 채택해야 할 모형은 앞면이 나올 확률이 0.5라는 것입니다, 즉 \\(P(heads) = 0.5\\)입니다. 만약 동전이 공정하지 않다면, 앞면이 나올 확률이 0.5가 아니라고 결론을 내려야 합니다. 이를 수식으로 표현하면 \\(P(heads)\\ne{0.5}\\)가 됩니다. 즉, 통계적 추론의 문제는 어떤 확률 모형이 맞는지를 알아내는 것입니다. 분명히, 통계적 질문은 확률적 질문과 동일하지 않지만, 둘은 깊이 연결되어 있습니다. 이러한 이유로, 좋은 통계 이론 입문서는 확률이 무엇이며, 그것이 어떻게 작동하는지를 설명하는 것부터 시작해야 합니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>확률이란?</span>"
    ]
  },
  {
    "objectID": "07-Introduction-to-probability.html#확률과-통계는-어떻게-다른가",
    "href": "07-Introduction-to-probability.html#확률과-통계는-어떻게-다른가",
    "title": "7  확률이란?",
    "section": "",
    "text": "공정한 동전을 10번 던졌을 때 모두 앞면이 나올 확률은 얼마인가?\n6면 주사위를 두 번 굴렸을 때 두 번 모두 6이 나올 확률은 얼마인가?\n완벽하게 섞인 카드 데크에서 다섯 장을 뽑았을 때 모두 하트일 확률은 얼마인가?\n내가 복권에 당첨될 확률은 얼마인가?\n\n\n\n\n\n내 친구가 동전을 10번 던졌는데 모두 앞면이 나왔다면, 내 친구는 나를 속이고 있는 걸까?\n카드 데크에서 맨 위 다섯 장의 카드가 모두 하트라면, 데크가 제대로 섞였을 확률은 얼마인가?\n복권 위원장의 배우자가 복권에 당첨되었다면, 복권이 조작되었을 가능성은 얼마인가?\n\n\n\nH H H H H H H H H H H",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>확률이란?</span>"
    ]
  },
  {
    "objectID": "07-Introduction-to-probability.html#확률이란-무엇을-의미하는가",
    "href": "07-Introduction-to-probability.html#확률이란-무엇을-의미하는가",
    "title": "7  확률이란?",
    "section": "7.2 확률이란 무엇을 의미하는가?",
    "text": "7.2 확률이란 무엇을 의미하는가?\n먼저 이 질문부터 시작해 보겠습니다. “확률”이란 무엇일까요? 놀랍게도, 통계학자와 수학자들은 확률의 규칙에 대해서는 (대체로) 동의하지만, 이 단어의 의미에 대해서는 그다지 합의가 이루어지지 않았습니다. 이는 다소 이상하게 느껴질 수도 있습니다. 우리는 “기회”, “가능성”, “있을 법한”, “확률적”이라는 단어를 편하게 사용하며, 그 의미를 이해하는 것이 어렵지 않다고 생각합니다. 하지만 실제로 이런 개념이 무엇인지 정의하려다 보면, 대화가 끝난 후에도 완전히 이해하지 못한 것 같은 기분이 들 수 있습니다. 그리고 이는 많은 일상 개념과 마찬가지로, 우리는 그것이 무엇인지 정확히 파악하고 있지 못한 것일 수 있습니다.\n그럼, 한번 시도해 보겠습니다. 두 로봇 축구팀, 아두이노 아스널과 C 밀란이 경기를 한다고 가정해 보겠습니다. 심사숙고 후에, 저는 아두이노 아스널이 이길 확률이 80%라고 결정했습니다. 그렇다면, 이것이 의미하는 바는 무엇일까요? 다음 세 가지 가능성이 있습니다:\n\n이들은 로봇 팀이므로 여러 번 반복해서 경기를 시킬 수 있고, 그렇게 하면 아두이노 아스널이 평균적으로 10번 중 8번 이긴다.\n특정 경기에서, C 밀란에 $1을 베팅하면 $5의 배당금을 받는 경우(즉, $1을 돌려받고 추가로 $4의 보상을 받는 경우), 또는 아두이노 아스널에 $4를 베팅하면 $1의 보상을 받는 경우(즉, $4를 돌려받고 추가로 $1을 받는 경우)에만 베팅이 “공정하다”고 판단된다.\n아두이노 아스널의 승리에 대한 나의 주관적인 “신념” 또는 “확신”이 C 밀란의 승리에 대한 신념보다 네 배 더 강하다.\n\n이 세 가지는 모두 그럴듯해 보입니다. 하지만 이들은 서로 동일하지 않으며, 모든 통계학자가 이를 전적으로 지지하는 것도 아닙니다. 그 이유는 서로 다른 통계적 이념(정말로 존재합니다!)이 있기 때문이며, 자신이 어떤 입장을 취하느냐에 따라 위 진술 중 일부가 무의미하거나 관련이 없다고 주장할 수도 있습니다. 이 절에서는 문헌에서 볼 수 있는 두 가지 주요 접근법을 간략히 소개하려 합니다. 이 두 가지가 유일한 접근법은 아니지만, 가장 대표적인 두 진영이라 할 수 있습니다.\n\n7.2.1 빈도주의자 관점\n확률에 대한 두 가지 주요 접근 방식 중 첫 번째이자 통계학에서 더 지배적인 접근 방식은 빈도주의자 관점(frequentist view)이며, 이는 확률을 장기적 빈도(long-run frequency)로 정의합니다. 공정한 동전을 반복해서 던진다고 가정해 봅시다. 정의에 따라, 이 동전은 \\(P(H) = 0.5\\)의 확률로 앞면이 나옵니다. 그렇다면 우리는 어떤 결과를 관찰할 수 있을까요? 첫 번째 20회의 동전 던지기가 다음과 같을 수도 있습니다.\n\nT,H,H,H,H,T,T,H,H,H,H,T,H,H,T,T,T,T,T,H\n\n단, T는 뒷면, H는 앞면. 이 경우 20번의 동전 던지기 중 11번(55%)이 앞면이 나왔습니다. 이제 제가 앞면이 나온 횟수(\\(N_H\\))를 기록하고, 매번 동전을 던질 때마다 앞면이 나온 비율 \\(\\frac{N_H}{N}\\)을 계산했다고 가정해 봅시다. Table 7.1 은 그 결과를 보여줍니다(실제로 동전을 던져서 데이터를 수집했습니다!).\n\n\n\n\nTable 7.1. 동전 던지기와 앞면 비율\n\n\n\n\n\nnumber of flipsnumber of headsproportion\n\n100.00\n\n210.50\n\n320.67\n\n430.75\n\n540.80\n\n640.67\n\n740.57\n\n850.63\n\n960.67\n\n1070.70\n\n1180.73\n\n1280.67\n\n1390.69\n\n14100.71\n\n15100.67\n\n16100.63\n\n17100.59\n\n18100.56\n\n19100.53\n\n20110.55\n\n\n\n\n\n\n\n초반에는 앞면의 비율이 심하게 변동하는 것을 볼 수 있습니다. 처음에는 0.00에서 시작해 0.80까지 오르기도 합니다. 그러나 시간이 지나면서 점차 변동 폭이 줄어들고, 대부분의 값이 “올바른” 정답인 0.50에 가까워지는 것을 확인할 수 있습니다. 이것이 빈도주의자 확률 정의의 핵심입니다. 공정한 동전을 계속해서 던지면, \\(N\\)이 점점 커질수록(\\(N \\rightarrow \\infty\\)) 앞면이 나오는 비율이 50%에 수렴합니다. 수학자들이 신경 쓰는 미묘한 기술적 사항들이 있지만, 질적으로 볼 때 이것이 빈도주의자 확률의 정의입니다.\n안타깝게도, 저는 무한한 개수의 동전을 가지고 있지도 않고, 무한히 동전을 던질 인내심도 없습니다. 하지만 컴퓨터는 이런 단순 반복 작업에 능숙합니다. 그래서 컴퓨터를 이용해 동전을 1000번 던지는 시뮬레이션을 수행하고, \\(\\frac{N_H}{N}\\)이 \\(N\\)이 증가함에 따라 어떻게 변화하는지 시각화했습니다. 실제로 네 번 실행하여 결과가 우연이 아님을 확인했습니다. Figure 7.1 에서 그 결과를 볼 수 있습니다. 보시다시피, 관찰된 앞면의 비율은 결국 변동을 멈추고 안정됩니다. 그리고 최종적으로 수렴하는 값이 바로 앞면이 나올 실제 확률입니다.\n빈도주의자 확률 정의는 몇 가지 바람직한 특성을 가지고 있습니다. 첫째, 객관적입니다. 즉, 사건의 확률은 반드시 현실 세계에 근거해야 합니다. 확률 명제가 의미를 가지려면 (일련의) 실제 세계에서 발생하는 사건을 참조해야 하며, 해당 사건들의 상대적 빈도를 고려해야 합니다.1 둘째, 명확합니다. 동일한 연속적 사건을 관찰하고 확률을 계산하는 모든 사람들은 필연적으로 동일한 결과를 도출해야 합니다.\n그러나 빈도주의자 접근법에는 단점도 있습니다. 가장 큰 문제는 무한한 연속적 사건이 실제 세계에 존재하지 않는다는 것입니다. 예를 들어, 주머니에서 동전을 꺼내 던진다고 가정해 봅시다. 동전이 바닥에 닿을 때마다 표면이 마모되며, 결국 동전은 닳아서 사용할 수 없게 됩니다. 따라서 “무한한 동전 던지기”라는 개념이 의미가 있는지, 혹은 객관적인지에 대해 의문을 가질 수 있습니다. 또한, 빈도주의자 정의는 적용 범위가 제한적입니다. 일상적인 언어에서 사람들이 확률을 언급하는 많은 경우가 빈도주의자 정의에 의해 설명될 수 없습니다.\n예를 들어, 기상학자가 TV에 나와서 “2048년 11월 2일 애들레이드에서 비가 올 확률은 60%입니다”라고 말한다고 가정해 봅시다. 우리는 이 말을 자연스럽게 받아들이지만, 빈도주의자 관점에서 이를 정의하는 것은 쉽지 않습니다. 애들레이드는 하나뿐이고, 2048년 11월 2일도 한 번뿐입니다. 즉, 빈도주의적으로 정의할 수 있는 무한한 사건의 연속이 존재하지 않습니다.\n\n\n\n\n\n\n\n\nFigure 7.1. 빈도주의적 확률이 작동하는 방식의 예시. 공정한 동전을 반복해서 던지면 앞면이 나온 비율이 점차 안정되며, 궁극적으로 실제 확률인 0.5에 수렴합니다. 각 패널은 네 개의 서로 다른 시뮬레이션 실험을 보여줍니다. 각 실험에서 동전을 1000번 던졌으며, 매번 앞면이 나온 비율을 기록했습니다. 어떤 실험에서도 정확히 0.5에 도달하지는 않았지만, 실험을 무한히 연장하면 결국 0.5에 수렴하게 됩니다.\n\n\n\n\n\n빈도주의자 확률 개념은 단일 사건(single event)에 대한 확률 진술을 금지합니다. 빈도주의자 관점에서 보면, 내일 비가 올 수도 있고, 안 올 수도 있습니다. 단일하고 반복 불가능한 사건에 확률이 부여될 수 없습니다. 물론, 빈도주의자들은 이 문제를 해결하기 위해 몇 가지 기발한 방법을 사용하기도 합니다. 한 가지 가능성은 기상학자가 “60%의 비 확률을 예측할 수 있는 날의 범주가 있고, 그러한 범주의 날만을 보면 실제로 60%의 확률로 비가 올 것이다”라는 의미로 말하는 것일 수도 있습니다. 이는 직관적으로는 다소 이상하게 들리지만, 빈도주의자들은 가끔 이러한 방식으로 접근하는 경우가 있습니다. 그리고 이러한 개념은 이후 Section 8.5 등 에서 다시 다룰 것입니다.\n\n\n7.2.2 베이지안 관점\n베이지안 관점은 종종 주관주의자 관점이라고 불리며, 통계학자들 사이에서는 소수 의견이었지만 지난 수십 년간 꾸준히 영향력을 넓혀 왔습니다. 베이지안주의에는 여러 가지 유형이 있어 정확히 “베이지안 관점”이 무엇인지 정의하기 어렵습니다. 주관적 확률에 대한 가장 일반적인 생각은 어떤 사건에 대한 확률이란 지능적이고 합리적인 행위자가 그 사건이 참이라고 생각하는 신념의 정도로 정의하는 것입니다. 이러한 관점에서는 확률이 객관적으로 세상에 존재하는 것이 아니라 사람이나 다른 지능적인 존재의 생각과 가정 속에서만 존재하게 됩니다.\n그러나 이러한 접근법이 작동하려면 “신념의 정도”를 조작적으로 정의할 방법이 필요합니다. 이를 공식화하는 한 가지 방법은 “합리적인 도박”의 개념으로 설명하는 것입니다. 물론 이 외에도 다양한 방법이 존재합니다. 예를 들어, 내가 내일 비가 올 확률이 60%라고 믿는다고 가정해 봅시다. 누군가가 내일 비가 오면 $5를 받고 비가 오지 않으면 $5를 잃는 내기를 제안한다면, 내 입장에서는 꽤 괜찮은 내기입니다. 반면, 비가 올 확률이 40%라고 생각한다면 이 내기는 좋은 선택이 아닙니다. 이렇게 우리는 내가 기꺼이 받아들이는 내기를 기준으로 “주관적 확률”의 개념을 조작적으로 정의할 수 있습니다.\n베이지안 접근법의 장점과 단점은 무엇일까요? 가장 큰 장점은 어떠한 사건에 대해서도 확률을 부여할 수 있다는 것입니다. 반복 가능한 사건에만 한정될 필요가 없습니다. 많은 사람들에게 단점으로 여겨지는 부분은 순수하게 객관적일 수 없다는 점입니다. 확률을 명시하려면 해당 신념의 정도를 가진 존재를 지정해야 합니다. 이 존재는 인간, 외계인, 로봇, 심지어 통계학자일 수도 있습니다. 하지만 반드시 어떤 지능적 행위자가 존재해야 하며, 그 행위자는 무언가를 믿고 있어야 합니다. 많은 사람들에게 이는 불편하게 느껴질 수 있으며, 확률이 임의적이라고 생각될 수 있습니다. 베이지안 접근법은 해당 행위자가 합리적이어야 한다는 것(즉, 확률 규칙을 따라야 한다는 것)을 요구하지만, 각자가 자신의 신념을 가질 수 있도록 허용합니다. 나는 동전이 공정하다고 믿을 수 있고, 당신은 그렇지 않을 수도 있습니다. 둘 다 합리적임에도 불구하고 말입니다.\n반면, 빈도주의 관점은 두 관찰자가 동일한 사건에 대해 서로 다른 확률을 부여하는 것을 허용하지 않습니다. 이런 일이 발생한다면 최소한 한 명은 틀렸다고 간주됩니다. 그러나 베이지안 관점은 이러한 상황을 막지 않습니다. 서로 다른 배경 지식을 가진 두 관찰자는 동일한 사건에 대해 정당하게 다른 신념을 가질 수 있습니다. 요약하자면, 빈도주의자 관점이 때때로 너무 좁아서(우리가 확률을 부여하고 싶은 많은 것들을 제외하기 때문에) 비판받는다면, 베이지안 관점은 너무 넓어서(관찰자 간의 차이를 과도하게 허용하기 때문에) 비판받습니다.\n\n\n7.2.3 무엇이 서로 다르고 누가 옳을까?\n이제 두 가지 관점을 각각 살펴보았으니, 이를 비교해 보는 것이 좋을 것 같습니다. 이 절의 시작 부분에서 언급한 가상의 로봇 축구 경기를 다시 떠올려 보세요. 빈도주의자와 베이지안은 앞의 세 가지 진술에 대해 어떻게 말할까요? 빈도주의자는 어떤 진술이 확률의 올바른 정의라고 생각할까요? 베이지안은 어떤 정의를 선택할까요? 이 진술들 중 일부는 빈도주의자나 베이지안에게는 무의미하게 여겨질까요? 두 관점을 잘 이해했다면 이러한 질문에 답할 수 있는 감각이 생겼을 것입니다.\n자, 이제 두 관점의 차이를 이해했다고 가정하고, 둘 중 어떤 것이 옳은가라는 질문이 떠오를 수 있습니다. 솔직히 말하자면, 정답이 있다고는 생각하지 않습니다. 제가 알기로는 빈도주의자들이 사건의 연속성에 대해 생각하는 방식에는 수학적으로 잘못된 점이 없으며, 베이지안들이 합리적 행위자의 신념을 정의하는 방식에도 수학적으로 문제가 없습니다. 사실, 세부적으로 파고들어 보면 베이지안과 빈도주의자는 실제로 많은 부분에서 의견이 일치합니다. 많은 빈도주의적 방법들이 베이지안들이 합리적인 행위자가 선택할 것이라고 동의하는 결론으로 이어지며, 많은 베이지안 방법들도 매우 우수한 빈도주의적 특성을 가지고 있습니다.\n저는 대체로 실용주의자이기 때문에 신뢰할 수 있는 통계적 방법이라면 무엇이든 사용합니다. 결과적으로 이는 제가 베이지안 방법을 선호하게 만들었으며, 그 이유는 이 책의 후반부에서 설명할 것입니다. 그렇다고 해서 빈도주의적 방법에 근본적으로 반대하는 것은 아닙니다. 모든 사람이 저처럼 너그럽지는 않습니다. 예를 들어, 20세기 통계학의 거장 중 한 명이자 베이지안 접근법에 강력히 반대한 로널드 피셔 경(Sir Ronald Fisher)은 통계의 수학적 기초에 관한 논문에서 베이지안 확률을 “통계 개념의 정확성으로 가는 진보를 방해하는 난해한 정글”이라고 표현했습니다 (Fisher, 1922, p. 311). 심리학자 폴 미힐(Paul Meehl)은 빈도주의적 방법에 의존하는 것은 “즐거운 길을 따라 많은 여인을 유혹하지만, 과학적으로 의미 있는 후손은 남기지 못하는, 강력하지만 불모의 지적 난봉꾼”으로 당신을 만들 수 있다고 말했습니다 (Meehl, 1967, p. 114). 보시다시피 통계학의 역사에는 흥미로운 이야기가 많습니다.\n어쨌든 저는 개인적으로 베이지안 관점을 선호하지만, 대부분의 통계 분석은 빈도주의적 접근법을 기반으로 합니다. 제 이유는 실용적입니다. 이 책의 목표는 전형적인 심리학 학부 통계 수업에서 다루는 내용을 대략적으로 포괄하는 것이며, 대부분의 심리학자들이 사용하는 통계 도구를 이해하려면 빈도주의적 방법을 잘 이해해야 합니다. 이는 결코 헛된 노력이 아닙니다. 나중에 베이지안 관점으로 전환하고 싶어지더라도, 최소한 “정통” 빈도주의자 관점에 대한 책을 한 권쯤은 읽어야 합니다. 게다가 저는 베이지안 관점을 완전히 무시하지 않을 것입니다. 때때로 베이지안 관점에서 해설을 덧붙일 것이며, Chapter 16 에서 이 주제를 더 깊이 다룰 예정입니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>확률이란?</span>"
    ]
  },
  {
    "objectID": "07-Introduction-to-probability.html#기본-확률-이론",
    "href": "07-Introduction-to-probability.html#기본-확률-이론",
    "title": "7  확률이란?",
    "section": "7.3 기본 확률 이론",
    "text": "7.3 기본 확률 이론\n베이지안과 빈도주의자 간의 이념적 논쟁에도 불구하고, 사람들은 일반적으로 확률이 따라야 할 규칙에 대해서는 대체로 동의합니다. 이러한 규칙을 도출하는 방법은 여러 가지가 있지만, 가장 널리 사용되는 접근법은 20세기의 위대한 소련 수학자 안드레이 콜모고로프(Andrey Kolmogorov)의 작업을 기반으로 합니다. 이 내용을 깊이 다루지는 않겠지만, 기본적인 개념을 설명해 보겠습니다. 이를 위해 제 바지에 대한 이야기를 해야 할 것 같습니다.\n\n7.3.1 확률분포란?\n제 삶에서 충격적인 진실 중 하나는 제가 단 다섯 벌의 바지만 가지고 있다는 것입니다. 더욱 안타까운 점은 그 바지들에게 이름을 붙였다는 것이죠. 저는 각각 \\(X_1\\), \\(X_2\\), \\(X_3\\), \\(X_4\\), \\(X_5\\)라고 부릅니다. 저는 매일 정확히 한 벌의 바지를 골라 입습니다. 이 상황을 확률 이론의 언어로 설명하자면, 각각의 바지(즉, 각 \\(X\\))를 기본 사건(elementary event) 이라고 합니다. 기본 사건 의 핵심 특징은 매번 관찰을 수행할 때(예: 제가 바지를 입을 때) 그 결과는 오직 하나의 사건으로 결정된다는 점입니다. 저는 항상 한 벌의 바지만 입기 때문에, 제 바지들은 이 조건을 충족합니다. 이와 마찬가지로, 모든 가능한 사건들의 집합을 표본 공간(sample space) 이라고 합니다. 물론 어떤 사람들은 이를 “옷장”이라고 부르겠지만, 이는 확률론적 관점에서 제 바지를 고려하는 것을 거부하는 것일 뿐입니다.\n이제 표본 공간(옷장)과 여러 개의 기본 사건(바지)이 마련되었습니다. 이제 우리가 해야 할 일은 이러한 기본 사건에 확률(probability) 을 부여하는 것입니다. 어떤 사건 \\(X\\)에 대한 확률 \\(P(X)\\)는 0과 1 사이의 값입니다. \\(P(X)\\)의 값이 클수록 그 사건이 발생할 가능성이 높아집니다. 예를 들어, \\(P(X) = 0\\)이라면 사건 \\(X\\)가 절대 발생하지 않는다는 의미입니다(즉, 저는 그 바지를 절대 입지 않습니다). 반면, \\(P(X) = 1\\)이라면 사건 \\(X\\)가 반드시 발생한다는 의미입니다(즉, 저는 항상 그 바지를 입습니다). 중간 값이라면 그 바지를 가끔 입는다는 뜻입니다. 예를 들어, \\(P(X) = 0.5\\)라면 저는 그 바지를 절반의 확률로 입습니다.\n여기까지 오면 거의 끝났습니다. 이제 마지막으로 알아야 할 것은 “항상 무언가는 일어난다”는 점입니다. 제가 매번 바지를 입을 때는, 결국 어떤 바지가 되었든 입고 있는 상태가 된다는 것입니다. 이 다소 뻔한 진술을 확률론적인 관점에서 해석하면, 기본 사건들의 확률을 모두 더하면 반드시 1이 되어야 한다는 뜻입니다. 이는 전체 확률의 법칙(law of total probability) 으로 알려져 있습니다. 더 중요한 점은 이러한 조건이 충족되면, 우리가 다루는 것이 확률분포(probability distribution)가 된다는 것입니다. 예를 들어, Table 7.2 는 하나의 확률분포 예시를 보여줍니다. 각각의 사건에 할당된 확률은 0과 1 사이의 값이며, 모든 사건의 확률을 더하면 1이 됩니다. 멋지군요! 또한 이 분포를 시각적으로 표현하기 위해 막대 그래프를 그릴 수도 있습니다(Section 5.3 참고). Figure 7.2 는 이를 나타낸 그래프입니다.\n\n\n\n\nTable 7.2. 바지 착용에 대한 확률분포\n\n\n\n\n\n어떤 바지를 입을까?라벨확률\n\n청바지\\(X_1 \\)\\(P(X_1)=0.5 \\)\n\n회색 청바지\\(X_2 \\)\\(P(X_2)=0.3 \\)\n\n검은 청바지\\(X_3 \\)\\(P(X_3)=0.1 \\)\n\n검은 정장\\(X_4 \\)\\(P(X_4)=0 \\)\n\n파란 운동복\\(X_5 \\)\\(P(X_5)=0.1 \\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.2. 바지 확률분포의 시각적 표현. 다섯 개의 기본 사건이 있으며, 이는 제가 소유한 다섯 벌의 바지에 해당합니다. 각 사건은 발생할 확률을 가지며, 이 확률은 0에서 1 사이의 값입니다. 모든 확률을 더하면 1이 됩니다.\n\n\n\n\n\n이제 우리는 중요한 성취를 이뤄냈습니다. 여러분은 확률분포가 무엇인지 배웠고, 저는 드디어 제 바지만을 집중적으로 다루는 그래프를 만들 수 있었습니다. 우리 모두가 승리한 셈이죠!\n마지막으로 언급해야 할 점은 확률 이론이 비기본 사건(non-elementary events) 에 대해서도 논의할 수 있도록 한다는 것입니다. 이를 가장 쉽게 설명하는 방법은 예제를 드는 것입니다. 제 바지 예시에서 “제가 청바지(jeans)를 입을 확률”을 고려해 봅시다. 이 경우 “제가 청바지를 입는다”라는 사건은 실제 발생한 기본 사건이 특정 조건을 만족하면 성립하는 것으로 간주됩니다. 즉, “청바지” 사건 \\(E\\)는 “청색 청바지(blue jeans)”, “검은 청바지(black jeans)”, “회색 청바지(gray jeans)”라는 기본 사건이 발생할 경우 성립합니다. 수학적으로 정의하면, “청바지” 사건 \\(E\\)는 기본 사건 \\((X_1, X_2, X_3)\\)의 집합과 같습니다. 만약 이 기본 사건들 중 하나라도 발생하면, 사건 \\(E\\) 역시 발생한 것으로 간주됩니다.\n이렇게 \\(E\\)의 정의를 정리한 후, \\(P(E)\\)를 계산하는 것은 매우 간단합니다. 개별 사건들의 확률을 모두 더하면 됩니다. 이 경우, 각각의 확률이 청색 청바지 \\(.5\\), 회색 청바지 \\(.3\\), 검은 청바지 \\(.1\\)이므로, 제가 청바지를 입을 확률은 다음과 같습니다: \\[P(E)=P(X_1)+P(X_2)+P(X_3) = 0.5 + 0.3 + 0.1 = 0.9\\]\n이 모든 것이 너무도 당연하고 단순하다고 생각할 수도 있습니다. 그리고 그 생각이 맞습니다. 우리가 한 일은 단지 몇 가지 기본적인 수학을 상식적인 직관에 적용한 것뿐입니다. 하지만 이러한 간단한 원리를 바탕으로 매우 강력한 수학적 도구들을 만들어 낼 수 있습니다. 이 책에서는 그 세부 사항을 다루지는 않겠지만, (비기본 사건에 대한) 확률이 만족해야 하는 몇 가지 다른 규칙들을 Table 7.3 에 정리해 두었습니다. 이러한 규칙들은 앞서 설명한 단순한 가정들로부터 도출될 수 있지만, 이 책에서는 실제로 이 규칙들을 사용할 일이 없으므로 여기에서 직접 유도하지는 않겠습니다.\n\n\n\n\nTable 7.3. 확률이 만족해야 하는 몇 가지 규칙\n\n\n\n\n\n일상 용어표기법공식\n\n아닌 경우 (not A)\\(P (\\neg A) \\)\\(1-P(A) \\)\n\nA 또는 B\\(P(A \\cup B) \\)\\(P(A) + P(B) - P(A \\cap B) \\)\n\nA 그리고 B\\(P(A \\cap B) \\)\\(P(A|B) P(B) \\)",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>확률이란?</span>"
    ]
  },
  {
    "objectID": "07-Introduction-to-probability.html#sec-The-binomial-distribution",
    "href": "07-Introduction-to-probability.html#sec-The-binomial-distribution",
    "title": "7  확률이란?",
    "section": "7.4 이항 분포",
    "text": "7.4 이항 분포\n짐작할 수 있겠지만, 확률분포는 매우 다양합니다. 그러나 이들 모두가 똑같이 중요한 것은 아닙니다. 사실, 이 책의 대부분 내용은 단 5개의 분포에 의존합니다: 이항 분포, 정규 분포, \\(t\\)-분포, \\(\\chi^2\\) (“카이제곱”) 분포, 그리고 \\(F\\)-분포입니다. 따라서 다음 섹션에서는 이 다섯 가지 분포를 간략하게 소개하고, 특히 이항 분포와 정규 분포에 집중하겠습니다. 그중 가장 단순한 이항 분포부터 시작하겠습니다.\n\n7.4.1 이항 분포란?\n확률 이론은 본래 도박 게임의 작동 방식을 설명하려는 시도에서 시작되었습니다. 그래서 이항 분포를 논의할 때 주사위를 굴리거나 동전을 던지는 실험을 예로 드는 것이 적절할 것입니다. 간단한 “실험”을 상상해 봅시다. 제 손에는 20개의 동일한 여섯 면 주사위가 있습니다. 각 주사위의 한 면에는 해골 그림이 있고, 나머지 다섯 면은 모두 비어 있습니다. 이 20개의 주사위를 모두 굴렸을 때 정확히 4개의 해골이 나올 확률은 얼마일까요? 주사위가 공정하다고 가정하면, 해골이 나올 확률은 6분의 1입니다. 즉, 하나의 주사위에서 해골이 나올 확률은 약 0.167입니다. 이 정보만으로도 우리의 질문에 답할 수 있습니다.\n몇 가지 용어와 표기법을 먼저 소개하겠습니다. 실험에서 주사위를 굴리는 횟수는 \\(N\\)으로 표시하며, 이는 이항 분포의 크기 모수(size parameter)라고 합니다. 또한, 하나의 주사위에서 해골이 나올 확률을 \\(\\theta\\)로 나타내며, 이를 이항 분포의 성공확률(success probability)이라고 부릅니다.2 마지막으로, 주사위를 굴렸을 때 나온 해골의 개수를 \\(X\\)로 나타냅니다. \\(X\\)의 실제 값은 우연에 따라 결정되므로 이를 확률변수(random variable)라고 부릅니다. 이제 이 용어들을 사용해 문제를 좀 더 정확하게 표현할 수 있습니다. 우리가 계산하고자 하는 것은 \\(\\theta = 0.167\\)이고 \\(N = 20\\)일 때 \\(X = 4\\)가 될 확률입니다. 일반적인 형태로는 다음과 같이 나타낼 수 있습니다: \\[P(X|\\theta,N)\\]\n우리가 관심 있는 특수한 경우는 \\(X = 4, \\theta = 0.167\\), 그리고 \\(N = 20\\)입니다.\n[추가 기술적 설명3]\n압니다. “표기법, 표기법, 또 표기법”이라고 생각하고 있을 겁니다. 하지만 실제로 중요한 건 아닙니다. 이 책의 독자 중 대부분은 표기법을 배우기 위해 이 책을 보는 게 아니니까요. 대신 이항 분포를 어떻게 사용하는지 설명하겠습니다. 이항 분포의 공식은 주석에 포함했으니,4 관심 있는 분들은 참고하면 됩니다. 대부분의 독자가 공식에 크게 관심이 없고, 이 책에서도 공식이 꼭 필요한 것은 아니므로 자세한 설명은 생략하겠습니다. 대신 이항 분포가 실제로 어떻게 보이는지 보여드리겠습니다.\n이를 위해, Figure 7.3 은 주사위 실험에서 \\(X = 0\\) (해골 없음)부터 \\(X = 20\\) (모두 해골)까지 가능한 모든 \\(X\\) 값에 대한 이항 확률을 나타낸 그래프입니다. 본질적으로 막대그래프이며, Figure 7.2 에서 그린 “바지 확률” 그래프와 다르지 않습니다. 가로축에는 가능한 모든 사건이 나열되어 있고, 세로축에서는 각 사건의 확률을 확인할 수 있습니다. 20개의 주사위를 굴려서 4개의 해골이 나올 확률은 약 0.20입니다 (정확한 값은 0.2022036이며, 곧 확인할 것입니다). 즉, 이 실험을 반복하면 약 20%의 확률로 이러한 결과가 발생할 것입니다.\n\n\n\n\n\n\n\n\nFigure 7.3. 크기 매개변수 \\(N = 20\\)과 성공 확률 \\(\\theta = \\frac{1}{6}\\)인 이항 분포. 각 막대는 특정 결과(즉, 하나의 가능한 \\(X\\) 값)의 확률을 나타냅니다. 확률분포이므로 각 확률은 0과 1 사이의 값이어야 하며, 모든 막대의 높이를 합하면 1이 되어야 합니다.\n\n\n\n\n\n이제 \\(\\theta\\)와 \\(N\\) 값을 변경했을 때 이항 분포가 어떻게 변하는지 살펴보겠습니다. 이번에는 주사위를 굴리는 대신 동전을 던지는 실험을 생각해 봅시다. 공정한 동전을 여러 번 던지고, 관찰된 앞면(헤드)의 개수에 관심이 있습니다. 이 경우 성공 확률은 \\(\\theta = \\frac{1}{2}\\)입니다. 동전을 \\(N = 20\\)번 던진다면 어떻게 될까요? 이번에는 성공 확률만 변경하고 실험 규모는 그대로 유지했습니다. 이항 분포는 어떻게 바뀔까요? Figure 7.4 에서 볼 수 있듯이, 분포의 중심이 이동하는 것이 주요 변화입니다. 만약 \\(N = 100\\)번 동전을 던진다면 어떻게 될까요? 이 경우는 Figure 7.4 (b)에서 볼 수 있습니다. 분포는 여전히 중앙에 집중되어 있지만, 가능한 결과의 변동성이 조금 더 큽니다.\n\n\n\n\n\n\n\n\nFigure 7.4. 공정한 동전을 던지는 두 가지 이항 분포. 이때 성공 확률은 \\(\\theta = \\frac{1}{2}\\)입니다. (a) 패널에서는 동전을 \\(N = 20\\)번 던졌고, (b) 패널에서는 \\(N = 100\\)번 던졌습니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>확률이란?</span>"
    ]
  },
  {
    "objectID": "07-Introduction-to-probability.html#sec-The-normal-distribution",
    "href": "07-Introduction-to-probability.html#sec-The-normal-distribution",
    "title": "7  확률이란?",
    "section": "7.5 정규 분포",
    "text": "7.5 정규 분포\n이항 분포가 개념적으로 가장 이해하기 쉬운 분포이긴 하지만, 가장 중요한 분포는 아닙니다. 이 타이틀은 바로 정규 분포가 차지합니다. 정규 분포는 “종 모양 곡선(bell curve)” 또는 “가우시안 분포(Gaussian distribution)”라고도 불립니다. 정규 분포는 두 가지 모수로 설명됩니다: 분포의 평균 \\(\\mu\\)와 표준 편차 \\(\\sigma\\)입니다. 변수 \\(X\\)가 정규 분포를 따른다는 것을 나타내는 표기법은 다음과 같습니다: \\[X \\sim Normal(\\mu,\\sigma)\\]\n[추가적인 기술적 설명5]\n변수가 정규 분포를 따른다는 것이 어떤 의미인지 감을 잡아 봅시다. 이를 위해 평균 \\(\\mu = 0\\)이고 표준 편차 \\(\\sigma = 1\\)인 정규 분포를 나타낸 Figure 7.5 를 살펴보세요.\n\n\n\n\n\n\n\n\nFigure 7.5. 평균 \\(\\mu = 0\\), 표준 편차 \\(\\sigma = 1\\)인 정규 분포입니다. x축은 변수의 값을 나타내며, y축은 해당 값을 관찰할 확률의 밀도를 보여줍니다. 그러나 y축은 확률(Probability)이 아니라 확률밀도(Probability Density)로 표시된다는 점에 주의하세요.\n\n\n\n\n\n“종 모양 곡선”이라는 이름이 어디서 유래했는지 알 수 있습니다. 실제로 종(bell)처럼 보이기 때문입니다. 이항 분포를 설명할 때 사용한 그래프와는 달리, Figure 7.5 의 정규 분포 그래프는 히스토그램 같은 막대 그래프가 아닌 부드러운 곡선으로 나타나 있습니다. 이는 임의로 선택된 것이 아니며, 정규 분포가 연속형인 반면 이항 분포는 이산형이기 때문입니다.6\n예를 들어, 앞 절의 주사위 굴리기 예제에서는 해골 3개나 4개가 나오는 것은 가능했지만, 해골 3.9개가 나오는 것은 불가능했습니다. 이러한 특성이 이전의 그래프에 반영되어 있습니다. 예를 들어 Figure 7.3 에서 \\(X = 3\\)과 \\(X = 4\\)에 막대가 있지만, 그 사이에는 아무것도 없습니다. 그러나 연속형 변수에는 이러한 제약이 없습니다.\n예를 들어 날씨에 대해 생각해 봅시다. 봄날의 기온은 23도, 24도, 23.9도 등 연속적인 모든 값이 가능하기 때문에 온도는 연속형 변수입니다. 따라서 정규 분포는 봄철 기온을 설명하는 데 매우 적합할 수 있습니다.7\n이제 정규 분포가 어떻게 작동하는지 직관적으로 이해하기 위해, 분포의 모수를 조작해 보겠습니다. 먼저 Figure 7.6 에서는 평균이 다른 정규 분포들을 보여줍니다. 표준 편차는 동일하므로, 모든 분포의 “폭”은 같으며 단지 좌우로 이동한 것뿐입니다. 반면, 평균을 고정한 상태에서 표준 편차를 증가시키면 분포의 정점은 같은 위치에 남아 있지만 분포는 더 넓어지며, 이는 Figure 7.7 에서 확인할 수 있습니다.\n분포가 넓어질수록 정점의 높이가 낮아진다는 점에 주목하세요. 이는 이항 분포의 막대 높이의 합이 1이 되어야 하는 것과 같은 원리입니다. 정규 분포의 경우 곡선 아래의 전체 면적이 1이 되어야 하기 때문입니다.\n\n\n\n\n\n\n\n\nFigure 7.6. 정규 분포의 평균을 변경했을 때의 모습입니다. 실선은 평균 \\(\\mu = 4\\)인 정규 분포를, 점선은 평균 \\(\\mu = 7\\)인 정규 분포를 나타냅니다. 두 경우 모두 표준 편차는 \\(\\sigma = 1\\)입니다. 예상대로 두 분포의 형태는 동일하지만, 점선은 오른쪽으로 이동한 것을 볼 수 있습니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.7. 정규 분포의 표준 편차를 변경했을 때의 모습입니다. 두 분포 모두 평균 \\(\\mu = 5\\)를 가지지만, 표준 편차가 다릅니다. 실선은 표준 편차 \\(\\sigma = 1\\)인 분포를 나타내고, 점선은 표준 편차 \\(\\sigma = 2\\)인 분포를 보여줍니다. 두 분포 모두 같은 중심을 가지고 있지만, 점선이 더 넓게 퍼져 있는 것을 볼 수 있습니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.8. 곡선 아래의 면적(AUC; Areas Under Curve)은 관측값이 특정 범위 내에 속할 확률을 나타냅니다. 실선은 평균 \\(\\mu = 0\\), 표준편차 \\(\\sigma = 1\\)인 정규분포를 나타냅니다. 음영 처리된 부분은 두 가지 중요한 경우의 “곡선 아래 면적”을 보여줍니다. 패널 (a)에서는 관측값이 평균의 ±1 표준편차 내에 있을 확률이 68.3%임을 확인할 수 있습니다. 패널 (b)에서는 관측값이 평균의 ±2 표준편차 내에 있을 확률이 95.4%임을 보여줍니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.9. 곡선 아래 면적(AUC) 개념의 두 가지 추가 예제입니다. 패널 (a)에서는 관측값이 평균보다 1 표준편차 이하일 확률이 15.9%임을 보여줍니다. 패널 (b)에서는 관측값이 평균보다 1 표준편차 이하와 평균 사이에 있을 확률이 34.1%임을 나타냅니다. 이 두 수치를 더하면 15.9% + 34.1% = 50%가 됩니다. 정규분포 데이터에서는 관측값이 평균보다 작을 확률이 50%입니다. 물론 이는 관측값이 평균보다 클 확률도 50%임을 의미합니다.\n\n\n\n\n\n다음 내용으로 넘어가기 전에 정규분포의 한 가지 중요한 특성을 강조하고 싶습니다. 실제 평균과 표준편차가 무엇이든 상관없이, 전체 면적의 \\(68.3\\%\\)가 평균의 ±1 표준편차 범위 내에 존재합니다. 이와 마찬가지로, 분포의 \\(95.4\\%\\)는 평균의 ±2 표준편차 내에 있으며, \\((99.7\\%)\\)는 평균의 ±3 표준편차 범위 내에 포함됩니다. 이 개념은 Figure 7.8 에 설명되어 있으며, Figure 7.9 에서도 확인할 수 있습니다.\n\n7.5.1 확률밀도\n정규 분포에 대한 논의 동안 제가 일부러 숨기고 있었던 것이 있습니다. 일부 입문서에서는 아예 언급조차 하지 않기도 합니다. 그들이 그렇게 하는 것이 옳을 수도 있습니다. 제가 숨기고 있던 것은 통계의 특수한 기준으로 보더라도 이상하고 직관에 반하는 개념입니다. 다행히도, 이 개념은 기본적인 통계 분석을 수행하기 위해 깊이 이해할 필요는 없습니다. 오히려, 기초를 넘어선 단계에서 중요해지기 시작하는 개념입니다. 그러니 완전히 이해되지 않더라도 너무 걱정하지 말고, 대략적인 개념을 따라가려고 노력해 주세요.\n정규 분포에 대한 논의 전반에서 뭔가 잘 맞지 않는 한두 가지가 있었을 겁니다. 혹시 그래프의 y축이 단순한 “밀도”가 아니라 “확률밀도(Probability Density)”로 표시된 것을 눈치챘을지도 모릅니다. 또는 정규 분포의 공식에서 \\(P(X)\\) 대신 \\(p(X)\\)를 사용한 것도요.\n사실 여기서 제시된 것은 실제로 “확률”이 아니라 다른 개념입니다. 이 개념을 이해하기 위해서는 \\(X\\)가 연속형 변수라는 것이 실제로 무엇을 의미하는지에 대해 잠시 생각해 볼 필요가 있습니다. 예를 들어, 바깥 기온에 대해 이야기한다고 가정해 봅시다. 온도계가 23도를 가리키지만, 실제로 정확히 23도인 것은 아닙니다. 아마 23.1도일 수도 있다고 생각할 수 있습니다. 그러나 그것도 정확하지 않을 것입니다. 실제로는 23.09도일 수도 있겠죠. 하지만 그것도 확실하지 않습니다. 이쯤 되면 감이 오실 겁니다. 진정한 의미의 연속적인 양은 정확히 무엇인지 결코 알 수 없다는 것이 문제입니다.\n이제 이러한 사실이 확률에 대해 이야기할 때 무엇을 의미하는지 생각해 봅시다. 내일의 최고 기온이 평균 23도, 표준편차 1인 정규 분포에서 표본추출된다고 가정합시다. 그렇다면 정확히 23도가 될 확률은 얼마일까요? 정답은 “0”이거나, 아니면 “0에 한없이 가까운 수”입니다. 왜 그럴까요? 이는 무한히 작은 다트판을 맞추려는 것과 같습니다. 아무리 정확한 조준을 해도 맞출 수 없습니다. 현실에서는 정확히 23도인 값을 얻을 수 없습니다. 항상 23.1도나 22.99998도처럼 조금씩 다를 것입니다. 즉, 기온이 정확히 23도일 확률에 대해 이야기하는 것은 전혀 의미가 없습니다. 그러나 일상적인 언어에서는 누군가 “지금 기온이 23도야”라고 말했을 때 실제로 22.9998도라고 해도, 그 사람을 거짓말쟁이라고 부르지 않을 것입니다. 왜냐하면 일상적인 언어에서 “23도”는 대개 “22.5도와 23.5도 사이 어딘가”라는 의미로 받아들여지기 때문입니다. 이처럼 기온이 정확히 23도일 확률을 묻는 것은 의미가 없지만, 기온이 22.5도와 23.5도 사이일 확률이나 20도와 30도 사이일 확률, 또는 어떤 범위일 확률을 묻는 것은 훨씬 의미가 있어 보입니다.\n이 논의의 핵심은 연속 분포에 대해 이야기할 때 특정 값일 확률을 논하는 것은 의미가 없다는 것입니다. 그러나 특정 범위 내에 값이 존재할 확률에 대해서는 이야기할 수 있습니다. 이러한 범위에 해당하는 확률을 알아내기 위해서는 “곡선 아래의 면적”을 계산해야 합니다. 이 개념은 이미 살펴본 바 있으며, Figure 7.8 에서는 음영 처리된 부분이 실제 확률을 나타냅니다(예: 평균에서 표준편차 1 이내에 해당하는 값을 관찰할 확률).\n이제 이야기의 일부는 설명이 되었습니다. 연속 확률분포를 어떻게 해석해야 하는지에 대해 간략히 설명했습니다(즉, 곡선 아래의 면적이 핵심입니다). 그런데 앞서 설명한 \\(p(x)\\)의 공식은 실제로 무엇을 의미할까요? 분명히 \\(p(x)\\)는 확률을 나타내지 않습니다. 그렇다면 이것은 무엇일까요? 이 값 \\(p(x)\\)의 이름은 확률밀도(probability density)이며, 우리가 그린 그래프에서는 곡선의 높이에 해당합니다. 확률밀도 자체는 그 자체로 의미가 있는 것은 아니지만, 곡선 아래의 면적이 항상 실제 확률로 해석될 수 있도록 “설정”됩니다. 솔직히 말해, 지금 단계에서는 이 정도만 알아두어도 충분합니다.8",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>확률이란?</span>"
    ]
  },
  {
    "objectID": "07-Introduction-to-probability.html#sec-Other-useful-distributions",
    "href": "07-Introduction-to-probability.html#sec-Other-useful-distributions",
    "title": "7  확률이란?",
    "section": "7.6 다른 유용한 분포들",
    "text": "7.6 다른 유용한 분포들\n정규 분포는 통계학에서 가장 많이 활용되는 분포입니다(곧 그 이유를 설명하겠습니다). 이항 분포 또한 다양한 목적으로 매우 유용합니다. 그러나 통계학의 세계에는 수많은 확률분포가 존재하며, 이 중 일부는 지나가며 마주치게 됩니다. 특히 이 책에서 등장할 세 가지 분포는 \\(t\\)-분포, \\(\\chi^2\\) 분포, 그리고 \\(F\\)-분포입니다. 이 분포들에 대한 공식은 제공하지 않고, 자세한 설명도 생략하겠지만, 몇 가지 그림을 보여드리겠습니다: Figure 7.10, Figure 7.11, Figure 7.12.\n\n\n\n\n\n\n\n\nFigure 7.10. 자유도가 3인 \\(t\\)-분포(실선). 정규 분포와 비슷하게 보이지만 완전히 동일하지는 않습니다. 비교를 위해 표준 정규 분포를 점선으로 함께 표시했습니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.11. 자유도가 3인 \\(\\chi^2\\) 분포. 관측값은 항상 0보다 커야 하며, 분포가 상당히 비대칭적입니다. 이러한 특징이 카이제곱 분포의 핵심적인 요소입니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.12. 자유도가 3과 5인 \\(F\\)-분포. 전반적으로 카이제곱 분포와 비슷해 보이지만, 일반적으로는 완전히 동일하지 않습니다.\n\n\n\n\n\n\\(t\\)-분포는 Figure 7.10 에서 보듯이 정규 분포와 매우 유사한 형태의 연속 분포입니다. \\(t\\)-분포의 “꼬리”가 정규 분포의 꼬리보다 더 두껍게(즉, 더 멀리 뻗어 있음) 나타난다는 점이 중요한 차이점입니다. 이 분포는 데이터가 실제로는 정규 분포를 따르지만, 평균이나 표준편차를 모르는 상황에서 자주 등장합니다. 이 분포는 Chapter 11 에서 다시 다루게 됩니다.\n\\(\\chi^2\\) 분포는 다양한 상황에서 등장하는 또 다른 분포입니다. 이 책에서는 Chapter 10 의 범주형 데이터 분석에서 만나게 될 것입니다. 그러나 실제로는 다양한 곳에서 나타납니다. 수학적으로 살펴보면(누구나 수학을 사랑하죠?), \\(\\chi^2\\) 분포가 자주 등장하는 주된 이유는, 정규 분포를 따르는 여러 변수를 제곱한 후 이를 더하는 과정(이를 “제곱합(sum of squares)”이라고 부름)을 거치면 그 결과가 \\(\\chi^2\\) 분포를 따르기 때문입니다. 이 사실이 놀라울 정도로 자주 유용하게 쓰입니다. 어쨌든, \\(\\chi^2\\) 분포는 Figure 7.11 같습니다.\n\\(F\\)-분포는 \\(\\chi^2\\) 분포와 비슷한 모양을 가졌으며, 두 개의 \\(\\chi^2\\) 분포를 비교해야 할 때 등장합니다. 언뜻 듣기에는 정상적인 사람이 굳이 하고 싶어 할 일 같지 않지만, 실제 데이터 분석에서는 매우 중요합니다. 이전에 \\(\\chi^2\\) 분포가 “제곱합”을 다룰 때 핵심적인 분포라고 했던 것을 기억하시나요? 이는 두 개의 다른 “제곱합”을 비교하려면 \\(F\\)-분포가 필요하다는 뜻입니다. 물론 아직 제곱합과 관련된 구체적인 예시는 제시하지 않았지만, 이는 Chapter 13 에서 다루게 될 것입니다. 그리고 바로 그곳에서 \\(F\\)-분포를 만나게 됩니다. 아, 그리고 Figure 7.12 에 해당 그림이 있습니다.\n이제 이 섹션을 마무리하겠습니다. 우리는 세 가지 새로운 분포인 \\(\\chi^2\\), \\(t\\), 그리고 \\(F\\) 분포를 살펴보았습니다. 이들은 모두 연속 분포이며, 정규 분포와 밀접한 관련이 있습니다. 이 섹션에서 가장 중요한 점은 이 분포들이 서로 깊이 연관되어 있으며, 정규 분포와도 밀접한 관계가 있다는 기본 개념을 이해하는 것입니다. 이 책의 뒷부분에서는 정규 분포를 따르거나 적어도 정규 분포를 가정하는 데이터를 만나게 될 것입니다. 지금 여러분이 이해해야 할 점은, 데이터가 정규 분포를 따른다고 가정하면 \\(\\chi^2\\), \\(t\\), \\(F\\) 분포가 데이터 분석 과정에서 자주 등장한다는 것입니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>확률이란?</span>"
    ]
  },
  {
    "objectID": "07-Introduction-to-probability.html#요약",
    "href": "07-Introduction-to-probability.html#요약",
    "title": "7  확률이란?",
    "section": "7.7 요약",
    "text": "7.7 요약\n이번 장에서는 확률에 대해 이야기했습니다. 우리는 확률이 무엇을 의미하는지, 그리고 통계학자들이 확률의 의미에 대해 왜 의견을 일치시키지 못하는지에 대해 이야기했습니다. 우리는 확률이 따라야 하는 규칙들에 대해서도 이야기했습니다. 그리고 확률분포의 개념을 소개하고, 통계학자들이 작업하는 몇 가지 중요한 확률분포에 대해 많은 부분을 할애해 설명했습니다. 절 별로 나누어 보면 다음과 같습니다:\n\n확률 이론과 통계학: 확률과 통계는 어떻게 다른가?\n확률에 대한 빈도주의자 관점 대 베이지안 관점.\n기본 확률 이론.\n이항 분포, 정규 분포, 그리고 다른 유용한 분포들.\n\n예상하셨겠지만, 제 설명은 결코 포괄적이지 않습니다. 확률 이론은 그 자체로 수학의 큰 분야이며, 통계학과 데이터 분석에의 적용과는 완전히 별개입니다. 그 때문에 이 주제에 대해 쓴 책이 수천 권이며, 대학에서는 일반적으로 확률 이론만을 다루는 여러 수업을 제공합니다. 심지어 확률분포 문서화라는 “더 간단한” 작업만 하더라도 큰 주제입니다. 이 장에서는 5 가지 표준 확률분포를 설명했지만, 제 책꽂이에는 “통계 분포”라는 45 장짜리 책(Evans et al., 2011)이 있는데, 이 책은 그보다 훨씬 많은 분포를 다룹니다. 다행히도 여러분에게는 이 모든 것이 필요하지 않습니다. 실제 데이터 분석을 할 때 수십 개의 통계적 분포를 알아야 할 필요는 거의 없으며, 이 책에서는 확실히 필요하지도 않습니다. 하지만 다른 가능성들이 있다는 것을 아는 것은 결코 나쁘지 않습니다.\n마지막으로 언급한 점에 대해 덧붙이자면, 이 장 전체가 다소 본질에서 벗어난 이야기일 수 있다는 느낌이 있습니다. 많은 대학의 심리학 통계학 수업에서는 이 내용을 매우 빠르게 훑고 지나가며(저희 수업도 그랬습니다), 더 고급 수업들에서도 이 분야의 기본적인 기초를 개관하는 것도 “잊어버리는” 경우가 많습니다. 대부분의 심리학자들은 확률과 밀도의 차이를 알지 못할 것이며, 최근까지도 빈도주의 확률과 베이지안 확률의 차이를 알고 있는 사람은 거의 없었습니다. 하지만 저는 이러한 것들을 통계를 적용하기 전에 이해하는 것이 중요하다고 생각합니다. 예를 들어, 통계적 추론을 할 때 “언급될 수 있는 것”에 대한 규칙들이 많이 있는데, 이 규칙들은 종종 임의적이고 이상하게 보일 수 있습니다. 그러나 베이지안과 빈도주의의 구분을 이해하면 이 규칙들이 왜 있는지 이해가 됩니다. 마찬가지로, Chapter 11 에서는 \\(t\\)-검정에 대해 이야기할 예정인데, \\(t\\)-검정의 메커니즘을 정말 잘 이해하려면 \\(t\\)-분포가 실제로 어떻게 생겼는지에 대한 감각이 도움이 됩니다. 이 정도면 이해가 되었으리라 희망합니다.\n\n\n\n\nEvans, M., Hastings, N., & Peacock, B. (2011). Statistical distributions (3rd ed). Wiley. https://doi.org/10.1002/9780470627242\n\n\nFisher, R. A. (1922). On the mathematical foundation of theoretical statistics. Philosophical Transactions of the Royal Society A, 222, 309–368. https://doi.org/10.1098/rsta.1922.0009\n\n\nMeehl, P. H. (1967). Theory testing in psychology and physics: A methodological paradox. Philosophy of Science, 34, 103–115. https://doi.org/10.1086/288135",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>확률이란?</span>"
    ]
  },
  {
    "objectID": "07-Introduction-to-probability.html#footnotes",
    "href": "07-Introduction-to-probability.html#footnotes",
    "title": "7  확률이란?",
    "section": "",
    "text": "물론, 이것이 빈도주의자들이 가설적인 진술을 하지 못한다는 뜻은 아닙니다. 다만, 확률에 대한 진술을 하려면 해당 진술을 잠재적으로 관찰 가능한 사건들의 연속과 그 안에서 나타나는 서로 다른 결과들의 상대적 빈도로 다시 설명할 수 있어야 합니다.↩︎\n여기서 “성공(success)”이라는 용어는 다소 임의적이며, 반드시 긍정적인 결과를 의미하는 것은 아닙니다. 예를 들어, \\(\\theta\\)가 버스 사고에서 승객이 다칠 확률을 나타낸다고 해도 여전히 성공 확률이라고 부르지만, 그렇다고 사고가 발생하기를 바라는 것은 아닙니다!↩︎\n미적분을 조금 아는 독자를 위해 더 정확한 설명을 덧붙입니다. 확률이 0과 1 사이의 값이며 총합이 1이 되어야 하는 것처럼, 확률밀도 함수도 0 이상의 값이며 전체 구간에 대해 적분한 결과가 1이어야 합니다. \\(X\\)가 구간 [a, b]에 속할 확률은 해당 범위에서 밀도 함수를 정적분하여 계산합니다: \\(\\int_{a}^{b} p(x) dx\\). 미적분을 모른다면 걱정하지 않아도 됩니다. 이 책에서는 필요하지 않습니다.↩︎\n이항 분포의 공식에서 \\(X!\\)는 팩토리얼 함수입니다 (즉, 1부터 \\(X\\)까지의 모든 정수를 곱한 값). \\[P(X | \\theta, N) = \\displaystyle\\frac{N!}{X! (N-X)!} \\theta^X (1-\\theta)^{N-X}\\] 이 식이 잘 이해되지 않아도 너무 걱정하지 마세요.↩︎\n이항 분포의 경우와 마찬가지로, 이 책에 정규 분포의 공식도 포함시켰습니다. 통계학을 배우는 모든 사람이 최소한 한 번은 이 공식을 보는 것이 중요하다고 생각하기 때문입니다. 하지만 이 책은 입문서이므로 이를 자세히 다루지 않고 각주에 간단히 설명합니다: \\[p(X|\\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(X-\\mu)^2}{2\\sigma^2}}\\]↩︎\n연속형 분포에는 미묘하고 다소 혼란스러운 특성이 있습니다. 곡선의 높이(y축)는 특정 \\(x\\) 값을 관찰할 확률 자체가 아니라는 점입니다. 하지만 곡선의 높이가 높은 값일수록 더 관찰될 가능성이 크다는 것은 사실입니다. (자세한 내용은 확률밀도 절 참조)↩︎\n실제로 정규 분포는 매우 유용하기 때문에, 변수 자체가 연속형이 아니더라도 자주 사용됩니다. 범주의 수가 충분히 많다면(예: 설문지의 리커트 척도 응답), 정규 분포를 근사적으로 사용하는 것이 일반적입니다. 실제로 이는 예상보다 훨씬 잘 맞습니다.↩︎\n약간의 미적분 지식이 있는 독자를 위해 좀 더 정확한 설명을 덧붙이겠습니다. 확률이 0보다 크거나 같은 수이며 그 합이 1이 되어야 하는 것과 마찬가지로, 확률밀도 역시 0보다 크거나 같은 수이며 전체 가능한 \\(X\\)의 값에 대해 적분했을 때 그 값이 1이 되어야 합니다. \\(X\\)가 a와 b 사이에 존재할 확률을 계산하려면 확률밀도 함수의 해당 구간에 대한 정적분을 계산하면 됩니다: \\(\\int_{a}^{b} p(x) dx\\). 만약 미적분이 잘 기억나지 않거나 배우지 않았다면 걱정하지 마세요. 이 책에서는 필요하지 않습니다.↩︎",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>확률이란?</span>"
    ]
  },
  {
    "objectID": "08-Estimating-unknown-quantities-from-a-sample.html",
    "href": "08-Estimating-unknown-quantities-from-a-sample.html",
    "title": "8  표본으로 미지의 모수 추정하기",
    "section": "",
    "text": "8.1 표본, 모집단 및 표본추출\nIV 부의 서두에서 귀납적 추론의 수수께끼를 논의하며, 모든 새로운 사실에 대한 학습은 가정을 필요로 한다는 것을 강조한 바 있다. 이것을 진실이라고 받아들인다면, 우리의 첫 번째 과제는 데이터에 대해 몇 가지 일반적인 가정을 세우는 것이다. 여기서 표본 이론(sampling theory)이 등장하게 된다. 확률 이론이 모든 통계 이론을 구축하는 기초라면, 표본 이론은 그 위에 집을 세울 수 있는 틀이라 할 수 있다. 표본 이론은 통계적 추론이 의존하는 가정을 명시하는 데 중요한 역할을 한다. 그리고 통계학자들이 생각하는 방식으로 “추론을 수행하는 것”에 대해 이야기하려면, 우리가 무엇으로부터 추론을 도출하는지(즉, 표본)와 무엇에 대해 추론을 도출하는지(즉, 모집단)를 보다 명확하게 정의할 필요가 있다.\n대부분의 연구 상황에서 연구자가 이용할 수 있는 것은 표본(sample) 데이터이다. 실험을 수행하여 일정 수의 참가자를 모집할 수도 있고, 여론 조사 기관이 일정 수의 사람들에게 전화를 걸어 투표 의향을 물을 수도 있다. 이러한 방식으로 우리가 확보할 수 있는 데이터 세트는 유한하며 불완전하다. 예를 들어, 실험에 모든 사람을 참여시키는 것은 불가능하며, 여론 조사 기관은 국가의 모든 유권자에게 전화를 걸 시간과 비용을 감당할 수도 없다. Chapter 4 에서 기술 통계를 논의할 때, 우리가 관심을 가진 대상은 오직 표본뿐이었다. 우리의 유일한 목표는 해당 표본을 기술하고, 요약하며, 그래프로 나타내는 방법을 찾는 것이었다. 하지만 이제부터는 상황이 달라질 것이다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>표본으로 미지의 모수 추정하기</span>"
    ]
  },
  {
    "objectID": "08-Estimating-unknown-quantities-from-a-sample.html#표본-모집단-및-표본추출",
    "href": "08-Estimating-unknown-quantities-from-a-sample.html#표본-모집단-및-표본추출",
    "title": "8  표본으로 미지의 모수 추정하기",
    "section": "",
    "text": "8.1.1 모집단 정의하기\n표본은 구체적인 개념입니다. 데이터 파일을 열어 보면 거기에 표본에서 얻은 데이터가 들어 있습니다. 반면, 모집단(population)은 더 추상적인 개념입니다. 모집단은 연구자가 결론을 내리고자 하는 모든 가능한 사람들 또는 모든 가능한 관측치를 포함하는 집합을 의미하며, 일반적으로 표본보다 훨씬 더 큽니다. 이상적인 상황에서는 연구자가 연구를 시작할 때 관심 있는 모집단이 무엇인지 명확하게 정의하는 것이 바람직합니다. 연구 설계 및 데이터로 가설을 검증하는 과정은 연구자가 진술하고자 하는 모집단에 따라 달라지기 때문입니다.\n어떤 경우에는 관심 있는 모집단을 명확하게 정의하기가 쉽습니다. 예를 들어, 이 장의 서두에서 언급한 “여론 조사 기관” 예시에서 모집단은 연구 시점에 등록된 모든 유권자들로 이루어지며, 이는 수백만 명에 이릅니다. 표본은 그 모집단에 속하는 1000명의 사람들로 구성됩니다. 그러나 대부분의 연구에서는 상황이 훨씬 더 복잡합니다. 일반적인 심리학 실험에서 관심 있는 모집단을 결정하는 것은 다소 까다로울 수 있습니다. 예를 들어, 100명의 학부생을 실험 참가자로 모집하여 실험을 수행한다고 가정해 봅시다. 인지 과학자로서 나는 인간의 정신이 어떻게 작동하는지에 대해 알고자 합니다. 그렇다면 다음 중 무엇이 “모집단”에 해당할까요?\n\n애들레이드 대학교의 학부 심리학 학생 전원?\n전 세계의 학부 심리학 학생들?\n현재 살아 있는 호주인들?\n표본과 비슷한 연령대의 호주인들?\n현재 살아 있는 모든 사람들?\n과거, 현재, 미래의 모든 인간들?\n모든 지적 존재들?\n\n각 항목은 실제로 정신을 소유한 존재들의 집단을 정의하며, 인지 과학자로서 나에게 모두 흥미로운 대상이 될 수 있습니다. 그러나 이들 중 어떤 집단이 진정한 관심 모집단이어야 하는지는 명확하지 않습니다. 또 다른 예로, IV 부의 서두에서 논의했던 웰즐리-크로커 게임을 고려해 봅시다. 여기에서 표본은 웰즐리가 12번 연속 승리하고 0번 패배한 특정한 게임 결과의 순서를 의미합니다. 그렇다면 모집단은 무엇일까요? 앞의 예와 마찬가지로, 모집단이 무엇인지 명확하지 않습니다.\n\n웰즐리와 크로커가 목적지에 도착할 때까지의 모든 게임 결과?\n웰즐리와 크로커가 평생 동안 게임을 계속했을 경우의 모든 결과?\n웰즐리와 크로커가 영원히 살아남아 세상의 언덕이 다 사라질 때까지 게임을 계속했을 경우의 모든 결과?\n무한한 평행 우주를 생성하고, 각 평행 우주의 웰즐리/크로커가 동일한 12개의 언덕에 대해 추측을 했을 경우의 모든 결과?\n\n\n\n8.1.2 단순 무작위 표본\n모집단을 어떻게 정의하든 간에 중요한 점은 표본이 모집단의 부분집합이며, 우리가 가진 표본을 이용해 모집단의 특성을 추론하는 것이 목표라는 것입니다. 표본과 모집단 사이의 관계는 표본이 선택된 방식, 즉 표본추출 방법(sampling method)에 따라 달라지며, 이 과정이 중요한 이유를 이해하는 것이 필수적입니다.\n간단한 예를 들어봅시다. 10개의 칩(chips)이 들어 있는 주머니가 있다고 가정합시다. 각 칩에는 고유한 문자가 인쇄되어 있어 구별할 수 있으며, 칩의 색깔은 검은색과 흰색 두 가지입니다. 이 칩들의 집합이 우리가 관심을 두는 모집단이며, 이는 Figure 8.1 의 왼쪽 그림에 표현되 있습니다. 그림에서 볼 수 있듯이, 검은색 칩이 4개, 흰색 칩이 6개 있지만, 실제로 실험을 수행할 때 주머니 안을 들여다보지 않는 한 이를 알 수는 없습니다. 이제 다음과 같은 “실험”을 진행한다고 가정합시다. 주머니를 흔든 후 눈을 감고 칩 4개를 꺼내되, 꺼낸 칩을 다시 주머니에 넣지 않습니다. 첫 번째로 나온 칩은 \\(a\\)(검은색), 그다음은 \\(c\\)(흰색), 그다음은 \\(j\\)(흰색), 마지막으로 \\(b\\)(검은색)이었습니다. 이후 모든 칩을 다시 주머니에 넣고 같은 실험을 반복할 수 있으며, 이는 Figure 8.1 오른쪽에 표현되어 있습니다. 실험을 반복할 때마다 결과가 다르게 나타날 수 있지만, 과정 자체는 동일합니다. 이렇게 같은 과정이 반복될 때마다 다른 결과가 나올 수 있는 경우를 확률 과정(random process)이라고 합니다.1 그러나 주머니를 흔든 후 칩을 선택했으므로 모든 칩이 동일한 확률로 선택될 가능성이 높다고 생각할 수 있습니다. 모집단 내 모든 구성원이 동일한 확률로 선택될 수 있는 표본추출 절차를 단순 무작위 표본추출(simple random sample)이라고 합니다. 또한, 칩을 꺼낸 후 다시 주머니에 넣지 않았기 때문에 같은 칩을 표본에서 두 번 관찰할 수 없으며, 이러한 경우를 비복원 표본추출(sampling without replacement)이라고 합니다.\n\n\n\n\n\n\n\n\nFigure 8.1. 유한 모집단에서의 비복원 단순 무작위 표본추출\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8.2. 유한 모집단에서의 편향된 비복원 표본추출\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8.3. 유한 모집단에서의 단순 무작위 복원 표본추출\n\n\n\n\n\n표본추출 절차의 중요성을 이해하기 위해 다른 실험 방식을 고려해 봅시다. 만약 다섯 살짜리 아이가 주머니를 열고 검은색 칩 4개를 골라내며, 꺼낸 칩을 다시 넣지 않는 방식으로 진행했다면 어떻게 될까요? 이러한 편향된 표본추출 방식은 Figure 8.2 에 표현되어 있습니다. 이제 4개의 검은색 칩이 선택되고 흰색 칩이 하나도 선택되지 않았다는 사건이 갖는 증거로서의 가치를 생각해 봅시다. 이는 표본추출 방식에 따라 다르지 않을까요? 만약 특정 색깔의 칩만 선택하도록 편향된 표본추출한 방식이라면, 검은색 칩만 포함된 표본이 모집단에 대해 제공하는 정보는 매우 제한적일 것입니다. 이러한 이유로 통계학자들은 데이터가 단순 무작위 표본일 때를 선호합니다. 이렇게 하면 데이터 분석이 훨씬 쉬워지기 때문입니다.\n또 다른 표본추출 방법도 고려할 가치가 있습니다. 이번에는 눈을 감고 주머니를 흔든 후 칩을 하나 꺼냅니다. 그러나 이번에는 관측값을 기록한 후 칩을 다시 주머니에 넣고 같은 과정을 반복하여 4개의 칩을 선택합니다. 이처럼 선택한 항목을 다시 모집단에 포함시키는 방식을 복원 표본추출(sampling with replacement)이라고 합니다. 이 방식에서는 동일한 모집단 항목이 여러 번 관찰될 가능성이 있으며, 이는 Figure 8.3 에서 설명되어 있습니다.\n내 경험에 따르면 대부분의 심리학 실험은 비복원 표본추출 방식을 따릅니다. 왜냐하면 같은 사람이 두 번 실험에 참여하는 것이 허용되지 않기 때문입니다. 그러나 대부분의 통계 이론은 복원 표본추출을 가정하여 개발됩니다. 하지만 현실에서는 이 차이가 거의 문제가 되지 않습니다. 모집단이 충분히 클 경우(예: 10개 이상의 개체가 존재할 경우)2 복원 표본추출과 비복원 표본추출 간의 차이는 무시할 수 있을 정도로 작기 때문입니다. 반면, 단순 무작위 표본과 편향된 표본 간의 차이는 간과하기 어려운 차이를 가집니다.\n\n\n8.1.3 대부분의 표본은 단순 무작위 표본이 아니다\n위에서 제시한 가능한 모집단 목록을 보면 알 수 있듯이, 우리가 관심을 갖는 대부분의 모집단에서 단순 무작위 표본을 얻는 것은 거의 불가능합니다. 내가 실험을 진행할 때, 참가자가 애들레이드 대학교의 학부 심리학 학생들 중에서 무작위로 표본추출되었다면, 그것만으로도 작은 기적이라고 생각할 것입니다. 이는 내가 일반화하고 싶은 모집단 중에서 가장 좁은 범주임에도 그렇습니다. 다른 유형의 표본추출 방법에 대한 자세한 논의는 이 책의 범위를 벗어나지만, 대략적인 개념을 제공하기 위해 몇 가지 중요한 방법을 소개하겠습니다.\n\n층화 표본추출(stratified sampling): 모집단이 여러 개의 하위 모집단(층)으로 나뉘어 있거나 나눌 수 있다고 가정해 봅시다. 예를 들어, 여러 다른 지역에서 연구를 진행할 수도 있습니다. 모집단 전체에서 무작위로 표본을 추출하는 대신, 각 층에서 별도로 무작위 표본을 수집하는 방식을 사용할 수도 있습니다. 층화 표본추출은 모집단이 이미 명확한 층으로 나누어져 있을 경우 단순 무작위 표본추출보다 더 쉽고, 특히 희귀한 하위 모집단을 포함하고 있을 때 더 효율적일 수 있습니다. 예를 들어, 조현병을 연구할 때 모집단을 두 개의 층(조현병 환자와 비(非)조현병 환자)으로 나누고, 각 그룹에서 동일한 수의 사람을 표본으로 추출하는 것이 훨씬 더 나은 방법일 것입니다. 무작위로 사람을 선택하면 조현병 환자가 표본에 거의 포함되지 않아 연구가 무의미해질 수도 있습니다. 이러한 특정한 층화 표본추출 방식을 과표집(oversampling)이라고 하며, 희귀한 그룹을 의도적으로 더 많이 포함하도록 하는 기법입니다.3\n눈덩이 표본추출(snowball sampling): “숨겨진” 또는 접근하기 어려운 모집단에서 표본을 추출할 때 유용한 기법이며, 특히 사회과학에서 흔히 사용됩니다. 예를 들어, 연구자가 트랜스젠더 집단을 대상으로 여론 조사를 하고 싶다고 가정해 봅시다. 연구팀이 처음에는 소수의 트랜스젠더 참여자에 대한 연락처만 가지고 있을 수 있습니다. 따라서 연구는 우선 이들에게 설문에 참여해 달라고 요청하는 것으로 시작됩니다(1단계). 설문이 끝난 후, 연구자는 이들에게 추가로 참여할 만한 다른 사람들의 연락처를 제공해 달라고 요청합니다. 이렇게 확보된 새로운 연락처를 대상으로 2단계 조사가 진행됩니다. 이러한 과정이 반복되면서 연구자는 충분한 데이터를 확보하게 됩니다. 눈덩이 표본추출의 가장 큰 장점은 일반적으로 데이터를 확보하기 어려운 상황에서도 표본을 얻을 수 있다는 점입니다. 그러나 통계적으로는 표본이 매우 비무작위적이며, 그 비무작위성이 어떻게 작용하는지 파악하기 어렵다는 단점이 있습니다. 또한 현실적인 문제도 있습니다. 모집단이 “숨겨진” 이유가 있는 경우가 많기 때문에, 이 방법을 잘못 사용할 경우 비윤리적인 결과를 초래할 수 있습니다. 여기서 트랜스젠더 집단을 예로 든 이유도 이와 관련이 있습니다. 연구자가 조심하지 않으면, 원치 않는 사람을 아웃팅(outing)하게 될 수도 있으며(이는 매우 심각한 실수입니다), 그런 실수를 하지 않더라도 사람들의 사회적 네트워크를 연구 목적으로 이용하는 것이 사생활 침해로 느껴질 수 있습니다. 무엇보다, 연구자가 사람들에게 연락을 취하기 전에 미리 동의를 얻는 것이 어렵다는 점도 문제입니다. 때로는 단순히 “우리가 당신을 연구하고 싶다”는 의도를 밝히는 것만으로도 상처를 줄 수 있습니다. 사회적 네트워크는 복잡한 구조를 가지고 있으며, 사회적 네트워크로 데이터를 수집할 수 있다고 해서 그렇게 하는 것이 좋은 것은 아닐 수 있다는 것을 기억해야 합니다.\n편의 표본추출(convenience sampling): 말 그대로 연구자에게 편리한 방식으로 표본을 선택하는 방법이며, 모집단에서 무작위로 선택하는 것은 아닙니다. 눈덩이 표본추출도 편의 표본추출의 한 형태이지만, 이 외에도 다양한 방식이 존재합니다. 심리학 연구에서 흔히 볼 수 있는 예로, 학부 심리학 학생들을 대상으로 한 연구를 들 수 있습니다. 이러한 표본은 일반적으로 두 가지 측면에서 비무작위적입니다. 첫째, 학부 심리학 학생들을 대상으로 한다는 것 자체가 특정 하위 모집단에 국한된다는 점입니다. 둘째, 학생들이 어떤 연구에 참여할지를 직접 선택하는 경우가 많기 때문에, 이는 심리학 학생들 전체에서 무작위로 선택된 하위 집단이 아니라 자발적으로 참여한 일부 집단이라는 점에서 더욱 비무작위적입니다. 현실적으로 보면, 대부분의 연구는 어느 정도 편의 표본추출에 의존합니다. 이는 연구의 중요한 한계가 될 수도 있지만, 반드시 그렇지만은 않습니다.\n\n\n\n8.1.4 단순 무작위 표본이 아니면 얼마나 문제가 될까?\n현실에서 데이터를 수집할 때는 대부분 단순 무작위 표본을 사용하지 않습니다. 그렇다면 이것이 문제가 될까요? 조금만 생각해 보면, 데이터가 단순 무작위 표본이 아닐 경우 문제가 될 수 있다는 점이 명확해집니다. Figure 8.1 과 Figure 8.2 의 차이를 생각해 보면 됩니다. 하지만 걱정할 만큼 나쁜 상황은 아닙니다. 일부 유형의 편향된 표본은 전혀 문제가 되지 않습니다. 예를 들어, 층화 표본추출 기법을 사용할 경우 연구자가 의도적으로 편향을 만들었으며, 이는 종종 연구의 효과를 높이기 위한 것입니다. 또한, 이러한 경우에는 연구자가 만든 편향을 보정할 수 있는 통계적 기법도 존재합니다(이 책에서는 다루지 않지만!). 따라서 이러한 상황에서는 문제가 되지 않습니다.\n보다 일반적으로 보았을 때, 무작위 표본추출은 수단이지 목적이 아니라는 점을 기억하는 것이 중요합니다. 편의 표본에 의존했다고 가정해 봅시다. 그렇다면 표본이 편향되었을 가능성이 큽니다. 하지만 표본추출 과정에서 편향이 발생했다고 해서 반드시 문제가 되는 것은 아닙니다. 문제가 되는 경우는 그 편향이 잘못된 결론을 내리게 만드는 경우뿐입니다. 이런 관점에서 본다면, 표본이 모든 면에서 무작위적일 필요는 없으며, 연구에서 관심을 두고 있는 심리학적 현상과 관련하여 무작위적이면 충분합니다.\n예를 들어, 내가 작업 기억 용량(working memory capacity)에 대한 연구를 진행한다고 가정해 봅시다. 연구 1에서는 현재 살아 있는 모든 인간을 대상으로 무작위 표본을 추출할 수 있는 능력을 갖고 있지만, 한 가지 예외가 있습니다. 월요일에 태어난 사람만 표본으로 선택할 수 있습니다. 연구 2에서는 호주 인구에서 무작위로 표본을 추출할 수 있습니다. 나는 연구 결과를 전 세계 모든 인간에게 일반화하고 싶습니다. 그렇다면 어느 연구가 더 나을까요? 당연히 연구 1입니다. 왜일까? “월요일에 태어났다”는 것이 작업 기억 용량과 관련이 있을 이유가 전혀 없기 때문입니다. 반면, “호주에서 태어났다”는 것은 다를 수 있습니다. 호주는 부유한 산업국이며, 매우 잘 발달된 교육 시스템을 갖추고 있습니다. 이 시스템에서 성장한 사람들은 작업 기억 용량을 측정하는 테스트를 설계한 사람들과 훨씬 더 유사한 삶의 경험을 공유했을 가능성이 높습니다. 이러한 공통된 경험은 테스트를 어떻게 수행해야 하는지에 대한 유사한 신념을 형성할 수도 있고, 심리학 실험이 어떻게 진행되는지에 대한 공통된 가정을 만들 수도 있습니다. 이런 요소들은 실제로 중요한 영향을 미칠 수 있습니다. 예를 들어, “시험 방식”이 호주 참가자들에게 보다 추상적인 시험 자료에 집중하는 법을 가르쳤을 수도 있습니다. 반면, 유사한 환경에서 성장하지 않은 사람들은 이러한 방식에 익숙하지 않을 수 있습니다. 따라서 이런 편향된 표본이 작업 기억 용량에 대한 잘못된 판단을 하게 만들 수도 있습니다.\n이 논의에서 두 가지 중요한 점을 짚어볼 수 있습니다. 첫째, 연구를 설계할 때 어떤 모집단을 연구 대상으로 삼을 것인지 신중하게 생각하고, 그 모집단에 적합한 방식으로 표본을 추출하려고 노력해야 합니다. 현실적으로는 대부분 “편의 표본”을 사용할 수밖에 없는 경우가 많습니다(예: 심리학 교수들이 심리학 학생들을 대상으로 연구를 수행하는 이유는 비용이 가장 적게 들기 때문이며, 학계의 예산은 풍족하지 않습니다). 하지만 그렇다고 해도, 이러한 방법이 초래할 위험이 무엇인지에 대해 고민하는 것이 필요합니다. 둘째, 다른 연구자의 연구를 비판할 때, 단순히 그들이 편의 표본을 사용했다고 해서 비판하는 것은 적절하지 않습니다. 만약 연구 결과가 왜곡되었을 가능성이 있다고 주장하려면, 최소한 그 편향이 결과에 어떤 영향을 미쳤을지에 대한 구체적인 이론을 제시하는 것이 예의일 것입니다.\n\n\n\n\n\n\n작업 기억이란\n\n\n\n작업 기억(working memory)는 정보를 짧은 시간 동안 일시적으로 저장하고 조작하는 능력을 말합니다. 이는 우리가 복잡한 인지 작업을 수행할 때 필수적인 역할을 합니다. 예를 들어, 문제 해결, 의사 결정, 언어 이해, 계산 등의 과정에서 작업 기억이 활발하게 사용됩니다.\n작업 기억의 주요 특징은 다음과 같습니다.\n\n일시적 저장: 정보를 짧은 시간 동안만 유지합니다. (몇 초에서 수십 초 정도)\n정보 조작: 단순히 저장하는 것뿐만 아니라 그 정보를 활용하거나 변형할 수 있습니다.\n제한된 용량: 한 번에 처리할 수 있는 정보의 양이 제한되어 있습니다. (보통 7±2 개의 항목이라고 알려짐)\n\n작업 기억의 구성 요소에 대한 Baddeley & Hitch 자신의 모형에서 다음과 같이 설명합니다.\n\n중앙 집행기(Central Executive):\n\n작업 기억의 컨트롤 타워 역할을 합니다.\n\n주의 집중, 정보 전환, 억제 등을 관리합니다.\n\n음운 루프(Phonological Loop):\n\n언어적 정보(단어, 숫자 등)를 처리하고 유지합니다.\n\n예: 전화번호를 머릿속으로 반복하며 기억하기.\n\n시공간 스케치패드(Visuospatial Sketchpad):\n\n시각적 및 공간적 정보를 처리합니다.\n\n예: 지도를 떠올리며 길 찾기.\n\n에피소드 버퍼(Episodic Buffer):\n\n여러 종류의 정보를 통합하고 장기 기억과 연결합니다.\n\n\n작업 기억이 사용되는 작업의 예는 다음과 같습니다.\n\n암산하기: 37 + 48을 머릿속으로 계산할 때, 숫자들을 기억하고 더하는 과정을 조작합니다.\n\n지시 따르기: “왼쪽으로 가서 두 번째 문을 열어”라는 지시를 듣고 행동하기.\n\n문장 이해하기: 긴 문장을 읽으면서 앞 문장의 내용을 기억하고 연결하기.\n\n작업 기억과 단기 기억의 차이는 다음과 같습니다.\n\n단기 기억: 정보를 단순히 잠시 저장하는 것에 초점.\n\n작업 기억: 저장뿐만 아니라 정보를 활발히 조작하는 것이 특징.\n\n이해하기 쉽게 말하면, 단기 기억은 정보를 “메모”하는 종이 쪽지이고, 작업 기억은 그 쪽지를 보면서 “계산하거나 생각하는 작업 공간”이라고 볼 수 있습니다.\n\n\n\n\n8.1.5 모집단 모수와 표본 통계량\n이제, 무작위 표본을 얻는 과정에서 발생하는 까다로운 방법론적 문제를 잠시 제쳐두고, 약간 다른 문제를 고려해 봅시다. 지금까지 우리는 과학자가 모집단을 바라보는 방식에 대해 이야기했습니다. 심리학자에게 모집단은 사람들의 집단일 수 있고, 생태학자에게 모집단은 곰들의 집단일 수 있습니다. 대부분의 경우, 과학자들이 관심을 가지는 모집단은 실제 세계에 존재하는 구체적인 것들입니다. 그러나 통계학자들은 다소 독특한 사고방식을 가집니다. 한편으로는 과학자들처럼 현실 세계의 데이터와 과학에 관심이 있지만, 다른 한편으로는 수학자들처럼 순수한 추상적 개념을 다루기도 합니다. 그 결과, 통계 이론에서는 모집단을 다소 추상적으로 정의하는 경향이 있습니다. 심리학 연구자들이 추상적인 이론적 개념을 구체적인 측정값으로 조작적으로 정의하듯이(Section 2.1), 통계학자들도 모집단 개념을 자신들이 다룰 수 있는 수학적 객체로 조작적으로 정의합니다. 여러분은 이 조작적 객체를 이미 Chapter 7 에서 보았습니다. 바로 확률분포(probability distributions)입니다.\n개념은 비교적 간단합니다. 예를 들어, 우리가 IQ 점수에 대해 논의한다고 가정해 봅시다. 심리학자에게 모집단은 IQ 점수를 가진 실제 인간 집단입니다. 그러나 통계학자는 이를 보다 단순하게 만들어 Figure 8.4 (a)에서 나타난 확률분포로 조작적으로 정의합니다. IQ 테스트는 평균 IQ가 100이고, 표준 편차가 15이며, IQ 점수 분포가 정규 분포를 따르도록 설계됩니다. 이러한 값들을 모집단 모수(population parameters)라고 하며, 이는 모집단 전체의 특성을 나타냅니다. 즉, 모집단의 평균 ()는 100이고, 모집단의 표준 편차 ()는 15라고 말할 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 8.4. IQ 점수의 모집단 분포(패널 (a))와 무작위로 추출한 두 개의 표본. 패널 (b)는 100개의 표본을, 패널 (c)는 10,000개의 표본을 포함하고 있다.\n\n\n\n\n\n이제, 실험을 수행한다고 가정해 봅니다. 나는 무작위로 100명을 선택하여 IQ 테스트를 실시하고, 이를 통해 모집단에서 단순 무작위 표본을 얻습니다. 내 표본은 다음과 같은 숫자들로 구성될 것입니다.\n\n106 101 98 80 74 … 107 72 100\n\n각각의 IQ 점수는 평균이 100이고 표준 편차가 15인 정규 분포에서 추출된 값입니다. 따라서 표본의 히스토그램을 그려보면 Figure 8.4 (b)와 같은 모양이 됩니다. 보시다시피, 히스토그램의 형태는 모집단 분포(Figure 8.4 (a) 참조)와 대체로 유사하지만, 여전히 매우 조잡한 근사값에 불과합니다. 표본의 평균을 계산하면 모집단 평균인 100에 가까운 값을 얻을 수 있지만, 정확히 동일하지는 않습니다. 이 경우, 내 표본에 포함된 사람들의 평균 IQ는 98.5이고, 표준 편차는 15.9로 나타났습니다. 이러한 값들을 표본 통계량(sample statistics)이라고 하며, 이는 내 데이터 집합의 특성을 나타냅니다. 표본 통계량은 모집단의 실제 값과 유사하지만 동일하지는 않습니다. 일반적으로, 표본 통계량은 우리가 데이터에서 직접 계산할 수 있는 값이며, 모집단 모수는 우리가 알아내고자 하는 대상입니다.\n이 장의 뒷부분에서, [모집단 모수 추정]을 위해 표본 통계량을 사용하는 방법과 신뢰구간 추정에 대해 논의할 것입니다. 하지만 그 전에 표본 이론(sampling theory)에서 더 알아야 할 몇 가지 개념이 남아 있습니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>표본으로 미지의 모수 추정하기</span>"
    ]
  },
  {
    "objectID": "08-Estimating-unknown-quantities-from-a-sample.html#대수의-법칙",
    "href": "08-Estimating-unknown-quantities-from-a-sample.html#대수의-법칙",
    "title": "8  표본으로 미지의 모수 추정하기",
    "section": "8.2 대수의 법칙",
    "text": "8.2 대수의 법칙\n이전 절에서 표본 크기가 \\(N = 100\\)인 가상의 IQ 실험 결과를 보여주었습니다. 실제 모집단 평균이 100이고 표본 평균이 98.5인 것을 보면, 이는 비교적 정확한 추정치임을 알 수 있습니다. 많은 과학 연구에서 이 정도의 정밀도는 충분히 받아들일 수 있지만, 어떤 경우에는 훨씬 더 정밀한 결과가 필요합니다. 그렇다면 표본 통계량을 모집단 모수에 더 가깝게 만들려면 어떻게 해야 할까요? 가장 명백한 해결책은 더 많은 데이터를 수집하는 것입니다. 이제 10,000명의 IQ를 측정하는 훨씬 더 큰 실험을 수행했다고 가정해 봅시다. 우리는 jamovi를 사용하여 이 실험의 결과를 시뮬레이션할 수 있습니다. IQsim.omv 파일은 jamovi 데이터 파일로, 평균이 100이고 표준 편차가 15인 모집단에서 정규 분포를 따르는 10,000개의 난수를 생성한 것입니다. 이 작업은 jamovi의 ‘= NORM(100,15)’ 함수를 사용하여 새로운 변수를 계산함으로써 수행되었습니다. Figure 8.5 의 히스토그램과 밀도 그래프를 보면, 더 큰 표본이 모집단의 실제 분포를 더 잘 반영한다는 것을 확인할 수 있습니다. 이는 표본 통계량에도 반영됩니다. 더 큰 표본에서 얻은 평균 IQ는 99.68, 표준 편차는 14.90으로, 이제 모집단의 실제 값과 매우 가까워졌습니다.\n\n\n\n\n\n\n\n\nFigure 8.5. jamovi를 사용하여 정규 분포에서 추출한 무작위 표본\n\n\n\n\n\n이 말을 하는 것이 조금 부질없게 느껴지지만, 여러분이 반드시 기억해야 할 것은 표본 크기가 클수록 더 좋은 정보를 얻을 수 있다는 점입니다. 사실 이 점은 너무나도 명백해서 굳이 언급할 필요도 없어 보입니다. 실제로 확률론의 창시자 중 한 명인 야코프 베르누이는 1713년에 이 개념을 공식화하면서 다소 거만한 태도를 보였습니다. 그는 다음과 같이 설명했습니다.\n\n“가장 어리석은 사람조차도 어떤 본능적인 직관에 의해, 그리고 별다른 가르침 없이도(이는 주목할 만한 점이다), 더 많은 관찰이 이루어질수록 목표에서 벗어날 위험이 줄어든다는 것을 확신하게 된다.” (Stigler, 1986, p. 65)\n\n이 문장은 다소 무례하게 들릴 수도 있고(게다가 성차별적인 느낌도 있습니다), 하지만 그의 핵심 주장 자체는 맞습니다. 우리는 본능적으로 더 많은 데이터가 더 나은 결과를 가져온다는 사실을 이해하고 있습니다. 그렇다면, 왜 그런 걸까요? 놀랍지 않게도, 우리가 공유하는 이 직관은 정확하며, 통계학자들은 이를 대수의 법칙(law of large numbers)이라고 부릅니다. 대수의 법칙은 여러 가지 표본 통계량에 적용되는 수학적 법칙이지만, 가장 쉽게 이해할 수 있는 방식은 이를 평균에 대한 법칙으로 보는 것입니다. 표본 평균은 평균을 계산하는 과정(즉, 여러 값의 평균을 구하는 것)에서 비롯되는 통계량이므로, 이를 통해 대수의 법칙을 살펴보겠습니다. 대수의 법칙이 표본 평균에 적용될 때, 이 법칙은 다음과 같이 말합니다. 표본 크기가 커질수록 표본 평균은 모집단 평균에 점점 더 가까워진다는 것입니다. 보다 정확히 표현하면, 표본 크기가 무한대로 증가할 때(\\(N \\longrightarrow \\infty\\)), 표본 평균은 모집단 평균에 수렴합니다(\\(\\bar{X} \\longrightarrow \\mu\\))4.\n대수의 법칙이 참이라는 것을 증명할 생각은 없지만, 이는 통계 이론에서 가장 중요한 도구 중 하나입니다. 대수의 법칙은 우리가 점점 더 많은 데이터를 수집하면 결국 진실에 가까워질 것이라는 믿음을 정당화하는 근거가 됩니다. 어떤 특정한 데이터 집합에서 계산된 표본 통계량이 완벽히 정확할 가능성은 낮지만, 대수의 법칙에 따르면 더 많은 데이터를 수집할수록 표본 통계량은 점점 모집단 모수에 가까워지게 됩니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>표본으로 미지의 모수 추정하기</span>"
    ]
  },
  {
    "objectID": "08-Estimating-unknown-quantities-from-a-sample.html#표본-분포와-중심극한정리",
    "href": "08-Estimating-unknown-quantities-from-a-sample.html#표본-분포와-중심극한정리",
    "title": "8  표본으로 미지의 모수 추정하기",
    "section": "8.3 표본 분포와 중심극한정리",
    "text": "8.3 표본 분포와 중심극한정리\n대수의 법칙은 매우 강력한 도구이지만, 우리의 모든 질문에 답해줄 수는 없습니다. 이 법칙이 제공하는 것은 기본적으로 “장기적인 보장”일 뿐입니다. 즉, 우리가 무한한 양의 데이터를 수집할 수 있다고 가정하면, 대수의 법칙은 우리가 구한 표본 통계량이 정확할 것이라고 보장합니다. 하지만 경제학자 존 메이너드 케인스가 유명하게 지적했듯이, 장기적인 보장은 현실 세계에서 그다지 유용하지 않습니다.\n\n“[장기적인 관점은] 현재의 문제를 해결하는 데 있어 잘못된 길잡이가 될 수 있습니다. 장기적으로 보면 우리는 모두 죽습니다. 경제학자들이 폭풍이 지나고 바다가 다시 평온해질 것이라고 말하는 것은 격동의 시기에는 아무런 도움도 되지 않습니다.” (Keynes, 1923, p. 80)\n\n경제학에서 그렇듯이, 심리학과 통계학에서도 마찬가지입니다. 표본 평균을 계산할 때 결국에는 올바른 답을 얻게 된다는 것만으로는 충분하지 않습니다. 표본 크기가 \\(N = 100\\)인 실제 데이터 집합을 다루는 상황에서, 무한히 큰 데이터 집합이 모집단 평균의 정확한 값을 알려줄 것이라는 사실은 아무런 위안이 되지 않습니다. 현실에서는, 더 작은 표본에서 표본 평균이 어떤 행태를 보이는지를 이해하는 것이 필수적입니다.\n\n8.3.1 평균의 표본 분포\n이 점을 염두에 두고, 이제 표본 크기가 10,000인 연구를 고려하는 대신 훨씬 더 작은 실험을 생각해 보겠습니다. 이번에는 \\(N = 5\\)명의 사람을 표본으로 선정하여 그들의 IQ 점수를 측정합니다. 이전과 마찬가지로 jamovi의 ‘= NORM(100,15)’ 함수를 사용하여 이 실험을 시뮬레이션할 수 있지만, 이번에는 10,000명이 아니라 단 5명의 참가자만 필요합니다. jamovi가 생성한 다섯 개의 숫자는 다음과 같습니다.\n\n90 82 94 99 110\n\n이 표본에서의 평균 IQ는 정확히 95입니다. 예상할 수 있듯이, 이는 이전 실험보다 훨씬 덜 정확한 결과입니다. 이제 내가 이 실험을 반복하기로 결정했다고 가정해 봅시다. 즉, 가능한 한 동일한 절차를 다시 수행하고, 무작위로 새로운 5명을 선정하여 그들의 IQ를 측정하는 것입니다. jamovi를 사용하면 이 과정을 다시 시뮬레이션할 수 있으며, 다음과 같은 다섯 개의 숫자가 생성됩니다.\n\n78 88 111 111 117\n\n이번 표본에서의 평균 IQ는 101입니다. 실험을 10번 반복하면 Table 8.1 에서 볼 수 있는 결과를 얻게 되며, 각 반복에서 표본 평균이 달라진다는 것을 확인할 수 있습니다.\n\n\n\n\nTable 8.1. 각 표본 크기가 \\(( N = 5 )\\)인 IQ 실험의 10번 반복 결과\n\n\n\n\n\n사람 1사람 2사람 3사람 4사람 5표본평균\n\n반복 19082949911095.0\n\n반복 27888111111117101.0\n\n반복 3111122919886101.6\n\n반복 4989611999107103.8\n\n반복 510511310310398104.4\n\n반복 68189938511492.4\n\n반복 71009310898133106.4\n\n반복 810710010511785102.8\n\n반복 98611910873116100.4\n\n반복 109512611212076105.8\n\n\n\n\n\n\n\n이제 이 방식대로 계속해서 “5명의 IQ 점수” 실험을 반복한다고 가정해 봅시다. 매번 실험을 반복할 때마다 표본 평균을 기록합니다. 시간이 지나면서 새로운 데이터 집합이 축적될 것입니다. 이 데이터 집합에서는 각 실험이 단일 데이터 포인트를 생성합니다. 내 데이터 집합에서 처음 10개의 관측치는 Table 8.1 에 나열된 표본 평균이며, 다음과 같이 시작됩니다.\n\n95.0 101.0 101.6 103.8 104.4 …\n\n이 과정을 10,000번 반복한 후 히스토그램을 그려보면 어떻게 될까요? 실제로 그렇게 해보았으며, 그 결과는 Figure 8.6 에서 확인할 수 있습니다. 이 그림이 보여주듯이, 5개의 IQ 점수를 평균 내면 보통 90에서 110 사이의 값이 나옵니다. 하지만 더 중요한 점은, 실험을 여러 번 반복하면 표본 평균의 분포가 형성된다는 것입니다! (Table 8.1). 통계학에서 이 분포를 평균의 표본 분포라고 부릅니다.\n표본 분포는 통계학에서 또 하나의 중요한 이론적 개념이며, 작은 표본의 특성을 이해하는 데 필수적입니다. 예를 들어, 처음 수행한 “5명의 IQ 점수” 실험에서는 표본 평균이 95였습니다. 그러나 Figure 8.6 의 표본 분포는 이 실험이 별로 정확하지 않다는 사실을 알려줍니다. 만약 실험을 반복한다면, 표본 평균이 80에서 120 사이에서 변동할 가능성이 높습니다.\n\n\n\n\n\n\n\n\nFigure 8.6. 5명의 IQ 점수 실험에서 평균의 표본 분포. 무작위로 5명을 표본으로 선정하여 그들의 평균 IQ를 계산하면 거의 확실히 80에서 120 사이의 값을 얻게 됩니다. 하지만 120을 초과하거나 80 미만의 IQ를 가진 사람이 꽤 많음에도 불구하고, 이러한 값이 나오기는 어렵습니다. 비교를 위해, 검은색 선은 모집단의 IQ 분포를 나타냅니다.\n\n\n\n\n\n\n\n8.3.2 모든 표본 통계량에는 표본 분포가 존재한다!\n표본 분포에 대해 생각할 때 기억해야 할 중요한 점은, 우리가 계산할 수 있는 모든 표본 통계량에는 표본 분포가 존재한다는 것입니다. 예를 들어, “5명의 IQ 점수” 실험을 반복할 때마다 그 실험에서 가장 높은 IQ 점수를 기록한다고 가정해 봅시다. 그러면 다음과 같은 데이터 집합이 형성될 것입니다.\n\n110 117 122 119 113 …\n\n이 과정을 계속 반복하면 전혀 다른 표본 분포가 생성됩니다. 즉, 이는 최대값의 표본 분포입니다. 5명의 IQ 점수 중 최대값의 표본 분포는 Figure 8.7 에서 확인할 수 있습니다. 예상할 수 있듯이, 무작위로 5명을 선정한 후 가장 높은 IQ 점수를 가진 사람을 찾으면, 그 사람은 평균 이상의 IQ를 가지고 있을 가능성이 큽니다. 대부분의 경우, IQ가 100에서 140 사이인 사람을 얻게 될 것입니다.\n\n\n\n\n\n\n\n\nFigure 8.7. 5명의 IQ 점수 실험에서 최대값의 표본 분포. 무작위로 5명을 선정한 후 가장 높은 IQ 점수를 가진 사람을 선택하면, 대부분 IQ가 100에서 140 사이에 위치할 것이다.\n\n\n\n\n\n\n\n8.3.3 중심극한정리\n이제 표본 분포가 무엇인지, 특히 평균의 표본 분포가 무엇인지에 대해 어느 정도 이해했을 것입니다. 이번 절에서는 표본 평균의 분포가 표본 크기에 따라 어떻게 변하는지 이야기하고자 합니다. 직관적으로, 여러분은 이미 답의 일부를 알고 있습니다. 표본 크기가 작으면 표본 평균이 부정확할 가능성이 큽니다. 작은 실험을 반복하여 평균을 다시 계산하면 매우 다른 값을 얻게 될 것입니다. 즉, 표본 분포의 폭이 넓다는 뜻입니다. 반대로, 큰 실험을 반복하여 표본 평균을 다시 계산하면 이전 실험과 거의 동일한 값을 얻을 것이므로 표본 분포가 매우 좁아집니다. 이를 시각적으로 Figure 8.8 에서 확인할 수 있습니다. 표본 크기가 커질수록 표본 분포가 좁아지는 것을 볼 수 있습니다. (a)에서는 각 데이터 세트에 단 하나의 관측값만 포함되어 있어, 각 표본의 평균이 한 개인의 IQ 점수와 동일합니다. 따라서 평균의 표본 분포는 당연히 IQ 점수의 모집단 분포와 동일합니다. 그러나 표본 크기를 2로 늘리면 개별적인 IQ 점수보다 표본 평균이 모집단 평균에 더 가까워지는 경향이 있으며, 따라서 히스토그램(즉, 표본 분포)이 모집단 분포보다 약간 좁아집니다. 표본 크기를 10으로 늘리면 (c)에서 볼 수 있듯이, 표본 평균의 분포가 모집단 평균 주위에 꽤 밀집되는 경향이 있습니다. 이러한 효과는 표준 오차(standard error)라고 하는 표본 분포의 표준 편차를 계산하여 정량화할 수 있습니다. 표준 오차는 일반적으로 SE로 표시되며, 우리가 주로 관심을 가지는 표본 평균의 표준 오차는 SEM이라는 약어를 사용합니다. 그림에서 확인할 수 있듯이, 표본 크기 \\(N\\)이 증가할수록 SEM은 감소합니다.\n\n\n\n\n\n\n\n\n\nFigure 8.8. 표본 크기에 따른 평균의 표본 분포 변화. 각 패널에서 IQ 데이터 10,000개 표본을 생성하고, 각 표본 내에서 평균 IQ를 계산하였습니다. 히스토그램은 이러한 평균들의 분포(즉, 평균의 표본 분포)를 나타냅니다. 개별적인 IQ 점수는 평균 100, 표준 편차 15인 정규 분포에서 추출되었으며, 검은 실선이 이를 나타냅니다.\n\n\n\n\n\n이제까지 한 가지 중요한 사실을 설명했습니다. 그러나 지금까지 간과했던 점이 하나 있습니다. 앞선 모든 예제는 “IQ 점수” 실험을 기반으로 하였으며, IQ 점수는 대략 정규 분포를 따르므로 모집단 분포도 정규 분포라고 가정했습니다. 그런데 모집단 분포가 정규 분포가 아니라면 어떻게 될까요? 평균의 표본 분포는 어떻게 변할까요? 놀라운 점은 모집단 분포의 모양이 어떠하든 간에 표본 크기 \\(N\\)이 커질수록 평균의 표본 분포는 점점 정규 분포에 가까워진다는 것입니다. 이를 보여주기 위해 몇 가지 시뮬레이션을 수행했습니다. 먼저, Figure 8.9 히스토그램으로 나타낸 “비대칭” 분포에서 시작했습니다. 검은 실선으로 표시된 종 모양의 곡선과 삼각형 모양의 히스토그램을 비교하면 모집단 분포가 정규 분포와 전혀 닮지 않았음을 알 수 있습니다. 다음으로, 이 분포에서 \\(N = 2\\)개의 표본을 추출하여 실험을 여러 번 수행한 후, 표본 평균을 계산했습니다. Figure 8.9 (b)는 이 표본 평균들의 히스토그램(즉, 평균의 표본 분포)을 나타냅니다. 여전히 정규 분포는 아니지만, 모집단 분포(Figure 8.9 (a))보다는 검은 실선에 훨씬 더 가까워졌습니다. 표본 크기를 \\(N = 4\\)로 늘리면 평균의 표본 분포는 거의 정규 분포(Figure 8.9 (c))와 유사해지며, \\(N = 8\\)에 도달하면 거의 완벽한 정규 분포를 이룹니다. 즉, 표본 크기가 너무 작지만 않다면 모집단 분포의 형태와 관계없이 평균의 표본 분포는 대략 정규 분포를 따릅니다!\n이제 우리는 평균의 표본 분포에 대해 다음과 같은 중요한 사실을 확인할 수 있습니다.\n\n평균의 표본 분포에서는 평균이 모집단 평균과 동일하다.\n평균의 표본 분포에서는 표준 편차(즉, 표준 오차)는 표본 크기가 증가할수록 작아진다.\n평균의 표본 분포에서는 표본 크기가 증가할수록 정규 분포에 가까워진다.\n\n이러한 사실은 단순한 경험적 관찰이 아니라, 통계학에서 가장 유명한 정리 중 하나인 중심극한정리(central limit theorem)에 의해 수학적으로 증명됩니다. 중심극한정리는 다음을 포함한 여러 가지 중요한 내용을 포함하고 있습니다. 모집단 분포의 평균이 \\(\\mu\\), 표준 편차가 \\(\\sigma\\)일 때, 평균의 표본 분포 또한 평균 \\(\\mu\\)를 가지며 표준 오차는 다음과 같이 계산됩니다.\n\\[SEM=\\frac{\\sigma}{\\sqrt{N}}\\]\n즉, 모집단의 표준 편차 \\(\\sigma\\)를 표본 크기 \\(N\\)의 제곱근으로 나누므로, 표본 크기가 커질수록 SEM은 감소합니다. 또한 중심극한정리는 평균의 표본 분포가 점점 정규 분포에 가까워진다고 알려줍니다.5\n이 결과는 여러 가지 측면에서 유용합니다. 이는 왜 큰 규모의 실험이 작은 실험보다 신뢰할 만한지를 설명해주며, 표준 오차에 대한 명확한 공식을 제공함으로써 큰 실험이 얼마나 더 신뢰할 만한지를 알려줍니다. 또한, 정규 분포가 왜 그렇게 “일반적(normal)”인지에 대한 이유도 설명해줍니다. 실제 실험에서 우리가 측정하고자 하는 많은 것들은 사실 여러 가지 다른 양들의 평균값입니다. (예를 들어, IQ로 측정되는 “일반적인” 지능은 많은 “특정한” 기술과 능력들의 평균이라고 볼 수 있습니다.) 이러한 경우, 평균이 된 값은 정규 분포를 따르게 됩니다. 이 수학적 법칙 덕분에, 정규 분포는 실제 데이터에서 반복적으로 나타납니다.\n\n\n\n\n\n\n\n\nFigure 8.9. 중심극한정리의 시각적 설명. (a)에서는 모집단 분포가 정규 분포가 아니지만, (b)-(d)에서는 표본 크기가 2, 4, 8로 증가함에 따라 평균의 표본 분포가 정규 분포에 가까워지는 것을 볼 수 있습니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>표본으로 미지의 모수 추정하기</span>"
    ]
  },
  {
    "objectID": "08-Estimating-unknown-quantities-from-a-sample.html#모집단-모수-추정하기",
    "href": "08-Estimating-unknown-quantities-from-a-sample.html#모집단-모수-추정하기",
    "title": "8  표본으로 미지의 모수 추정하기",
    "section": "8.4 모집단 모수 추정하기",
    "text": "8.4 모집단 모수 추정하기\n이전 절의 모든 IQ 예제에서는 실제로 모집단 모수를 미리 알고 있었습니다. 지능 측정에 대한 첫 번째 강의에서 모든 학부생이 배우듯이, IQ 점수는 평균이 100이고 표준편차가 15가 되도록 정의되어 있습니다. 그러나 이것은 약간의 “거짓말”입니다. 어떻게 IQ 점수가 실제 모집단 평균이 100이라고 알 수 있을까요? 이는 테스트를 설계한 사람들이 매우 큰 표본에 대해 테스트를 실시하고, 그들의 표본이 평균 100이 되도록 점수 규칙을 조정했기 때문입니다. 물론 이것은 나쁜 일이 아닙니다. 이는 심리학적 측정을 설계하는 데 있어 중요한 부분입니다. 하지만 이 이론적 평균 100은 테스트 설계자들이 사용한 모집단에만 해당된다는 점을 기억하는 것이 중요합니다. 좋은 테스트 설계자들은 실제로 다양한 모집단(예: 연령대, 국적 등)에 적용할 수 있는 “테스트 기준”을 제공하기 위해 상당한 노력을 기울입니다.\n이러한 기준은 매우 유용하지만, 대부분의 연구는 이러한 기준이 만들어진 모집단과는 다른 사람들을 대상으로 합니다. 예를 들어, 남호주 산업 도시인 포트 피리(Port Pirie)에서 저수준 납 중독이 인지 기능에 미치는 영향을 측정하고 싶다고 가정해 보겠습니다. 포트 피리에는 납 제련소가 있습니다. 아마도 포트 피리 사람들의 IQ 점수를 같은 남호주의 산업 도시인 와이알라(Whyalla)의 사람들과 비교하고 싶을 것입니다. 와이알라에는 강철 제련소가 있습니다.6\n어느 도시를 연구하든 모집단의 실제 평균 IQ가 100이라고 단순히 가정하는 것은 타당하지 않습니다. 남호주의 산업 도시에 자동으로 적용할 수 있는 신뢰할 만한 기준 데이터를 가진 사람은 제가 알기로는 없습니다.\n따라서 우리는 데이터 표본을 통해 모집단 모수를 추정해야 합니다. 그렇다면 이 작업을 어떻게 수행할 수 있을까요?\n\n8.4.1 모집단 평균 추정하기\n포트 피리에서 100명의 주민이 IQ 테스트를 받아주었다고 가정해 보겠습니다. 이들의 평균 IQ 점수는 \\(\\bar{X} = 98.5\\)로 나타났습니다. 그렇다면 포트 피리 전체 모집단의 실제 평균 IQ는 얼마일까요? 당연히 정확한 답은 알 수 없습니다. 진짜 평균이 97.2일 수도 있고, 103.5일 수도 있습니다. 우리의 표본이 포괄적이지 않기 때문에 확정적인 답을 내릴 수 없습니다. 그렇더라도 “최선의 추정값”을 말해야 한다면, 저는 98.5라고 대답할 것입니다. 이것이 바로 통계적 추정(statistical estimation)의 본질입니다: 최선의 추정(best guess)을 제시하는 것.\n이 예제에서는 미지의 모집단 모수에 대한 추정이 간단합니다. 표본 평균(sample mean)을 계산하고, 이를 모집단 평균(population mean)의 추정치로 사용합니다. 매우 단순해 보이지만, 다음 절에서는 이 직관적인 답변에 대한 통계적 근거를 설명하겠습니다. 다만, 지금 중요한 것은 표본 통계량(sample statistic)과 모집단 모수의 추정치(estimate of the population parameter)가 개념적으로 다르다는 점을 인식하는 것입니다.\n\n표본 통계량은 데이터의 기술적 설명입니다.\n\n모수의 추정치는 모집단에 대한 추정값입니다.\n\n이러한 차이를 명확히 하기 위해, 통계학자들은 서로 다른 표기법을 사용합니다.\n\n모집단의 실제 평균이 \\(\\mu\\)로 표시된다면,\n\n모집단 평균의 추정치는 \\(\\hat{\\mu}\\)로 표시합니다.\n\n반면, 표본 평균은 \\(\\bar{X}\\) 또는 경우에 따라 \\(m\\)으로 표시됩니다.\n\n하지만 단순 무작위 표본의 경우, 모집단 평균의 추정치는 표본 평균과 동일합니다. 예를 들어, 표본 평균이 \\(\\bar{X} = 98.5\\)라면, 모집단 평균의 추정치도 \\(\\hat{\\mu} = 98.5\\)가 됩니다. 표기법을 명확하게 정리하기 위해, 아래 표(Table 8.2)를 참고하세요.\n\n\n\n\nTable 8.2. 평균에 대한 표기법\n\n\n\n\n\n기호의미우리가 알고 있는가?\n\n\\( \\hat{X} \\)표본 평균예, 원본 데이터에서 계산됨\n\n\\( \\mu \\)모집단 평균거의 알 수 없음\n\n\\( \\hat{\\mu} \\)모집단 평균의 추정치예, 단순 랜덤 표본에서는 표본 평균과 동일\n\n\n\n\n\n\n\n\n\n8.4.2 모집단 표준편차 추정하기\n지금까지 추정은 꽤 단순해 보였고, 아마도 왜 제가 여러분에게 표본 이론에 대한 모든 내용을 읽게 했는지 궁금할 수 있습니다. 평균의 경우, 모집단 모수의 추정치(즉, \\(\\hat{\\mu}\\))는 해당 표본 통계량(즉, \\(\\bar{X}\\))과 동일했습니다. 하지만 항상 그런 것은 아닙니다. 이를 이해하기 위해 모집단 표준편차의 추정치를 어떻게 구성할 수 있는지 생각해 보겠습니다. 이 추정치는 \\(\\hat{\\sigma}\\)로 나타내겠습니다. 이 경우 무엇을 추정치로 사용해야 할까요? 처음에는 평균을 추정할 때 했던 것처럼 표본 통계량을 그대로 사용하면 된다고 생각할 수 있습니다. 거의 맞는 생각이지만, 완전히 옳지는 않습니다.\n그 이유는 이렇습니다. 하나의 관측값만 포함된 표본이 있다고 가정해 보겠습니다. 이 예에서는 실제 모집단에 대한 직관이 허용되지 않는 상황을 고려하는 것이 도움이 되므로, 완전히 허구의 예를 사용하겠습니다. 예를 들어, 제 신발의 “크로뮬런스(cromulence)”를 측정했다고 합시다. 측정 결과 제 신발의 크로뮬런스는 \\(20\\)이었습니다. 즉, 표본은 다음과 같습니다:\n\\[20\\]\n이 표본은 표본 크기 \\(N = 1\\)인 완전히 유효한 표본입니다. 표본 평균은 \\(20\\)이고, 표본의 모든 관측값이 (당연히) 표본 평균과 같기 때문에 표본 표준편차는 \\(0\\)입니다. 표본을 기술하는 데 있어서 이는 옳은 결과입니다. 표본이 하나의 관측값만 포함하고 있으므로 표본 내에서 관찰되는 변동성이 없는 것이 당연합니다. 따라서 표본 표준편차 \\(s = 0\\)은 적절한 결과입니다. 하지만 이 값을 모집단 표준편차의 추정치로 사용하려고 하면 전혀 말이 안 되는 것처럼 느껴지지 않나요? 물론 “크로뮬런스”가 무엇인지 저도 여러분도 모르지만, 데이터에 대해서는 알고 있습니다. 표본에서 변동성이 보이지 않는 유일한 이유는 표본이 너무 작아서 변동성을 보여줄 수 없기 때문입니다! 따라서 표본 크기가 \\(N = 1\\)일 경우 모집단의 표준편차에 대해서는 “모르겠다”라고 대답하는 것이 더 적절한 것처럼 느껴집니다.\n하지만 표본 평균과 모집단 평균에 대해서는 같은 직관이 적용되지 않습니다. 모집단 평균에 대한 최선의 추측을 해야 한다면, \\(20\\)이라고 추정하는 것이 비이성적인 선택은 아닙니다. 물론 단 하나의 관측값만으로는 그 추측에 자신이 없겠지만, 여전히 할 수 있는 최선의 추정입니다.\n이 예를 조금 더 확장해 보겠습니다. 이번에는 신발의 크로뮬런스에 대한 관측값이 \\(N = 2\\)개 있습니다. 전체 표본은 다음과 같습니다:\n\\[20, 22\\]\n이번에는 두 개의 관측값이 있어 변동성을 관찰할 수 있게 되었습니다. 변동성을 관찰하기 위해 필요한 최소한의 관측값은 두 개입니다! 새로운 데이터 세트에서 표본 평균은 \\(\\bar{X} = 21\\), 표본 표준편차는 \\(s = 1\\)입니다. 이제 모집단에 대해 어떤 직관을 얻을 수 있을까요? 모집단 평균의 경우, 최선의 추정치는 여전히 표본 평균입니다. 추측해야 한다면 모집단 평균 크로뮬런스가 \\(21\\)이라고 예상할 것입니다. 그렇다면 표준편차는 어떨까요? 이 부분은 좀 더 복잡합니다. 표본 표준편차는 두 개의 관측값에 기반하고 있으며, 저처럼 느끼는 사람이라면 이 두 개의 관측값만으로는 모집단의 진정한 변동성을 충분히 드러내기에 부족하다고 직관적으로 생각할 것입니다. 단순히 추정치가 틀렸을 것이라고 예상하는 것이 아니라, 그 오차가 체계적일 것이라는 점이 걱정되는 것입니다. 구체적으로는, 표본 표준편차가 모집단 표준편차보다 작을 가능성이 높다고 의심하는 것입니다.\n이 직관은 타당해 보이지만, 이를 실제로 보여주면 더 좋겠죠. 사실 이러한 직관을 수학적으로 증명할 수 있는 공식이 존재하지만, 관련 수학적 배경 지식이 없다면 그다지 도움이 되지 않습니다. 대신 몇 가지 실험 결과를 시뮬레이션하여 보여드리겠습니다. 이를 위해 다시 IQ 연구로 돌아가 보겠습니다. 모집단의 실제 평균 IQ가 \\(100\\), 표준편차가 \\(15\\)라고 가정합시다. 먼저 \\(N = 2\\)개의 IQ 점수를 측정한 후 표본 표준편차를 계산하는 실험을 진행합니다. 이 과정을 여러 번 반복하고, 이러한 표본 표준편차들의 히스토그램을 그리면 표준편차의 표본 분포(sampling distribution)를 얻을 수 있습니다. 이 분포를 Figure 8.10 에 나타냈습니다. 실제 모집단 표준편차는 15이지만, 이 실험에서는 평균적으로 약 8.4의 표준편차가 추정되어 실제 값보다 훨씬 낮은 결과를 보입니다! 즉, 표본 표준편차는 모집단 표준편차의 (편향된) 편의추정량(biased estimator)이라는 것입니다. 이는 모집단 평균이 \\(100\\)일 때 표본 평균의 분포를 그렸던 Figure 8.8 (b)의 결과와 매우 다릅니다. 당시에는 표본 평균의 평균값도 \\(100\\)이었으므로, (편향되지 않은) 불편추정량(unbiased estimator)이였기 때문입니다.\n이제 시뮬레이션을 확장해 보겠습니다. \\(N=2\\)로 제한하지 않고, 표본 크기를 1부터 10까지로 늘려 실험을 반복합니다. 표본 평균과 표본 표준편차의 평균값을 표본 크기의 함수로 나타내면 Figure 8.11 같은 결과가 나옵니다. 이 그래프를 위해 관측값이 각각 1개인 데이터 세트를 10,000개, 관측값이 2개인 데이터 세트를 또 10,000개, 이렇게 표본 크기 10까지 시뮬레이션을 진행했습니다. 각 데이터 세트는 평균이 100, 표준편차가 15인 정규분포를 따르는 가상의 IQ 데이터로 구성했습니다. 결과적으로 표본 평균은 표본 크기에 상관없이 평균적으로 100이었으며(Figure 8.11 (a)), 이는 모집단 평균과 같습니다. 즉, 불편추정량입니다. 이것이 바로 모집단 평균의 최선의 추정치로 표본 평균을 사용하는 이유입니다.7 오른쪽 그래프((Figure 8.11 (b))는 매우 다릅니다. 평균적으로 표본 표준편차 \\(s\\)는 모집단 표준편차 \\(\\sigma\\)보다 작으며, 특히 표본 크기가 작을수록 이 경향이 두드러집니다. 즉, 표본 표준편차는 편의추정치입니다. 다시 말해, 모집단 표준편차 \\(\\hat{\\sigma}\\)에 대한 최선의 추정치를 구하고 싶다면 표본 표준편차 \\(s\\)보다 약간 더 큰 값을 선택해야 합니다.\n\n\n\n\n\n\n\n\nFigure 8.10. 두 개의 IQ 점수 실험에서의 표본 표준편차의 샘플링 분포. 실제 모집단의 표준편차는 15(점선)이며, 히스토그램에서 볼 수 있듯이 대부분의 실험은 이보다 훨씬 작은 표본 표준편차를 산출합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8.11. 표본 평균은 모집단 평균의 불편추정량이라는 그림 (a)와 표본 표준편차는 모집단 표준편차의 편의추정량이라는 것을 보여주는 그림 (b).\n\n\n\n\n\n이러한 체계적인 편향을 수정하는 방법은 매우 간단합니다. 어떻게 수정되는지 살펴보겠습니다. 표준편차를 다루기 전에 분산부터 살펴보겠습니다. 모집단 모수 추정하기 절에서 설명한 바와 같이, 표본 분산은 표본 평균으로부터의 제곱 편차를 평균한 것으로 정의됩니다. 즉:\n\\[s^2=\\frac{1}{N} \\sum_{i=1}^{N}(X_i-\\bar{X})^2\\]\n표본 분산 \\(s^2\\)은 모집단 분산 \\(\\sigma^2\\)의 편의추정량입니다. 하지만 약간의 수정을 가하면 불편추정량으로 변환할 수 있습니다. 단순히 \\(N\\)이 아닌 \\(N-1\\)로 나누기만 하면 됩니다.\n이것이 모집단 분산 \\(\\sigma\\)의 불편추정량입니다. 이는 모집단 모수 추정하기에서 제기한 질문에 대한 답이기도 합니다. 왜 jamovi에서 분산 계산 결과가 약간 달랐을까요? 그것은 jamovi가 \\(s^2\\)이 아닌 \\(\\hat{\\sigma}^2\\)를 계산하기 때문입니다. 표준편차의 경우도 마찬가지입니다. \\(N\\)이 아닌 \\(N-1\\)로 나누면 모집단 표준편차의 불편추정량을 얻을 수 있습니다. jamovi의 내장 표준편차 함수를 사용할 때 계산되는 것은 \\(s\\)가 아니라 \\(\\hat{\\sigma}\\)입니다.8\n마지막으로 한 가지 더. 실제로는 많은 사람들이 \\(\\hat{\\sigma}\\) (즉, \\(N-1\\)로 나누는 공식)를 표본 표준편차라고 부릅니다. 엄밀히 말하면 이는 틀린 표현입니다. 표본 표준편차는 \\(s\\)(\\(N\\)으로 나누는 공식)와 같아야 합니다. 이 둘은 개념적으로나 수치적으로 동일하지 않습니다. 하나는 표본의 특성이며, 다른 하나는 모집단의 특성에 대한 추정치입니다. 그러나 실제로 중요한 것은 모집단 모수의 추정치이기 때문에 대부분의 경우 \\(\\hat{\\sigma}\\)를 보고합니다. 물론 이 수치가 보고되어야 할 정확한 결과입니다. 다만 “표본 표준편차”라는 표현이 “모집단 표준편차 추정치”보다 짧기 때문에 용어 사용이 다소 부정확해지는 경우가 있습니다. 이는 큰 문제가 아니며, 저 역시 다른 사람들과 같은 방식으로 사용합니다. 그럼에도 불구하고 두 개념을 구분하는 것이 중요하다고 생각합니다. “표본의 알려진 특성”과 “표본이 속한 모집단에 대한 추정”을 혼동하는 것은 결코 좋은 생각이 아닙니다. \\(s\\)와 \\(\\hat{\\sigma}\\)를 동일하게 여기기 시작하는 순간, 바로 그 혼동이 발생하게 됩니다.\n이 섹션을 마무리하며 개념을 더 명확히 하기 위해 추가적인 표를 제공합니다 (Table 8.3 and Table 8.4).\n\n\n\n\nTable 8.3. 표준편차 표기법\n\n\n\n\n\n기호의미우리가 알고 있는가?\n\n\\( s \\)표본 표준편차예, 원본 데이터에서 계산됨\n\n\\( \\sigma  \\)모집단 표분편차거의 알 수 없음\n\n\\( \\hat{\\sigma } \\)모집단 표준편차의 추정치예, 그러나 표본표준편차와 같지 않음\n\n\n\n\n\n\n\n\n\n\n\nTable 8.4. 분산 표기법\n\n\n\n\n\n기호의미우리가 알고 있는가?\n\n\\( s^2 \\)표본 분산예, 원본 데이터에서 계산됨\n\n\\( \\sigma^2  \\)모집단 분산거의 알 수 없음\n\n\\( \\hat{\\sigma }^2 \\)모집단 분산의 추정치예, 그러나 표본분산과 같지 않음",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>표본으로 미지의 모수 추정하기</span>"
    ]
  },
  {
    "objectID": "08-Estimating-unknown-quantities-from-a-sample.html#sec-Estimating-a-confidence-interval",
    "href": "08-Estimating-unknown-quantities-from-a-sample.html#sec-Estimating-a-confidence-interval",
    "title": "8  표본으로 미지의 모수 추정하기",
    "section": "8.5 신뢰구간 추정",
    "text": "8.5 신뢰구간 추정\n\n통계학이란 무엇이 확실하다고 말할 필요가 없다는 것을 의미한다\n– 출처 불명9\n\n이 장의 지금까지는 통계학자들이 표본 데이터를 바탕으로 모집단의 모수를 추정할 때 사용하는 표본 이론의 기본 개념을 설명했습니다. 이러한 논의에서 알 수 있듯이, 우리가 이러한 표본 이론이 필요한 이유 중 하나는 모든 데이터 세트에는 일정한 불확실성이 있기 때문에 우리의 추정치는 결코 완벽하게 정확할 수 없다는 점입니다. 그러나 이 논의에서 빠진 부분은 바로 이러한 추정치에 수반되는 불확실성의 정도를 정량화하려는 시도입니다. 예를 들어, 심리학과 학부생의 평균 IQ가 \\(115\\)라고 추정한다고 가정합시다(이 숫자는 단순한 예일 뿐입니다). 여기서 끝나는 것이 아니라, 우리는 이 추정치에 대한 확신의 정도를 표현할 수 있기를 원합니다. 예를 들어, 실제 평균이 \\(109\\)와 \\(121\\) 사이에 있을 확률이 \\(95\\%\\)라고 말할 수 있다면 더 좋을 것입니다. 이를 평균의 신뢰구간(confidence interval)이라고 부릅니다.\n표본 분포에 대한 이해를 바탕으로 평균의 신뢰구간을 구성하는 것은 실제로 매우 간단합니다. 방법은 다음과 같습니다. 모집단의 실제 평균이 \\(\\mu\\), 표준 편차가 \\(\\sigma\\)라고 가정합니다. 이제 \\(N\\)명의 참가자를 대상으로 연구를 완료했고, 이들의 평균 IQ는 \\(\\bar{X}\\)입니다. 중심극한정리에 대한 논의에서 알 수 있듯이, 평균의 표본 분포는 대략 정규 분포를 따릅니다. 또한 정규 분포에 대한 논의에서, 정규 분포된 값이 실제 평균으로부터 약 두 표준 편차 이내에 있을 확률이 \\(95\\%\\)라는 것을 배웠습니다.\n좀 더 정확히 말하자면, 실제로는 정규 분포된 값이 실제 평균으로부터 \\(1.96\\) 표준 편차 이내에 있을 확률이 \\(95\\%\\)입니다. 다음으로, 표본 분포의 표준 편차를 표준 오차(standard error)라고 하며, 평균의 표준 오차는 SEM으로 표기한다는 점을 기억하세요. 이러한 요소들을 모두 조합하면, 실제로 관측된 표본 평균 \\(\\bar{X}\\)가 모집단 평균으로부터 \\(1.96\\) 표준 오차 이내에 있을 확률이 \\(95\\%\\)라는 것을 알 수 있습니다.\n물론, \\(1.96\\)이라는 숫자가 특별한 것은 아닙니다. 단지 \\(95\\%\\) 신뢰구간을 원할 때 사용하는 곱셈 인자일 뿐입니다. 만약 \\(70\\%\\) 신뢰구간을 원한다면, \\(1.96\\) 대신 \\(1.04\\)를 사용하면 됩니다.\n수학적으로 이것은 다음과 같이 표현할 수 있습니다:\n\\[\\mu - (1.96 \\times SEM) \\leq \\bar{X} \\leq \\mu + (1.96 \\times SEM)\\]\n여기서 \\(SEM = \\frac{\\sigma}{\\sqrt{N}}\\)이며, 이 부등식이 성립할 확률은 \\(95\\%\\)입니다. 그러나 이 식은 우리가 실제로 알고자 하는 질문에 대한 답은 아닙니다. 이 식은 모집단의 모수를 알고 있을 때 표본 평균에 대해 예상할 수 있는 내용을 보여줍니다. 우리가 원하는 것은 이 과정을 반대로 적용하는 것입니다. 즉, 특정 표본을 관측한 상황에서 모집단 모수에 대해 어떤 추정을 할 수 있는지 알고 싶습니다. 그러나 이를 수행하는 것은 어렵지 않습니다. 약간의 고등학교 수준의 대수학을 활용하면, 이 식을 다음과 같이 변형할 수 있습니다:\n\\[\\bar{X} - (1.96 \\times SEM) \\leq \\mu \\leq \\bar{X} + (1.96 \\times SEM)\\]\n이 식은 이 범위가 모집단 평균 \\(\\mu\\)를 포함할 확률이 \\(95\\%\\)임을 의미합니다. 이 범위를 95% 신뢰구간이라고 하며, \\(CI_{95}\\)로 표기합니다. 요약하면, \\(N\\)이 충분히 크고(즉, 평균의 표본 분포가 정규 분포라고 가정할 수 있을 만큼 충분히 큰 경우), 다음과 같은 95% 신뢰구간 공식을 사용할 수 있습니다:\n\\[CI_{95} = \\bar{X} \\pm (1.96 \\times \\frac{\\sigma}{\\sqrt{N}})\\]\n\n8.5.1 신뢰구간 해석하기\n신뢰구간에서 가장 어려운 점은 그것이 의미하는 바를 이해하는 것입니다. 사람들이 신뢰구간을 처음 접할 때 거의 항상 드는 첫 번째 본능적인 반응은 “실제 평균(true mean)이 신뢰구간 안에 있을 확률이 95%다”라고 말하는 것입니다. 이 표현은 단순하고, “95%의 확신(confidence)”을 가진다는 것이 무엇을 의미하는지에 대한 상식적인 개념을 포착하는 것처럼 보입니다.\n하지만 이 표현은 정확하지 않습니다. 이 직관적인 정의는 모집단 평균(population mean)의 값에 대한 개인적인 믿음에 매우 크게 의존합니다. “나는 95% 확신한다”라고 말하는 이유는 그것이 나의 믿음이기 때문입니다. 일상 생활에서는 이것이 전혀 문제되지 않지만, [확률이란 무엇을 의미하는가?] 절을 떠올려 보면, 개인적인 믿음과 확신에 대해 이야기하는 것은 베이지안(Bayesian) 관점이라는 것을 알 수 있습니다.\n그러나 신뢰구간은 베이지안 도구가 아닙니다. 이 장의 다른 모든 내용과 마찬가지로 신뢰구간은 빈도주의자의 도구입니다. 빈도주의적 방법을 사용할 경우, 베이지안 해석을 적용하는 것은 적절하지 않습니다. 빈도주의적 방법을 사용할 때는 빈도주의자의 해석을 따라야 합니다!\n그렇다면 올바른 해석은 무엇일까요? 빈도주의자 관점의 확률에 대해 우리가 말한 내용을 기억해 보세요. 우리가 “확률적 진술”을 할 수 있는 유일한 방법은 일련의 사건에 대해 이야기하고, 다양한 유형의 사건들이 발생하는 빈도를 세는 것입니다. 이 관점에서 95% 신뢰구간의 해석은 반드시 반복과 관련이 있어야 합니다. 구체적으로 말하자면, 만약 우리가 동일한 실험을 여러 번 반복하고, 각 반복마다 95% 신뢰구간을 계산한다면, 그 신뢰구간들 중 약 95%는 실제 평균을 포함하게 될 것입니다. 더 일반적으로 말하면, 이러한 절차를 사용하여 생성된 모든 신뢰구간의 95%는 실제 모집단 평균을 포함해야 합니다.\n이 개념은 Figure 8.12 에 나와 있으며, 이는 “IQ 점수 10개 측정” 실험(상단 그림)과 “IQ 점수 25개 측정” 실험(하단 그림)에 대해 각각 50개의 신뢰구간을 생성한 결과를 보여줍니다. 우리는 대략 95%의 신뢰구간이 진짜 모집단 평균을 포함할 것으로 예상하며, 실제로 Figure 8.12 에서 이를 확인할 수 있습니다.\n여기서 중요한 차이점은, 베이지안 주장은 모집단 평균 자체에 대한 확률적 진술을 한다는 점입니다. 즉, 모집단 평균에 대한 우리의 불확실성을 언급하는 것이죠. 그러나 빈도주의자 해석에서는 모집단을 “반복”할 수 없기 때문에 이러한 방식의 확률적 진술은 허용되지 않습니다.\n빈도주의자 관점에서는 모집단 평균이 고정된 값이며, 이에 대해 확률적 진술을 할 수는 없습니다. 그러나 신뢰구간은 반복 가능한 것이며, 이에 대한 실험을 여러 번 반복할 수 있습니다. 따라서 빈도주의자는 신뢰구간이 실제 평균을 포함할 확률에 대해서는 이야기할 수 있지만, 실제 모집단 평균이 신뢰구간 안에 포함될 확률에 대해서는 이야기할 수 없습니다. 왜냐하면 모집단 평균은 반복 가능한 사건이 아니기 때문입니다.\n이 점이 다소 까다롭게 느껴질 수 있지만, 중요한 부분입니다. 해석의 차이는 수학적 접근의 차이로 이어지기 때문입니다. 신뢰구간의 베이지안 대안으로는 신용구간(credible interval)이라는 개념이 있습니다. 대부분의 상황에서 신뢰구간과 신용구간은 매우 유사하지만, 경우에 따라 극적으로 다를 수 있습니다. 약속한 대로, 베이지안 관점에 대해서는 Chapter 16 에서 더 자세히 설명하겠습니다.\n\n\n\n\n\n\n\n\nFigure 8.12. 95% 신뢰구간. 상단 그래프 (a)는 10명의 IQ를 측정한 실험을 50번 시뮬레이션한 결과를 보여줍니다. 점은 표본 평균의 위치를 표시하며, 선은 95% 신뢰구간을 나타냅니다. 50개의 신뢰구간 중 대부분은 실제 평균(즉, 100)을 포함하고 있지만, 파란색과 별표(*)로 표시된 일부 신뢰구간은 그렇지 않습니다. 하단 그래프 (b)는 25명의 IQ를 측정한 실험을 시뮬레이션한 결과를 보여줍니다.\n\n\n\n\n\n\n\n8.5.2 jamovi에서 신뢰구간 계산하기\njamovi에는 ‘기술통계’ 기능을 통해 평균에 대한 신뢰구간을 간단히 계산할 수 있는 방법이 포함되어 있습니다. ‘기술통계’ 창의 ‘통계’ 옵션에는 ’평균에 대한 표준오차’와 ’평균에 대한 신뢰구간’을 선택할 수 있는 체크박스가 있습니다. 이 기능을 사용하면 기본값인 95% 신뢰구간을 확인할 수 있습니다.\n예를 들어, IQsim.omv 파일을 불러온 후 ’평균에 대한 신뢰구간’을 선택하면, 시뮬레이션된 평균 IQ에 대한 신뢰구간을 확인할 수 있습니다. 하한 95% 신뢰구간 = 99.39, 상한 95% 신뢰구간 = 99.97로 표시됩니다. 따라서 \\(N = 10,000\\)인 시뮬레이션된 대규모 표본 데이터에서 평균 IQ 점수는 99.68이며, 95% 신뢰구간은 99.39에서 99.97 사이입니다.\njamovi에서 신뢰구간을 시각화할 때는 박스 도표 옵션에서 평균을 포함하도록 지정할 수 있습니다. 또한, Chapter 13 절에서 배우게 될 일원 분산 분석(ANOVA)과 같은 특정 통계 검정을 사용할 때도 신뢰구간을 데이터 분석의 일부로 시각화할 수 있습니다. 이는 꽤 유용한 기능이므로, 나중에 그 방법을 자세히 설명하겠습니다.\n\n\n\n\n\n\n실습: 신뢰구간 구하기\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’IQ sim’을 선택합니다.\n‘기술통계’-’기술통계’를 선택합니다.\n왼편의 ‘기술통계’ 패널에서 IQsim를 ‘변수’ 상자에 넣습니다.\n‘통계’ 옵션의 ’평균 분산’에 있는 ’평균에 대한 표준오차’와 ’평균에 대한 신뢰구간’을 체크 합니다. 그러면 결과 창의 기술통계 부분에 표준 오차와 신뢰구간의 하한과 상한 값이 나타납니다.\n‘평균에 대한 신뢰구간’ 오른편에 있는 95%라는 수치를 90% 또는 99%로 바꾸어 신뢰구간의 상한과 하한이 어떻게 변화하는지 살펴봅니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>표본으로 미지의 모수 추정하기</span>"
    ]
  },
  {
    "objectID": "08-Estimating-unknown-quantities-from-a-sample.html#요약",
    "href": "08-Estimating-unknown-quantities-from-a-sample.html#요약",
    "title": "8  표본으로 미지의 모수 추정하기",
    "section": "8.6 요약",
    "text": "8.6 요약\n이 장에서는 두 가지 주요 주제를 다루었습니다. 장의 전반부에서는 표본 이론에 대해 설명하고, 후반부에서는 이 표본 이론을 활용하여 모집단의 모수를 추정하는 방법에 대해 다루었습니다. 절 구분은 다음과 같습니다:\n\n표본, 모집단 및 표본추출에 대한 기본 개념\n표본의 통계 이론: 대수의 법칙과 표본 분포와 중심극한정리\n모집단 모수 추정하기. 평균과 표준편차\n신뢰구간 추정\n\n항상 그렇듯이, 이 장에서는 표본추출과 추정과 관련된 모든 주제를 다루지는 않았지만, 심리학 입문 수업을 위한 내용으로는 꽤 포괄적이라고 생각합니다. 대부분의 응용 연구자들은 이보다 더 많은 이론이 필요하지 않을 것입니다. 이 장에서 다루지 않은 큰 질문 중 하나는 단순 무작위 표본추출이 아닌 경우에는 어떻게 해야 하는가입니다. 이러한 상황을 다루기 위한 다양한 통계 이론이 존재하지만, 이는 이 책의 범위를 벗어나는 내용입니다.\n\n\n\n\nKeynes, J. M. (1923). A tract on monetary reform. Macmillan & Company.\n\n\nStigler, S. M. (1986). The history of statistics. Harvard University Press.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>표본으로 미지의 모수 추정하기</span>"
    ]
  },
  {
    "objectID": "08-Estimating-unknown-quantities-from-a-sample.html#footnotes",
    "href": "08-Estimating-unknown-quantities-from-a-sample.html#footnotes",
    "title": "8  표본으로 미지의 모수 추정하기",
    "section": "",
    "text": "엄밀한 수학적 의미에서 무작위성(randomness)을 정의하는 것은 매우 복잡하며, 이 책의 범위를 넘어섭니다. 따라서 여기에서는 기술적으로 엄격한 정의를 사용하지 않고, 동일한 과정을 반복할 때마다 다른 결과가 나올 가능성이 있다면 무작위성을 포함한 과정이라고 간주합니다.↩︎\n&lt;역주&gt; 저자의 표현이 정확하지는 않다. 모집단의 절대적 크기가 중요한 것이 아니라 표본의 크기에 비해 모잡단의 크기가 충분히 커야만 복원 표본추출과 비복원 추출의 차이가 무시될 수 있다. 모집단이 천 개의 개체로 구성되어 있다고 하더라도 표본의 크기가 천 개이면 복원 추출과 비복원 추출의 결과의 차이는 무시될 수 없다.↩︎\n현실은 그렇게 단순하지 않습니다. 사람을 “조현병 환자”와 “비(非)조현병 환자”라는 이분법적 범주로 나누는 것은 명확한 기준이 없는 경우가 많습니다. 그러나 이 책은 임상심리학 교재가 아니므로, 이러한 단순화를 이해해 주길 바랍니다.↩︎\n엄밀히 말하면, 대수의 법칙은 독립적인 값들의 평균으로 표현될 수 있는 모든 표본 통계량에 적용됩니다. 이는 확실히 표본 평균에는 적용됩니다. 그러나 다른 많은 표본 통계량 역시 특정 형태의 평균으로 표현될 수 있습니다. 예를 들어, 표본 분산도 일종의 평균으로 다시 쓸 수 있기 때문에 대수의 법칙이 적용됩니다. 그러나 표본의 최솟값은 어떤 형태로든 평균으로 표현될 수 없기 때문에 대수의 법칙이 적용되지 않습니다.↩︎\n평소처럼, 여기서 약간 대충 설명하고 있습니다. 중심극한정리는 이 섹션에서 암시하는 것보다 조금 더 일반적입니다. 대부분의 입문 통계 교재에서처럼, 저는 중심극한정리가 성립하는 한 가지 상황을 다루었습니다. 즉, 동일한 분포에서 추출된 다수의 독립적인 사건에 대해 평균을 구하는 경우입니다. 그러나 중심극한정리는 이보다 훨씬 더 광범위한 개념입니다. 예를 들어 “U-통계량(U-statistics)”이라는 전체 클래스가 있으며, 이들은 모두 중심극한정리를 만족하므로 큰 표본 크기에서 정규 분포를 따르게 됩니다. 평균(mean)은 이러한 통계량 중 하나이지만, 유일한 것은 아닙니다.↩︎\n실제로 이 질문에 관심이 있다면, 여기서 제가 설명하는 것보다 훨씬 더 신중해야 합니다. 와이알라의 IQ 점수를 포트 피리와 단순 비교하고 그 차이가 납 중독 때문이라고 가정할 수는 없습니다. 두 도시의 유일한 차이가 서로 다른 제련소 때문이라고 하더라도(사실 그렇지 않습니다), 사람들이 이미 납 오염이 인지 결손을 일으킨다고 믿고 있다는 사실을 고려해야 합니다.\nChapter 2 절을 떠올려 보면, 이는 포트 피리 표본과 와이알라 표본 사이에 서로 다른 요구 효과(demand effects)가 존재한다는 의미입니다. 즉, 데이터에서 실제는 없는 집단 사이의 차이를 발견할 수 있으며, 이는 사람들이 “실제 차이”가 있다고 믿는 것 때문에 발생할 수 있습니다.\n연구자들이 실험복을 입고 IQ 테스트를 들고 포트 피리에 나타난다면, 현지인들이 여러분의 연구 목적을 눈치채지 못할 것이라고 생각하는 것은 매우 비현실적입니다. 일부 사람들은 연구에 협조적이지 않을 수 있고, 또 다른 사람들은 자신의 고향이 부정적으로 보이지 않도록 더 열심히 테스트에 임할 수도 있습니다.\n반면, 와이알라에서는 “철광석 오염”이라는 개념이 일반적이지 않기 때문에 이러한 동기 부여 효과가 상대적으로 약할 것입니다. 심리학 연구는 이렇게 복잡합니다.↩︎\n여기서 중요한 부분을 생략하고 있다는 점을 언급해야겠습니다. 불편추정량은 바람직한 특성이지만, 편향 외에도 중요한 요소들이 존재합니다. 다만 이 책의 범위를 벗어나므로 자세한 논의는 하지 않겠습니다. 단지 이 부분에 복잡성이 숨어 있음을 알려드리고자 합니다.↩︎\n\\(N-1\\)로 나누면 모집단 분산의 불편추정치를 얻을 수 있습니다:\n\\[\\hat{\\sigma}^2=\\frac{1}{N-1}\\sum_{i=1}^{N}(X_i - \\bar{X})^2\\]\n표준편차의 경우도 마찬가지입니다:\n\\[\\hat{\\sigma}=\\sqrt{\\frac{1}{N-1}\\sum_{i=1}^{N}(X_i-\\bar{X})^2}\\]\n여기서 또 하나의 숨겨진 점이 있습니다. \\(\\hat{\\sigma}^2\\)이 \\(\\sigma^2\\)의 불편추정량이라면, 제곱근을 취하면 \\(\\hat{\\sigma}\\) 역시 \\(\\sigma\\)의 불편추정량일 거라고 생각하겠죠? 이상하게도 그렇지 않습니다. 실제로 \\(\\hat{\\sigma}\\)에는 미묘한 편향이 존재합니다. 참으로 이상한 일입니다. \\(\\hat{\\sigma}^2\\)는 모집단 분산 \\(\\sigma^2\\)의 편향 없는 추정량이지만, 제곱근을 취하면 \\(\\hat{\\sigma}\\)는 모집단 표준편차 \\(\\sigma\\)의 편의추정량이 됩니다. 정말 기묘하죠? 왜 그럴까요? 기술적인 설명은 “비선형 변환(예: 제곱근)과 기댓값 연산은 교환되지 않기 때문”입니다. 다만 수학 통계학 강의를 듣지 않았다면 이 설명은 다소 어렵게 들릴 수 있습니다. 다행히도 실제로는 큰 문제가 되지 않습니다. 이 편향은 매우 작으며, 실제로는 모두 \\(\\hat{\\sigma}\\)를 사용하고 잘 작동합니다. 때때로 수학은 참 성가시기도 합니다.↩︎\n이 인용구는 많은 티셔츠와 웹사이트에서 볼 수 있으며, 몇몇 학술 논문(예: https://jse.amstat.org/v10n3/friedman.html)에서도 언급됩니다. 그러나 이 말의 정확한 출처는 찾을 수 없었습니다.↩︎",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>표본으로 미지의 모수 추정하기</span>"
    ]
  },
  {
    "objectID": "09-Hypothesis-testing.html",
    "href": "09-Hypothesis-testing.html",
    "title": "9  가설 검정",
    "section": "",
    "text": "9.1 다양한 종류의 가설들\n결국 우리 모두는 광기에 굴복하게 됩니다. 나에게 그날은 정교수로 승진하는 순간 찾아올 것입니다. 상아탑 속에서 종신직의 보호를 받으며, 마침내 나는 (말하자면) 제정신을 놓고 가장 비생산적인 심리학 연구 분야인 초감각적 지각(ESP)의 탐구에 몰두할 수 있게 될 것입니다.3\n이제 이 멋진 날이 왔다고 가정해 봅시다. 나의 첫 번째 연구는 투시 능력이 존재하는지를 테스트하는 간단한 실험입니다. 각 참가자는 책상에 앉아 실험자가 보여주는 카드를 봅니다. 카드의 한쪽은 검은색, 다른 한쪽은 흰색입니다. 실험자는 카드를 인접한 방의 책상 위에 놓습니다. 카드는 완전히 무작위로 검은색 면 또는 흰색 면이 위로 향하도록 배치되며, 이 무작위화는 실험자가 참가자와 함께 있는 동안이 아니라, 참가자가 방을 떠난 후에 이루어집니다. 또 다른 실험자가 방에 들어가 참가자에게 현재 카드의 어느 면이 위를 향하고 있는지를 묻습니다. 이는 단 한 번만 수행되는 실험입니다. 각 참가자는 단 한 장의 카드를 투시하고 한 번만 답변을 합니다. 그리고 참가자는 정답을 아는 사람과 접촉하는 일이 전혀 없습니다. 따라서 내 데이터 세트는 매우 단순합니다. 나는 \\(N\\)명의 사람들에게 질문을 했고, 그중 \\(X\\)명이 정답을 맞혔습니다. 구체적인 수치를 들어 설명하자면, \\(N = 100\\)명의 참가자를 대상으로 실험을 했고, \\(X = 62\\)명이 정답을 맞혔다고 가정해 봅시다. 놀라울 정도로 높은 숫자이긴 하지만, 이것이 ESP의 증거를 발견했다고 주장하기에 충분할까요? 가설 검정은 이런 상황에서 유용합니다. 그러나 가설을 검정하는 방법을 논의하기 전에, 먼저 가설이 무엇을 의미하는지 명확히 할 필요가 있습니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>가설 검정</span>"
    ]
  },
  {
    "objectID": "09-Hypothesis-testing.html#다양한-종류의-가설들",
    "href": "09-Hypothesis-testing.html#다양한-종류의-가설들",
    "title": "9  가설 검정",
    "section": "",
    "text": "9.1.1 연구 가설과 통계적 가설\n우리가 첫 번째로 명확히 구분해야 하는 개념은 연구 가설과 통계적 가설의 차이입니다. ESP 연구에서 나의 궁극적인 과학적 목표는 투시 능력이 존재한다는 것을 입증하는 것입니다. 이러한 상황에서 나의 연구 목표는 명확합니다. 나는 ESP의 증거를 발견하기를 바라고 있습니다. 경우에 따라 연구자의 태도가 보다 중립적일 수도 있으며, 이 경우 연구 목표는 투시 능력이 존재하는지 여부를 규명하는 것이 됩니다. 어쨌든, 여기서 말하고자 하는 핵심은 연구 가설이란 본질적으로 실질적이며 검증 가능한 과학적 주장이라는 점입니다. 심리학자라면 연구 가설은 근본적으로 심리학적 개념과 관련됩니다. 다음은 연구 가설에 해당하는 예입니다:\n\n음악을 들으면 다른 것에 주의를 기울이는 능력이 감소한다. 이 진술은 두 가지 심리학적으로 의미 있는 개념(음악 감상과 주의 집중) 사이의 인과 관계를 주장하는 것이므로 타당한 연구 가설입니다.\n지능은 성격과 관련이 있다. 이 진술은 두 가지 심리학적 구성 개념(지능과 성격) 사이의 관계에 대한 주장입니다. 그러나 인과 관계가 아니라 상관 관계를 주장하는 점에서 위 가설보다는 약한 주장입니다.\n지능이란 정보 처리의 속도이다. 이 가설은 앞의 두 가지와는 성격이 다릅니다. 관계에 대한 주장이 아니라 지능의 본질적 성격에 대한 존재론적 주장입니다. 보통 “X가 Y에 영향을 미치는가?”라는 형식의 연구 가설을 실험적으로 검증하는 것이 “X란 무엇인가?”라는 질문을 해결하는 것보다 훨씬 쉽습니다. 실질적으로 연구자들은 존재론적 주장에서 도출된 관계론적 주장을 검증하는 경우가 많습니다. 예를 들어, 만약 내가 지능이란 뇌의 정보 처리 속도라고 믿는다면, 나의 실험은 지능 측정치와 정보 처리의 속도 측정치 사이의 관계를 탐색하는 방식으로 설계될 것입니다. 결론적으로, 대부분의 일상적인 연구 질문은 본질에서 관계적인 경향을 띠지만, 연구 질문은 거의 대부분 세상의 본질에 대한 더 깊은 존재론적 질문에 의해 추동됩니다.\n\n연구 가설은 때때로 상당히 복잡하게 얽혀 있을 수 있습니다. 예를 들어, ESP 연구에서 나의 궁극적인 목표는 “ESP가 존재한다”는 존재론적 주장을 검증하는 것일 수 있지만, 실험적으로는 “일부 사람들이 투시 능력을 가지고 있다”라는 보다 구체적인 가설을 설정할 수도 있습니다. 그렇다고 해서 모든 것이 연구 가설로 인정되는 것은 아닙니다. 의미 있는 연구 가설로 보기 어려운 몇 가지 예를 들어봅시다.\n\n사랑은 전쟁터다. 이 진술은 너무 모호해서 검증할 수 없습니다. 연구 가설이 어느 정도의 모호함을 가질 수는 있지만, 이론적 아이디어를 실행 가능한 방식으로 구체화할 수 있어야 합니다. 어쩌면 내가 충분히 창의적이지 않아서 그런지 모르겠지만, 이를 구체적인 연구 설계로 변환하는 방법을 전혀 떠올릴 수 없습니다. 그렇다면 이것은 과학적 연구 가설이 아니라 그냥 팝송 가사에 불과합니다. 그렇다고 해서 이 주제가 흥미롭지 않다는 것은 아닙니다. 인간이 가진 많은 깊은 질문들이 이 범주에 속합니다. 언젠가 과학이 사랑에 대해 검증 가능한 이론을 구성하거나 신의 존재를 시험할 수 있을지도 모릅니다. 하지만 지금은 불가능하며, 그런 날이 올 것이라고 기대하지도 않습니다.\n동어반복 클럽의 첫 번째 규칙은 동어반복 클럽의 첫 번째 규칙이다. 이 진술은 실질적인 주장이 아닙니다. 항상 참인 문장일 뿐입니다. 현실 세계의 어떤 상태도 이 주장과 모순될 수 없습니다. 우리는 이를 반증 불가능한 가설이라고 부르며, 따라서 이 주장은 과학의 영역 밖에 있습니다. 과학에서 무엇을 주장하든 간에, 그 주장은 틀릴 가능성이 있어야 합니다.\n내 실험에서 “예”라고 말하는 사람이 “아니오”라고 말하는 사람보다 많을 것이다. 이 진술도 연구 가설로 볼 수 없습니다. 이는 심리학적 현상에 대한 주장이라기보다는 단순히 데이터에 대한 주장일 뿐입니다(물론 연구 질문 자체가 사람들이 “예”라고 말하는 편향을 가지는지 여부라면 예외가 될 수 있습니다). 사실, 이 가설은 연구 가설이라기보다는 통계적 가설에 더 가까워 보입니다.\n\n보는 바와 같이, 연구 가설은 때때로 다소 복잡할 수 있으며, 본질적으로 과학적 주장입니다. 통계적 가설은 전혀 다른 개념입니다. 통계적 가설은 수학적으로 정확해야 하며, 데이터 생성 메커니즘(즉, “모집단”)의 특정 특성에 대한 구체적인 주장이어야 합니다. 그렇다 하더라도, 통계적 가설은 연구자가 관심을 가지는 실질적인 연구 가설과 명확한 관계를 가져야 합니다. 예를 들어, 내 ESP 연구에서 연구 가설은 “어떤 사람들은 벽을 통해 사물을 볼 수 있다”는 것입니다. 나는 이를 데이터가 생산되는 방식에 대한 명확한 진술로 변환하고자 합니다. 그렇다면 그 진술은 어떤 방식이어야 할까요? 실험에서 내가 관심을 가지는 양은 \\(P(correct)\\), 즉 참가자들이 정답을 맞힐 확률입니다. 이 확률을 나타내기 위해 그리스 문자 \\(\\theta\\)(theta)를 사용합시다. 다음은 네 가지 다른 통계적 가설입니다.\n\nESP가 존재하지 않으며 실험이 잘 설계되었다면 참가자들은 단순히 무작위로 추측할 것입니다. 따라서 정답을 맞힐 확률은 \\(\\theta=0.5\\)일 것입니다.\n반대로 ESP가 존재하고 참가자들이 카드를 볼 수 있다면, 정답률은 우연보다 높을 것이므로 통계적 가설은 \\(\\theta &gt; 0.5\\)가 됩니다.\n또 다른 가능성으로, ESP가 존재하지만 색상이 모두 반대로 보이고 사람들이 이를 인식하지 못하는 경우를 가정해 봅시다(조금 황당하지만, 가능성을 배제할 수는 없습니다). 이 경우 참가자들의 정답률은 우연보다 낮을 것이며, 이는 \\(\\theta &lt; 0.5\\)라는 통계적 가설에 대응됩니다.\n마지막으로, ESP가 존재하지만 참가자들이 올바른 색상을 보고 있는지, 반대로 보고 있는지 알 수 없는 경우를 생각해 봅시다. 이 경우 우리가 데이터에 대해 주장할 수 있는 유일한 것은 정답을 맞힐 확률이 0.5와 다르다는 것입니다. 이는 \\(\\theta \\neq 0.5\\)라는 통계적 가설에 해당합니다.\n\n이 모든 것은 적법한 통계적 가설입니다 왜냐하면 모집단의 모수에 대한 진술이면서 내 실험과 의미 있게 연결되어 있기 때문입니다.\n이 논의에서 내가 분명하게 말하고자 하는 것은, 통계적 가설 검정을 수행할 때 연구자는 두 가지 별개의 가설을 고려해야 한다는 점입니다. 먼저 연구 가설(심리학적 주장)이 있어야 하고, 이는 다시 통계적 가설(데이터 생성 모집단에 대한 주장)로 연결되어야 합니다. 내 ESP 연구에서 이 관계는 Table 9.1 같이 나타낼 수 있습니다.\n\n\n\n\nTable 9.1. Research and statistical hypotheses\n\n\n\n\n\n저자의 연구 가설:\\( ext{``}\\)ESP가 존재한다\\(    ext{''}\\)\n\n저자의 통계적 가설:\\( \\theta \\neq 0.5 \\)\n\n\n\n\n\n\n\n그리고 여기서 핵심적으로 인식해야 할 점은 다음과 같습니다. 통계적 가설 검정은 연구 가설이 아니라 통계적 가설을 검정하는 것입니다. 연구 설계가 잘못되었다면 연구 가설과 통계적 가설 간의 연결이 끊어집니다. 예를 들어, 만약 내 ESP 연구에서 참가자가 창문에 반사된 카드를 볼 수 있는 환경에서 실험이 수행되었다면, 아마도 \\(\\theta \\neq 0.5\\)라는 강력한 데이터적 증거를 찾을 수 있을 것입니다. 그러나 이것이 “ESP가 존재하는가?”라는 연구 가설에 대해서는 아무것도 알려주지 못할 것입니다.\n\n\n9.1.2 귀무가설과 대립가설\n지금까지는 순조롭습니다. 저는 세상에 대해 믿고 싶은 바와 일치하는 연구 가설을 가지고 있고, 이를 데이터가 생성된 방식에 대한 나의 믿음과 일치하는 통계적 가설로 연결하였습니다. 이 지점에서 많은 사람들의 직관에 다소 반하는 일이 벌어집니다. 왜냐하면 지금부터 제가 할 일은 제가 믿고 싶은 것과는 정반대에 해당하는 새로운 통계적 가설(귀무가설(null hypothesis), \\(H_0\\))4을 만들어내고, 실제로 관심 있는 것(이제는 대립가설(alternative hypthesis), \\(H_1\\)이라 부를 것입니다)을 거의 무시한 채 오로지 귀무가설에 집중할 것이기 때문입니다.\n우리의 초감각적 지각(ESP) 예제에서, 귀무가설은 \\(\\theta = 0.5\\)입니다. 이는 만약 ESP가 존재하지 않는다면 기대할 수 있는 것입니다. 물론 저는 ESP가 완전히 실재하기를 바라므로, 이 귀무가설의 대립가설은 \\(\\theta \\neq 0.5\\)가 됩니다. 본질적으로 여기서 우리가 하는 일은 \\(\\theta\\)의 가능한 값을 두 그룹으로 나누는 것입니다. 즉, 제가 진실이 아니길 바라는 값들(귀무가설)과, 실제로 맞다면 기쁠 값들(대립가설)로 나누는 것이죠.\n이렇게 구분한 후에 중요한 점은, 가설 검정의 목표가 대립가설이 (아마도) 참임을 보여주는 것이 아니라는 것입니다. 가설 검정의 목표는 귀무가설이 (아마도) 거짓임을 보여주는 것입니다. 대부분의 사람들은 이것이 꽤 이상하게 느껴집니다.\n제 경험상, 이 개념을 가장 잘 이해하는 방법은 가설 검정을 형사 재판5에 비유하는 것입니다. 귀무가설의 재판이라고 할 수 있죠. 귀무가설은 피고인이고, 연구자는 검사이며, 통계적 검정 자체는 판사 역할을 합니다. 형사 재판과 마찬가지로 무죄 추정의 원칙이 적용됩니다. 즉, 연구자인 여러분이 합리적 의심을 넘어 귀무가설이 거짓임을 입증하지 못하는 한, 귀무가설은 참으로 간주됩니다.\n여러분은 실험을 자유롭게 설계할 수 있으며(물론 합리적인 범위 내에서!), 그 목표는 데이터가 귀무가설이라는 범죄(즉, 거짓임)에 대해 유죄 판결을 이끌어낼 가능성을 극대화하는 것입니다. 그러나 한 가지 함정이 있습니다. 바로 통계적 검정이 재판의 규칙을 정하고, 이 규칙들은 귀무가설을 보호하도록 설계되어 있으며, 특히 귀무가설이 실제로 참일 경우 잘못된 유죄 판결의 가능성을 낮게 유지하도록 보장합니다. 이는 매우 중요한 부분입니다. 결국 귀무가설에는 변호사가 없고, 연구자가 이를 거짓으로 입증하려고 필사적으로 노력하는 상황에서 누군가는 귀무가설을 보호해야 하기 때문입니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>가설 검정</span>"
    ]
  },
  {
    "objectID": "09-Hypothesis-testing.html#두-가지-오류-유형",
    "href": "09-Hypothesis-testing.html#두-가지-오류-유형",
    "title": "9  가설 검정",
    "section": "9.2 두 가지 오류 유형",
    "text": "9.2 두 가지 오류 유형\n통계적 검정이 어떻게 구성되는지에 대한 세부 사항으로 들어가기 전에, 그 철학적 배경을 이해하는 것이 유용합니다. 저는 이전에 귀무가설 검정과 형사 재판의 유사성을 언급하며 이를 암시했지만, 이제는 명확한 설명이 필요합니다. 이상적으로는 우리가 절대 오류를 범하지 않는 검정을 구성하고 싶지만, 현실 세계는 복잡하기 때문에 이것은 불가능합니다. 때때로 단순히 운이 나쁠 수도 있습니다. 예를 들어, 동전을 10번 던졌는데 모두 앞면이 나왔다고 가정해 봅시다. 이는 동전이 편향되었다는 강한 증거처럼 보이지만, 실제로 공정한 동전이라 해도 이런 결과가 나올 확률은 1/1024입니다. 즉, 현실에서는 우리가 실수를 저지를 가능성을 받아들여야 합니다. 따라서 통계적 가설 검정의 목표는 오류를 제거하는 것이 아니라, 이를 최소화하는 것입니다.\n이 시점에서 “오류”가 무엇을 의미하는지 좀 더 정확히 정의해야 합니다. 먼저, 명확한 사실을 진술하겠습니다. 귀무가설은 참이거나 거짓이며, 우리의 검정은 귀무가설을 유지하거나 기각하게 됩니다.6 따라서 Table 9.2 가 보여주듯이, 검정을 수행하고 결정을 내린 후에는 네 가지 경우 중 하나가 발생할 수 있습니다.\n\n\n\n\nTable 9.2. 귀무가설 통계 검정 (NHST)\n\n\n\n\n\n\\( H_0 \\) 유지\\( H_0 \\) 기각\n\n\\( H_0 \\) 참올바른 결정오류 (1종 오류)\n\n\\( H_0 \\) 거짓오류 (2종 오류)올바른 결정\n\n\n\n\n\n\n\n결과적으로 여기에는 두 가지 다른 유형의 오류가 존재합니다. 실제로 참인 귀무가설을 기각하면 제1종 오류(Type I error)를 범한 것입니다. 반대로 실제로 거짓인 귀무가설을 유지하면 제2종 오류(Type II error)를 범한 것입니다.\n통계적 검정이 형사 재판과 비슷하다고 말한 것을 기억하시나요? 정말 그렇습니다. 형사 재판에서는 피고가 유죄임을 “합리적 의심의 여지 없이” 입증해야 합니다. 모든 증거 규칙은 (이론적으로는) 무고한 피고가 잘못 유죄 판결을 받지 않도록 보장하기 위해 설계되어 있습니다. 재판은 피고인의 권리를 보호하기 위해 존재하며, 영국 법학자 윌리엄 블랙스톤(William Blackstone)은 “한 명의 무고한 사람이 고통받느니 열 명의 유죄자가 놓여나는 것이 낫다”고 말했습니다. 즉, 형사 재판은 두 가지 유형의 오류를 동일하게 취급하지 않습니다. 무고한 사람을 처벌하는 것이 유죄자를 놓치는 것보다 훨씬 더 나쁘게 여겨집니다. 통계적 검정도 이와 비슷합니다. 검정의 가장 중요한 설계 원칙은 제1종 오류의 확률을 통제하고 이를 일정한 확률 이하로 유지하는 것입니다. 이 확률은 \\(\\alpha\\)로 표시되며, 유의수준(significance level)이라고 불립니다. 이 개념이 전체 검정 설계의 중심이므로 다시 한 번 강조하겠습니다. 가설 검정은 제1종 오류율이 \\(\\alpha\\)를 초과하지 않으면 가설 검정의 유의수준이 \\(\\alpha\\)라고 합니다.\n그렇다면 제2종 오류율은 어떨까요? 당연히 이것도 통제하고 싶습니다. 이 확률은 \\(\\beta\\)로 표시됩니다. 그러나 실제로는 제2종 오류율보다는 검정력(power)에 더 자주 주목합니다. 검정력은 실제로 거짓인 귀무가설을 기각할 확률을 의미하며, 이는 \\(1 - \\beta\\)입니다. 이를 명확히 하기 위해 동일한 표를 다시 제시하되, 관련 수치를 추가했습니다(Table 9.3).\n\n\n\n\nTable 9.3. 귀무가설 통계 검정 (NHST) - 추가 정보\n\n\n\n\n\n\\( H_0 \\) 유지\\( H_0 \\) 기각\n\n\\( H_0 \\) 참\\(1 - \\alpha\\) (올바른 유지 확률)\\(\\alpha\\)  (1종 오류율)\n\n\\( H_0 \\) 거짓\\(\\beta\\) (2종 오류율)\\(1 - \\beta\\) (검정력)\n\n\n\n\n\n\n\n강력한 검정(powerful hypothesis test)이란 \\(\\alpha\\)를 원하는 (작은) 수준으로 유지하면서도 \\(\\beta\\)를 작게 유지하는 검정을 의미합니다. 관례적으로 과학자들은 세 가지 다른 유의수준 \\(\\alpha\\)을 사용합니다: 0.05, 0.01, 0.001입니다. 여기에 비대칭성이 있다는 점에 주목하세요. 검정은 \\(\\alpha\\) 수준을 작게 유지하도록 설계되어 있지만, \\(\\beta\\)에 대한 보장은 없습니다. 물론 제2종 오류율도 작게 유지하고 싶으며 이를 위해 검정을 설계하려고 노력하지만, 이는 일반적으로 제1종 오류율을 통제하는 것보다 덜 중요하게 여겨집니다. 만약 블랙스톤이 통계학자였다면 이렇게 말했을지도 모릅니다. “참인 귀무가설을 하나 기각하는 것보다 거짓인 귀무가설 열 개를 유지하는 것이 낫다.” 솔직히 말하면, 저는 이 철학에 전적으로 동의하지 않습니다. 이러한 접근법이 타당한 상황도 있고, 그렇지 않은 상황도 있다고 생각합니다. 하지만 중요한 것은 이 방식이 검정이 설계된 방식이라는 점입니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>가설 검정</span>"
    ]
  },
  {
    "objectID": "09-Hypothesis-testing.html#검정-통계량과-표본-분포",
    "href": "09-Hypothesis-testing.html#검정-통계량과-표본-분포",
    "title": "9  가설 검정",
    "section": "9.3 검정 통계량과 표본 분포",
    "text": "9.3 검정 통계량과 표본 분포\n이제 가설 검정이 어떻게 구성되는지에 대해 구체적으로 이야기해야 할 시점입니다. 이를 위해 ESP 실험 예제로 돌아가 보겠습니다. 잠시 실제 데이터를 무시하고 실험의 구조에 대해 생각해 보겠습니다. 실제 숫자가 무엇이든 관계없이 데이터의 형태는 \\(N\\)명의 사람 중 \\(X\\)명이 숨겨진 카드의 색상을 정확히 맞혔다는 것입니다. 또한, 잠시 동안 귀무가설이 실제로 참이라고 가정해 보겠습니다. 즉, ESP가 존재하지 않으며, 누군가가 올바른 색상을 선택할 확률이 정확히 \\(\\theta = 0.5\\)라고 가정합니다. 그렇다면 데이터는 어떤 모습일까요? 분명히, 올바른 답을 한 사람의 비율이 대략 50%에 가까울 것으로 예상됩니다. 수학적으로 표현하면, \\(\\frac{X}{N}\\)이 대략 0.5라고 말할 수 있습니다.\n물론 이 비율이 정확히 0.5일 것이라고 기대하지는 않습니다. 예를 들어, \\(N = 100\\)명을 테스트했을 때 \\(X = 53\\)명이 맞혔다면, 이 데이터는 귀무가설과 상당히 일치한다고 볼 수 있습니다. 반면에 \\(X = 99\\)명이 맞혔다면 귀무가설이 틀렸다고 확신할 수 있을 것입니다. 마찬가지로 단 3명만 맞혔다면 비슷하게 귀무가설이 틀렸다고 확신할 수 있을 것입니다.\n이제 좀 더 기술적으로 접근해 보겠습니다. 우리는 데이터로부터 계산할 수 있는 \\(X\\)라는 값을 가지고 있습니다. 이 \\(X\\)의 값을 보고 귀무가설이 맞는지 여부를 판단하거나 대립가설을 지지할지를 결정합니다. 이러한 결정을 내리는 데 사용하는 계산값을 검정 통계량(test statistic)이라고 합니다.\n검정 통계량을 선택한 후의 다음 단계는 어떤 값에서 귀무가설을 기각하게 할지, 어떤 값에서 귀무가설을 유지하게 할지 정확히 정의해야 합니다. 이를 위해서는 귀무가설이 참일 때 검정 통계량의 표본 분포(sampling distribution)가 어떻게 되는지를 알아야 합니다. (이전에 Section 8.3.1 에서 표본 분포에 대해 설명한 바 있습니다.)\n왜 이것이 필요할까요? 이 분포는 귀무가설이 참일 경우 \\(X\\)가 어떤 값을 가질 것인지를 정확히 알려줍니다. 따라서 이 분포를 이용해 귀무가설이 실제 데이터에 어라나 부합되는지를 평가할 수 있습니다.\n검정 통계량의 표본 분포를 어떻게 결정할까요? 많은 가설 검정에서는 이 과정이 꽤 복잡합니다. 이 책의 후반부에서는 일부 검정에 대해 이 과정을 약간 얼버무리는 설명을 할 수도 있습니다(솔직히 일부는 저도 완전히 이해하지 못합니다). 그러나 때로는 매우 간단한 경우도 있습니다. 다행히도 ESP 예제는 가장 간단한 경우 중 하나입니다.\n모집단의 모수 \\(\\theta\\)는 사람들이 질문에 올바르게 답할 확률이며, 검정 통계량 \\(X\\)는 샘플 크기 \\(N\\) 중 정답을 맞힌 사람의 수입니다. 이러한 분포는 Section 7.4 에서 본 적이 있으며, 이는 바로 이항 분포입니다. 해당 절에서 소개한 표기법과 용어를 사용하면 귀무가설은 \\(X\\)가 이항 분포를 따른다고 예측합니다:\n\\[X \\sim Binomial(\\theta,N)\\]\n귀무가설이 \\(\\theta = 0.5\\)라고 가정하고, 실험의 샘플 크기가 \\(N = 100\\)명일 경우 필요한 표본 분포를 얻을 수 있습니다. 이 표본 분포는 Figure 9.1 에 나타나 있습니다. 놀랍지도 않게, 귀무가설은 \\(X = 50\\)이 가장 가능성이 높은 결과라고 말합니다. 또한 40에서 60 사이의 정답 수가 나올 가능성이 매우 높다고 예측합니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>가설 검정</span>"
    ]
  },
  {
    "objectID": "09-Hypothesis-testing.html#의사결정-내리기",
    "href": "09-Hypothesis-testing.html#의사결정-내리기",
    "title": "9  가설 검정",
    "section": "9.4 의사결정 내리기",
    "text": "9.4 의사결정 내리기\n이제 거의 다 끝났습니다. 우리는 검정 통계량 \\(X\\)를 구성했으며, 이 값이 \\(\\frac{N}{2}\\)에 가까우면 귀무가설을 유지하고, 그렇지 않으면 기각해야 한다는 점에 대해 꽤 확신을 가지고 있습니다. 이제 남은 질문은 다음과 같습니다. 정확히 어떤 검정 통계량 값을 귀무가설과 관련시키고, 어떤 값을 대립가설과 관련시켜야 할까요?\n예를 들어, ESP 연구에서 \\(X = 62\\)라는 값을 관찰했습니다. 이제 어떤 결정을 내려야 할까요? 귀무가설을 믿어야 할까요, 아니면 대립가설을 지지해야 할까요?\n\n\n\n\n\n\n\n\nFigure 9.1. 귀무가설이 참일 때 검정 통계량 \\(X\\)의 표본 분포. ESP 시나리오에서는 이항 분포를 따릅니다. 귀무가설이 올바른 답변의 확률이 \\(\\theta = .5\\)라고 가정하므로, 표본 분포는 가장 가능성이 높은 값이 50(100명 중)이라고 예측합니다. 대부분의 확률 질량은 40에서 60 사이에 분포합니다.\n\n\n\n\n\n\n9.4.1 기각역과 임계값\n앞의 질문에 답하기 위해서는 검정 통계량 \\(X\\)의 기각역(critical region) 개념을 소개해야 합니다. 검정의 기각역은 귀무가설을 기각하게 되는 \\(X\\)의 값들을 의미하며, 이 때문에 기각역을 기각 영역(rejection region)이라고 부르기도 합니다. 그렇다면 이 기각역은 어떻게 찾을 수 있을까요? 다음과 같은 점들을 고려해 보겠습니다.\n\n귀무가설을 기각하기 위해서는 \\(X\\)가 매우 크거나 매우 작아야 합니다.\n귀무가설이 참일 경우, \\(X\\)의 표본 분포는 \\(Binomial(0.5, N)\\)입니다.\n유의수준 \\(\\alpha = 0.05\\)일 때, 기각역은 이 표본 분포의 5%를 포함해야 합니다.\n\n이 마지막 점을 이해하는 것이 중요합니다. 기각역은 귀무가설을 기각하게 되는 \\(X\\)의 값들에 해당하며, 표본 분포는 귀무가설이 실제로 참일 때 특정 \\(X\\) 값일 확률입니다. 이제 만약 기각역이 표본 분포의 20%를 차지하도록 선택했다고 가정해 보겠습니다. 그러면 귀무가설이 실제로 참이라면 귀무가설을 잘못 기각할 확률은 얼마일까요? 답은 당연히 20%입니다. 따라서 이는 유의수준 \\(\\alpha = 0.2\\)인 검정을 설계한 것이 됩니다. 우리가 원하는 유의수준이 \\(\\alpha = 0.05\\)라면, 기각역은 검정 통계량의 표본 분포에서 5%만을 차지해야 합니다.\n이러한 세 가지 조건이 문제를 명확히 해결해 줍니다. 우리의 기각역은 분포의 가장 극단적인 값들, 즉 꼬리(tails) 부분으로 구성됩니다. 이는 Figure 9.2 에서 시각적으로 설명됩니다. 유의수준 \\(\\alpha = 0.05\\)를 원할 경우, 기각역은 \\(X \\leq 40\\) 및 \\(X \\geq 60\\)에 해당합니다.7 즉, “참”을 응답한 사람 수가 41에서 59 사이에 있으면 귀무가설을 유지해야 합니다. 만약 이 수가 \\(0\\)에서 \\(40\\) 사이이거나 \\(60\\)에서 \\(100\\) 사이에 있다면 귀무가설을 기각해야 합니다. 이때 \\(40\\)과 \\(60\\)을 임계값(critical values)이라 하는데, 임계값은 기각역의 경계값입니다.\n\n\n\n\n\n\n\n\nFigure 9.2. 유의수준 \\(\\alpha = 0.05\\)인 ESP 연구의 가설 검정에 대한 기각역. 이 그래프는 귀무가설 하의 \\(X\\) 표본 분포를 보여줍니다(즉, Figure 9.1 과 동일). 회색 막대는 귀무가설을 유지하는 \\(X\\)의 값을 나타내고, 파란색(더 진한 음영) 막대는 기각역으로, 귀무가설을 기각하는 \\(X\\)의 값들입니다. 대립가설이 양측 검정(즉, \\(\\theta &lt; 0.5\\) 및 \\(\\theta &gt; 0.5\\) 모두 허용)이므로 기각역은 분포의 양쪽 꼬리를 포함합니다. 유의수준이 \\(\\alpha = 0.05\\)가 되도록 각 기각역은 표본 분포의 2.5%를 차지해야 합니다.\n\n\n\n\n\n이제 가설 검정은 사실상 완료되었습니다:\n\n유의수준 \\(\\alpha\\)를 선택합니다 (예: \\(\\alpha = 0.05\\).\n귀무가설 \\(H_0\\)과 대립가설 \\(H_1\\)을 비교하는 데 적절한 검정 통계량(예: \\(X\\))을 선택합니다.\n귀무가설이 참이라는 가정 하에 검정 통계량의 표본 분포(이 경우 이항 분포)를 구합니다.\n적절한 유의수준을 만족하는 기각역(0–40 및 60–100)을 계산합니다.\n\n이제 실제 데이터(예: \\(X = 62\\))에 대한 검정 통계량 값을 계산하고, 이를 임계값과 비교하여 결론을 내리기만 하면 됩니다. \\(62\\)는 임계값 \\(60\\)보다 크므로 귀무가설을 기각하게 됩니다. 다시 말해, 이 검정은 통계적으로 유의한(significant) 결과를 도출했다고 할 수 있습니다.\n\n\n9.4.2 통계적 “유의성”에 대한 주의사항\n\n다른 신비주의 점술 기법들과 마찬가지로, 통계적 방법 또한 비전문가들이 그 기법을 이해하지 못하도록 의도적으로 만들어진 특유의 전문용어를 사용한다.\n– G. O. Ashley의 말로 전해짐8\n\n이 시점에서 “유의한(significant)”이라는 단어에 대해 잠시 짚고 넘어가야 합니다. 통계적 유의성(statistical significance)이라는 개념은 사실 매우 단순하지만, 불행히도 이름이 좋지 않습니다. 데이터가 귀무가설을 기각할 수 있게 해준다면, 우리는 “결과가 통계적으로 유의하다(statistically significant)”고 말하며, 이를 줄여서 단순히 “유의한(significant) 결과”라고 표현하기도 합니다. 이 용어는 꽤 오래된 것으로, 당시에는 “유의한(significant)”이 단순히 “표시된(indicated)” 정도의 의미로 사용되었습니다. 그러나 현대에는 이 단어가 “중요한(important)”에 더 가까운 의미로 받아들여지고 있습니다. 이로 인해 많은 현대 독자들이 통계학을 처음 배울 때 혼란을 겪게 됩니다. “유의한 결과”라면 반드시 중요한 결과일 것이라고 생각하기 때문입니다. 하지만 전혀 그렇지 않습니다. “통계적으로 유의하다”는 말은 단지 데이터가 귀무가설을 기각할 수 있었음을 의미할 뿐입니다. 이 결과가 실제로 중요한지는 전혀 별개의 문제이며, 이는 여러 가지 다른 요소에 달려 있습니다.\n\n\n9.4.3 단측 검정과 양측 검정의 차이\n지금까지 구성한 가설 검정에 대해 한 가지 더 짚고 넘어가야 할 부분이 있습니다. 제가 사용한 통계적 가설을 살펴보면:\n\\[H_0: \\theta=0.5\\]\n\\[H_1:\\theta \\neq 0.5\\]\n대립가설(alternative hypothesis)이 \\(\\theta &lt; 0.5\\)인 경우와 \\(\\theta &gt; 0.5\\)인 경우 모두를 포함하고 있다는 것을 알 수 있습니다. 이는 초감각적 지각(ESP)이 우연 이상의 성과를 낼 수도 있고, 우연보다 못한 성과를 낼 수도 있다고 생각하는 경우에 타당합니다(실제로 그렇게 생각하는 사람들도 있습니다). 통계 용어로 이것을 양측 검정(two-sided test) 이라고 부릅니다. 이렇게 부르는 이유는 대립가설이 귀무가설의 양 “측면”을 모두 포함하기 때문이며, 그 결과 검정의 기각역은 표본 분포의 양쪽 꼬리 부분을 포함하게 됩니다(유의수준 \\(\\alpha\\)가 0.05일 경우 각각 2.5%씩). 이는 앞서 Figure 9.2 에서 설명한 바 있습니다.\n그러나 이것이 유일한 방법은 아닙니다. 만약 제가 ESP가 오직 우연 이상의 성과를 낼 때만 믿을 수 있다고 생각한다면, 대립가설은 \\(\\theta &gt; 0.5\\)인 경우만을 포함하게 됩니다. 이 경우 귀무가설은 다음과 같이 바뀝니다:\n\\[H_0: \\theta \\leq 0.5\\]\n\\[H_1: \\theta &gt; 0.5\\]\n이러한 경우를 단측 검정(one-sided test) 이라고 하며, 기각역은 표본 분포의 한쪽 꼬리만을 포함하게 됩니다. 이는 Figure 9.3 에 설명되어 있습니다.\n\n\n\n\n\n\n\n\nFigure 9.3. 단측 검정의 기각역. 이 경우 대립가설은 \\(\\theta \\geq .5\\)이므로, 우리는 큰 값의 \\(X\\)에 대해서만 귀무가설을 기각하게 됩니다. 따라서 기각역은 표본 분포의 상위 꼬리 부분만을 포함하며, 이는 분포의 상위 5%에 해당합니다. 양측 검정의 경우는 Figure 9.2 를 참조하세요.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>가설 검정</span>"
    ]
  },
  {
    "objectID": "09-Hypothesis-testing.html#sec-The-p-value-of-a-test",
    "href": "09-Hypothesis-testing.html#sec-The-p-value-of-a-test",
    "title": "9  가설 검정",
    "section": "9.5 가설 검정의 \\(p\\)-값",
    "text": "9.5 가설 검정의 \\(p\\)-값\n어떤 의미에서 우리의 가설 검정은 이미 완료되었습니다. 우리는 검정 통계량을 구성했고, 귀무가설이 참일 경우의 표본 분포를 파악한 후, 검정의 기각역을 설정했습니다. 그럼에도 불구하고 사실상 가장 중요한 수치인 \\(p\\)-값을 아직 다루지 않았습니다. 이제 이 주제를 살펴보겠습니다. \\(p\\)-값을 해석하는 방법에는 두 가지가 있으며, 하나는 로널드 피셔(Sir Ronald Fisher)가, 다른 하나는 예지 네이만(Jerzy Neyman)이 제안한 것입니다. 두 가지 방법 모두 정당하며, 가설 검정을 바라보는 매우 다른 사고방식을 반영합니다. 대부분의 입문 교재는 피셔의 해석만을 소개하는 경향이 있지만, 이는 다소 아쉬운 일입니다. 제 생각에는 네이만의 해석이 더 간결하고, 실제로 귀무가설 검정의 논리를 더 잘 반영한다고 봅니다. 그러나 여러분의 생각은 다를 수 있으므로 두 가지 해석을 모두 포함했습니다. 먼저 네이만의 해석부터 시작하겠습니다.\n\n9.5.1 의사결정에 대한 유연한 관점\n앞서 설명한 가설 검정 절차의 한 가지 문제점은 결과가 “가까스로 유의한” 경우와 “매우 유의한” 경우를 전혀 구분하지 않는다는 점입니다. 예를 들어, 제가 수행한 ESP 연구에서 얻은 데이터가 겨우 기각역에 들어갔기 때문에 유의한 효과를 얻긴 했지만, 상당히 아슬아슬했다고 합시다. 반면, \\(N = 100\\)명의 참가자 중 \\(X = 97\\)명이 정답을 맞춘 연구를 수행했다고 가정해 봅시다. 이 경우 역시 유의한 결과를 얻겠지만, 훨씬 큰 차이로 유의하므로 이에 대한 모호함이 전혀 없을 것입니다. 제가 설명한 절차에서는 이 둘을 구분하지 않습니다. 허용 가능한 제1종 오류율로 \\(\\alpha = .05\\)를 채택하는 표준 관행을 따르면, 이 두 경우 모두 유의한 결과로 간주됩니다.\n이러한 상황에서 \\(p\\)-값이 유용합니다. 이를 이해하기 위해, 동일한 데이터 세트에 대해 다양한 \\(\\alpha\\) 값을 사용하여 여러 번 가설 검정을 수행했다고 가정해 봅시다. 원래의 ESP 데이터에 대해 그렇게 하면 Table 9.4 같은 결과를 얻게 됩니다.\n\n\n\n\nTable 9.4. 다양한 \\(\\alpha\\) 수준에서 귀무가설 기각 여부\n\n\n\n\n\n\\( \\alpha \\) 값0.050.040.030.020.01\n\n귀무가설 기각?예예예아니오아니오\n\n\n\n\n\n\n\nESP 데이터(\\(X = 62\\) 성공, \\(N = 100\\) 관찰)를 검정할 때, \\(\\alpha\\) 수준이 \\(.03\\) 이상인 경우 항상 귀무가설을 기각하게 됩니다. 반면, \\(\\alpha\\) 수준이 \\(.02\\) 이하인 경우에는 항상 귀무가설을 유지하게 됩니다. 따라서 이 데이터에 대해 귀무가설을 기각할 수 있는 가장 작은 \\(\\alpha\\) 값이 \\(.02\\)와 \\(.03\\) 사이 어딘가에 있습니다. 이것이 바로 \\(p\\)-값입니다. 실제로 ESP 데이터의 \\(p\\)-값은 \\(p = .021\\)입니다. 요약하자면, \\(p\\)는 귀무가설을 기각하기 위해 허용해야 하는 가장 작은 제1종 오류율(\\(\\alpha\\))로 정의됩니다.\n만약 \\(p\\)가 나타내는 오류율이 감내하기 어려운 수준이라면 귀무가설을 유지해야 합니다. 반대로 \\(p\\) 수준의 오류율을 감수할 수 있다면 귀무가설을 기각하고 대립가설을 지지하는 것이 정당화됩니다.\n실질적으로 \\(p\\)는 모든 가능한 \\(\\alpha\\) 값에 대한 가설 검정 결과를 요약한 것입니다. 이로 인해 우리의 의사결정 과정이 보다 “유연해지는” 효과가 있습니다. \\(p \\le \\alpha\\)인 검정에서는 귀무가설을 기각하고, \\(p &gt; \\alpha\\)인 검정에서는 귀무가설을 유지하게 됩니다. 제 ESP 연구에서는 \\(X = 62\\)를 얻었고, 그 결과 \\(p = .021\\)이 도출되었습니다. 따라서 감수해야 하는 오류율은 \\(2.1\\%\\)입니다. 반면, 실험 결과가 \\(X = 97\\)이었다면 어떻게 될까요? 이번에는 \\(p\\)-값이 \\(p = 1.36 \\times 10^{-25}\\)로 줄어듭니다. 이는 매우, 매우 작은9 제1종 오류율입니다. 두 번째 경우에서는 약 10자(10조의 조배)분의 \\(1\\) 수준의 제1종 오류율만 감수하면 되므로, 훨씬 더 높은 확신을 가지고 귀무가설을 기각할 수 있습니다.\n\n\n9.5.2 극단적 데이터 발생의 확률\n\\(p\\)-값의 두 번째 정의는 로널드 피셔 경(Sir Ronald Fisher)으로부터 비롯되었으며, 실제로 대부분의 통계학 입문 교과서에서 이 정의를 볼 수 있습니다. 기각역(critical region)을 구성할 때, 그것이 표본 분포의 꼬리 부분(즉, 극단적인 값들)에 해당한다는 것을 눈치채셨나요? 이는 우연이 아닙니다. 거의 모든 “좋은” 가설 검정은 이러한 특성을 가지고 있습니다(여기서 “좋은”은 제2종 오류율 \\(\\beta\\)를 최소화하는 의미입니다). 그 이유는 좋은 기각역이란 대개 귀무가설이 참일 때 관찰될 가능성이 가장 낮은 검정 통계량의 값들에 해당되기 때문입니다. 이 규칙이 성립한다면, 우리는 \\(p\\)-값을 검정 통계량이 실제로 관찰한 값이나 그보다 더 극단적인 값을 관찰할 확률로 정의할 수 있습니다. 다시 말해, (\\(p\\)-값이 작다는 것은) 데이터가 귀무가설 하에서 극단적인 값이어서 나올 법하지 않으므로, 귀무가설이 틀렸을 가능성이 높다는 것입니다.\n\n\n9.5.3 흔한 실수\n이제 네이만의 가설 검정 접근법과 피셔의 접근법이라는 두 가지 상당히 다르지만 타당한 \\(p\\)-값 해석 방법이 있다는 것을 알았습니다. 불행히도, 특히 통계를 처음 배울 때 종종 제시되는 완전히 잘못된 세 번째 설명이 있습니다. 이 잘못된 접근법은 \\(p\\)-값을 “귀무가설이 참일 확률”로 해석하는 것입니다. 직관적으로 매력적인 생각일 수 있지만, 두 가지 핵심적인 측면에서 틀렸습니다.\n첫째, 귀무가설 검정은 빈도주의자의 도구이며, 빈도주의 확률 접근법은 귀무가설에 확률을 부여하는 것을 허용하지 않습니다. 이 확률 개념에 따르면 귀무가설은 참이거나 거짓일 뿐이며, “5% 확률로 참이다”라고 말할 수 없습니다.\n둘째, 가설에 확률을 부여할 수 있는 베이지안 접근법에서도, \\(p\\)-값은 귀무가설이 참일 확률에 해당하지 않습니다. 이 해석은 \\(p\\)-값이 계산되는 수학적 방식과 전혀 일치하지 않습니다. 직설적으로 말하자면, 이러한 방식으로 생각하는 것이 직관적으로 그럴듯해 보여도, \\(p\\)-값을 이렇게 해석할 어떠한 정당성도 없습니다. 절대 그렇게 하지 마세요.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>가설 검정</span>"
    ]
  },
  {
    "objectID": "09-Hypothesis-testing.html#가설-검정-결과-보고하기",
    "href": "09-Hypothesis-testing.html#가설-검정-결과-보고하기",
    "title": "9  가설 검정",
    "section": "9.6 가설 검정 결과 보고하기",
    "text": "9.6 가설 검정 결과 보고하기\n가설 검정의 결과를 작성할 때는 일반적으로 여러 가지 정보를 보고해야 하지만, 어떤 검정을 수행했느냐에 따라 달라집니다. 이 책의 나머지 부분에서는 다양한 검정 결과를 보고하는 방법에 대해 다룰 것이므로(특히 자세한 예시는 Section 10.1.9 참고), 일반적으로 어떻게 작성하는지 감을 잡을 수 있을 것입니다. 하지만 어떤 검정을 수행하든 반드시 해야 할 한 가지는 \\(p\\)-값과 그 결과가 유의한지 여부를 언급하는 것입니다.\n이것이 필요하다는 사실은 놀랍지 않을 것입니다. 이는 검정을 수행하는 핵심 목적이기 때문입니다. 다만, 논란이 될 수 있는 부분은 결과를 정확히 어떻게 보고해야 하는지에 대한 문제입니다. 귀무가설 검정의 전체적인 틀 자체에 반대하는 사람들을 제외하더라도, 검정에서 얻은 \\(p\\)-값을 그대로 보고해야 하는지, 아니면 사전에 선택한 유의수준 \\(\\alpha\\)(예: \\(p &lt; .05\\))만을 보고해야 하는지에 대한 논쟁이 존재합니다.\n\n9.6.1 문제의 핵심\n이것이 문제가 되는 이유를 이해하려면, \\(p\\)-값이 너무 편리한 개념이라는 점을 인식해야 합니다. 실제로, \\(p\\)-값을 계산할 수 있다는 사실은 검정을 수행하기 위해 사전에 특정한 \\(\\alpha\\) 수준을 정할 필요가 없음을 의미합니다. 대신, \\(p\\)-값을 계산한 후 직접 해석하기만 하면 되비다. 예를 들어, \\(p = .062\\)라는 결과를 얻었다면, 귀무가설을 기각하기 위해서는 1종 오류율을 \\(6.2\\%\\)까지 감수해야 한다는 의미입니다. 만약 개인적으로 \\(6.2\\%\\)가 용납할 수 없는 수준이라고 생각한다면, 귀무가설을 유지하면 됩니다. 따라서, “실제 \\(p\\)-값을 보고하고, 독자가 허용 가능한 1종 오류 비율을 스스로 결정하도록 하면 되지 않을까?”라는 주장이 나옵니다. 이 접근법은 의사결정 과정을 “유연하게” 만드는 장점이 있습니다. 사실, 네이만의 \\(p\\)-값 정의를 받아들인다면, 이것이 바로 \\(p\\)-값의 핵심입니다. \\(\\alpha = .05\\)라는 고정된 유의수준을 “채택”과 “기각”을 구분하는 경계선으로 설정할 필요가 없으며, 이로 인해 \\(p = .051\\)과 \\(p = .049\\)를 근본적으로 다르게 취급해야 하는 문제를 피할 수 있습니다.\n이러한 유연성은 \\(p\\)-값의 장점이지만 단점이기도 합니다. 많은 사람들이 정확한 \\(p\\)-값을 보고하는 것을 선호하지 않는 이유는 연구자에게 지나치게 많은 자유를 부여하기 때문입니다. 특히, 데이터를 본 후에 허용할 수 있는 오류 허용 범위를 변경할 가능성을 열어두게 됩니다. 예를 들어, 내 ESP 실험을 생각해 보겠습니다. 만약 실험을 수행한 결과 \\(p\\)-값이 \\(.09\\)로 나왔다면, 나는 귀무가설을 기각해야 할까요, 아니면 채택해야 할까요? 사실, 나는 아직 내가 정말로 받아들일 수 있는 1종 오류 수준에 대해 깊이 생각해 보지 않았습니다. 이 주제에 대해 명확한 의견이 없습니다. 하지만 ESP가 존재하는지 여부에 대해서는 확실한 의견이 있으며, 내 연구가 신뢰할 수 있는 과학 저널에 게재될 수 있을지에 대해서도 분명한 입장이 있습니다. 놀랍게도, 데이터를 확인한 후에는 \\(9\\%\\)의 오류율이 그리 나쁘지 않다고 생각되기 시작합니다. 특히, 내 실험이 실패했다고 인정하는 것이 얼마나 곤란한지를 고려하면 더욱 그렇습니다. 따라서, 사후적으로 결정을 내린 것처럼 보이지 않도록 하기 위해, 이제 나는 \\(\\alpha = .1\\)이라고 선언합니다. 1종 오류율이 \\(10\\%\\) 정도라면 나쁘지 않으며, 이 수준에서 내 검정 결과는 유의미하다는 주장을 펼칠 수 있습니다. 이렇게 하면 나는 내가 구하는 것을 얻을 것입니다.\n즉, 문제는 연구자가 아무리 선한 의도를 가지고 정직한 사람이라 할지라도, 데이터를 본 후 결과를 조금이라도 조정하고 싶은 유혹이 강하다는 점입니다. 실험을 수행해 본 사람이라면 누구나 공감할 것입니다. 실험 과정은 길고 어려우며, 연구자는 자신의 가설에 깊이 애착을 가지게 됩니다. 따라서 실험이 원하는 결과를 내지 못했다는 사실을 인정하기 어려울 수 있습니다. 바로 이것이 문제입니다. “순수한” \\(p\\)-값을 사용하면, 연구자가 데이터가 실제로 말하는 내용이 아니라 자신이 믿고 싶은 방식으로 데이터를 해석하게 될 가능성이 높아집니다. 만약 이를 허용한다면, 과학을 수행하는 의미가 사라지지 않을까요? 그렇다면 사실과 관계없이 누구든 원하는 대로 믿도록 내버려 두는 것이나 마찬가지입니다. 물론, 이는 다소 극단적인 표현이지만, 이러한 우려가 있는 이유입니다. 이러한 관점에서는 반드시 사전에 \\(\\alpha\\) 값을 설정하고, 검정 결과가 유의한지 여부만을 보고해야 합니다. 그래야만 연구자들이 정직함을 유지할 수 있습니다.\n\n\n\n\nTable 9.5. \\(p\\)-값 수준에 대한 일반적인 해석\n\n\n\n\n\n일반 표기유의성 표시해석귀무가설 상태\n\n\\( p \\) &gt; .05유의하지 않음유지됨\n\n\\( p \\) &lt; .05*\\( \\alpha \\) = .05에서는 유의하지만 \\( \\alpha \\) = .01 또는 \\( \\alpha \\) = .001에서는 유의하지 않음기각됨\n\n\\( p \\) &lt; .01**\\( \\alpha \\) = .05 및 \\( \\alpha \\) = .01에서는 유의하지만 \\( \\alpha \\) = .001에서는 유의하지 않음기각됨\n\n\\( p \\) &lt; .001***모든 수준에서 유의함기각됨\n\n\n\n\n\n\n\n\n\n9.6.2 두 가지 해결책\n실제로 연구자가 사전에 단일 \\(\\alpha\\) 수준을 지정하는 경우는 거의 없습니다. 대신, 과학자들은 일반적으로 \\(.05\\), \\(.01\\), \\(.001\\)의 세 가지 표준 유의수준을 사용합니다. 결과를 보고할 때, 이 중 어느 유의수준에서 귀무가설을 기각할 수 있는지를 표시합니다. 이는 Table 9.5 에 요약되어 있습니다. 이를 통해 조금 더 유연한 의사결정 규칙을 적용할 수 있으며, \\(p &lt; .01\\)은 \\(p &lt; .05\\)보다 더 강한 증거를 의미한다는 점을 반영할 수 있습니다. 이러한 수준들은 관례적으로 미리 정해져 있기 때문에, 연구자가 데이터를 본 후 \\(\\alpha\\) 수준을 임의로 조정하는 것도 방지할 수 있습니다.\n그럼에도 불구하고 많은 연구자들은 여전히 정확한 \\(p\\)-값을 보고하는 것을 선호합니다. \\(p = .06\\)을 어떻게 해석할지 독자가 직접 결정하도록 하는 것이 더 중요하다고 생각하는 경우도 많습니다. 하지만 실제로는, 정확한 \\(p\\)-값을 선호하는 연구자들조차도 작은 \\(p\\) 값에 대해서는 \\(p &lt; .001\\)로 표기하는 경우가 많습니다. 이는 일부 소프트웨어(예: SPSS)가 \\(p &lt; .001\\)일 때 \\(p = .000\\)으로 표시하는 등의 이유 때문이며, 아주 작은 \\(p\\)-값이 오해를 불러일으킬 수 있기 때문입니다. 현실적으로 어떤 통계 분석도 \\(p &lt; .001\\)보다 더 강한 확신을 제공하기 어렵기 때문입니다. 즉, \\(p &lt; .001\\)은 “이 검정에서 볼 때, 증거가 압도적이다”라는 의미로 받아들여집니다.\n이 모든 점을 고려했을 때, 정확히 무엇을 해야 할지 궁금할 수 있습니다. 이 주제에 대한 의견은 상당히 상충됩니다. 어떤 사람들은 정확한 \\(p\\)-값을 보고해야 한다고 주장하는 반면, 다른 사람들은 Table 9.1 에서 설명한 계층적 접근 방식을 사용해야 한다고 주장합니다. 따라서 제가 줄 수 있는 가장 좋은 조언은 해당 분야에서 작성된 논문이나 보고서를 살펴보고 관례가 무엇인지 확인하는 것입니다. 일관된 패턴이 보이지 않는다면, 선호하는 방법을 사용하면 됩니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>가설 검정</span>"
    ]
  },
  {
    "objectID": "09-Hypothesis-testing.html#가설-검정-실행하기",
    "href": "09-Hypothesis-testing.html#가설-검정-실행하기",
    "title": "9  가설 검정",
    "section": "9.7 가설 검정 실행하기",
    "text": "9.7 가설 검정 실행하기\n이 시점에서 일부 사람들은 이것이 “실제” 가설 검정인지, 아니면 단순한 예제인지 궁금해할 수도 있습니다. 이는 실제 가설 검정입니다. 이전 논의에서 저는 가장 단순한 실제 사례를 설정하고 기본 원칙으로부터 검정을 구축했습니다. 그러나 이 검정은 이미 존재하는 것입니다. 이는 이항 검정(binomial test)이라고 불리며, jamovi에서 ‘빈도’ 메뉴를 눌러 사용할 수 있는 통계 분석입니다. 귀무가설을 검정하기 위해 성공 확률이 \\(p = .5\\)라는 가정하에,10 binomialtest.omv 데이터 파일에서 \\(N = 100\\)명 중 \\(x = 62\\)명이 올바른 응답을 한 데이터를 사용하여 분석하면, Figure 9.4 에 나타난 결과를 얻을 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 9.4. jamovi에서의 이항 검정 분석 및 결과\n\n\n\n\n\n현재 이 출력은 다소 낯설게 보일 수 있지만, 기본적으로 올바른 정보를 제공하고 있음을 알 수 있습니다. 특히, \\(p\\)-값이 \\(0.02\\)로 일반적으로 선택되는 유의 수준 \\(\\alpha = .05\\)보다 작기 때문에 귀무가설을 기각할 수 있습니다. 앞으로 이러한 출력 결과를 읽는 방법에 대해 더 자세히 설명할 것이며, 시간이 지나면 쉽게 이해하고 해석할 수 있게 될 것입니다.\n\n\n\n\n\n\n실습: 이항 검정\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Binomial Test’를 선택합니다.\n‘빈도’-’2 결과 이항 검증’을 선택합니다.\n왼편의 ‘Propotion Test (2 Outcomes)’ 패널에서 Outcome를 ‘변수’ 상자에 넣습니다.\n‘검증 값’은 귀무가설 하에서의 성공 확률 \\(\\theta_0\\)를 나타냅니다. 0.5로 설정되어 있는지 확인합니다. (’검증 값’은 ’Test value’의 잘못된 번역으로 ’검정 값’ 또는 ’테스트 값’이라고 해야 합니다.)\n’가설’에서 대립가설의 종류를 선택합니다.\n\n\n‘검증 값’은’\\(\\neq\\) 검정 값’으로 표시되어야 하는데 번역 오류입니다. \\(\\theta \\neq \\theta_0\\)의 대립가설을 사용하여 양측 검정을 합니다.\n’&gt; 테스트 값’은 \\(\\theta &gt; \\theta_0\\)의 대립가설을 사용하여 오른쪽 단측 검정을 합니다.\n’&lt; 테스트 값’은 \\(\\theta &lt; \\theta_0\\)의 대립가설을 사용하여 왼쪽 단측 검정을 합니다.\n\n\n신뢰구간도 함께 살펴보기 위하여 ‘추가 통계’ 옵션의 ’신뢰구간’을 체크합니다.\n\n그러면 Figure 9.4 같은 결과를 얻을 수 있습니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>가설 검정</span>"
    ]
  },
  {
    "objectID": "09-Hypothesis-testing.html#sec-Effect-size-sample-size-and-power",
    "href": "09-Hypothesis-testing.html#sec-Effect-size-sample-size-and-power",
    "title": "9  가설 검정",
    "section": "9.8 효과 크기, 표본 크기 및 검정력",
    "text": "9.8 효과 크기, 표본 크기 및 검정력\n이전 절에서 통계적 가설 검정의 주요 설계 원칙이 제1종 오류율을 제어하는 것임을 강조했습니다. 우리가 \\(\\alpha = .05\\)로 설정하는 것은 참인 귀무가설 중 단 5%만이 잘못 기각되도록 하기 위한 시도입니다. 그러나 이것이 제2종 오류를 신경 쓰지 않는다는 의미는 아닙니다. 사실 연구자의 관점에서 보면, 귀무가설이 실제로 거짓임에도 불구하고 이를 기각하지 못하는 오류는 매우 성가신 문제입니다. 이를 염두에 두면 가설 검정의 이차적인 목표는 제2종 오류율 \\(\\beta\\)를 최소화하는 것일 겁니다. 그러나 일반적으로는 제2종 오류를 최소화한다는 표현을 사용하지 않고, 검정력을 극대화한다는 표현을 사용합니다. 검정력은 \\(1 - \\beta\\)로 정의되므로, 두 표현은 동일합니다.\n\n9.8.1 검정력 함수\n\n\n\n\n\n\n\n\nFigure 9.5. 대립 가설 하에서 모집단 모수 값이 \\(\\theta = 0.55\\)일 때의 표본 분포. 분포의 합리적인 비율이 기각 영역에 위치함\n\n\n\n\n\n잠시 제2종 오류가 실제로 무엇인지 생각해 봅시다. 제2종 오류는 대립가설이 참임에도 불구하고 귀무가설을 기각하지 못하는 경우 발생합니다. 이상적으로는 제1종 오류율을 \\(\\alpha = .05\\)로 설정할 수 있는 것처럼, 단일 숫자 \\(\\beta\\)를 계산하여 제2종 오류율을 결정할 수 있으면 좋겠지만, 이 계산은 그보다는 훨씬 더 까다로운 문제입니다. 이를 이해하기 위해 ESP 연구에서 대립가설이 실제로 \\(\\theta\\)의 다양한 값을 포함한다는 점을 생각해 보겠습니다. 즉, 대립가설은 \\(\\theta = 0.5\\)를 제외한 모든 값을 포함합니다.\n만약 실제로 정답을 선택할 확률이 55%라고 가정하면 (\\(\\theta = .55\\)), \\(X\\)의 실제 표본 분포는 귀무가설이 예측하는 분포와 달라질 것입니다. 이제 100 개의 응답 중 \\(X = 55\\)의 정답이 가장 가능성이 높은 값이 됩니다. 뿐만 아니라, Figure 9.5 에서 보듯이 전체 표본 분포가 오른편으로 이동합니다. 한편, 기각역은 변하지 않습니다. 정의상 기각역은 귀무가설 하에서의 예측을 기반으로 하기 때문입니다. 귀무가설이 틀렸을 경우, 표본 분포에서 훨씬 더 많은 부분이 기각역에 포함됩니다. 즉, 귀무가설이 실제로 거짓일 때 귀무가설을 기각할 확률이 더 커지게 됩니다.\n그러나 \\(\\theta = .55\\)가 대립가설에 부합되는 유일한 값은 아닙니다. 만약 실제 \\(\\theta\\) 값이 \\(0.7\\)이라면 어떻게 될까요? 이 경우의 표본 분포는 Figure 9.6 에서 볼 수 있듯이 거의 전 부분이 기각역에 포함됩니다. 따라서 \\(\\theta = 0.7\\)일 때 귀무가설을 올바르게 기각할 확률(즉, 검정력)은 \\(\\theta = 0.55\\)일 때보다 훨씬 커집니다. 즉, \\(\\theta = .55\\)와 \\(\\theta = .70\\)은 모두 대립가설에 속하지만, 제2종 오류율은 서로 다릅니다.\n\n\n\n\n\n\n\n\nFigure 9.6. 대립 가설 하에서 모집단 모수 값이 \\(\\theta = 0.70\\)일 때의 표본 분포. 분포의 거의 전체가 기각 영역에 위치함\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 9.7. 귀무가설을 기각할 확률을, 실제 \\(\\theta\\) 값의 함수로 나타낸 그래프. 명백히, 실제 \\(\\theta\\) 값이 귀무가설이 지정한 값(\\(\\theta = .5\\))과 많이 다를수록 검정의 검정력(올바른 기각 확률)이 더 큼. 실제 \\(\\theta\\) 값이 \\(.5\\)일 때(검은 점으로 표시됨), 귀무가설이 참이므로 귀무가설을 기각하는 것은 제1종 오류(Type I Error)가 됨\n\n\n\n\n\n즉, 검정의 검정력(즉, \\(1 - \\beta\\))은 실제 \\(\\theta\\) 값에 따라 달라진다. 이를 설명하기 위해, 모든 \\(\\theta\\) 값에 대한 귀무가설 기각 확률을 계산하여 Figure 9.7 에 나타냈다. 이 그래프는 보통 검정력 함수(power function)라고 불린다. 이 함수는 검정의 성능을 요약하는 좋은 지표로, 가능한 모든 \\(\\theta\\) 값에 대한 검정력 \\((1 - \\beta)\\)을 제공한다. 실제 \\(\\theta\\) 값이 \\(0.5\\)에 가까울수록 검정력이 급격히 감소하지만, 멀어질수록 검정력은 커진다.\n이것의 의미는 검정력(즉, \\(1 - \\beta\\))이 실제 \\(\\theta\\) 값에 따라 달라진다는 것입니다. 이를 설명하기 위해 모든 \\(\\theta\\) 값에 대해 귀무가설을 기각할 확률을 계산하여 Figure 9.7 에 그래프로 나타냈습니다. 이 그래프는 보통 검정력 함수라고 불립니다. 이는 검정이 얼마나 효과적인지를 요약한 좋은 지표로, 모든 가능한 \\(\\theta\\) 값에 대한 검정력 \\((1 - \\beta)\\)를 보여줍니다. 그래프에서 볼 수 있듯이, 실제 \\(\\theta\\) 값이 \\(0.5\\)에 가까울수록 검정력은 급격히 감소하지만, \\(0.5\\)에서 멀어질수록 검정력은 증가합니다.\n\n\n9.8.2 효과 크기\n\n모든 모형이란 틀린 것이기 때문에, 과학자는 무엇이 중요하게 틀렸는지에 주의해야 한다. 호랑이가 주위에 있는 상황에서 쥐를 걱정하는 것은 적절하지 않다.\n– 조지 박스 (George Box) (Box, 1976, p. 792).\n\nFigure 9.7 에 제시된 그래프는 가설 검정에 대한 기본적인 개념을 보여줍니다. 만약 실제 세계의 상태가 귀무가설이 예측하는 것과 매우 다르다면 검정력은 매우 높아집니다. 그러나 실제 상태가 귀무가설과 유사하지만 완전히 동일하지 않으면 검정력은 매우 낮아집니다. 따라서 실제 세계의 상태가 귀무가설과 얼마나 “유사한지”를 정량화할 수 있다면 유용할 것입니다. 이를 측정하는 통계량을 효과 크기(effect size)라는 척도입니다 (예: Cohen (1988); Ellis (2010)). 효과 크기는 상황에 따라 약간 다르게 정의되지만 (따라서 이 절에서는 일반적인 개념에 대해 설명합니다), 그것이 포착하려는 질적 개념은 항상 동일합니다 (예: Table 9.6 참조). 즉, 실제 모집단 모수와 귀무가설이 가정하는 모수 값 사이의 차이가 얼마나 큰가 하는 것입니다. ESP 예제를 사용하면, \\(\\theta_0 = 0.5\\)가 귀무가설이 가정하는 값이고, \\(\\theta\\)가 실제 값이라고 할 때, 효과 크기의 단순한 척도는 실제 값과 귀무가설 값의 차이 (즉, \\(\\theta - \\theta_0\\))나 이 차이의 절대값 \\(\\lvert \\theta - \\theta_0 \\rvert\\) 등이 될 수 있습니다.\n\n\n\n\nTable 9.6. 통계적 유의성과 효과 크기 간의 관계를 이해하는 데 도움이 되는 대략적인 가이드입니다. 기본적으로, 유의한 결과가 없다면 효과 크기는 거의 의미가 없습니다. 왜냐하면 그 효과가 실제인지에 대한 증거가 없기 때문입니다. 반면, 유의한 효과가 있지만 효과 크기가 작다면, 그 결과가 실제일지라도 별로 흥미롭지 않을 가능성이 큽니다. 물론 이는 연구하는 주제에 따라 달라집니다. 어떤 상황에서는 작은 효과도 실질적으로 큰 중요성을 가질 수 있습니다. 따라서 이 표를 너무 진지하게 받아들이지 마세요 – 어디까지나 대략적인 가이드일 뿐입니다.\n\n\n\n\n\n큰 효과 크기작은 효과 크기\n\n유의한 결과차이가 있으며,  실용적으로 중요함차이가 있지만,  흥미롭지 않을 수 있음\n\n유의하지 않은 결과효과 없음효과 없음\n\n\n\n\n\n\n\n효과 크기를 왜 계산할까요? 실험을 수행하고 데이터를 수집한 뒤, 가설 검정에서 유의한 효과를 얻었다고 가정해 봅시다. 단순히 유의한 효과가 있다고 말하는 것으로 충분하지 않을까요? 결국 가설 검정의 목적이 그것 아닌가요? 음, 그렇기도 하고 그렇지 않기도 합니다. 가설 검정을 수행하는 목적은 귀무가설이 틀렸음을 증명하려는 것이 맞습니다. 그러나 그것이 우리가 관심 있는 전부는 아닙니다. 만약 귀무가설이 \\(\\theta = 0.5\\)라고 주장하고 우리가 그것이 틀렸다는 것을 보여주었다면, 이는 이야기의 절반만을 말한 것입니다. 귀무가설을 기각한다는 것은 \\(\\theta \\neq 0.5\\)라고 믿는다는 것을 의미하지만, \\(\\theta = 0.51\\)과 \\(\\theta = 0.8\\) 사이에는 큰 차이가 있습니다. 만약 \\(\\theta = 0.8\\)이라는 결과가 나왔다면, 우리는 단순히 귀무가설이 틀렸다는 것뿐만 아니라, 그것이 매우 틀렸다는 것을 알게 됩니다. 반면, 귀무가설을 성공적으로 기각했지만 실제 값 \\(\\theta\\)가 겨우 0.51이라면 (이는 아주 큰 규모의 연구에서만 가능할 것입니다), 귀무가설이 틀렸다는 것은 맞지만, 그 효과 크기가 너무 작아서 우리가 실제로 신경 쓸 필요가 있는지는 명확하지 않습니다.\nESP 연구 맥락에서는 어떤 형태로든 실제 초능력의 존재를 입증하는 것이 꽤 흥미로운 일이 될 수 있으므로 여전히 중요할 수 있습니다11. 그러나 다른 맥락에서는 \\(1\\%\\)의 차이는 실제 차이라 하더라도 그다지 흥미롭지 않을 수 있습니다. 예를 들어, 남학생과 여학생 간의 고등학교 시험 점수 차이를 조사했을 때 여학생의 점수가 평균적으로 \\(1\\%\\) 높게 나온다면, 수천 명의 학생 데이터를 가지고 있다면 이 차이는 거의 확실히 통계적으로 유의미할 것입니다. 하지만 \\(p\\)-값이 아무리 작더라도 이 차이는 그다지 흥미롭지 않습니다. 이렇게 작은 차이로 남학생 교육에 위기가 있다고 주장하고 싶으신가요? 바로 이런 이유로, 가설 검정 결과와 함께 표준화된 효과 크기 척도를 보고하는 것이 점점 더 표준이 되어가고 있습니다 (비록 천천히 진행되고 있지만). 가설 검정은 관찰된 효과가 실제인지 (즉, 단순한 우연이 아닌지) 여부를 알려주고, 효과 크기는 그것이 실제로 중요하거나 신경 쓸 가치가 있는지를 알려줍니다.\n\n\n9.8.3 연구의 검정력 높이기\n과학자들이 실험의 검정력을 극대화하는 데 집착하는 것은 놀랄 일이 아닙니다. 우리는 실험이 성공하기를 원하고, 따라서 귀무가설이 틀렸을 경우 이를 기각할 확률을 최대화하고 싶어 합니다. 앞서 본 것처럼 검정력에 영향을 주는 요소 중 하나는 효과 크기(effect size)입니다. 따라서 검정력을 높이기 위해 할 수 있는 첫 번째 일은 효과 크기를 키우는 것입니다. 실제로 이것이 의미하는 바는, 연구를 설계할 때 효과 크기를 증폭시킬 수 있는 방식으로 설계하라는 것입니다. 예를 들어, ESP 연구에서 나는 심령 능력이 조용하고 어둡고 방해 요소가 적은 방에서 가장 잘 발휘된다고 믿을 수 있습니다. 그렇다면 나는 그런 환경에서 실험을 진행하려고 할 것입니다. 만약 내가 어떤 식으로든 사람들의 ESP 능력을 강화할 수 있다면, 실제 값 \\(\\theta\\)가 상승할 것이고12, 따라서 효과 크기도 더 커질 것입니다. 요약하자면, 영리한 실험 설계는 효과 크기를 변화시킬 수 있기 때문에 검정력을 높이는 한 가지 방법입니다.\n안타깝게도, 최상의 실험 설계를 갖추었더라도 효과가 미미할 수 있습니다. 예를 들어, ESP가 실제로 존재하더라도 최적의 조건에서도 그 효과가 매우 미약할 수 있습니다. 이런 상황에서는 검정력을 높이는 가장 좋은 방법은 표본 크기(sample size)를 늘리는 것입니다. 일반적으로 관찰값이 많을수록 두 가설을 구별할 가능성이 높아집니다. 만약 내가 ESP 실험을 10명의 참가자와 진행했는데, 이 중 7명이 숨겨진 카드의 색을 맞췄다면 별로 인상 깊지 않을 것입니다. 하지만 10,000명의 참가자를 대상으로 진행했는데 7,000명이 정답을 맞췄다면, 내가 뭔가를 발견했다고 생각할 가능성이 훨씬 높아질 것입니다. 다시 말해, 표본 크기가 커질수록 검정력이 증가합니다. Figure 9.8 는 이러한 사실을 보여주고 있습니다. 이 그래프는 실제 모수 \\(\\theta = 0.7\\)일 때, 표본 크기 \\(N\\)이 1에서 100까지 변화하는 동안의 검정력 변화를 나타냅니다. 여기서 귀무가설은 \\(\\theta_0 = 0.5\\)라고 가정합니다.\n\n\n\n\n\n\n\n\nFigure 9.8. 표본 크기 \\(N\\)에 따른 검정력의 변화. 이 경우, 실제 값 \\(\\theta\\)는 0.7이지만, 귀무가설은 \\(\\theta = 0.5\\)라고 가정합니다. 전반적으로, \\(N\\)이 클수록 검정력은 증가합니다. (이 함수에서 보이는 작은 지그재그 패턴은 \\(\\theta\\), \\(\\alpha\\), 그리고 이항 분포가 이산적이라는 사실 사이의 복잡한 상호작용 때문이며, 이는 실질적인 목적에는 큰 영향을 미치지 않습니다.)\n\n\n\n\n\n검정력이 중요하기 때문에, 실험을 계획할 때 예상되는 검정력이 어느 정도일지 아는 것이 좋습니다. 물론 실제 효과 크기가 무엇인지 알 수 없기 때문에 정확히 아는 것은 불가능합니다. 그러나 때로는 (가끔은) 효과 크기가 얼마나 클지 추측할 수 있습니다. 그렇다면 필요한 표본 크기도 추정할 수 있습니다! 이러한 개념을 검정력 분석(power analysis)이라고 하며, 이러한 분석이 가능하다면 매우 유용한 도구가 됩니다. 분석을 통해 실험을 성공적으로 수행할 시간이나 예산이 충분한지 알 수 있습니다. 검정력 분석은 실험 설계의 필수 요소가 되어야 한다는 주장이 점점 더 많아지고 있으므로 알아둘 가치가 있습니다.\n그러나 이 책에서는 검정력 분석에 대해 다루지 않습니다. 그 이유는 뻔한 이유와 본질적인 이유로 나뉩니다. 뻔한 이유는, 아직 검정력 분석에 대해 쓸 시간이 없었다는 것입니다. 본질적인 이유는, 제가 여전히 검정력 분석에 대해 약간 회의적이기 때문입니다. 연구자로서 저는 검정력 분석을 실제로 수행할 수 있는 상황에 거의 처해본 적이 없습니다. (a) 제 실험이 다소 비표준적이라 효과 크기를 제대로 정의할 수 없거나, (b) 효과 크기가 얼마나 될지 전혀 감이 없어서 결과를 해석할 수 없는 경우가 많았습니다. 게다가, 통계 컨설팅을 직업으로 하는 사람(제 아내입니다)과 많은 대화를 나눈 결과, 실제로 누군가가 그녀에게 검정력 분석을 요청하는 유일한 경우는 보조금 신청서를 작성할 때라는 사실을 알게 되었습니다. 즉, 실제로 과학자들이 검정력 분석을 원할 때는 관료적 절차에 의해 강제로 해야 할 때뿐이라는 것입니다. 이는 누구의 일상적인 업무의 일부가 아닙니다.\n결론적으로, 저는 검정력이 중요한 개념이라는 점에는 동의하지만, 검정력 분석은 사람들이 생각하는 것만큼 유용하지 않다고 봅니다. 다만, (a) 실제 실험 설계에 맞춰 검정력을 계산하는 방법을 누군가가 알아냈고, (b) 효과 크기가 어느 정도일지에 대한 좋은 예측이 가능한 경우에는 예외가 될 수 있습니다13. 아마 다른 사람들은 저보다 나은 경험을 했을 수도 있지만, 저는 개인적으로 (a)와 (b)가 모두 충족되는 상황에 처해본 적이 없습니다. 어쩌면 앞으로 생각이 바뀔 수도 있고, 이 책의 미래 버전에는 검정력 분석에 대한 더 자세한 논의가 포함될 수도 있습니다. 하지만 지금은 이 주제에 대해 이 정도만 언급하는 것이 저에게 편안할 것 같습니다.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>가설 검정</span>"
    ]
  },
  {
    "objectID": "09-Hypothesis-testing.html#고려해야-할-몇-가지-문제",
    "href": "09-Hypothesis-testing.html#고려해야-할-몇-가지-문제",
    "title": "9  가설 검정",
    "section": "9.9 고려해야 할 몇 가지 문제",
    "text": "9.9 고려해야 할 몇 가지 문제\n이 장에서 설명한 내용은 귀무가설 유의성 검정(null hypothesis significance testing; NHST)에 대한 정통적 설명입니다. NHST가 어떻게 작동하는지 이해하는 것은 필수적입니다. 왜냐하면 NHST는 20세기 초에 두각을 나타낸 이후로 추론 통계학에서 지배적인 접근 방식이었기 때문입니다. 이는 대다수의 과학자들이 데이터를 분석할 때 의존하는 방법이므로, 설령 이 방법을 싫어하더라도 반드시 알아야 합니다. 그러나 이 접근법에도 문제가 있습니다. 이 방식안에 내재한 몇 가지 별난 점, 형성 과정에서의 역사적 특이성, 이 방식이 옳은지에 대한 이론적 논쟁, 그리고 주의하지 않으면 빠지기 쉬운 실질적인 함정들이 존재합니다. 이 주제에 대해 깊이 다루지는 않겠지만, 이러한 문제 중 몇 가지를 간략하게 논의할 가치가 있다고 생각합니다.\n\n9.9.1 네이만 대 피셔\n가장 먼저 알아야 할 점은 정통적인 NHST가 사실 두 가지 상당히 다른 가설 검정 접근법의 혼합물이라는 것입니다. 하나는 로널드 피셔 경이 제안한 것이고, 다른 하나는 예지 네이만이 제안한 것입니다(Lehmann (2011) 의 역사적 요약 참조). 이 역사는 복잡한데, 이는 피셔와 네이만이 실제 인물로서 시간이 지남에 따라 의견이 변했으며, 그들 중 누구도 수십 년 후 그들의 작업을 어떻게 해석해야 하는지에 대한 ’최종적인 입장’을 제시하지 않았기 때문입니다. 그렇긴 해도, 이 두 접근법을 간략히 요약하면 다음과 같습니다.\n먼저, 피셔의 접근법에 대해 이야기해 봅시다. 내가 이해한 바로는, 피셔는 오직 하나의 가설(귀무가설)만 있다고 가정했고, 우리가 해야 할 일은 귀무가설이 데이터와 불일치하는지를 알아보는 것이라고 생각했습니다. 그의 관점에서는, 귀무가설 하에서 데이터의 발생 “가능성이 충분하게 낮은지”를 확인해야 합니다. 사실, 우리가 앞서 논의했던 내용을 기억한다면, 이것이 바로 피셔가 \\(p\\)-값을 정의하는 방식입니다. 피셔에 따르면, 귀무가설이 데이터를 너무나 설명하지 못한다면 귀무가설을 안전하게 기각할 수 있습니다. 그러나 비교할 다른 가설이 없기 때문에 ’대립가설을 채택’할 방법은 없습니다. 왜냐하면 명시적으로 진술된 대립가설이 존재하지 않기 때문입니다. 이게 전부입니다.\n반면에, 네이만은 가설 검정의 목적이 행동에 대한 지침을 제공하는 것이라고 생각했으며, 그의 접근법은 피셔의 방법보다 다소 더 정식화된 것이었습니다. 그의 관점에서는 우리에게는 할 수 있는 여러 가지 행동(귀무가설을 채택하거나 대립가설을 채택하는 것)이 있으며, 검정의 목적은 데이터가 어떤 행동을 지지하는지를 알려주는 것입니다. 이 관점에서는 대립가설을 올바르게 명시하는 것이 중요합니다. 대립가설이 무엇인지 모르면 검정의 검정력이 얼마나 되는지, 혹은 어떤 행동이 타당한지 알 수 없습니다. 그의 틀은 실제로 서로 다른 가설 간의 경쟁을 요구합니다. 네이만에게 있어 \\(p\\)-값은 귀무가설 하에서 데이터(또는 더 극단적인 데이터)가 나올 확률을 직접적으로 측정하는 것이 아니라, 어떤 “가능한 (기준의) 검정”이 귀무가설을 채택하라고 말하는지, 그리고 어떤 “가능한 (기준의) 검정”이 대립가설을 채택하라고 말하는지를 추상적으로 설명하는 것이었습니다.\n보시다시피, 오늘날 우리가 사용하는 방법은 이 두 가지 접근법의 이상한 혼합물입니다. 우리는 귀무가설과 대립가설 둘 다를 설정한다고 이야기합니다(네이만), 하지만 대개14 \\(p\\)-값을 극단적인 데이터 관점에서 정의합니다(피셔). 그러나 여전히 \\(\\alpha\\) 값은 사용합니다(네이만). 일부 통계 검정은 명시적으로 대립가설을 설정하지만(네이만), 다른 검정은 이에 대해 모호하게 다룹니다(피셔). 그리고 적어도 일부 사람들에 따르면, 우리는 대립가설을 채택한다고 말하는 것이 허용되지 않습니다(피셔). 상당히 혼란스럽지만, 이 설명이 왜 그렇게 혼란스러운지 이해하는 데 도움이 되길 바랍니다.\n\n\n9.9.2 베이지안 대 빈도주의자\n앞서 이 장에서 \\(p\\)-값을 귀무가설이 참일 확률로 해석할 수 없다는 점을 강조했습니다. NHST(귀무가설 유의성 검정)는 본질적으로 빈도주의자의 도구이며(Chapter 7 참조), 따라서 가설에 확률을 부여하는 것을 허용하지 않습니다. 귀무가설은 참이거나 거짓일 뿐입니다.\n반면, 베이지안 통계 접근법은 확률을 신념의 정도로 해석하므로, “귀무가설이 참일 확률이 10%이다”라고 말하는 것이 전혀 문제가 되지 않습니다. 이는 단지 해당 가설에 대한 신뢰도의 반영일 뿐입니다. 하지만 빈도주의 접근법에서는 이러한 해석이 허용되지 않습니다. 빈도주의자라면 확률은 독립적인 반복 실험을 많이 했을 때 나타나는 결과(즉, 장기 빈도)로 정의됩니다. 이런 확률 해석을 따른다면, 귀무가설이 참일 “확률”을 논하는 것은 완전히 말이 안 됩니다. 귀무가설은 참이거나 거짓일 뿐이며, 이 진술에 대해 장기 빈도를 논할 방법은 없습니다. “귀무가설의 확률”을 논하는 것은 “자유의 색깔”을 논하는 것만큼 무의미합니다. 그런 것은 존재하지 않습니다!\n가장 중요한 점은, 이것이 단순한 이념적 문제가 아니라는 것입니다. 만약 자신이 베이지안이며 가설에 대한 확률적 진술을 하는 것이 괜찮다고 결정했다면, 이러한 확률을 계산하는 베이지안 규칙을 따라야 합니다. 이에 대해서는 Chapter 16 에서 더 자세히 설명하겠지만, 지금 강조하고 싶은 점은 \\(p\\)-값은 \\(H_0\\)가 참일 확률을 추정하는 데 사용되는 것은 매우 부적절하다는 것입니다. 만약 귀무가설의 확률을 알고 싶다면, \\(p\\)-값은 당신이 찾고 있는 답이 아닙니다!\n\n\n9.9.3 주의 사항\n보시다시피, 가설 검정 이론은 복잡하며, 현재까지도 통계학 내에서는 이것이 “어떻게” 작동해야 하는지를 두고 논쟁이 계속되고 있습니다. 그러나 통계학자들 간의 의견 불일치는 우리의 주된 관심사가 아닙니다. 우리의 실제 관심사는 실질적인 데이터 분석입니다.\n그리고 “정통”적인 귀무가설 유의성 검정 방법(NHST)에는 많은 단점이 있지만, 저처럼 확고한 베이지안조차도 책임감 있게만 사용된다면 이 방법이 유용할 수 있다는 점에 동의할 것입니다. 대부분의 경우 이 방법은 합리적인 답을 제공하며, 이를 통해 흥미로운 사실들을 배울 수 있습니다. 지금까지 논의한 다양한 이념적 문제와 역사적 혼란은 차치하고, 통계학에서 가장 큰 위험 요소는 사려 깊지 못함(thoughtlessness)이라는 사실이 남습니다. 여기서 말하는 사려 깊지 못하다는 것은 어리석음을 의미하는 것이 아니라, 말 그대로 “생각하지 않는 것”을 뜻합니다. 각 검정이 데이터에 대해 실제로 무엇을 말해주는지, 그리고 그것이 당신의 해석과 일치하는지를 곰곰이 생각하지 않고 서둘러 결과를 해석하려는 태도가 가장 큰 함정입니다.\n이를 설명하기 위해 다음의 예를 살펴보겠습니다(참조: Gelman & Stern (2006)). 제가 ESP(초감각적 지각) 연구를 진행하면서 남성과 여성 참가자 데이터를 별도로 분석하기로 했다고 가정해 봅시다. 남성 참가자 중 50명 중 33명이 카드의 색상을 정확히 맞췄습니다. 이는 유의한 효과입니다(\\(p\\)-값 = 0.03). 반면, 여성 참가자 중 50명 중 29명이 맞췄으며, 이는 유의하지 않은 결과입니다(\\(p\\)-값 = 0.32). 이러한 결과를 보고 대부분의 사람들은 남성과 여성의 초능력 차이에 대한 이유를 궁금해하게 됩니다. 그러나 이는 잘못된 해석입니다.\n곰곰이 생각해 보면, 우리는 실제로 남성과 여성을 직접 비교하는 검정을 수행한 것이 아닙니다. 우리가 한 일은 단지 남성 그룹의 결과를 우연성과 비교한 것(이항 검정 결과 유의함), 그리고 여성 그룹의 결과를 우연성과 비교한 것(이항 검정 결과 유의하지 않음)뿐입니다. 만약 남성과 여성 간에 실제 차이가 있다고 주장하고 싶다면, 차이가 없다는 귀무가설을 검정하는 것이 타당합니다! 우리는 다른 가설 검정을 통해 이를 수행할 수 있습니다,15 그러나 이를 수행하면, 남성과 여성 간에 유의한 차이가 있다는 증거는 없었습니다(\\(p\\)-값 = 0.54). 이제 여러분은 두 그룹 사이에 근본적인 차이가 있다고 생각하십니까? 물론 아닙니다. 여기서 발생한 일은 두 그룹(남성과 여성) 모두 데이터가 경계선상에 있었고, 순전히 우연히 한 그룹은 \\(p\\)-값 = 0.05라는 “마법의 선”을 넘었고, 다른 그룹은 넘지 못했을 뿐입니다. 이것이 남성과 여성 간의 차이가 의미하는 것은 아닙니다. 이 오류는 너무나 흔하기 때문에 항상 경계해야 합니다. 유의함과 유의하지 않음 사이의 차이가 곧 실제 차이에 대한 증거가 아닙니다. 두 그룹 간에 차이가 있다고 말하고 싶다면, 그 차이에 대해 검정해야 합니다!\n위의 예는 단지 하나의 사례일 뿐입니다. 이것을 강조한 이유는 매우 흔한 사례이기 때문이며, 더 큰 관점에서 보면 데이터 분석은 정확하게 수행하기가 쉽지 않습니다. 무엇을 검정하고 싶은지, 왜 그것을 검정하려는지, 그리고 검정 결과가 실제 세계에서 의미가 있는지 충분히 생각해 보십시오.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>가설 검정</span>"
    ]
  },
  {
    "objectID": "09-Hypothesis-testing.html#요약",
    "href": "09-Hypothesis-testing.html#요약",
    "title": "9  가설 검정",
    "section": "9.10 요약",
    "text": "9.10 요약\n귀무가설 검정은 가장 널리 사용되는 통계 기법 중 하나입니다. 대다수의 과학 논문은 어떤 형태로든 가설 검정 결과를 보고합니다. 따라서 과학을 하는 데 있어 최소한 \\(p\\)-값이 무엇을 의미하는지 대략적으로라도 이해하지 않고는 넘어갈 수 없습니다. 이런 이유로, 이 장은 책에서 가장 중요한 장 중 하나라고 할 수 있습니다. 평소와 마찬가지로, 이 장에서 다룬 핵심 개념을 간단히 정리하며 마무리하겠습니다.\n\n다양한 종류의 가설들. 연구 가설과 통계적 가설. 귀무가설과 대립가설.\n두 가지 오류 유형. 제1종 오류와 제2종 오류.\n검정 통계량과 표본 분포.\n의사결정 내리기를 위한 가설 검정.\n가설 검정의 \\(p\\)-값. “유연한” 의사결정 도구로서의 \\(p\\)-값.\n가설 검정 결과 보고하기.\n가설 검정 실행하기.\n효과 크기, 표본 크기 및 검정력.\n가설 검정과 관련된 고려해야 할 몇 가지 문제.\n\n이후 Chapter 16 장에서 귀무가설 검정 이론을 베이지안 관점에서 다시 살펴보고, 기존의 전통적인 접근법을 선호하지 않는 경우 사용할 수 있는 여러 가지 새로운 도구들을 소개할 것입니다. 하지만 지금은 추상적인 통계 이론을 마무리하고, 본격적으로 구체적인 데이터 분석 도구들을 논의해 보겠습니다.\n\n\n\n\nBox, G. E. P. (1976). Science and statistics. Journal of the American Statistical Association, 71, 791–799. https://doi.org/10.1080/01621459.1976.10480949\n\n\nCohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Lawrence Erlbaum. https://doi.org/10.4324/9780203771587\n\n\nEllis, P. D. (2010). The essential guide to effect sizes: Statistical power, meta-analysis, and the interpretation of research results. Cambridge University Press. https://doi.org/10.1017/CBO9780511761676\n\n\nGelman, A., & Stern, H. (2006). The difference between “significant” and “not significant” is not itself statistically significant. The American Statistician, 60, 328–331. https://doi.org/10.1198/000313006X152649\n\n\nLehmann, E. L. (2011). Fisher, Neyman, and the creation of classical statistics. Springer.",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>가설 검정</span>"
    ]
  },
  {
    "objectID": "09-Hypothesis-testing.html#footnotes",
    "href": "09-Hypothesis-testing.html#footnotes",
    "title": "9  가설 검정",
    "section": "",
    "text": "이 인용문은 비트겐슈타인(1922)의 저서 ’논리-철학 논고(Tractatus Logico-Philosophicus)’에서 가져왔습니다.↩︎\n기술적인 참고 사항. 아래 설명은 많은 입문서에서 제공하는 표준적인 설명과 미묘하게 다릅니다. 귀무가설 검정(null hypothesis testing)의 정통 이론은 20세기 초 로널드 피셔(Sir Ronald Fisher)와 예지 네이만(Jerzy Neyman)의 연구에서 비롯되었으나, 사실 피셔와 네이만은 가설 검정이 어떻게 작동해야 하는지에 대해 서로 다른 견해를 가지고 있었습니다. 대부분의 교과서에서 사용하는 표준적인 가설 검정 방식은 이 두 접근법을 절충한 형태입니다. 여기에서의 설명은 특히 \\(p\\)-값의 의미에 관해 정통적인 관점보다는 네이만의 접근법에 조금 더 가깝습니다.↩︎\n이 분야를 실제로 믿는 분들께는 죄송하지만, 내가 읽어본 ESP 관련 문헌에 따르면 이것이 실제로 존재한다고 믿을 만한 근거는 없습니다. 하지만 공정하게 말하자면, 일부 연구는 엄격하게 설계되었으며 심리학 연구 설계 관점에서 흥미로운 주제가 될 수 있습니다. 물론, 이 나라에서는 누구나 자신의 시간과 노력을 들여 내가 틀렸다고 증명할 자유가 있지만, 그것이 지적 능력을 활용하는 실용적인 방법이라고 생각하지는 않습니다.↩︎\n&lt;역주&gt; 귀무가설(歸無假說)을 영가설(零假說)이라고도 합니다.↩︎\n이 비유는 영국/미국/호주처럼 대척적인 법체계를 가진 나라에만 적절합니다. 제가 이해한 바로는, 프랑스의 심문 중심 법체계는 꽤 다릅니다.↩︎\n가설 검정에 대해 이야기할 때 사용하는 언어에 대한 부가적 설명입니다. 먼저, 피해야 할 단어는 “증명(prove)”입니다. 통계적 검정은 가설이 참인지 거짓인지 “증명”하지 않습니다. 증명은 확실성을 의미하며, 흔히 말하듯이 통계학은 “확신한다고 말할 필요가 없는” 학문입니다. 이 점에 대해서는 거의 모든 사람이 동의합니다. 그러나 그 외에도 혼란스러운 부분이 있습니다. 일부 사람들은 “귀무가설을 기각했다(rejected the null)”, “귀무가설을 기각하지 못했다(failed to reject the null)”, 또는 “귀무가설을 유지했다(retained the null)”와 같은 표현만 사용해야 한다고 주장합니다. 이러한 관점에 따르면 “대립가설을 채택했다(accept the alternative)” 또는 “귀무가설을 채택했다(accept the null)”와 같은 표현은 사용할 수 없습니다. 개인적으로 저는 이것은 지나치다고 생각합니다. 제 의견으로는 이것은 귀무가설 검정과 칼 포퍼(Karl Popper)의 반증주의 과학 철학을 혼동하는 것이라고 봅니다. 반증주의와 귀무가설 검정은 유사점이 있지만 동일하지는 않습니다. 하지만 개인적으로는 가설을 채택한다고 말하는 것이 괜찮다고 생각합니다(특히 귀무가설의 경우, “채택”이 반드시 참을 의미하지 않는다는 전제하에). 그러나 많은 사람들이 이에 동의하지 않을 수 있습니다. 중요한 것은 이러한 특이한 규칙이 존재한다는 점을 알고 있어야, 자신의 결과를 작성할 때 당황하지 않을 수 있다는 것입니다.↩︎\n엄밀히 말하면, 방금 구성한 검정은 \\(\\alpha = 0.057\\)로, 다소 관대한 유의수준입니다. 만약 기각역의 경계를 39와 61로 설정했다면 기각역은 분포의 3.5%만을 포함하게 됩니다. 따라서 \\(\\alpha = 0.05\\)에 더 가깝게 만들기 위해 \\(40\\)과 \\(60\\)을 임계값으로 사용하고, 5.7%의 제1종 오류율(type I error rate)을 허용하는 것이 더 적절하다고 판단했습니다.↩︎\n인터넷에서는 Ashley가 이 말을 했다고 꽤 확신하는 듯하지만, 이 주장에 대한 출처를 제시하는 사람은 찾을 수 없었다.↩︎\n과학적 표기법이 익숙하지 않은 분들을 위해 쓰자면, 이는 \\(p = .000000000000000000000000136\\)입니다!↩︎\n여기서 \\(p\\)는 \\(p\\)-값과 관련이 없습니다. jamovi 이항 검정의 \\(p\\) 인자는 귀무가설에 따른 올바른 성공 확률을 나타냅니다. 즉, 이는 \\(\\theta\\) 값입니다.↩︎\n실제로는 아주 작은 효과 크기는 우려스러운 점이 있습니다. 왜냐하면 아주 사소한 방법론적 결함만으로도 그 정도 효과를 유발했을 가능성이 있기 때문입니다. 또한 실제로 완벽한 실험은 없기 때문에 항상 고려해야 할 방법론적 결함들이 있기 마련입니다.↩︎\n실제 모집단 모수 \\(\\theta\\)가 반드시 변하지 않는 자연의 법칙을 나타내는 것은 아니라는 것에 주의하세요. 이 맥락에서 \\(\\theta\\)는 사람들이 다른 방에 있는 카드의 색을 올바르게 추측할 확률을 나타낼 뿐입니다. 따라서 모집단 모수는 여러 요소에 의해 영향을 받을 수 있습니다. 물론, 이는 ESP가 실제로 존재한다는 가정 하에서 가능한 이야기입니다!↩︎\n이의 한 가지 예외는 연구자들이 새로운 의학적 치료법의 효과를 연구할 때입니다. 이 경우 기존 치료법 대비 탐지하고자 하는 중요한 효과 크기를 사전에 명시합니다. 이를 통해 새로운 치료법의 잠재적 가치를 평가할 수 있습니다.↩︎\n이 책에서는 네이만과 피셔의 \\(p\\)-값 정의를 모두 설명하고 있지만, 대부분의 책은 그렇지 않습니다. 대부분의 입문서에서는 피셔의 정의만을 제공합니다.↩︎\n이 경우, 피어슨 카이제곱 독립성 검정을 수행해야 합니다.(Chapter 10 참조).↩︎",
    "crumbs": [
      "통계 이론",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>가설 검정</span>"
    ]
  },
  {
    "objectID": "10-Categorical-data-analysis.html",
    "href": "10-Categorical-data-analysis.html",
    "title": "10  범주형 데이터 분석",
    "section": "",
    "text": "10.1 \\(\\chi^2\\) (카이제곱) 적합도 검정\n\\(\\chi^2\\) 적합도(goodness-of-fit) 검정은 가장 오래된 가설 검정 중 하나입니다. 이 검정은 1900년경 칼 피어슨(Karl Pearson)에 의해 개발되었으며 (Pearson, 1900), 이후 로널드 피셔(Sir Ronald Fisher)에 의해 몇 가지 수정이 이루어졌습니다(Fisher, 1922). 이 검정은 명목 변수의 관측된 빈도 분포가 기대되는 빈도 분포와 일치하는지를 평가하는 데 사용됩니다. 예를 들어, 어떤 집단의 환자들이 실험적 치료를 받고 있으며, 이들의 건강 상태가 호전되었는지, 그대로인지, 악화되었는지를 평가했다고 가정해 봅시다. 적합도 검정을 사용하면 “호전”, “변화 없음”, “악화”의 각 범주에서 관측된 환자 수가 기존의 표준 치료를 받았을 때 기대되는 수치와 일치하는지를 검정할 수 있습니다. 이제 이 개념을 심리학적인 맥락에서 더 깊이 생각해 봅시다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>범주형 데이터 분석</span>"
    ]
  },
  {
    "objectID": "10-Categorical-data-analysis.html#chi2-카이제곱-적합도-검정",
    "href": "10-Categorical-data-analysis.html#chi2-카이제곱-적합도-검정",
    "title": "10  범주형 데이터 분석",
    "section": "",
    "text": "10.1.1 카드 데이터\n수년에 걸쳐 여러 연구에서 인간이 무작위성을 시뮬레이션하는 데 어려움을 겪는다는 사실이 밝혀졌습니다. 우리가 무작위로 행동하려고 노력하더라도, 인간은 패턴과 구조를 기반으로 사고하기 때문에 “무작위로 행동하라”는 요청을 받으면 실제로는 전혀 무작위적이지 않은 행동을 하게 됩니다. 따라서 인간의 무작위성(혹은 비무작위성)에 대한 연구는 우리가 세상을 어떻게 인식하는지에 대한 깊은 심리학적 질문을 제기합니다.\n이제, 이를 염두에 두고 아주 간단한 연구를 살펴보겠습니다. 가령, 사람들이 섞인 카드 데크를 상상한 후, 그중에서 “무작위로” 한 장을 선택하도록 요청했다고 가정해 봅시다. 첫 번째 카드를 선택한 후, 두 번째 카드도 같은 방식으로 선택하도록 합니다. 우리는 이 두 선택에서 사람들이 선택한 카드의 무늬(하트, 클럽, 스페이드, 다이아몬드)를 분석하려고 합니다. 예를 들어, \\(N = 200\\)명의 사람들에게 이 실험을 수행한 후, 그들이 실제로 무작위로 카드를 선택했는지를 데이터를 통해 알아보고자 합니다.\n이 데이터는 randomness.csv 파일에 저장되어 있으며, jamovi에서 파일을 열어 스프레드시트 형태로 보면 세 개의 변수가 포함되어 있습니다. 각 참가자에게 고유한 식별자를 할당하는 id 변수, 그리고 참가자들이 선택한 카드 무늬를 나타내는 choice_1과 choice_2 변수가 있습니다.\n우선, 사람들이 첫 번째로 선택한 카드에 집중해 보겠습니다. ‘기술통계’-‘기술통계’ 메뉴에서 ‘빈도분포표’ 옵션을 사용하면 각 무늬가 선택된 횟수를 계산할 수 있습니다. 그 결과는 Table 10.1 과 같습니다.\n\n\n\n\nTable 10.1. 각 무늬가 선택된 횟수\n\n\n\n\n\n클럽다이아몬드하트스페이드\n\n35516450\n\n\n\n\n\n\n\n이 작은 빈도표는 꽤 유용합니다. 표를 보면 사람들이 클럽보다 하트를 더 자주 선택하는 경향이 있는 것처럼 보이지만, 단순히 표만 보고서는 이것이 실제로 유의한 차이인지, 아니면 단순한 우연인지 확신하기 어렵습니다. 따라서 이를 확인하기 위해 통계적 분석을 수행해야 하며, 다음 절에서 분석 방법을 설명하겠습니다.\n좋습니다. 이제부터 이 표를 우리가 분석해야 할 데이터로 다루겠습니다. 다만, 데이터를 수학적으로 표현해야 하는 경우가 생길 것이므로(양해 부탁드립니다!) 이에 대한 표기법을 명확히 해두는 것이 좋겠습니다.\n수학적 표기에서는 “관측값(observed)”이라는 단어를 문자 \\(O\\)로 줄여 나타내며, 첨자를 이용해 특정 위치의 관측값을 나타냅니다. 예를 들어, 표에서 두 번째 관측값은 수식으로 \\(O_2\\)라고 표기됩니다. Table 10.2 는 영어 설명과 수학적 기호 간의 관계를 설명합니다.\n\n\n\n\nTable 10.2. 영어 설명과 수학적 기호 간의 관계\n\n\n\n\n\n레이블인덱스, i수학 기호값\n\n클럽, \\( \\clubsuit \\)1\\( O_1 \\)35\n\n다이아몬드, \\( \\diamondsuit \\)2\\( O_2 \\)51\n\n하트, \\( \\heartsuit \\)3\\( O_3 \\)64\n\n스페이드, \\( \\spadesuit \\)4\\( O_4 \\)50\n\n\n\n\n\n\n\n이제 개념이 좀 더 명확해졌기를 바랍니다. 또한, 수학자들은 특정한 값보다는 일반적인 개념을 선호하기 때문에, \\(i\\)번째 범주에 속하는 관측 횟수를 의미하는 \\(O_i\\)라는 표기법도 사용됩니다(\\(i\\)는 1, 2, 3, 4 중 하나일 수 있음).\n마지막으로, 모든 범주의 관측 빈도를 나타내고 싶을 때, 통계학자들은 이를 하나의 벡터2로 묶어서 표기하는데, 이를 \\(O\\)라고 부르겠습니다.\n\\[O = (O_1, O_2, O_3, O_4)\\]\n이 표기법은 새로운 개념이 아니라 단순한 기호일 뿐입니다. 예를 들어, \\(O = (35, 51, 64, 50)\\)이라고 하면, 이는 우리가 관측한 빈도표를 수학적 표기법으로 표현한 것일 뿐입니다.\n\n\n10.1.2 귀무가설과 대립가설\n앞 절에서 설명했듯이, 우리의 연구 가설은 “사람들은 무작위로 카드를 선택하지 않는다”는 것입니다. 이제 이 연구 가설을 통계적 가설로 변환한 후, 이에 대한 통계적 검정을 구성해 보겠습니다. 여기서 사용할 검정 방법은 피어슨(Pearson)의 \\(\\chi^2\\) (카이제곱) 적합도 검정이며, 대부분의 경우와 마찬가지로 먼저 귀무가설을 신중하게 설정해야 합니다.\n이 경우에는 귀무가설을 설정하는 것은 비교적 쉽습니다. 우선, 귀무가설을 문장으로 표현해 보겠습니다.\n\\[H_0: \\text{ 네 가지 무늬가 동일한 확률로 선택된다}\\]\n이제 이를 수학적으로 표현해 봅시다. \\(P_j\\)를 \\(j\\)번째 무늬가 선택될 실제 확률이라고 하겠습니다. 귀무가설이 참이라면, 네 가지 무늬 각각이 25%의 확률로 선택될 것입니다. 즉, 귀무가설은 다음과 같은 주장입니다.\n\\[P_1 = .25, \\quad P_2 = .25, \\quad P_3 = .25, \\quad P_4 = .25\\]\n앞서 관측 빈도를 벡터 \\(O\\)로 묶어 데이터 전체를 요약했던 것처럼, 귀무가설과 관련된 확률들을 벡터 \\(P\\)로 묶을 수 있습니다. 벡터 \\(P = (P_1, P_2, P_3, P_4)\\)를 귀무가설을 나타내는 확률들의 집합이라고 하면, 귀무가설은 다음과 같이 표현됩니다.\n\\[H_0: P = (.25, .25, .25, .25)\\]\n이 사례에서 귀무가설은 모든 범주의 확률이 서로 동일한 값을 가지는 벡터 \\(P\\)로 표현됩니다. 하지만 반드시 이렇게 될 필요는 없습니다. 예를 들어, 실험 과제가 참가자들에게 클럽이 다른 무늬보다 두 배 더 많은 카드 데크에서 카드를 무작위로 선택하도고 요구하는 것이었다면, 귀무가설은 다음과 같이 설정될 수도 있습니다.\n\\[P = (.4, .2, .2, .2)\\]\n중요한 것은 확률 값들이 모두 양수이고 합이 1이 되면 귀무가설로서 유효하다는 점입니다. 하지만 적합도 검정은 일반적으로 모든 범주가 동일한 확률을 가질 것이라는 귀무가설을 검정하는 데 자주 사용되므로, 이번 예제에서도 이를 유지하겠습니다.\n그렇다면 대립가설(alternative hypothesis), 즉 \\(H_1\\)은 어떻게 설정해야 할까요? 우리가 관심 있는 것은 단순히 확률들이 동일하지 않다는 것을 보여주는 것입니다(즉, 사람들의 선택이 완전히 무작위적이지 않음을 증명하는 것). 따라서 “인간 친화적인(human-friendly)” 버전의 가설은 다음과 같습니다.\n\\[H_0: \\text{ 네 가지 무늬가 동일한 확률로 선택된다}\\] \\[H_1: \\text{ 적어도 하나의 무늬는 선택 확률이 0.25가 아니다}\\]\n반면, “수학자 친화적인(mathematician-friendly)” 버전은 다음과 같이 표현됩니다.\n\\[H_0: P = (.25, .25, .25, .25)\\] \\[H_1: P \\neq (.25, .25, .25, .25)\\]\n\n\n10.1.3 “적합도” 검정 통계량\n이제 우리는 관측 빈도 \\(O\\)와 귀무가설을 검정하는 데 사용될 확률들의 집합 \\(P\\)를 갖게 되었습니다. 이제 해야 할 일은 귀무가설을 검정하는 것입니다. 항상 그렇듯이, \\(H_0\\)와 \\(H_1\\)을 비교하려면 검정 통계량이 필요합니다. 적합도 검정에서 사용하는 기본적인 방법은 데이터가 귀무가설과 얼마나 “가까운지”를 측정하는 검정 통계량을 구성하는 것입니다. 만약 데이터가 귀무가설이 참일 때 기대되는 모습과 다르다면, 귀무가설은 참이 아닐 가능성이 큽니다.\n그렇다면, 귀무가설이 참이라면 우리는 무엇을 기대할 수 있을까요? 좀 더 정확히 말하자면, 기대 빈도(expected frequencies)는 무엇일까요? 여기서 \\(N = 200\\)개의 관측값이 있으며, (귀무가설이 참이라면) 하나의 관측값이 하트를 선택할 확률은 \\(P_3 = .25\\)입니다. 따라서 하트가 선택될 것으로 기대되는 횟수는 \\(200 \\times .25 = 50\\)입니다. 이를 더 일반적으로 표현하면, 만약 \\(E_i\\)를 “귀무가설이 참일 경우 \\(i\\)번째 범주에서 기대되는 응답 수”라고 정의하면:\n\\[E_i = N \\times P_i\\]\n이 계산은 상당히 간단합니다. 만약 200개의 관측값이 네 개의 범주로 나뉠 수 있고, 네 개의 범주가 동일한 확률을 가진다고 가정하면, 각 범주에서 평균적으로 50번의 관측값이 기대될 것입니다.\n그렇다면 이제 이를 검정 통계량으로 어떻게 변환할 수 있을까요? 우리가 해야 할 일은 각 범주에서 기대되는 관측값(\\(E_i\\))과 실제 관측값(\\(O_i\\))을 비교하는 것입니다. 이를 기반으로 적절한 검정 통계량을 도출할 수 있어야 합니다. 우선, 귀무가설이 기대한느 값과 실제 관측된 값 사이의 차이를 계산해 보겠습니다. 즉, “관측값 - 기대값” 차이 점수를 계산합니다:\n\\[O_i - E_i\\]\n이 계산 결과는 Table 10.3 에 기술되어 있습니다.\n\n\n\n\nTable 10.3. 기대 빈도와 관측 빈도\n\n\n\n\n\n\\( \\clubsuit \\)\\( \\diamondsuit \\)\\( \\heartsuit \\)\\( \\spadesuit \\)\n\n기대빈도 \\( E_i\\)50505050\n\n관측빈도 \\( O_i\\)35516450\n\n차이 \\( O_i-E_i\\)-151140\n\n\n\n\n\n\n\n이제 계산 결과를 보면, 사람들이 귀무가설이 기대하는 것보다 하트를 더 많이 선택하고, 클럽을 더 적게 선택했다는 것을 알 수 있습니다. 하지만 조금만 더 생각해 보면, 이러한 차이값 그대로는 우리가 원하는 것을 완전히 설명할 수 없다는 것을 알 수 있습니다. 직관적으로 생각했을 때, 귀무가설이 기대한 값보다 관측값이 너무 적은 경우(클럽의 경우)와 너무 많은 경우(하트의 경우)는 동일하게 “틀렸다”고 볼 수 있습니다. 그런데 현재 방식으로 계산하면 클럽의 경우 음수 값이, 하트의 경우 양수 값이 나오므로 조금 이상해 보입니다. 이를 해결하는 간단한 방법은 모든 값을 제곱하는 것입니다. 즉, 다음을 계산합니다.\n\\[(E_i - O_i)^2\\]\n이 결과는 Table 10.4 에 기술되어 있습니다.\n\n\n\n\nTable 10.4. 차이값을 제곱한 결과\n\n\n\n\n\n\\( \\clubsuit \\)\\( \\diamondsuit \\)\\( \\heartsuit \\)\\( \\spadesuit \\)\n\n22511960\n\n\n\n\n\n\n\n이제 한 걸음 더 나아갔습니다. 현재 우리가 얻은 값들은 귀무가설이 부정확한 예측을 했을 때(클럽과 하트) 크게 나타나고, 정확한 예측을 했을 때(다이아몬드와 스페이드) 작게 나타납니다. 다음으로, 몇 가지 기술적인 이유로 인해(곧 설명하겠습니다) 모든 값을 기대 빈도 \\(E_i\\)로 나누겠습니다. 즉, 다음을 계산합니다.\n\\[\\frac{(E_i - O_i)^2}{E_i}\\]\n이 예에서는 모든 범주의 \\(E_i\\) 값이 50이므로, 계산이 그리 흥미롭지는 않지만, 그래도 진행해 보겠습니다(Table 10.5).\n\n\n\n\nTable 10.5. 제곱된 차이값을 기대 빈도로 나눈 값(오차 점수)\n\n\n\n\n\n\\( \\clubsuit \\)\\( \\diamondsuit \\)\\( \\heartsuit \\)\\( \\spadesuit \\)\n\n4.500.023.920.00\n\n\n\n\n\n\n\n결과적으로, 우리는 네 개의 “오차(error) 점수”를 얻게 되었습니다. 각 점수는 우리가 귀무가설을 사용하여 관측 빈도를 예측했을 때, 귀무가설이 얼마나 “틀렸는지”를 나타냅니다. 이를 유용한 검정 통계량으로 변환하기 위해, 단순히 이 값들을 모두 더해봅시다. 이렇게 해서 얻어진 값이 바로 적합도(goodness-of-fit) 통계량이며, 보통 \\(\\chi^2\\) (카이제곱) 또는 GOF라고 불립니다. 계산식은 다음과 같습니다.\n\\[\\sum \\frac{(observed - expected)^2}{expected}\\]\n우리의 데이터에 적용하면, 이 값은 8.44가 됩니다.\n만약 \\(k\\)가 총 범주의 개수를 의미한다고 하면(즉, 이번 카드 데이터에서는 \\(k = 4\\)), \\(\\chi^2\\) 통계량은 다음과 같이 정의됩니다.\n\\[\\chi^2 = \\sum_{i=1}^{k} \\frac{(O_i-E_i)^2}{E_i}\\]\n직관적으로 보면, 만약 \\(\\chi^2\\) 값이 작다면 관측값 \\(O_i\\)가 귀무가설이 예측한 값 \\(E_i\\)와 매우 가깝다는 의미이므로, 귀무가설을 기각하려면 충분히 큰 \\(\\chi^2\\) 값이 필요합니다.\n우리의 카드 데이터에서 계산한 \\(\\chi^2\\) 값은 8.44였습니다. 이제 중요한 질문은, 이 값이 귀무가설을 기각하기에 충분히 큰 값인가 하는 것입니다.\n\n\n10.1.4 적합도(GOF) 통계량의 표본 분포\n\\(\\chi^2\\) 값이 귀무가설을 기각하기에 충분히 큰지 판단하려면, 귀무가설이 참일 때 \\(\\chi^2\\)의 표본 분포가 어떻게 될지를 알아야 합니다. 이 절에서는 바로 그 부분을 설명하려고 합니다. \\(\\chi^2\\) 통계량의 표본 분포가 어떻게 구성되는지 꽤 자세히 보여드린 후, 다음 절에서 이를 활용하여 가설 검정을 구성할 것입니다. 만약 빠르게 결론을 보고 싶고, 표본 분포가 자유도가 \\(k - 1\\)인 \\(\\chi^2\\) (카이제곱) 분포를 따른다는 것을 그대로 받아들일 수 있다면, 이 절을 건너뛰어도 됩니다. 하지만 적합도 검정이 왜 그렇게 작동하는지 알고 싶다면 계속 읽어 주세요.\n우선, 귀무가설이 실제로 참이라고 가정해 봅시다. 그렇다면, 특정 관측값이 \\(i\\)번째 범주에 속할 확률은 \\(P_i\\)입니다. 결국, 이것이 바로 우리가 설정한 귀무가설의 정의입니다. 그렇다면 이 말이 실제로 의미하는 바는 무엇일까요?\n이것은 마치 “대자연”이 특정 관측값이 범주 \\(i\\)에 속할지 여부를 결정하는 데 가중치가 있는 동전을 던지는 것과 비슷합니다(즉, 앞면이 나올 확률이 \\(P_j\\)인 동전). 따라서 우리는 관측 빈도 \\(O_i\\)를 이렇게 생각할 수 있습니다. 대자연이 \\(N\\)번 동전을 던져(데이터 세트의 각 관측값마다 한 번씩), 그중 정확히 \\(O_i\\)번 앞면이 나온 것입니다. 물론, 이 방식은 다소 기묘해 보일 수도 있습니다. 하지만 (제 희망으로는) 여러분이 이 상황을 어디선가 본 적이 있다는 점을 떠올리게 만들 것입니다. 바로 Chapter 7 에 있는 Section 7.4 에서 본 내용과 동일한 구조입니다. 즉, 귀무가설이 참이라면, 우리의 관측 빈도는 이항 분포에서 샘플링된 값이 됩니다.\n\\[O_i \\sim Binomial(P_i,N) \\]\n이제 Section 8.3.3 에서 논의했던 내용을 떠올려 보세요. 이항 분포는 \\(N\\)이 크고 \\(P_i\\)가 0이나 1에 너무 가깝지 않을 때, 정규 분포와 거의 동일한 형태를 보입니다. 즉, \\(N P_i\\)가 충분히 클 때, 이항 분포는 정규 분포에 가까워집니다. 다시 말해, 기대 빈도 \\(E_i\\)가 충분히 크다면, \\(O_i\\)의 이론적 분포는 대략적으로 정규 분포를 따르게 됩니다.\n더 나아가, 만약 \\(O_i\\)가 정규 분포를 따른다면, \\((O_i - E_i) / \\sqrt{E_i}\\) 역시 정규 분포를 따르게 됩니다. 여기서 \\(E_i\\)는 고정된 값이므로, \\(E_i\\)를 빼고 \\(\\sqrt{E_i}\\)로 나누는 것은 단순히 정규 분포의 평균과 표준 편차를 변환하는 효과만 있을 뿐입니다.\n이제 적합도 검정 통계량이 실제로 어떻게 구성되는지 살펴보겠습니다. 우리가 하는 일은 정규 분포를 따르는 여러 값을 가져와 제곱한 다음, 모두 더하는 것입니다. 그런데, 이런 방식도 익숙하지 않나요? Section 7.6 에서 다룬 바와 같이, 표준 정규 분포(즉, 평균이 0이고 표준 편차가 1인 정규 분포)를 따르는 여러 값을 제곱하여 더하면, 결과적으로 카이제곱(chi-square) 분포를 따르게 됩니다. 따라서 이제 우리는 귀무가설이 참일 때 적합도 통계량의 표본 분포가 카이제곱 분포를 따른다는 것을 알게 되었습니다. 멋지네요.\n이제 마지막으로 이야기할 것이 하나 남았습니다. 바로 자유도(degrees of freedom)입니다. Section 7.6 에서 이야기한 것처럼, 만약 우리가 더하는 항의 개수가 \\(k\\)라면, 결과적으로 얻어지는 카이제곱 분포의 자유도도 \\(k\\)가 됩니다. 그런데 이 절의 처음에서 말했듯이, 적합도 검정에서 실제 자유도는 \\(k - 1\\)입니다. 이것은 왜 그럴까요?\n그 답은, 우리가 찾고 있는 것이 더해지는 것 중에서 진정으로 독립적인 요소들의 개수라는 점에 있습니다. 다음 절에서 더 자세히 설명하겠지만, 우리가 계산한 \\(k\\)개의 항 중에서 진정으로 독립적인 것은 \\(k - 1\\)개뿐입니다. 따라서 자유도는 실제로 \\(k - 1\\)이 됩니다. 이에 대한 논의는 다음 절에서 이어집니다.3\n\n\n10.1.5 자유도\n\n\n\n\n\n\n\n\nFigure 10.1. 서로 다른 “자유도” 값을 가진 \\(\\chi^2\\) (카이제곱) 분포\n\n\n\n\n\nSection 7.6 에서 카이제곱 분포를 소개할 때 “자유도(degrees of freedom)” 가 정확히 무엇을 의미하는지에 대해 다소 모호하게 설명했습니다. 분명히 중요한 개념이지만, 정확히 무엇일까요? Figure 10.1 을 보면, 자유도를 변경하면 카이제곱 분포의 형태가 상당히 달라지는 것을 알 수 있습니다. 그런데 자유도란 정확히 무엇일까요? 카이제곱 분포를 도입하면서 정규 분포와의 관계를 설명할 때, 저는 자유도를 “제곱하여 합산하는 정규 분포 변수의 개수”라고 설명한 적이 있습니다. 하지만 대부분의 사람들에게는 이 개념이 다소 추상적이고 직관적으로 와닿지 않을 수 있습니다. 결국 우리가 해야 할 일은 자유도를 실제 데이터의 관점에서 이해하는 것입니다. 이제 이를 설명해 보겠습니다.\n자유도의 기본 개념은 상당히 간단합니다. 자유도는 데이터를 설명하는 데 사용되는 서로 다른 “값(quantities)”의 개수를 세고, 그 데이터가 충족해야 하는 “제약 조건(constraints)”의 개수를 빼서 계산합니다.4 이 설명이 다소 모호할 수 있으므로, 카드 데이터라는 구체적인 예를 들어 설명해 보겠습니다. 우리는 데이터를 네 개의 숫자 \\(O_1, O_2, O_3, O_4\\)로 설명합니다. 이 값들은 각각 하트(hearts), 클럽(clubs), 다이아몬드(diamonds), 스페이드(spades)에 해당하는 관측 빈도를 나타냅니다. 이 네 개의 숫자는 실험의 무작위적인 결과입니다. 하지만 실험에는 고정된 제약 조건이 존재합니다. 바로 표본 크기 \\(N\\)입니다.5 즉, 만약 우리가 하트를 선택한 사람이 몇 명인지, 다이아몬드를 선택한 사람이 몇 명인지, 클럽을 선택한 사람이 몇 명인지 알면, 스페이드를 선택한 사람의 수를 정확히 알아낼 수 있습니다. 즉, 데이터가 네 개의 숫자로 표현되긴 하지만, 실제로는 \\(4 - 1 = 3\\) 개의 자유도를 갖습니다. 이를 다르게 생각해 보면, 우리가 관심을 가지는 네 개의 확률(각각 네 가지 범주에 해당하는 확률)이 존재하지만, 이 확률의 합은 반드시 1이 되어야 한다는 제약이 있습니다. 따라서 자유도는 \\(4 - 1 = 3\\) 입니다. 관측된 빈도를 기준으로 생각하든, 확률을 기준으로 생각하든, 결론은 동일합니다. 일반적으로, \\(\\chi^2\\) (카이제곱) 적합도 검정을 실행할 때, \\(k\\) 개의 그룹이 존재한다면 자유도는 \\(k - 1\\) 이 됩니다.\n\n\n10.1.6 귀무가설 검정\n가설 검정을 구성하는 과정의 마지막 단계는 기각역을 결정하는 것입니다. 즉, 어떤 \\(\\chi^2\\) 값이 나오면 귀무가설을 기각할 것인지 정해야 합니다. 앞서 살펴본 바와 같이, \\(\\chi^2\\) 값이 클수록 귀무가설이 실험 데이터를 잘 예측하지 못함을 의미하며, 반대로 \\(\\chi^2\\) 값이 작을수록 귀무가설이 데이터를 잘 설명하고 있음을 의미합니다. 따라서 합리적인 전략은 \\(\\chi^2\\) 값이 어떤 임계값(critical value)보다 크면 귀무가설을 기각하고, 임계값보다 작으면 귀무가설을 유지하는 것입니다. 다시 말해, Chapter 9 에서 소개한 개념을 사용하면, 카이제곱 적합도 검정은 항상 (오른쪽) 단측 검정(one-sided test) 입니다. 그렇다면 우리가 해야 할 일은 이 임계값을 찾는 것입니다. 다행히도 이 과정은 비교적 간단합니다. 검정의 유의수준을 \\(\\alpha = .05\\) (즉, 제1종 오류율을 5%로 설정)로 하려면, 귀무가설이 참일 때 \\(\\chi^2\\) 값이 그 임계값보다 커질 확률이 5%가 되도록 임계값을 선택해야 합니다. 이를 Figure 10.2 에 시각적으로 나타내었습니다.\n\n\n\n\n\n\n\n\n\nFigure 10.2. \\(\\chi^2\\) (카이제곱) 적합도 검정에서 가설 검정이 작동하는 방식의 예시\n\n\n\n\n\n\n하지만 한 가지 의문이 생길 수 있습니다. “자유도가 \\(k-1\\)인 카이제곱 분포에서 임계값을 어떻게 찾을 수 있을까?” 아주 오래전, 제가 처음 심리학 통계 수업을 들었을 때, 우리는 이러한 임계값을 임계값 표에서 찾아보곤 했습니다. 예를 들어, Table 10.6 같은 표를 사용했습니다. 이 표를 보면, 자유도가 3이고 \\(p=0.05\\)일 때 카이제곱 분포의 임계값은 7.815임을 알 수 있습니다.\n\n\n\n\nTable 10.6. 카이제곱 분포의 임계값 표\n\n\n\n\n\nProbability\n\nDegrees of freedom0.950.90.70.50.10.050.010.001\n\n10.0040.0160.1480.4552.7063.8416.63510.828\n\n20.1030.2110.7131.3864.6055.9919.21013.816\n\n30.3520.5841.4242.3666.2517.81511.34516.266\n\n40.7111.0642.1953.3577.7799.48813.27718.467\n\n51.1451.6103.0004.3519.23611.07015.08620.515\n\n61.6352.2043.8285.34810.64512.59216.81222.458\n\n72.1672.8334.6716.34612.01714.06718.47524.322\n\n82.7333.4905.5277.34413.36215.50720.09026.124\n\n93.3254.1686.3938.34314.68416.91921.66627.877\n\n103.9404.8657.2679.34215.98718.30723.20929.588\n\nNon-significantSignificant\n\n\n\n\n\n\n\n따라서, 우리가 계산한 \\(\\chi^2\\) 통계량이 임계값 \\(7.815\\)보다 크다면 귀무가설을 기각할 수 있습니다. (귀무가설 \\(H_0\\)는 네 개의 무늬가 동일한 확률로 선택된다는 가정입니다.) 우리가 이전에 계산한 \\(\\chi^2\\) 값이 8.44였으므로, 귀무가설을 기각할 수 있습니다. 이것이 전부입니다. 이제 당신은 “피어슨의 \\(\\chi^2\\) 적합도 검정”을 알게 되었습니다. 축하합니다!\n\n\n10.1.7 jamovi에서 검정 수행하기\njamovi는 이러한 계산을 자동으로 수행하는 분석 기능을 제공합니다. Randomness.omv 파일을 사용해 보겠습니다. 분석 리본의 ‘빈도’-‘단일표본 비율 검증’-\\(N\\) 개의 결과’를 선택합니다. 그런 다음 나타나는 분석 창에서 분석하려는 변수인 choice 1을 ‘변수’ 상자로 이동합니다. 또한 ‘기대 빈도’ 체크박스를 선택하여 결과 표에 기대 빈도가 표시되도록 합니다. 이 모든 과정을 마치면, jamovi에서 Figure 10.3 같은 분석 결과를 확인할 수 있습니다.jamovi는 우리가 위에서 손으로 계산한 것과 동일한 기대 빈도 및 통계를 제공하며, \\(\\chi^2\\) 값은 8.44, 자유도(df)는 3, 그리고 \\(p\\)-값은 0.038입니다. 이제 더 이상 표에서 임계 \\(p\\)-값을 찾아볼 필요 없도록, jamovi가 자유도 3에 대한 실제 \\(p\\)-값을 제공해 줍니다.\n\n\n\n\n\n\n\n\nFigure 10.3. jamovi에서 수행한 \\(\\chi^2\\) 단일 표본 비율 검정, 관측 및 기대 빈도와 비율을 보여주는 표 포함\n\n\n\n\n\n\n\n10.1.8 귀무가설 지정하기\n이제, 모든 범주가 동일한 확률로 선택된다는 가정이 아닌 다른 귀무가설로 적합도 검정을 수행하려면 어떻게 해야 할까요? 예를 들어, 어떤 사람이 이론적으로 사람들이 빨간색 카드(하트, 다이아몬드)를 60%의 확률로 선택하고, 검은색 카드(클럽, 스페이드)를 40%의 확률로 선택할 것이라고 예측했다고 가정해 보겠습니다. (왜 그렇게 예측했는지는 모르겠지만요.) 추가적인 선호도는 없다고 가정하면, 귀무가설은 선택 중 30%가 하트, 30%가 다이아몬드, 20%가 스페이드, 20%가 클럽일 것으로 기대하는 것입니다. 즉, 하트와 다이아몬드는 스페이드와 클럽보다 1.5배 더 자주 나타날 것으로 예상됩니다. (비율 \\(30\\% : 20\\%\\)는 \\(1.5 : 1\\)과 같습니다.) 이에 따른 기대 빈도는 Table 10.7 에 나타나 있습니다.\n\n\n\n\nTable 10.7. 다른 귀무가설 하의 기대 빈도\n\n\n\n\n\n\\( \\clubsuit \\)\\( \\diamondsuit \\)\\( \\heartsuit \\)\\( \\spadesuit \\)\n\n기대빈도 \\( E_i\\)40606040\n\n\n\n\n\n\n\n이러한 이론은 터무니없어 보이지만, jamovi 분석을 통해 이 귀무가설을 명시적으로 설정하여 쉽게 검정할 수 있습니다. 분석 창(Figure 10.3 의 ‘비율 테스트 (N개의 결과)’로 표시된 부분)에서 ’기대비율’ 옵션을 확장하면, 선택한 변수(여기서는 choice 1)에 대한 범주별 비율을 입력할 수 있습니다. 새로운 귀무가설을 반영하도록 비율을 변경하고, Figure 10.4 같이 결과를 확인합니다.\n\n\n\n\n\n\n\n\nFigure 10.4. jamovi에서 \\(\\chi^2\\) 단일 표본 비율 검정의 기대 비율 변경\n\n\n\n\n\n이제 \\(\\chi^2\\) 통계량이 4.74, 자유도(df)는 3, 그리고 \\(p\\) 값은 0.192임을 확인할 수 있습니다. 이처럼, 우리의 새로운 귀무가설과 기대 빈도는 이전과 다르기 때문에 \\(\\chi^2\\) 검정 통계량과 \\(p\\)-값도 달라졌습니다. 하지만 아쉽게도 \\(p\\) 값이 0.192로 나타났기 때문에 귀무가설을 기각할 수 없습니다. (Section 9.5 를 다시 확인하면 그 이유를 알 수 있습니다.) 안타깝게도, 귀무가설이 다소 황당한 이론을 기반으로 한다고 하더라도, 이 데이터만으로는 그것을 기각할 충분한 증거를 제공하지 하였습니다.\n\n\n10.1.9 검정 결과를 보고하는 방법\n이제 검정이 어떻게 작동하는지, 그리고 멋진 jamovi 기반의 마법 같은 컴퓨팅 박스를 사용하여 검정을 어떻게 수행하는지 알게 되었습니다. 이제 알아야 할 다음 사항은 결과를 어떻게 작성해야 하는지입니다. 결국, 실험을 설계하고 실행하여 데이터를 분석하였더라도 이를 다른 사람들에게 알리지 않으면 의미가 없습니다! 따라서 이제 분석 결과를 보고할 때 어떻게 해야 하는지에 대해 이야기해 보겠습니다. 카드 무늬 예제를 계속 사용해 보겠습니다. 만약 이 결과를 논문 등으로 발표하려 한다면, 일반적으로 다음과 같이 보고하는 것이 일반적입니다.\n\n실험에 참여한 200명의 참가자 중 64명이 첫 번째 선택으로 하트를 선택했으며, 51명이 다이아몬드를, 50명이 스페이드를, 35명이 클럽을 선택했습니다. 네 가지 무늬에 대한 선택 확률이 동일한지를 검정하기 위해 카이제곱 적합도 검정을 수행했습니다. 결과는 유의한 것으로 나타났으며 (\\(\\chi^2(3) = 8.44, p&lt; .05\\)), 이는 사람들이 무작위로 무늬를 선택하지 않았음을 시사합니다.\n\n이 설명은 꽤 간단하며 특별한 점이 없어 보입니다. 그러나 몇 가지 유의해야 할 사항이 있습니다:\n\n통계 검정 전에 기술 통계를 제공한다. 나는 독자에게 검정을 수행하기 전에 데이터가 어떻게 생겼는지에 대한 정보를 제공했습니다. 일반적으로 이는 좋은 습관입니다. 독자는 당신만큼 데이터를 잘 알지 못하므로, 데이터를 제대로 설명하지 않으면 통계 검정이 그들에게 의미가 없을 수 있으며, 결국 좌절하여 울 수도 있습니다.\n검정하고자 하는 귀무가설이 무엇인지 설명한다. 사실, 모든 저자가 제공하는 것은 아니지만, 어떤 모호성이 있거나 독자가 여러분이 사용한 통계 도구를 잘 모를 가능성이 있는 경우에는 귀무가설을 설명하는 것은 좋은 습관입니다. 많은 경우 독자가 여러분이 사용한 검정에 대한 모든 세부 정보를 알고 있지 않을 수도 있기 때문에, 그들에게 친절하게 귀무가설이 무엇인지 “상기”시키는 것이 좋습니다. 적합도 검정의 경우, 과학계의 독자라면 대부분 그 방식을 알고 있겠지만(대부분의 기초 통계 수업에서 다루어짐), 그래도 귀무가설을 명확하게 기술하는 것이 좋습니다. 예를 들어, 카드 예제에서 나의 귀무가설은 네 가지 무늬의 선택 확률이 동일하다는 것이었습니다(\\(P_1 = P_2 = P_3 = P_4 = 0.25\\)). 그러나 이 가설이 특별한 것은 아닙니다. 예를 들어, \\(P_1 = 0.7\\)이고 \\(P_2 = P_3 = P_4 = 0.1\\)이라는 귀무가설로 적합도 검정을 수헹힐 수도 있습니다. 따라서 독자가 이해하기 쉽도록 귀무가설을 설명하는 것은 유용합니다. 또한, 나는 귀무가설을 수식이 아닌 단어로 설명했습니다. 수식으로 설명해도 괜찮지만, 대부분의 독자는 수학 기호보다 단어로 된 설명을 더 쉽게 이해하기 때문에, 많은 저자가 가능하면 단어로 설명하는 것을 선호합니다.\n“통계 블록(stat block)”을 포함한다. 검정 결과를 보고할 때 단순히 결과가 유의하다고 말하는 것이 아니라, “통계 블록”(즉, 괄호 안의 수학적으로 보이는 밀집된 부분)을 포함하여 “핵심” 통계 정보를 보고했습니다. 카이제곱 적합도 검정의 경우, 보고해야 할 정보는 검정 통계량(적합도 통계량이 8.44임), 검정에 사용된 분포 정보(\\(\\chi^2\\) 분포, 자유도 3으로 표기됨), 그리고 결과의 유의미 여부(이 경우 \\(p&lt; .05\\))입니다. 통계 블록에 포함해야 하는 정보는 검정마다 다르므로, 새로운 검정을 소개할 때마다 통계 블록이 어떻게 구성되어야 하는지 보여드릴 것입니다.6 하지만 일반 원칙은 독자가 원한다면 직접 검정 결과를 확인할 수 있도록 충분한 정보를 제공해야 한다는 것입니다.\n결과를 해석한다. 결과가 유의미하다는 것을 단순히 언급하는 것뿐만 아니라, 결과에 대한 해석(즉, 사람들이 무작위로 선택하지 않았다는 점)을 제공했습니다. 이는 독자가 데이터를 통해 무엇을 이해해야 하는지 명확하게 전달하는 데 도움이 됩니다. 이러한 해석이 없다면 독자는 결과가 무엇을 의미하는지 이해하기 어려울 것입니다.7\n\n결국, 가장 중요한 것은 독자에게 설명하는 것입니다. 결과를 보고하는 목적은 다른 사람과 커뮤니케이션하는 것입니다. 나는 수많은 보고서, 논문, 심지어 과학 기사에서도 단순히 숫자를 나열하는 데 집중한 나머지 독자와의 소통을 완전히 잊어버린 사례를 수도 없이 보아왔습니다.\n\n사탄은 통계와 성경 구절을 인용하는 것을 똑같이 좋아한다.8\n– H.G. 웰스",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>범주형 데이터 분석</span>"
    ]
  },
  {
    "objectID": "10-Categorical-data-analysis.html#독립성또는-연관성에-대한-chi2-검정",
    "href": "10-Categorical-data-analysis.html#독립성또는-연관성에-대한-chi2-검정",
    "title": "10  범주형 데이터 분석",
    "section": "10.2 독립성(또는 연관성)에 대한 \\(\\chi^2\\) 검정",
    "text": "10.2 독립성(또는 연관성)에 대한 \\(\\chi^2\\) 검정\n\n경비로봇 1: 멈춰라!\n경비로봇 2: 너는 로봇인가, 인간인가?\n리라: 로봇… 우리는 로봇이야.\n프라이: 어, 맞아! 그냥 두 로봇이 로봇답게 돌아다니고 있을 뿐이야! 응?\n경비로봇 1: 시험을 실시하라.\n경비로봇 2: 다음 중 무엇을 가장 선호하는가? A: 강아지, B: 연인이 준 예쁜 꽃, C: 크고 제대로 포맷된 데이터 파일?\n경비로봇 1: 선택하라!\n— 퓨처라마, “Fear of a Bot Planet”*\n\n얼마 전 나는 Chapek 9 행성의 원주민들이 가진 독특한 관습을 다룬 애니메이션 다큐멘터리를 보고 있었습니다. 이 행성의 수도에 들어가려면 방문자가 인간이 아니라 로봇임을 증명해야 한다고 합니다. 방문자가 인간인지 아닌지를 판별하기 위해, 원주민들은 그들에게 강아지, 꽃, 혹은 크고 제대로 포맷된 데이터 파일 중에서 무엇을 선호하는지 묻습니다. 꽤 영리한 방법이라고 생각했습니다. “하지만 만약 인간과 로봇이 같은 선호도를 가지고 있다면? 그렇다면 별로 좋은 테스트가 아닐 텐데.”\n마침 나는 Chapek 9의 행정 당국이 이 시험을 검증하기 위해 사용하는 테스트 데이터를 손에 넣었습니다. 그들이 한 일은 아주 단순했습니다. 여러 로봇과 여러 인간을 찾아서 선호하는 항목을 물어본 것이었습니다. 나는 그 데이터를 chapek9.omv라는 파일에 저장했고, 이제 이를 jamovi에서 불러올 수 있다. 개별 응답자를 식별하는 ID 변수 외에도, species(종)와 choice (선택)라는 두 개의 명목형(범주형) 텍스트 변수가 포함되어 있다. 총 180개의 데이터가 있으며, 여기에는 질문을 받은 모든 참여자(로봇과 인간 모두를 “참여자”로 간주함)가 포함됩니다. 구체적으로 보면, 93명의 인간과 87명의 로봇이 있으며, 압도적으로 많은 응답자가 데이터 파일을 선호한다고 답했습니다.\n이는 jamovi에서 ‘탐색’-‘기술통계’ 메뉴를 이용해 빈도분포표를 생성하면 직접 확인할 수 있다. 그러나 이 요약만으로는 우리가 관심 있는 질문에 대한 답을 얻을 수는 없습니다. 답을 얻으려면 데이터를 더 세부적으로 분석해야 합니다. 우리가 원하는 것은 종(species)에 따라 선택(choice)이 어떻게 달라지는지를 살펴보는 것이다. 즉, 데이터의 두 변수를 교차하여 분할표를 구해야 합니다. (Section 6.1 참고). jamovi에서 이를 수행하려면 ‘빈도’-‘분할표’-‘독립 표본’ 분석을 선택하면 됩니다. 그러면 Table 10.8 같은 표를 얻을 수 있습니다.\n\n\n\n\nTable 10.8. 데이터의 교차 분할표\n\n\n\n\n\n로봇인간합계\n\n강아지131528\n\n꽃301343\n\n데이터4465109\n\n합계8793180\n\n\n\n\n\n\n\n이 표를 보면, 대다수의 인간이 데이터 파일을 선택한 반면, 로봇들은 선택이 인간보다 고르게 분포된 것을 알 수 있습니다. 인간들이 데이터 파일을 더 선호하는 이유가 무엇인지에 대한 논의는 잠시 미뤄두고(사실 꽤 이상하게 보이기는 합니다), 우리가 우선적으로 해야 할 일은 인간과 로봇의 선택에서의 차이가 통계적으로 유의미한지를 확인하는 것입니다.\n\n\n\n\n\n\n실습: 분할표\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Chapek 9’을 선택합니다.\n‘탐색’-’기술통계’를 선택합니다.\n왼편의 ‘기술통계’ 패널에서 species를 ‘변수’ 상자에 넣습니다. 그리고 ‘기술통계’ 드롭다운 메뉴에서 ’Variable across rows’를 선택하여 기술통계가 행으로 나열되도록 합니다. 그리고 ’빈도분포표’를 체크합니다. 그러면 다음 같이 species에 대한 기술통계와 빈도표를 오른쪽 결과 창에서 볼 수 있습니다.\n\n\n\n\n\n\n\n\n\n\n\n왼편의 ’기술통계’의 오른편 화살표를 클릭하여 닫습니다.\n‘탐색’-‘기술통계’를 다시 선택한 뒤, 왼편의 ’기술통계’ 패널에서 choice를 ‘변수’ 상자에 넣습니다. 그리고 ‘기술통계’ 드롭다운 메뉴에서 ’Variable across rows’를 선택하여 기술통계가 행으로 나열되도록 합니다. 그리고 ’빈도분포표’를 체크합니다. 그러면 다음 같이 choice에 대한 기술통계와 빈도표를 오른쪽 결과 창에서 볼 수 있습니다.\n\n\n\n\n\n\n\n\n\n\n\n‘빈도’-’독립표본’을 선택합니다.\nchoice를 ‘행’에, species를 ’열’ 상자로 이동시킵니다. 그러면 결과 창에 다음과 같이 분할표가 나타납니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.2.1 가설 검정 구성하기\n이 데이터를 어떻게 분석할 수 있을까요? 구체적으로, 내 연구 가설은 “인간과 로봇이 질문에 다르게 대답한다”는 것입니다. 그렇다면 “인간과 로봇이 질문에 같은 방식으로 대답한다”는 귀무가설을 검정하는 방법을 어떻게 구성할 수 있을까요? 이전과 마찬가지로, 데이터를 설명하기 위한 표기법을 먼저 설정합시다(Table 10.9).\n\n\n\n\nTable 10.9. 데이터를 설명하는 표기법\n\n\n\n\n\n로봇인간합계\n\n강아지\\(O_{11}\\)\\(O_{12}\\)\\(R_{1}\\)\n\n꽃\\(O_{21}\\)\\(O_{22}\\)\\(R_{2}\\)\n\n데이터\\(O_{31}\\)\\(O_{32}\\)\\(R_{3}\\)\n\n합계\\(C_{1}\\)\\(C_{2}\\)\\( N \\)\n\n\n\n\n\n\n\n이 표기법에서 (O_{ij})는 참여자 중에서 종(species)이 (j)인(즉, 로봇 또는 인간)인 참여자가 응답 (i)(즉, 강아지, 꽃 또는 데이터 파일)를 선택한 횟수(관측 빈도)를 의미합니다. 총 관측수는 일반적인 표기법을 따라 (N)으로 표현합니다. 또한, (R_i)는 행(row) 합계를 나타내며(예: (R_1)은 꽃을 선택한 총 참여자 수), (C_j)는 열(column) 합계를 나타낸다(예: (C_1)은 로봇의 총 참여자 수).9\n이제 귀무가설이 의미하는 바를 생각해봅시다. 만약 로봇과 인간이 질문에 동일한 방식으로 응답한다면, “로봇이 강아지를 선택할 확률”과 “인간이 강아지를 선택할 확률”이 같아야 하며, 다른 두 선택지(꽃과 데이터 파일)에서도 마찬가지여야 합니다. 따라서, (P_{ij})를 “종 (j)에 속한 사람이 응답 (i)를 선택할 확률”로 정의하면, 귀무가설은 다음과 같이 표현됩니다:\n\\[\n\\begin{aligned}\nH_0 &: \\text{다음 조건이 모두 성립한다.} \\\\\n&P_{11} = P_{12}\\text{ (강아지를 선택할 확률이 동일),} \\\\\n&P_{21} = P_{22}\\text{ (꽃을 선택할 확률이 동일),} \\\\\n&P_{31} = P_{32}\\text{ (데이터 파일을 선택할 확률이 동일).}\n\\end{aligned}\n\\]\n사실, 귀무가설에서는 선택 확률이 응답자의 종(species)과 무관하다고 주장하고 있으므로, 이를 단순히 (P_i)로 표현할 수도 있습니다. 즉, (P_1)은 종에 무관하게 강아지를 선택할 실제 확률입니다.\n이제, 적합도 검정(goodness-of-fit test)과 마찬가지로, 기대 빈도(expected frequency)를 계산해야 합니다. 즉, 각 관측된 빈도 (O_{ij})에 대해 귀무가설 하에 기대되는 값을 구해야 합니다. 기대 빈도를 (E_{ij})라고 표기합시다. 이번에는 조금 더 복잡합니다. 종 (j)에 속한 참여자 수가 (C_j)명이고, 특정 응답 (i)를 선택할 실제 확률이 (P_i)라면, 기대 빈도는 다음과 같이 계산됩니다:\n\\[E_{ij}=C_j \\times P_i\\]\n여기까지는 좋은데, 한 가지 문제가 있습니다. 적합도 검정과는 달리, 귀무가설이 (P_i)의 특정 값을 명시적으로 제시하지 않았습니다. 즉, 데이터를 이용해 이 값을 추정해야 합니다(Chapter 8 참고). 다행히도, 이 과정은 간단합니다. 예를 들어, 전체 180명 중 28명이 꽃을 선택했다면, 꽃을 선택할 확률의 자연스러운 추정치는 ( )입니다. 이를 일반화하면, 응답 (i)를 선택할 확률의 추정치는 다음과 같습니다:\n\\[\\hat{P}_{i}= \\frac{R_i}{N}\\]\n따라서, 기대 빈도는 다음과 같이 행 합계와 열 합계의 곱을 총 관측 개수로 나눈 값으로 표현할 수 있습니다:\n\\[{E}_{ij}= \\frac{R_i \\times C_j}{N}\\]\n[추가 기술적 설명[^10-categorical-data-analysis-11]]\n엄밀히 말하면 (E_{ij})는 추정값이므로 ()라고 표기해야 하지만, 대부분의 사람들이 그렇게 하지 않으므로 나도 그러지 않겠습니다. 이제 기대 빈도를 계산하는 방법을 알았으니, 적합도 검정과 동일한 전략으로 검정 통계량을 정의할 수 있습니다. 사실상 동일한 통계량이라 할 수 있는데, (r)개의 행과 (c)개의 열을 가진 분할표(contingency table)에서 카이제곱 통계량 (^2)는 다음과 같이 정의됩니다:\n\\[X^2=\\sum_{i=1}^{r}\\sum_{j=1}^{c} \\frac{(E_{ij}-O_{ij})^2}{E_{ij}}\\]\n차이점은 행과 열 모두에 대해 합산해야 하므로, 두 개의 합산 기호( () )를 포함해야 한다는 것입니다.\n\n\n이전과 마찬가지로, (X^2) 값이 클수록 귀무가설이 데이터를 제대로 설명하지 못한다는 의미이며, (X^2) 값이 작을수록 귀무가설이 데이터를 잘 설명한다는 뜻입니다. 따라서, 적합도 검정과 동일하게, (X^2) 값이 너무 크면 귀무가설을 기각해야 합니다.\n예상하였겠지만, 이 통계량은 (^2) 분포를 따릅니다. 이제 자유도를 구해야 하는데, 이는 그리 어렵지 않습니다. 일반적으로 자유도는 분석 중인 데이터 포인트의 개수에서 제약 조건(constraints)의 개수를 뺀 값으로 생각할 수 있습니다. (r)개의 행과 (c)개의 열이 있는 분할표는 총 (r c)개의 관측 빈도를 포함하므로, 기본적으로 관측 개수는 (r c)입니다. 그렇다면 제약 조건은 무엇일까요? 이부분이 조금 복잡합니다. 하지만 답은 항상 동일합니다.\n\\[df=(r-1)(c-1)\\]\n그러나 자유도가 이 값을 가지는 이유는 실험 설계에 따라 설명이 달라집니다. 가령, 연구자가 정확히 87명의 로봇과 93명의 인간을 조사하려고 계획했다고 가정해 봅시다(즉, 열 합계는 실험자가 고정). 반면 행 합계는 자유롭게 변할 수 있습니다. (즉, 행 합계는 확률 변수). 이러한 상황에서 어떤 제약이 적용될까요? 우선, 실험자가 의도적으로 열 합계를 고정했으므로, 우리는 이미 (c)개의 제약을 가지고 있습니다. 그러나 실제로는 더 많은 제약이 존재합니다.\n귀무가설에서 자유로운 모수가 존재하였다는 점을 기억하세요(즉, 우리는 (P_i) 값을 추정해야 했습니다). 이러한 모수 또한 추가적인 제약과 같습니다. 그렇다면 자유로운 모수는 몇 개일까요? 이 확률들은 반드시 1이 되어야 하므로, 총 (r - 1)개의 자유 모수가 존재합니다.\n따라서 전체 자유도는 다음과 같습니다.\n\\[\n\\begin{split}\ndf & = \\text{(관찰 개수) - (제약 조건 개수)} \\\\\\\\\n& = (r \\times c) - (c + (r - 1)) \\\\\\\\\n& = rc - c - r + 1 \\\\\\\\ & = (r - 1)(c - 1)\n\\end{split}\n\\]\n다른 방식으로 생각해 봅시다. 실험자가 유일하게 고정한 것이 전체 표본 크기 (N)이라고 가정해 봅시다. 즉, 연구자는 처음 만난 180명을 조사했고, 그중 87명이 로봇이었고, 93명이 인간이었습니다. 이번에는 추론 과정이 조금 다르지만, 결국 같은 결과에 도달합니다. 우리의 귀무가설에는 여전히 선택 확률과 관련된 (r - 1)개의 자유 모수가 있고, 이제 종(species) 확률과 관련된 (c - 1)개의 자유 모수도 추가됩니다. 이는 무작위로 선택된 사람이 로봇일 확률도 추정해야 하기 때문입니다.10\n마지막으로, 전체 관찰 개수 (N)은 실험자가 고정했으므로, 이는 하나의 추가적인 제약이 됩니다. 따라서, 이제 (r c)개의 관찰이 있으며, 제약 조건은 ((c-1)+(r-1)+1)개가 된다. 결과적으로,\n\\[\n\\begin{split} df & = \\text{(관찰 개수) - (제약 조건 개수)} \\\\\\\\ & = (r \\times c) -\n((c-1) + (r - 1)+1) \\\\\\\\ & = (r - 1)(c - 1) \\end{split}\n\\]\n놀랍네요.\n\n\n10.2.2 jamovi에서 검정 수행하기\n좋습니다, 이제 검정이 어떻게 작동하는지 알았으니, jamovi에서 어떻게 실행하는지 살펴봅시다. 지루한 계산 과정을 하나하나 따라가며 오래 걸리는 방법을 강제로 익히게 하는 것도 유혹적이지만, 굳이 그럴 필요는 없다고 생각합니다. 이전 절에서 적합도 검정을 긴 과정을 거쳐 수행하는 방법을 이미 보여주었고, 독립성 검정도 개념적으로 다르지 않기 때문에 같은 과정을 반복한다고 해서 새로운 것을 배우는 것은 아닐 것입니다. 그러므로 바로 쉬운 방법을 보여주겠습니다.\njamovi에서 검정을 실행(‘빈도’-‘분할표’-‘독립 표본’)한 후, 결과 창에서 분할표 아래를 보면 \\(\\chi^2\\) 통계량이 나타납니다. 이 예에서는 \\(\\chi^2\\) 값이 10.72이고, 자유도(df)는 2, 그리고 \\(p\\)-값은 0.005입니다.\n간단하지 않습니까? 또한 jamovi에서 기대 빈도도 확인할 수도 있습니다. ‘칸’ 옵을 확장한 후 ‘빈도’-‘기대 빈도’ 체크박스를 선택하면 기대 빈도가 분할표에 나타납니다. 이와 함께 효과 크기도 확인하면 좋을 것입니다. 여기서는 크래머의 (V)(Cramér’s (V))를 사용할 것이며, ‘통계’ 옵션에서 ‘파이와 크레이머의 V’ 체크박스를 선택하면 확인할 수 있습니다. 크래머의 (V) 값은 (0.24)입니다. Figure 10.5 를 참고하세요. 이에 대해서는 나중에 좀 더 이야기하겠습니다.\n\n\n\n\n\n\n\n\nFigure 10.5. Chapek 9 데이터를 사용한 jamovi의 독립 표본 \\(\\chi^2\\) 검정\n\n\n\n\n\n이 출력 결과는 연구 결과를 작성하는 데 충분한 정보를 제공합니다.\n\n피어슨 \\(\\chi^2\\) 검정 결과, 종(species)과 선택(choice) 간에 유의미한 연관성이 나타났다 \\((\\chi^2(2) = 10.7, p&lt; .01)\\). 로봇은 꽃을 더 좋아한다고 응답할 가능성이 높았고, 인간은 데이터를 더 좋아한다고 응답할 가능성이 높았다.\n\n여기서 다시 한 번, 데이터를 사용하여 무슨 일이 일어나고 있는지 독자가 이해할 수 있도록 약간의 해석을 추가했음을 알 수 있습니다. 이후 논의 절에서는 더 많은 맥락을 제공할 수 있을 것입니다. 차이를 설명하기 위해, 예를 들자면 아마 다음과 같이 설명할 것 같습니다.\n\n인간이 로봇보다 데이터 파일을 더 선호하는 것으로 나타난 것은 다소 직관적이지 않은 결과이다. 하지만 맥락을 고려하면 어느 정도 이해할 수 있다. Chapek 9의 시민 당국은 인간을 식별하면 처형하고 해부하는 불행한 경향이 있기 때문이다. 따라서 인간 참가자들은 불리한 결과를 피하기 위해 정직하게 응답하지 않았을 가능성이 크다. 이는 연구 방법론상의 상당한 약점으로 간주해야 한다.\n\n이것은 극단적인 반응성 효과(reactivity effect)의 사례로 분류될 수 있을 것 같습니다. 분명한 것은, 이 경우에는 문제의 심각성이 연구의 목적을 사실상 무의미하게 만들 정도라는 점입니다. 즉, 이 연구는 인간과 로봇 간의 선호 차이를 이해하는 도구로서 거의 가치가 없습니다. 그러나 이 예시는 통계적으로 유의미한 결과(귀무가설이 기각되고 대립가설이 채택됨)를 얻는 것과 과학적으로 가치 있는 발견을 하는 것(큰 방법론적 결함 때문에 데이터가 연구 가설에 대해 아무런 의미 있는 정보를 제공하지 않음)의 차이를 잘 보여줍니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>범주형 데이터 분석</span>"
    ]
  },
  {
    "objectID": "10-Categorical-data-analysis.html#연속성-수정",
    "href": "10-Categorical-data-analysis.html#연속성-수정",
    "title": "10  범주형 데이터 분석",
    "section": "10.3 연속성 수정",
    "text": "10.3 연속성 수정\n이제 잠깐 다른 이야기를 해 봅시다. 사실 지금까지 약간의 거짓말을 했습니다. 자유도가 1일 때 계산에서 약간의 조정을 해야 합니다. 이를 연속성 수정(continuity correction) 또는 Yates 수정(Yates correction)이라고 합니다. 앞서 언급한 것처럼, \\(\\chi^2\\) 검정은 근사치를 기반으로 합니다. 특히, 이 검정은 이항 분포가 \\(N\\)이 크면 정규 분포와 유사해진다는 가정을 기반으로 합니다. 하지만 이 가정이 항상 잘 맞지는 않으며, 특히 자유도가 1일 때(예: \\(2 \\times 2\\) 분할표에서 독립성 검정을 수행할 때) 문제가 좀 발생합니다.\n주된 이유는 \\(X^2\\) 통계량의 표본 분포가 실제로는 이산형이기 때문입다(왜냐하면 범주형 데이터를 다루고 있기 때문입니다!). 반면, \\(\\chi^2\\) 분포는 연속형이므로 체계적인 오류가 발생할 수 있습니다. 구체적으로 말하면, \\(N\\)이 작고 자유도가 1일 때 적합도 검정 통계량이 과대 평가되는 경향이 있습니다. 즉, 실제 \\(\\alpha\\) 값이 우리가 생각하는 것보다 커지며, 그에 따라 \\(p\\)-값도 실제보다 작아집니다.\nYates의 논문을 읽어본 바로는,11 이 수정은 기본적으로 일종의 임시방편입니다. 어떤 이론적 원칙에서 도출된 것이 아니라, 검정의 결과를 관찰하고 이를 보완하기 위해 도입된 방법입니다. jamovi에서는 ‘Statistics’ 옵션에서 ‘\\(\\chi^2\\) continuity correction’ 체크박스를 선택하여 이 수정을 적용할 수 있습니다.12",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>범주형 데이터 분석</span>"
    ]
  },
  {
    "objectID": "10-Categorical-data-analysis.html#효과-크기",
    "href": "10-Categorical-data-analysis.html#효과-크기",
    "title": "10  범주형 데이터 분석",
    "section": "10.4 효과 크기",
    "text": "10.4 효과 크기\n앞서 Section 9.8 에서 논의했듯이, 연구자들이 효과 크기를 보고하는 것이 점점 더 일반적인 관행이 되고 있습니다. 당신이 \\(\\chi^2\\) 검정을 수행했고, 유의미한 결과를 얻었다고 가정해봅시다. 즉, 독립성 검정을 수행했다면 변수 사이의 연관성이 있으며, 적합도 검정을 수행했다면 특정 확률로부터 편차가 존재한다는 사실을 알게 되었습니다. 이제 중요한 것은 이 연관성이나 편차가 얼마나 강한가에 대한 효과 크기를 측정하여 보고하기를 원할 것입니다.\n효과 크기를 측정하는 방법은 여러 가지가 있으며, 이를 계산할 수 있는 도구도 다양합니다. 여기서 모든 방법을 다루지 않고 가장 일반적으로 보고되는 효과 크기 지표에 집중하겠습니다.\n일반적으로 가장 많이 보고되는 두 가지 지표는 \\(\\phi\\) 통계량과 이를 보완한 크래머의 (V)(Cramér’s (V))입니다.\n수학적으로는 매우 간단합니다. \\(\\phi\\) 통계량을 계산하려면, \\(\\chi^2\\) 값을 표본 크기로 나눈 후 제곱근을 취하면 됩니다. \\[\\phi=\\sqrt{\\frac{X^2}{N}}\\] \\(\\phi\\) 통계량은 0(완전한 독립)에서 1(완전한 연관) 사이의 값을 가지도록 설계되었지만, 분할표 크기가 \\(2 \\times 2\\)보다 클 경우 \\(\\phi &gt; 1\\)이 될 수도 있습니다. 이는 꽤 불만족스러운 상황입니다.\n이 문제를 해결하기 위해 Cramer (1946) 는 \\(\\phi\\)를 조정한 \\(V\\) 통계량을 제안했습니다. 분할표가 r행 c열일 때, \\(k = \\min(r, c)\\) 를 두 값 중 작은 값으로 정의합니다. 그러면 크래머의 \\(V\\)는 다음과 같이 계산됩니다. \\[V=\\sqrt{\\frac{X^2}{N(k-1)}}\\]\n이제 끝났습니다. 크래머의 \\(V\\)는 계산이 쉽고, 논리적인 값을 제공하기 때문에 널리 사용되는 것으로 보입니다. 이 값은 0(완전한 독립)에서 1(완전한 연관) 사이에서 안정적으로 유지된다는 장점이 있습니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>범주형 데이터 분석</span>"
    ]
  },
  {
    "objectID": "10-Categorical-data-analysis.html#검정의-가정들",
    "href": "10-Categorical-data-analysis.html#검정의-가정들",
    "title": "10  범주형 데이터 분석",
    "section": "10.5 검정의 가정들",
    "text": "10.5 검정의 가정들\n모든 통계적 검정은 데이터에 대한 가정을 합니다. 그러므로 이러한 가정이 충족되는지 확인하는 것이 좋습니다. 이번 장에서 다룬 카이제곱 검정의 가정은 다음과 같습니다:\n\n기대 빈도가 충분히 커야 합니다. 이전 절에서 \\(\\chi^2\\) 표본 분포는 이항 분포가 정규 분포와 상당히 유사하기 때문에 도축된다고 설명했던 것을 기억하나요? Chapter 7 에서 논의한 것처럼, 이는 관측치의 수가 충분히 클 때만 성립합니다. 실질적으로 이것이 의미하는 바는 모든 셀의 기대 빈도들이 충분히 커야 한다는 것입니다. 그렇다면 ’충분히 크다’는 어느 정도일까요? 의견이 분분하지만, 일반적으로 모든 기대 빈도가 5보다 큰 것이 바람직하다는 것이 기본적인 가정입니다. 그러나 표의 크기가 클 경우, 기대 빈도의 80% 이상이 5보다 크고 어떤 셀도 1보다 작지 않으면 괜찮다고 여겨지기도 합니다. 하지만 제가 찾아본 바에 따르면(예: Cochran, 1954), 이러한 기준들은 엄격한 규칙이라기보다는 대략적인 지침으로 제안된 것이며, 다소 보수적인 경향이 있습니다(Larntz, 1978).\n데이터는 서로 독립적이어야 합니다. 카이제곱 검정의 다소 숨겨진 가정 중 하나는 관측치들이 서로 독립적이어야 한다는 것입니다. 무슨 의미인지 설명해보겠습니다. 특정 병원에서 태어나는 아기들 중 남자 아기의 비율에 관심이 있다고 가정해 봅시다. 산부인과 병동을 돌아다니며 20명의 여자 아기와 10명의 남자 아기를 관찰했습니다. 꽤 설득력 있는 차이로 보이죠? 그러나 나중에 알고 보니, 사실 저는 같은 병동을 10번이나 방문했고, 실제로는 여자 아기 2명과 남자 아기 1명만 본 것이었습니다. 이제는 결과가 그렇게 설득력 있어 보이지는 않죠? 데이터의 30개 관측치는 전혀 독립적이지 않았으며, 실제로는 3개의 독립된 관측치에 불과했습니다. 이는 극단적이고 (매우 어리석은) 예이지만, 기본적인 문제를 잘 보여줍니다. 비독립성은 결과를 왜곡합니다. 때로는 이로 인해 귀무가설을 잘못 기각하게 되기도 하고, 반대로 귀무가설을 잘못 유지하게 만들 수도 있습니다. 약간 덜 어리석은 예로, 카드 실험을 조금 다르게 했다고 가정해 봅시다. 200명에게 무작위로 카드를 하나 선택는 상상을 해 보라고 요청하는 대신, 50명에게 각각 4장의 카드를 고르라고 했다고 가정합시다. 이 경우, 모든 사람이 한 장의 하트, 한 장의 클럽, 한 장의 다이아몬드, 한 장의 스페이드를 고른다면 (이러한 결과는 “대표성 휴리스틱”에 부합됩니다(Tversky & Kahneman, 1974)), 이것은 매우 비무작위적인 행동입니다. 그리고 이 경우, 네 개의 무늬 각각에 대해 관측 빈도가 50으로 나타납니다. 이 예에서는 관측치가 비독립적이기 때문에 (선택한 네 장의 카드가 서로 연관되어 있기 때문) 반대의 효과가 나타나 귀무가설을 잘못 유지하게 됩니다.\n\n만약 독립성이 위배된 상황에 처하게 된다면, 맥네마 검정(곧 다룰 예정)이나 코크란 검정(이 책에서는 다루지 않음)을 사용할 수 있습니다. 마찬가지로 셀의 기대 빈도가 너무 작다면 피셔의 정확검정을 고려해보세요. 이제 이러한 주제들에 대해 살펴보겠습니다.\n\n\n\n\n\n\n대표성 휴리스틱이란\n\n\n\n대표성 휴리스틱(Representativeness Heuristic)은 사람들이 확률이나 빈도를 판단할 때, 실제 통계적 가능성보다는 얼마나 전형적(대표적)으로 보이는지에 따라 결정을 내리는 인지적 편향입니다. 쉽게 말해, 어떤 사건이나 대상을 “얼마나 그럴듯해 보이는지”에 따라 확률을 추정하는 경향을 말합니다. 대표성 휴리스틱에 대한 예를 들어 보겠습니다.\n\n동전을 6번 던졌을 때 다음 두 결과 중 어떤 것이 더 나올 법해 보이나요?\n\nA: H-T-H-T-T-H\nB: H-H-H-H-T-T\n\n많은 사람들은 A가 더 무작위적이고 가능성이 높다고 생각합니다. 하지만 실제로는 두 결과 모두 동일한 확률로 발생합니다. 사람들이 A를 더 가능성 있어 보인다고 느끼는 이유는 “무작위스러워 보이는” 패턴이 더 대표적이라고 여기기 때문입니다.\n린다 문제(Linda Problem): 심리학자 아모스 트버스키(Amos Tversky)와 대니얼 카너먼(Daniel Kahneman)이 제시한 유명한 문제입니다.\n\n린다는 31세이고, 외향적이며 총명하고, 철학을 전공했습니다. 학생 시절에는 사회 정의와 차별 문제에 깊이 관여했습니다. 린다가 다음 중 어떤 직업을 가질 가능성이 더 높을까요?\nA: 은행원\nB: 은행원이자 페미니스트 활동가\n\n많은 사람들이 B를 선택하지만, 이는 논리적 오류입니다. A(은행원) 범주는 B(은행원이자 페미니스트)의 범주를 포함하므로, A의 확률이 항상 같거나 더 높아야 합니다. 사람들이 B를 선택하는 이유는 린다에 대한 설명이 “페미니스트 활동가”라는 직업을 더 대표하고 있다고 느껴지기 때문입니다.\n\n그러면 왜 이런 현상이 발생할까요? 사람들은 인지적 단순화와 전형성을 가지고 판단하는 경향이 있기 때문입니다. 인지적 단순화란, 사람들은 복잡한 확률 계산 대신, 더 쉽고 빠르게 결론을 내릴 수 있는 방법을 선호한다는 것입니다. 전형성은 어떤 사건이 우리가 가진 고정관념이나 경험과 얼마나 잘 맞는지에 따라 우리의 판단이 좌우된다는 것입니다.\n대표성 휴리스틱은 인간이 복잡한 문제에 대해 빠르게 판단할 수 있도록 돕지만, 편향된 판단으로 이어질 수 있습니다. 예를 들어, 도박사의 오류(Gambler’s Fallacy)도 대표성 휴리스틱의 한 사례로, 사람들이 과거의 무작위 결과가 미래의 결과에 영향을 줄 것이라고 잘못 믿는 현상입니다. (예: 동전 앞면이 계속 나왔으니 다음엔 뒷면이 나올 거라고 생각하는 것입니다.)\n그러므로 통계나 데이터 해석에서는 이러한 인지적 편향을 경계하는 것이 중요합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>범주형 데이터 분석</span>"
    ]
  },
  {
    "objectID": "10-Categorical-data-analysis.html#피셔의-정확검정",
    "href": "10-Categorical-data-analysis.html#피셔의-정확검정",
    "title": "10  범주형 데이터 분석",
    "section": "10.6 피셔의 정확검정",
    "text": "10.6 피셔의 정확검정\n셀의 빈도 수가 너무 작지만 두 변수가 독립적이라는 귀무가설을 검정하고 싶다면 어떻게 해야 할까요? 한 가지 답은 “더 많은 데이터를 수집하라”는 것이겠지만, 이는 너무 단순한 해결책입니다. 많은 상황에서 추가 데이터를 수집하는 것이 비현실적이거나 비윤리적일 수 있습니다. 이런 경우에, 통계학자들은 과학자들에게 더 나은 검정 방법을 제공할 도덕적 의무가 있습니다. 그리고 이 문제에 대해 피셔(Fisher, 1922)가 적절한 해답을 제시했습니다.\n기본 개념을 설명하기 위해, 마녀로 고발된 사람들의 감정 상태를 조사하는 현장 실험 데이터를 분석한다고 가정해 봅시다. 고발된 사람 중 일부는 현재 화형에 처해지고 있습니다.13 과학자에게는 불행한 일이지만 (일반 대중에게는 다행스럽게도), 실제로 화형 중인 사람을 찾는 것이 쉽지 않기 때문에 일부 셀의 빈도 수가 매우 적습니다. salem.csv 데이터의 분할표는 이 점을 잘 보여줍니다(Table 10.10).\n\n\n\n\nTable 10.10. salem.csv 데이터의 분할표\n\n\n\n\n\n행복FALSETRUE\n\n화형FALSE310\n\nTRUE30\n\n\n\n\n\n\n\n이 데이터를 보면, 화형을 당하는 사람들이 그렇지 않은 사람들보다 행복할 가능성이 더 높다고 의심하지 않을 수 없습니다. 하지만 카이제곱 검정은 표본 크기가 너무 작기 때문에 이를 검정하기가 어렵습니다. 화형 당하고 싶지 않은 사람으로서, 저는 이보다 더 나은 답을 얻고 싶습니다. 이럴 때 피셔의 정확검정(Fisher’s exact test)(Fisher, 1922)이 매우 유용하게 사용됩니다.\n피셔의 정확검정은 카이제곱 검정(또는 이 책에서 다루는 다른 가설 검정들)과는 약간 다르게 작동합니다. 검정 통계량(test statistic)을 사용하지 않고, \\(p\\)-값을 “직접” 계산하기 때문입니다. 이제 \\(2 \\times 2\\) 분할표에 대해 이 검정이 어떻게 작동되는지 기본 개념을 설명하겠습니다. 이전과 마찬가지로, 몇 가지 기호를 정의하겠습니다(Table 10.11).\n\n\n\n\nTable 10.11. 피셔의 정확검정에서 사용되는 기호\n\n\n\n\n\n행복불행합계\n\n화형에 쳐해짐\\(O_{11}\\)\\(O_{12}\\)\\(R_{1}\\)\n\n화형에 쳐해지지 않음\\(O_{21}\\)\\(O_{22}\\)\\(R_{2}\\)\n\n합계\\(C_{1}\\)\\(C_{2}\\)\\( N \\)\n\n\n\n\n\n\n\n피셔는 검정을 구성하기 위해, 행과 열의 합계 \\((R_1, R_2, C_1, C_2)\\)를 고정된 값으로 간주한 후, 이러한 총합을 바탕으로 관측된 빈도수 \\((O_{11}, O_{12}, O_{21}, O_{22})\\)가 나올 확률을 계산합니다. Chapter 7 에서 정의한 기호를 사용하면, 이는 다음과 같이 표현할 수 있습니다:\n\\[P(O_{11}, O_{12}, O_{21}, O_{22} \\, | \\, R_1, R_2, C_1, C_2)\\]\n이 확률을 계산하는 것은 약간 복잡한 과정일 수 있습니다. 하지만, 이 확률은 초기하 분포(hypergeometric distribution)로 설명됩니다. 우리가 해야 할 일은 이 특정 분할표가 나올 확률이나, 이보다 “더 극단적인 분할표”가 나올 확률을 계산하는 것입니다.14\n1920년대에는 이 합계를 계산하는 것이 매우 어렵고 복잡했지만, 오늘날에는 표의 크기와 표본 크기가 너무 크지 않다면 쉽게 계산할 수 있습니다. 개념적으로 어려운 부분은 어떤 분할표가 다른 분할표보다 더 “극단적”인지 정의하는 것입니다. 가장 쉬운 방법은 확률이 가장 낮은 분할표를 가장 극단적인 것으로 간주하는 것입니다. 이렇게 하면 \\(p\\)-값을 구할 수 있습니다.\njamovi에서 이 검정을 수행하려면, ‘분할표’ 분석의 ‘통계’ 옵션에서 피셔의 정확검정에 대한 체크 박스를 선택하면 됩니다. salem.csv 파일의 데이터를 사용해 이 옵션을 적용하면, 피셔의 정확검정 통계량이 결과에 표시됩니다. 여기서 우리가 주목할 것은 \\(p\\)-값이며, 이 경우 \\(p = 0.036\\)으로 귀무가설(화형 당하는 사람과 당하지 않는 사람의 행복 수준은 같다)을 기각하기에 충분히 작습니다. 결과는 Figure 10.6 을 참조하세요.\n\n\n\n\n\n\n\n\nFigure 10.6. jamovi에서의 피셔의 정확 검정 분석\n\n\n\n\n\n\n\n\n\n\n\n실습: 피셔의 정확검정\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Salem’을 선택합니다.\n‘빈도’-‘분할표’-’독립 표본’을 선택합니다.\n왼편의 ‘분할표’ 창에서 happy를 ‘행’ 상자에, on.fire를 ‘열’ 상자로 이동합니다.\n‘통계’ 옵션을 확장한 후 ’검증’의 ’피셔의 정확한 검정’을 체크합니다. 그러면 다음 같이 카이제곱 검정뿐 아니라 피셔의 정확검정도 결과 창에서 볼 수 있습니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>범주형 데이터 분석</span>"
    ]
  },
  {
    "objectID": "10-Categorical-data-analysis.html#sec-The-McNemar-test",
    "href": "10-Categorical-data-analysis.html#sec-The-McNemar-test",
    "title": "10  범주형 데이터 분석",
    "section": "10.7 맥네마 검정",
    "text": "10.7 맥네마 검정\n당신이 오스트레일리아 일반 정치당(AGPP)에서 일하게 되었다고 가정해 봅시다. 당신의 업무 중 하나는 AGPP의 정치 광고 효과를 평가하는 것입니다. 그래서 \\(N = 100\\) 명의 사람들을 모집하여 AGPP 광고를 시청하게 합니다. 광고를 보기 전에, 그들에게 AGPP에 투표할 의향이 있는지 물어보고, 광고 시청 후 다시 의견이 바뀌었는지를 확인합니다. 물론, 이 일이 능숙하다면 이 외에도 많은 조사를 하겠지만, 여기서는 이 단순한 실험만을 고려해 보겠습니다. 데이터를 기술하는 한 가지 방법은 Table 10.12 에 나타난 분할표를 사용하는 것입니다.\n\n\n\n\nTable 10.12. AGPP 정치 광고에 대한 데이터 분할표\n\n\n\n\n\n이전이후합계\n\nYes301040\n\nNo7090160\n\n합계100100200\n\n\n\n\n\n\n\n처음에는 이 상황이 피어슨의 카이제곱(\\(\\chi^2\\)) 독립성 검정에 적합하다고 생각할 수 있습니다 ([독립성(또는 연관성)에 대한 \\(\\chi^2\\) 검정)] 참고). 그러나 조금 더 생각해 보면 문제가 있다는 것을 알게 됩니다. 100명의 참가자지만 200개의 관측값이 있습니다. 이는 각 참가자가 광고 전(before)과 광고 후(after)에 각각 답변을 했기 때문입니다. 즉, 200개의 관측값이 서로 독립적이지 않다는 의미입니다. 만약 A 유권자가 첫 번째 질문에 “예”라고 답하고, B 유권자가 “아니오”라고 답했다면, A 유권자가 두 번째 질문에도 “예”라고 답할 가능성이 B 유권자보다 높을 것입니다. 이로 인해 독립성 가정이 위배되므로, 일반적인 \\(\\chi^2\\) 검정은 신뢰할 수 없는 결과를 제공합니다.\n이 상황이 드물다면 굳이 설명하지 않았겠지만, 이러한 상황은 매우 흔합니다. 이는 표준 반복 측정 설계에 해당하며, 지금까지 다룬 어느 검정도 이를 처리할 수 없습니다.\n이 문제에 대한 해결책은 맥네마(McNemar, 1947)에 의해 제시되었습니다. 핵심은 데이터를 약간 다른 방식으로 표로 정리하는 것입니다(Table 10.13).\n\n\n\n\nTable 10.13. 반복 측정 데이터를 다르게 정리하기\n\n\n\n\n\n이후: No이후: Yes합계\n\n이전: No65570\n\n이전: Yes25530\n\n합계9010100\n\n\n\n\n\n\n\n이제 우리의 귀무가설이 무엇인지 생각해 봅시다. 그것은 “광고 전”과 “광고 후”에 AGPP에 투표하겠다고 말하는 사람들의 비율이 같다는 것입니다. 데이터를 이렇게 재구성했기 때문에, 우리는 이제 행의 합과 열의 합이 동일한 분포에서 나왔다는 가설을 검정하게 됩니다. 따라서, 맥네마 검정에서 귀무가설은 “한계 동질성(marginal homogeneity)”입니다. 즉, 행의 합과 열의 합이 동일한 분포를 가진다는 것입니다:15\n\\[P_a + P_b = P_a + P_c\\]\n\\[P_c + P_d = P_b + P_d\\]\n따라서 귀무가설은 \\(P_b = P_c\\)로 단순화됩니다. 다시 말해, 맥네마 검정에서는 비대각선(off-diagonal) 항목(즉, \\(b\\)와 \\(c\\))만이 중요합니다! 이 점을 이해하면 한계 동질성 멕네마 검정(McNemar test of marginal homogeneity)은 일반적인 \\(\\chi^2\\) 검정과 다르지 않습니다.\nYates 보정을 적용한 후, 검정 통계량은 다음과 같습니다:\n\\[\\chi^2 = \\frac{(|b - c| - 0.5)^2}{b + c}\\]\n또는, 이 장에서 사용한 기호로 표현하면:\n\\[\\chi^2 = \\frac{(|O_{12} - O_{21}| - 0.5)^2}{O_{12} + O_{21}}\\]\n이 통계량은 자유도 \\(df = 1\\)인 \\(\\chi^2\\) 분포를 (근사적으로) 따릅니다. 그러나 다른 \\(\\chi^2\\) 검정과 마찬가지로 근사치일 뿐이므로, 셀의 기대 빈도가 충분히 커야 신뢰할 수 있는 결과를 얻을 수 있습니다.\n\n10.7.1 jamovi에서 맥네마 검정 수행하기\n\n\n\n\n\n\n\n\nFigure 10.7. jamovi에서의 맥네마 검정 결과\n\n\n\n\n\n맥네마 검정이 무엇인지 알았으니, 실제로 검정을 실행해 봅시다. agpp.csv 파일에는 앞서 설명한 데이터가 들어 있습니다. 이 agpp 데이터 세트에는 세 개의 변수가 포함되어 있습니다:\n\nid: 각 참가자를 식별하는 변수 (잠시 후 왜 유용한지 설명합니다)\n\nresponse_before: 첫 번째로 질문을 받았을 때 참가자의 답변\n\nresponse_after: 같은 질문을 두 번째로 받았을 때의 답변\n\n참가자는 이 데이터 세트에 한 번씩만 등장합니다. jamovi에서 ‘분석’-‘빈도’-‘분할표’-‘대응 표본’으로 이동한 다음, response_before를 ’행’ 박스로, response_after를 ‘열’ 박스로 옮기세요. 그러면 결과 창에 분할표가 나타나고, 그 아래에 맥네마 검정의 결과가 표시됩니다. Figure 10.7 을 참고하세요.\n이제 완료되었습니다! 우리는 방금 맥네마 검정을 통해 광고 시청 전후로 AGPP에 투표할 가능성이 변하지 않았는지를 확인했습니다. 검정 결과는 유의미했습니다 (\\(\\chi^2(1)= 12.03, p&lt; .001\\)), 이는 사람들이 광고를 본 후에도 AGPP에 투표할 가능성이 변하였다는 것을 시사합니다. 실제로 결과를 보면 광고가 부정적인 효과를 준 것 같습니다. 사람들은 광고를 본 후 AGPP에 투표할 가능성이 줄어들었습니다. 이는 일반적인 정치 광고의 품질을 고려하면 그다지 놀랄 일이 아닙니다.\n\n\n\n\n\n\n실습: 멕네마 검정\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’AGPP’를 선택합니다.\n‘빈도’-‘분할표’-’대응 표본’을 선택합니다.\n왼편의 ‘대응표본 빈도 표’ 창에서 response_before를 ‘행’ 상자에, response_after를 ‘열’ 상자로 이동합니다.\n의견이 바뀐 사람의 수(대각선 셀들)가 크지 않으므로 연속성 수정을 위해 \\(X^2\\) continuity correction을 체크합니다. 그러면 Figure 10.7 같이 멕네마 검정의 결과를 결과 창에서 볼 수 있습니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>범주형 데이터 분석</span>"
    ]
  },
  {
    "objectID": "10-Categorical-data-analysis.html#맥네마-검정과-독립성-검정의-차이점",
    "href": "10-Categorical-data-analysis.html#맥네마-검정과-독립성-검정의-차이점",
    "title": "10  범주형 데이터 분석",
    "section": "10.8 맥네마 검정과 독립성 검정의 차이점",
    "text": "10.8 맥네마 검정과 독립성 검정의 차이점\n이 장의 처음으로 돌아가서 카드 데이를 다시 살펴봅시다. 기억하시겠지만, 실제 실험 설계에서는 사람들이 두 번의 선택을 했습니다. 우리는 모든 참가자의 첫 번째 선택과 두 번째 선택에 대한 정보를 가지고 있기 때문에, 이를 기반으로 첫 번째 선택과 두 번째 선택을 교차 분석한 분할표를 만들 수 있습니다(Figure 10.8 위의 표).\n\n두 번째 선택이 첫 번째 선택에 영향을 받는지 알고 싶다면, 이때 독립성 검정이 유용합니다. 이 검정은 이 표의 행과 열 사이에 관계가 있는지 확인하는 데 중점을 둡니다.\n반대로, 두 번째 선택에서 평균적으로 무늬 선택 빈도가 첫 번째 선택과 다른지 알고 싶다면, 이때는 행의 합과 열의 합이 다른지를 확인하는 것입니다. 이러한 경우에는 맥네마 검정을 사용합니다.\n이러한 두 가지 다른 분석에서 생성된 검정 결과가 Figure 10.8 에 있습니다. 결과가 다르다는 것에 주목하세요! 이 두 검정은 동일한 검정이 아닙니다.\n\n\n\n\n\n\n\n\nFigure 10.8. Randomness.omv (카드 데이터)로 수행한 독립성 검정 vs. 대응표본 검정(맥네마 검정)\n\n\n\n\n\n\n\n\n\n\n\n실습: 카드 데이터에 대한 독립성 검점과 멕네마 검정\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Randomness’를 선택합니다.\n두 번의 선택이 연관성이 있는지를 보기 위해 ‘빈도’-‘분할표’-’독립 표본’을 선택합니다.\n왼편의 ‘분할표’ 창에서 choice_1을 ‘행’ 상자에, choice_2를 ‘열’ 상자로 이동합니다. 그러면 Figure 10.8 상단 같은 독립성 검정의 결과가 결과 창에 나타납니다.\n‘빈도’-‘분할표’-’대응 표본’을 선택합니다.\n왼편의 ‘대응표본 빈도 표’ 창에서 choice_1을 ‘행’ 상자에, choice_2를 ‘열’ 상자로 이동합니다. 그러면 Figure 10.8 하단 같은 맥네마 검정의 결과가 결과 창에 나타납니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>범주형 데이터 분석</span>"
    ]
  },
  {
    "objectID": "10-Categorical-data-analysis.html#요약",
    "href": "10-Categorical-data-analysis.html#요약",
    "title": "10  범주형 데이터 분석",
    "section": "10.9 요약",
    "text": "10.9 요약\n이 장에서 다룬 핵심 아이디어는 다음과 같습니다:\n\n\\(\\chi^2\\) (카이제곱) 적합도 검정은 여러 범주의 관측 빈도표가 있을 때 사용합니다. 이때 귀무가설은 관측 도수와 비교할 수 있는 범주별 확률을 주장합니다.\n\n독립성(또는 연관성)에 대한 \\(\\chi^2\\) 검정은 두 범주형 변수의 분할표(교차표)가 있을 때 사용합니다. 이때 귀무가설은 두 변수 사이에 관계나 연관성이 없다는 것입니다.\n\n효과 크기는 분할표의 경우 여러 방식으로 측정할 수 있습니다. 그중 크래머의 V(Cramér’s \\(V\\)) 통계량에 대해 언급했습니다.\n\n피어슨 검정의 두 가지 버전 모두 두 가지 가정에 의존합니다. 기대 빈도가 충분히 크다라는 것과 관측값이 독립적이라는 것입니다(검정의 가정들). 기대 빈도가 작을 때는 피셔의 정확검정을 사용할 수 있고, 독립성 위반 같은 경우에는 맥네마 검정을 사용할 수 있습니다.\n\n범주형 데이터 분석에 대해 더 배우고 싶다면, Agresti (1996) 의 Introduction to Categorical Data Analysis가 좋은 첫걸음이 될 것입니다. 제목에서 알 수 있듯이, 이 책은 범주형 데이터 분석의 입문서로서 훌륭합니다. 만약 입문서가 충분하지 않거나, 당신이 작업 중인 문제를 해결할 수 없다면, Agresti (2002) 의 Categorical Data Analysis를 고려해 볼 수 있습니다. 이 책은 더 심화된 내용을 다루므로, 바로 이 책으로 넘어가는 것은 권장하지 않습니다.\n\n\n\n\nAgresti, A. (1996). An introduction to categorical data analysis. Wiley. https://doi.org/10.1002/0470114754\n\n\nAgresti, A. (2002). Categorical data analysis (2nd ed.). Wiley. https://doi.org/10.1002/0471249688\n\n\nCochran, W. G. (1954). The \\(\\chi^2\\) test of goodness of fit. The Annals of Mathematical Statistics, 23, 315–345. https://doi.org/10.1214/aoms/1177729380\n\n\nCramer, H. (1946). Mathematical methods of statistics. Princeton University Press. https://doi.org/10.1515/9781400883868\n\n\nFisher, R. A. (1922). On the interpretation of \\(\\chi^2\\) from contingency tables, and the calculation of \\(p\\). Journal of the Royal Statistical Society, 84, 87–94. https://doi.org/10.1111/j.2397-2335.1922.tb00768.x\n\n\nHogg, R. V., McKean, J. V., & Craig, A. T. (2005). Introduction to mathematical statistics (6th ed.). Pearson.\n\n\nLarntz, K. (1978). Small-sample comparisons of exact levels for chi-squared goodness-of-fit statistics. Journal of the American Statistical Association, 73, 253–263. https://doi.org/10.1080/01621459.1978.10481567\n\n\nPearson, K. (1900). On the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling. Philosophical Magazine, 50, 157–175. https://doi.org/10.1080/14786440009463897\n\n\nSokal, R. R., & Rohlf, F. J. (1994). Biometry: The principles and practice of statistics in biological research (3rd ed.). Freeman.\n\n\nTversky, A., & Kahneman, D. (1974). Judgment under uncertainty: Heuristics and biases. Science, 185(4157), 1124–1131. https://doi.org/10.1126/science.185.4157.1124\n\n\nYates, F. (1934). Contingency tables involving small numbers and the \\(\\chi^2\\) test. Supplement to the Journal of the Royal Statistical Society, 1, 217–235. https://doi.org/10.2307/2983604",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>범주형 데이터 분석</span>"
    ]
  },
  {
    "objectID": "10-Categorical-data-analysis.html#footnotes",
    "href": "10-Categorical-data-analysis.html#footnotes",
    "title": "10  범주형 데이터 분석",
    "section": "",
    "text": "때때로 “chi-squared”라고도 합니다.↩︎\n벡터는 동일한 유형의 데이터 요소들이 연속적으로 나열된 것입니다:↩︎\n적합도 통계량의 공식을 \\(k - 1\\)개의 독립적인 요소들의 합으로 다시 작성하면, “정확한” 표본 분포를 얻을 수 있으며, 이는 자유도가 \\(k - 1\\)인 카이제곱 분포를 따릅니다. 이 책은 입문서이므로 그 수학적 과정을 자세히 설명하는 것은 범위를 벗어납니다. 여기서는 단지 적합도 통계량이 왜 카이제곱 분포와 연결되는지에 대한 개념적인 이해를 돕는 것이 목적입니다.↩︎\n여기에서 설명하는 개념은 다소 단순화된 것입니다. 이 개념은 여러 상황에 적절하게 적용되지만, 가끔 자유도가 정수가 아닌 값을 가질 수도 있습니다. 이러한 경우 너무 걱정할 필요는 없습니다. 자유도라는 개념 자체가 다소 복잡한 개념이며, 여기서 설명하는 간단한 이야기가 전부는 아닙니다. 입문 과정에서는 단순한 설명을 유지하는 것이 일반적으로 가장 좋지만, 자유도 개념이 완전히 단순하지 않다는 점을 미리 알려두는 것이 중요하다고 생각했습니다. 그렇지 않으면 나중에 \\(df = 3.4\\) 같은 값을 보게 되었을 때, 제가 아직 말하지 않은 무언가가 있다고 이해하는 것이 아니라 여러분이 잘못 이해했다고 혼란스러워할 수도 있기 때문입니다.↩︎\n실무에서는 표본 크기가 항상 고정된 것은 아닙니다. 예를 들어, 실험을 일정한 기간 동안 진행하고, 참여하는 사람 수는 해당 기간 동안 몇 명이 참여하는지에 따라 결정될 수도 있습니다. 하지만 여기서는 이러한 상황을 고려할 필요는 없습니다.↩︎\n사실, 통계 보고 방식의 관례는 학문 분야마다 조금씩 다릅니다. 나는 심리학에서의 표준 방식을 따르고 있습니다(내 전공이기 때문입니다). 하지만 독자가 결과를 검증할 수 있도록 충분한 정보를 제공하는 것은 어느 분야에서든 보편적으로 중요한 원칙이라고 생각합니다.↩︎\n어떤 사람들에게는 이러한 조언이 기술 보고서를 작성하는 “일반적인” 방식과 충돌하는 것처럼 들릴 수도 있습니다. 일반적으로 학생들은 “결과” 절에 데이터를 기술하고 통계 분석을 보고하며, “논의” 절에서 해석을 제공해야 한다고 배웁니다. 이는 기본적으로 맞는 말이지만, 너무 문자 그대로 받아들이지 않는 것이 중요합니다. 나는 보통 결과 절에서 데이터를 간단하게 해석하여 독자가 내용을 이해할 수 있도록 돕고, 논의 절에서는 내 결과가 기존 과학 문헌과 어떻게 연결되는지를 설명합니다. 즉, “해석은 논의 절에서 해야 한다”는 조언 때문에 결과 절이 난해한 정보 덩어리가 되지 않도록 주의하세요. 독자가 내용을 이해하는 것이 훨씬 더 중요합니다.↩︎\n아주 면밀하게 읽었거나 저처럼 수학적으로 꼼꼼함 사람이라면, 지난 절에서 카이제곱 검정을 보고한 방식에서 뭔가 이상하다고 느낄 수도 있습니다. “\\(\\chi^2(3) = 8.44\\)”라고 쓰는 것이 뭔가 잘못된 것처럼 보일 수도 있습니다. 결국, 8.44라는 값은 적합도 검정 통계량이므로, \\(X^2 = 8.44\\) 또는 \\(GOF = 8.44\\)라고 써야 하지 않을까요? 이는 표본 분포(즉, 자유도가 3인 \\(\\chi^2\\))와 검정 통계량(즉, \\(X^2\\))을 혼동하는 것처럼 보입니다. 아마도 단순한 오타라고 생각할 수도 있습니다. \\(\\chi\\)와 \\(X\\)가 상당히 비슷하게 생겼기 때문이죠. 그런데, 사실 그렇지 않습니다. “\\(\\chi^2(3) = 8.44\\)”라고 쓰는 것은 “검정 통계량의 표본 분포는 \\(\\chi^2(3)\\)이며, 검정 통계량의 값은 8.44이다”를 압축해서 표현한 것입니다. 어떤 의미에서는 이것이 다소 어리석게 보일 수도 있습니다. \\(\\chi^2\\) 분포를 따르는 여러 가지 검정 통계량이 존재하기 때문입니다. 우리가 적합도 검정에서 사용한 \\(X^2\\) 통계량은 여러 개 중 하나일 뿐입니다(비록 가장 일반적으로 사용되는 것 중 하나이지만요). 만약 이상적으로 완벽하게 직조된 세계라면, 검정 통계량과 표본 분포에 대해 각각 별도의 명칭을 가졌을 것입니다. 그렇게 하면, 통계 블록 자체가 연구자가 실제로 계산한 것이 무엇인지 명확하게 알려주겠죠. 때때로 이런 일이 실제로 발생하기도 합니다. 예를 들어, 피어슨 적합도 검정에서 사용되는 검정 통계량은 \\(X^2\\)로 쓰이지만, \\(G\\)-검정이라고 불리는 유사한 검정에서는 검정 통계량이 \\(G\\)로 표시됩니다 (Sokal & Rohlf, 1994). 흥미롭게도 피어슨 적합도 검정과 \\(G\\)-검정은 동일한 귀무가설을 검정하며, 표본 분포도 동일합니다(즉, 자유도가 \\(k - 1\\)인 카이제곱 분포를 따름). 만약 제가 카드 데이터에 대해 적합도 검정 대신 \\(G\\)-검정을 수행했다면, 검정 통계량 \\(G = 8.65\\)를 얻게 되었을 것입니다. 이는 이전에 얻은 \\(X^2 = 8.44\\)보다 약간 다른 값이며, \\(p\\)-값도 조금 더 작아져서 \\(p = .034\\)가 됩니다. 만약 일반적인 관례가 “검정 통계량, 표본 분포, p-값” 순서대로 보고하는 것이었다면, 두 결과는 다음과 같이 서로 다른 통계 블록을 갖게 되었을 것입니다: 원래 결과는 “\\(X^2 = 8.44\\), \\(\\chi^2(3)\\), \\(p = .038\\)”로, 새로운 \\(G\\)-검정 결과는 “\\(G = 8.65\\), \\(\\chi^2(3)\\), \\(p = .034\\)”로 보고되었을 것입니다. 그러나 현재의 압축된 보고 방식에서는 원래 결과가 “\\(\\chi^2(3) = 8.44, p = .038\\)”로, 새로운 결과가 “\\(\\chi^2(3) = 8.65, p = .034\\)”로 보고되므로, 실제로 어떤 검정을 수행했는지가 명확하지 않습니다. 그렇다면 왜 통계 블록이 수행된 검정을 명확히 지정하지 않는 세상에서 우리는 살게 된 것일까요? 근본적인 이유는 세상이 지저분하게 얽혀있기 때문입니다. 우리는(통계 도구의 사용자로서) 모든 것이 깔끔하고 체계적으로 정리되어 있기를 원합니다. 마치 잘 설계된 제품처럼 보이기를 바라지만, 현실의 삶이란 그런 것이 아닙니다. 통계학도 다른 학문과 마찬가지로 방대하게 분산된, 부분적으로 협력적이며 부분적으로 경쟁적인 프로젝트입니다. 그 누구도 그 전모를 완전히 이해하지 못하는 분야이기도 합니다. 우리가 데이터 분석 도구로 사용하는 것들은 통계의 신이 존재하여 이를 창조한 것이 아닙니다. 단지, 여러 사람들이 연구 논문으로 발표하고, 다양한 사람들이 이를 구현하고 수정하고, 또 다른 사람들이 교재를 통해 학생들에게 설명하는 과정을 거쳐 발전해 왔을 따름입니다. 그 결과, 이름조차 없는 검정 통계량도 많으며, 그 결과 대응하는 표본 분포와 동일한 이름을 가지게 되는 경우가 많습니다. 나중에 보겠지만, \\(\\chi^2\\) 분포를 따르는 검정 통계량은 보통 “카이제곱 통계량”이라고 불리고, \\(t\\) 분포를 따르는 것은 “\\(t\\)-통계량”이라고 불립니다. 그러나 \\(\\chi^2\\)와 \\(G\\)의 예시에서 보았듯이, 동일한 표본 분포를 따른다고 해서 동일한 검정 통계량인 것은 아닙니다. 따라서, 특히 특이한 검정을 수행한 경우에는 실제로 수행한 검정이 무엇인지 명확히 하는 것이 좋은 아이디어입니다. 단순히 “카이제곱 검정”이라고만 하면 정확히 어떤 검정을 의미하는지 명확하지 않을 수 있습니다. 다만, 가장 카이제곱 검정의 가장 일반적 형태가 적합도 검정과 독립성 검정이므로, 통계학을 배운 독자들은 대개 이를 유추할 수 있을 것입니다. 하지만 이 점은 항상 염두에 두어야 합니다.- \\(^a\\) 복잡하게 만드는 것이지만, \\(G\\)-검정은 가능도비(우도비) 검정(likelihood ratio test; LRT)의 특수한 경우입니다. 이 책에서는 LRT를 다루지는 않지만, 알아두면 꽤 편리한 개념입니다.↩︎\n기술적인 주석. 여기서 설명하는 방식은 열 합계가 고정되어 있고(즉, 연구자가 의도적으로 87명의 로봇과 93명의 인간을 조사했다고 가정) 행 합계는 확률적으로 결정된 것(즉, 28명이 강아지를 선택한 것은 조사 결과)으로 간주하였습니다. 수리 통계학 교재 (Hogg et al., 2005)에서 사용된 용어를 따르자면, 이는 사실상 카이제곱 동질성 검정(chi-square test of homogeneity)이라고 해야 하고, 행과 열 합계가 모두 실험에서 확률적 결과일 때만 카이제곱 독립성 검정(chi-square test of independence)이라는 용어를 사용해야 합니다. 이 책의 초기 초안에서는 두 개념을 구분했으나, 결국 두 검정이 동일하다는 사실을 알게 되어 하나로 합쳤습니다.↩︎\n현실에서 많은 사람들이 걱정하는 문제입니다.↩︎\nYates (1934) 는 간단한 해결책을 제안했습니다. 적합도 검정 통계량을 다음과 같이 재정의하는 것이다. \\[\\chi^{2}=\\sum_{i}\\frac{(|E_i-O_i|-0.5)^2}{E_i}\\] 기본적으로 모든 차이에 대해 0.5를 빼주는 방식입니다.↩︎\n&lt;역주&gt; 이 예에서는 \\(N\\)이 크므로 연속성 수정이 \\(p\\)-값에 크게 영향을 주지 않습니다. 또한 연속성 수정은 현재 그리 중요한 내용이 아닙니다. 피셔의 정확검정(Fisher’s exact test)는 이산 분포를 사용하여 이산형 검정량을 검정하기 때문에 이러한 문제가 없습니다. 과거에는 컴퓨팅 용량의 한계로 피셔의 정확검정이 어려웠지만 지금은 더 이상 문제가 되지 않습니다. 그러므로 \\(N\\)이 작은 경우에는 피셔의 정확검점을 하는 것이 좋습니다.↩︎\n이 예제는 Journal of Irreproducible Results에 실린 농담 기사에 기반한 것입니다.↩︎\n예상할 수 있듯이, 피셔의 정확 검정은 네이만이 아닌 피셔의 \\(p\\)-값 해석에 기반합니다. 자세한 내용은 Section 9.5 를 참조하세요.↩︎\n&lt;역주&gt; 여기서는 분할표의 셀을 맨 위의 행부터 시작하여 a, b, c, d로 명명하였다고 가정하고 있습니다.↩︎",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>범주형 데이터 분석</span>"
    ]
  },
  {
    "objectID": "11-Comparing-two-means.html",
    "href": "11-Comparing-two-means.html",
    "title": "11  두 평균 비교하기",
    "section": "",
    "text": "11.1 단일 표본 \\(z\\)-검정\n이 절에서는 통계에서 가장 쓸모없는 검정 중 하나인 \\(z\\)-검정을 설명하려고 합니다. 정말로! 이 검정은 실제로 거의 사용되지 않습니다. 유일한 진짜 목적은 통계를 가르칠 때 매우 편리한 징검다리 역할을 한다는 것입니다. 이는 아마도 통계에서 가장 (과도하게) 많이 사용되는 도구인 \\(t\\)-검정을 이해하는 과정에서 유용하기 때문입니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>두 평균 비교하기</span>"
    ]
  },
  {
    "objectID": "11-Comparing-two-means.html#단일-표본-z-검정",
    "href": "11-Comparing-two-means.html#단일-표본-z-검정",
    "title": "11  두 평균 비교하기",
    "section": "",
    "text": "11.1.1 검정이 해결하려는 추론 문제\n\\(z\\)-검정의 개념을 소개하기 위해 간단한 예제를 사용해 보겠습니다. 내 친구인 Zeppo 박사는 자신의 기초 통계학 수업을 곡선 채점 방식으로 평가합니다. 그의 수업의 평균 성적은 \\(67.5\\), 표준편차는 \\(9.5\\)라고 합시다. 그의 수백 명의 학생 중에서 20명이 심리학 수업도 수강합니다. 나는 호기심이 생겨서 심리학을 수강하는 학생들이 다른 학생들과 동일한 성적을 받는지(즉, 평균 \\(67.5\\)) 아니면 더 높은지 또는 낮은지 알고 싶어졌습니다. Zeppo 박사는 나에게 zeppo.csv 파일을 이메일로 보내 주었고, 나는 jamovi의 스프레드시트 보기에서 해당 학생들의 성적을 확인한 후, ‘탐색’—’기술통계’에서 평균을 계산했습니다.2 그 결과 평균값은 \\(72.3\\)이었습니다.\n\n50 60 60 64 66 66 67 69 70 74 76 76 77 79 79 79 81 82 82 89\n\n흠. 심리학 수강생들이 일반적으로 조금 더 높은 점수를 받는 것일 수도 있습니다. 표본 평균 \\(\\bar{X} = 72.3\\)은 가정된 모집단 평균 \\(\\mu = 67.5\\)보다 꽤 높은 편이지만, 한편으로는 표본 크기가 \\(N = 20\\)에 불과합니다. 어쩌면 단순한 우연일 수도 있습니다.\n이 질문에 답하려면 내가 알고 있는 내용을 명확하게 정리하는 것이 도움이 됩니다. 우선, 표본 평균은 \\(\\bar{X} = 72.3\\)임을 알고 있습니다. 심리학 수강생들이 다른 학생들과 동일한 표준편차를 가진다고 가정한다면, 모집단 표준편차는 \\(\\sigma = 9.5\\)라고 할 수 있습니다. 또한 Zeppo 박사가 곡선 채점 방식을 사용하고 있기 때문에 심리학 수강생들의 성적이 정규 분포를 따른다고 가정할 것입니다.\n\n\n\n\n\n\n\n\nFigure 11.1. 심리학 수강생들의 성적이 생성되었다고 가정하는 이론적 분포(실선)\n\n\n\n\n\n다음으로, 내가 데이터에서 얻고자 하는 정보를 명확히 하는 것이 중요합니다. 이번 경우 내 연구 가설은 심리학 수강생들의 모집단 평균 \\(\\mu\\)에 관한 것이며, 이는 현재 알려지지 않았습니다. 구체적으로 나는 \\(\\mu = 67.5\\)인지 아닌지를 알고 싶습니다. 이것이 내가 알고 있는 사실이라면, 우리의 문제를 해결할 수 있는 가설 검정을 고안할 수 있을까요? 데이터와 함께, 데이터가 생성되었다고 가정하는 분포를 Figure 11.1 에 나타냈습니다. 확실한 답을 찾기가 쉽지 않네요. 그렇지 않은가요? 이를 해결하려면 통계적 기법이 필요합니다.\n\n\n\n\n\n\nTip 11.1. 실습: 심리학 수강생의 통계학 점수\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Zeppo’를 선택합니다.\n‘데이터’ 메뉴를 선택한 후, 스프레드시트에서 x의 열이름을 더블클릭합니다. 그러면 x의 척도유형을 ’명명척도’에서 ’연속변수’로 바꿉니다.\n‘탐색’-‘기술통계’ 메뉴를 선택합니다.\n왼편의 ‘기술통계’ 창에서 x를 ‘변수’ 상자로 이동합니다.\n‘도표’ 옵션을 확장하여 ’히스토그램’을 체크합니다. 그러면 다음 같이 x의 평균 등의 기술통계량과 히스토그램을 확인할 수 있습니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.1.2 가설 검정 구성하기\n가설 검정을 구성하는 첫 번째 단계는 귀무가설과 대립가설이 무엇인지 명확히 하는 것입니다. 이는 그리 어렵지 않습니다. 우리의 귀무가설 \\(H_0\\)는 심리학 학생들의 실제 모집단 평균 \\(\\mu\\)가 \\(67.5\\)라는 것이며, 대립가설은 모집단 평균이 \\(67.5\\)가 아니라는 것입니다. 이를 수학적 표기법으로 나타내면 다음과 같습니다:\n\\[ H_0:\\mu= 67.5 \\] \\[ H_1:\\mu \\neq 67.5 \\]\n하지만 솔직히 말하면, 이 표기법이 문제에 대한 우리의 이해를 크게 향상시키지는 않습니다. 이는 단지 우리가 데이터에서 배우려는 내용을 간결하게 표현하는 방법일 뿐입니다. 우리의 검정을 위한 귀무가설 \\(H_0\\)와 대립가설 \\(H_1\\)은 Figure 11.2 에 예시되어 있습니다. 이러한 가설을 설정하는 것 외에도, 앞서 설명한 시나리오는 우리에게 유용할 수 있는 배경 정보를 제공합니다. 특히, 우리는 다음 두 가지 중요한 정보를 추가할 수 있습니다:\n\n심리학 성적은 정규 분포를 따른다.\n이 점수들의 실제 표준편차 \\(\\sigma\\)는 \\(9.5\\)로 알려져 있다.\n\n현재로서는 이 정보가 절대적으로 신뢰할 수 있는 사실이라고 가정할 것입니다. 실제로는 절대적으로 신뢰할 수 있는 배경 지식이 존재하지 않으며, 이러한 배경 지식에 의존하고자 한다면 이를 가정해야 합니다. 그러나 이러한 가정은 맞을 수도 그렇지 않을 수도 있으므로, 가정이 정당한지 확인해야 할 수도 있습니다. 하지만 지금은 단순한 접근 방식을 취하도록 하겠습니다.\n\n\n\n\n\n\n\n\nFigure 11.2. 단일 표본 \\(z\\)-검정(양측 검정)의 귀무 가설과 대립 가설에 대한 그래픽적 설명. 귀무 가설과 대립 가설 모두 모집단 분포가 정규분포를 따른다고 가정하며, 추가적으로 모집단의 표준편차가 알려져 있고 특정 값 \\(σ_0\\)로 고정되어 있다고 가정합니다. 귀무 가설(왼쪽)은 모집단 평균 \\(μ\\)가 특정 값 \\(μ_0\\)와 같다는 것이다. 대립 가설(오른쪽)은 모집단 평균이 이 값과 다르다는 것입니다, 즉 \\(μ ≠ μ_0\\).\n\n\n\n\n\n다음 단계는 \\(H_0\\)와 \\(H_1\\)을 구별하는 데 도움이 되는 적절한 검정 통계량을 찾는 것입니다. 가설들이 모두 모집단 평균 \\(\\mu\\)와 관련되어 있으므로, 표본 평균 \\(\\bar{X}\\)가 유용한 출발점이 될 것이라고 확신할 수 있습니다. 우리가 할 수 있는 일은 표본 평균 \\(\\bar{X}\\)와 귀무가설이 예측하는 모집단 평균 사이의 차이를 살펴보는 것입니다. 이 예제에서는 \\(\\bar{X} - 67.5\\)를 계산하는 것입니다. 보다 일반적으로, 귀무가설이 주장하는 모집단 평균 값을 \\(\\mu_0\\)라고 하면 다음을 계산해야 할 것입니다:\n\\[\\bar{X}-\\mu_0\\]\n이 값이 0에 가깝다면 귀무가설이 타당하게 여겨지지만, 이 값이 0에서 멀리 떨어져 있다면 귀무가설을 유지할 가치가 적어 보입니다. 그러면 얼마나 멀리 떨어져야 \\(H_0\\)를 기각하는 게 좋을까요?\n이를 알아내려면 좀 더 세밀한 접근이 필요하며, 앞서 언급한 두 가지 배경 정보를 활용해야 합니다. 즉, 원래 데이터가 정규 분포를 따르고 있으며 모집단 표준편차 \\(\\sigma\\)를 알고 있다는 점입니다. 만약 귀무가설이 참이라면, 즉 실제 평균이 \\(\\mu_0\\)라면, 우리가 데이터의 전체 모집단 분포를 알고 있음을 의미합니다. 즉, 평균이 \\(\\mu_0\\)이고 표준편차가 \\(\\sigma\\)인 정규 분포입니다.3\n좋습니다, 그렇다면 표본 평균 \\(\\bar{X}\\)의 분포에 대해 무엇을 말할 수 있을까요? 이전에 논의한 바와 같이 (Section 8.3.3 참조), 평균 \\(\\mu\\)를 갖는 표본 평균 \\(\\bar{X}\\)의 표본 분포 또한 정규 분포를 따릅니다. 하지만 이 표본 분포의 표준편차인 \\(se(\\bar{X})\\), 즉 평균의 표준오차는 다음과 같습니다:4\n\\[se(\\bar{X})=\\frac{\\sigma}{\\sqrt{N}}\\]\n여기서 필요한 요령은, 표본 평균 \\(\\bar{X}\\)을 표준 점수로 변환하는 것입니다(Section 4.5 참조). 이는 관례적으로 \\(z\\)로 표기되지만, 여기서는 \\(z_{\n\\bar{X}}\\)라고 표기하겠습니다. 이렇게 확장된 표기법을 사용하는 이유는 우리가 표본 평균의 표준화된 값을 계산하는 것이지, 개별 관측값의 표준화된 값을 계산하는 것이 아님을 상기시키기 위해서입니다. 이렇게 하면, 표본 평균에 대한 \\(z\\)-점수는 다음과 같이 계산됩니다:\n\\[z_{\\bar{X}}=\\frac{\\bar{X}- \\mu_0}{SE(\\bar{X})} =\\frac{\\bar{X}-\\mu_0}{\\frac{\\sigma}{\\sqrt{N}}}\\]\n이 \\(z\\)-점수가 우리의 검정 통계량입니다. 이 통계량을 사장점은 모든 \\(z\\)-점수와 마찬가지로 표준 정규 분포를 따른다는 점입니다.5\n즉, 원래 데이터가 어떤 척도로 측정되었든 간에, \\(z\\)-통계량 자체는 항상 동일한 해석을 가집니다. 즉, 이는 관측된 표본 평균 \\(\\bar{X}\\)과 귀무가설이 예측한 모집단 평균 \\(\\mu_0\\) 사이의 차이를 표준오차의 배수로 나타낸 것입니다. 더 나아가, 원래 모집단 모수가 무슨 값이든 상관없이, \\(z\\)-검정의 5% 기각역은 항상 동일하며, 이는 Figure 11.3 에 표현되어 있습니다. 한때 사람들이 통계를 손으로 계산해야 했던 시절에는, 누군가 Table 11.1 같은 표를 출판하였으며, 연구자들은 \\(z\\)-통계량을 손으로 계산한 후 책에서 임계값을 찾아볼 수 있었습니다.\n\n\n\n\n\n\n\n\nFigure 11.3. 양측 \\(z\\)-검정 (a) 및 단측 \\(z\\)-검정 (b)에 대한 기각역\n\n\n\n\n\n\n\n\n\nTable 11.1. 다양한 유의수준에 대한 임계값\n\n\n\n\n\n임계 \\(z\\)-값\n\n희망 \\(\\alpha\\) 수준양측 검정단측 검정\n\n.11.6448541.281552\n\n.051.9599641.644854\n\n.012.5758292.326348\n\n.0013.2905273.090232\n\n\n\n\n\n\n\n\n\n11.1.3 수작업을 통한 예제\n앞서 언급했듯이, z-검정은 실제로 거의 사용되지 않습니다. 너무 드물게 사용되기 때문에, jamovi의 기본 설치에는 이를 수행하는 내장 함수조차 없습니다. 하지만 이 검정은 매우 간단하기 때문에 수작업으로도 쉽게 계산할 수 있습니다. 이제 Zeppo 교수의 수업 데이터를 다시 살펴보겠습니다. 성적 데이터를 불러온 후, 첫 번째로 해야 할 일은 표본 평균을 계산하는 것입니다. 이미 계산한 결과는 \\(72.3\\)입니다. 또한, 이미 알려진 모집단의 표준편차(\\(\\sigma = 9.5\\)), 귀무가설에서 제시하는 모집단 평균 값(\\(\\mu_0 = 67.5\\)), 그리고 표본 크기(\\(N=20\\))도 알고 있습니다.\n다음으로, 평균의 (실제) 표준오차를 계산해 보겠습니다. 계산기로 쉽게 구할 수 있습니다.\n\\[\n\\begin{split}\nSE(\\bar{X}) & = \\frac{\\sigma}{\\sqrt{N}} \\\\\\\\\n& = \\frac{9.5}{\\sqrt{20}} \\\\\\\\\n& = 2.124265\n\\end{split}\n\\]\n마지막으로, \\(z\\)-점수를 계산합니다.\n\\[\n\\begin{split}\nz_{\\bar{X}} & = \\frac{\\bar{X} - \\mu_0}{SE(\\bar{X})} \\\\\\\\\n& = \\frac{ (72.3 - 67.5)}{ 2.124265} \\\\\\\\\n& = 2.259606\n\\end{split}\n\\]\n이 시점에서, 전통적인 방식으로 \\(z\\)-값 \\(2.26\\)을 임계값 표에서 찾아볼 수 있습니다. 우리의 원래 가설은 양측 검정(two-sided)이었습니다. 심리학 전공 학생들이 다른 학생들보다 통계학 성적이 더 높을지 낮을지에 대한 명확한 이론이 없었기 때문입니다. 따라서 가설 검정도 양측 검정(또는 양쪽 검정)으로 진행됩니다. 앞에서 본 작은 표를 참고하면, \\(z\\)-값 \\(2.26\\)은 유의수준 \\(\\alpha = .05\\)에서 유의성을 가지기 위한 임계값 \\(1.96\\)보다 크지만, \\(\\alpha = .01\\)에서 유의성을 가지기 위한 값 \\(2.58\\)보다는 작습니다. 따라서, 우리는 유의한 효과가 있다고 결론을 내릴 수 있으며, 이를 다음과 같이 기술할 수 있습니다.\n\n심리학 전공 학생들의 표본 평균 성적이 \\(73.2\\)이므로, 모집단의 표준편차가 \\(9.5\\)라고 가정할 때, 심리학 전공 학생들은 강의 평균과 유의하게 다른 통계학 성적을 보였다* (\\(z = 2.26, N = 20, p&lt;.05\\)).\n\n\n\n11.1.4 z-검정의 가정\n앞서 말했듯이, 모든 통계 검정에는 가정이 있습니다. 어떤 검정은 합리적인 가정을 하는 반면, 그렇지 않은 검정도 있습니다. 방금 설명한 단일 표본에 대한 \\(z\\)-검정은 세 가지 기본 가정을 합니다.\n\n정규성. 일반적으로 설명되는 방식에 따르면, \\(z\\)-검정은 모집단의 실제 분포가 정규분포를 따른다고 가정합니다.6 이는 종종 꽤 합리적인 가정이며, 만약 이 가정이 걱정된다면 이를 확인할 수도 있습니다(예를 들어, 표본의 정규성을 확인하는 방법 절을 참조하세요).\n독립성. 두 번째 가정은 데이터 내의 관측치들이 서로 상관관계를 가지지 않으며, 어떤 방식으로든 연관되지 않는다는 것입니다. 이를 통계적으로 확인하기가 쉽지 않으며, 실험 설계를 잘해야만 만족될 수 있습니다. 이 가정을 위반하는 명백한(그리고 어리석은) 예는 동일한 관측치를 데이터 파일에 여러 번 “복사”하여 실제로는 단 하나의 진정한 관측치만 존재하는데, 거대한 “표본 크기”를 만드는 경우입니다. 보다 현실적인 맥락에서는, 각 관측치가 연구 대상 모집단에서 완전히 무작위로 추출된 것인지 스스로에게 질문해봐야 합니다. 실무에서 이 가정이 완전히 충족되는 경우는 없지만, 우리는 데이터 사이의 상관관계로 인한 문제를 최소화하는 방식으로 연구를 설계하려고 노력합니다.\n알려진 표준편차. 세 번째 가정은 연구자가 모집단의 실제 표준편차를 알고 있다는 것입니다. 이는 매우 비현실적인 가정입니다. 현실 세계의 데이터 분석에서 모집단의 표준편차 \\(\\sigma\\)를 알고 있으면서 평균 \\(\\mu\\)를 완전히 모르는 경우는 없습니다. 즉, 이 가정은 항상 틀린 가정입니다.\n\n모집단의 표준편차 \\(\\sigma\\)를 알고 있다는 가정이 어리석다는 점을 고려하면, 이를 생략할 수 있는지 살펴보는 것이 좋겠습니다. 이는 지루한 \\(z\\)-검정의 영역을 벗어나, 유니콘과 요정, 그리고 레프리콘이 사는 신비로운 \\(t\\)-검정의 세계로 우리를 안내합니다!",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>두 평균 비교하기</span>"
    ]
  },
  {
    "objectID": "11-Comparing-two-means.html#sec-The-one-sample-t-test",
    "href": "11-Comparing-two-means.html#sec-The-one-sample-t-test",
    "title": "11  두 평균 비교하기",
    "section": "11.2 단일 표본 \\(t\\)-검정",
    "text": "11.2 단일 표본 \\(t\\)-검정\n곰곰이 생각해 본 결과, 심리학과 학생들의 성적이 반드시 Zeppo 교수의 수업을 듣는 다른 학생들과 동일한 표준편차를 가진다고 가정하는 것이 보장되지 않을 수도 있다고 판단했습니다 (Figure 11.4). 결국, 이들이 동일한 평균을 가지지 않는다는 가설을 고려하고 있다면, 왜 반드시 동일한 표준편차를 가져야 한다고 믿어야 할까요? 이러한 점을 고려하면, 모집단의 표준편차 \\(\\sigma\\) 값을 알고 있다고 가정하는 것을 그만두어야 할 것입니다. 이는 \\(z\\)-검정의 가정을 위반하는 것이므로, 다시 원점으로 돌아간 셈입니다. 그러나 그렇다고 해서 완전히 방법이 없는 것은 아닙니다. 어쨌든, 원래 데이터에서 모집단의 표준편차를 추정할 수 있습니다. 그 값은 9.52입니다. 즉, \\(\\sigma = 9.5\\)라고 확언할 수는 없지만, \\(\\hat{\\sigma} = 9.52\\)라고 말할 수는 있습니다.\n좋습니다. 이제 보이는 길은 \\(z\\)-검정을 수행하되, 모집단의 표준편차를 \\(9.5\\)라고 가정하는 대신 추정된 표준편차 \\(9.52\\)를 사용하는 것이라고 생각할 수 있습니다. 그리고 이 방법을 사용해도 여전히 통계적으로 유의한 결과가 나올 것이라는 점은 놀랍지 않을 것입니다. 이 접근 방식은 꽤 해결책에 가깝지만, 완전히 정확하지는 않습니다. 이제 우리는 모집단의 표준편차의 추정값에 의존하고 있기 때문에, 실제 모집단의 표준편차가 정확히 무엇인지 모르는 불확실성을 반영해야 합니다. 어쩌면 우리가 얻은 데이터가 우연의 산물이어서 실제 모집단의 표준편차가 \\(11\\)일 수도 있습니다. 만약 그것이 사실이라면, 그리고 우리가 \\(z\\)-검정을 수행하면서 \\(\\sigma=11\\)이라고 가정한다면, 결과는 유의하지 않게 나올 것입니다. 이것은 우리가 해결해야 할 문제이며 과제입니다.\n\n\n\n\n\n\n\n\nFigure 11.4. (양측) 일표본 \\(t\\)-검정에서의 귀무가설과 대립가설을 그래픽적으로 나타낸 그림. \\(z\\)-검정(Figure 11.2)과의 유사성을 주목하세요. 귀무가설은 모집단 평균 \\(\\mu\\)가 특정 값 \\(\\mu_0\\)과 같다는 것이며, 대립가설은 그렇지 않다는 것입니다. \\(z\\)-검정과 마찬가지로 데이터가 정규분포를 따른다고 가정하지만, 모집단 표준편차 \\(\\sigma\\)가 사전에 알려져 있다고 가정하지 않습니다.\n\n\n\n\n\n\n11.2.1 \\(t\\)-검정 소개\n이러한 표준편차의 애매성은 꽤 까다로운 문제이며, 1908년 William Sealy Gosset이라는 사람이 이를 해결했습니다(Student, 1908). 당시 그는 기네스(Guinness) 양조장에서 화학자로 일하고 있었는데(Box (1987) 참고), 기네스는 직원들이 통계 분석 결과를 출판하는 것을 탐탁지 않게 여겼습니다(아마도 영업 비밀로 여겼던 것 같습니다). 그래서 그는 “A Student”라는 가명으로 연구를 발표했으며, 오늘날까지도 \\(t\\)-검정의 공식 명칭은 스튜던트의 \\(t\\)-검정(Student’s \\(t\\)-test)입니다. Gosset이 핵심적으로 밝혀낸 것은 우리가 모집단의 표준 편차를 정확히 알지 못한다는 사실을 어떻게 반영해야 하는가 라는 점이었습니다.7 그 해답은 표본 분포가 앞의 \\(z\\)-검정의 표준정규분포에서 미묘하게 달라진다는 것입니다. \\(t\\)-검정에서 우리가 사용하는 검정 통계량은 이제 \\(t\\)-통계량이라고 불리며, 앞에서 설명한 방식과 동일하게 계산됩니다. 귀무가설이 참일 때 모집단의 평균을 \\(\\mu\\), 표본 평균을 \\(\\bar{X}\\)이고 모집단 표준 편차의 추정값을 \\(\\hat{\\sigma}\\)라고 하면, \\(t\\)-통계량은 다음과 같이 계산됩니다.\n\\[t=\\frac{\\bar{X}-\\mu}{\\frac{\\hat{\\sigma}}{\\sqrt{N}}}\\]\n이 공식에서 바뀐 것은 기존의 알려진 모집단 표준 편차 \\(\\sigma\\) 대신 추정값 \\(\\hat{\\sigma}\\)를 사용했다는 점과, 이 추정값이 \\(N\\)개의 관측값을 기반으로 계산되었다면 표본 분포는 자유도(\\(df\\))가 \\(N-1\\)인 \\(t\\)-분포가 된다는 것입니다. \\(t\\)-분포는 정규분포와 매우 유사하지만, “더 두꺼운 꼬리”를 가지고 있습니다. 이는 Section 7.6 에서 논의되었으며, Figure 11.5 에 시각적으로 표현되어 있습니다. 하지만 자유도(\\(df\\))가 커질수록 \\(t\\)-분포는 점점 표준정규분포와 동일해집니다. 이는 당연한 일입니다. 만약 표본 크기 \\(N\\)이 70,000,000이라면, 표준 편차의 추정값은 거의 완벽할 것입니다. 따라서 \\(N\\)이 매우 클 경우, \\(t\\)-검정은 \\(z\\)-검정과 동일한 방식으로 작동할 것이라고 기대할 수 있습니다. 그리고 실제로도 그렇게 됩니다!\n\n\n\n\n\n\n\n\nFigure 11.5. 자유도가 2일 때(왼쪽)와 10일 때(오른쪽)의 \\(t\\)-분포. 비교를 위해 표준 정규분포(평균 0, 표준 편차 1)를 점선으로 표시했습니다. \\(t\\)-분포는 정규분포보다 꼬리가 두껍고(첨도(kurtosis)가 더 높음), 자유도가 작을수록 이 효과가 극적으로 나타나지만, 자유도가 커지면 정규분포와의 차이가 거의 없어집니다. 즉, 자유도가 충분히 크다면 \\(t\\)-분포는 본질적으로 정규분포와 동일합니다.\n\n\n\n\n\n\n\n11.2.2 jamovi에서 검정 수행하기\n예상할 수 있듯이, \\(t\\)-검정의 절차는 \\(z\\)-검정과 거의 동일합니다. 따라서 저수준 명령어를 사용하여 계산하는 방법을 지루하게 설명하는 것은 큰 의미가 없습니다. 앞서 수행했던 계산과 거의 동일하지만, 표준 편차의 추정값을 사용하고, 정규분포 대신 \\(t\\)-분포를 이용해 가설을 검정한다는 점만 다릅니다. 따라서 다시 한번 자세한 계산 과정을 반복하는 대신, 실제 \\(t\\)-검정을 수행하는 방법을 바로 보여드리겠습니다.\njamovi에는 다양한 유형의 \\(t\\)-검정을 수행할 수 있는 매우 유연한 분석 기능이 있습니다. 사용 방법도 매우 간단합니다. ‘분석’-‘T-검정’-‘단일표본 T-검정’8을 선택하고, 관심 있는 변수(\\(X\\))를 ‘변수’ 상자로 이동한 후, 귀무가설의 평균값(‘67.5’)을 ‘가설’-‘검정 값’ 상자에 입력하면 됩니다. 매우 간단하죠. Figure 11.6 을 보면, 여러 정보가 표시되는데, 여기서 가장 중요한 것은 \\(t\\)-검정 통계량이 2.25이고, 자유도는 19이며, 이에 해당하는 \\(p\\)-값이 \\(0.036\\)이라는 점입니다.\n\n\n\n\n\n\n\n\nFigure 11.6. jamovi에서 수행한 단일 표본 \\(t\\)-검정\n\n\n\n\n\n또한 결과에는 두 가지 추가적인 정보도 포함시킬 수 있습니다. 하나는 95% 신뢰 구간이며, 다른 하나는 효과 크기입니다(효과 크기에 대해서는 나중에 더 자세히 설명할 예정입니다). 지금까지의 과정은 비교적 간단했습니다. 그렇다면, 이제 이 출력을 어떻게 해석해야 할까요?\n우리가 이 예제를 진지하게 분석한다고 가정하면, 결과가 통계적으로 유의미하다는 사실(\\(p\\)-값이 0.05보다 작음)에 기뻐할 것입니다. 이러한 결과를 보고할 때는 다음과 같이 표현할 수 있습니다.\n&gt; 평균 성적이 \\(72.3\\)인 심리학 학생들은 평균 성적 \\(67.5\\)보다 약간 높은 점수를 기록했다 (\\(t(19) = 2.25\\), \\(p = .036\\)); 평균 차이는 \\(4.80\\)이었으며, 95% 신뢰 구간은 \\(0.34\\)에서 \\(9.26\\)이었다.\n여기서 \\(t(19)\\)는 자유도가 19인 \\(t\\) 통계량을 의미하는 표기법입니다. 다만, 많은 경우 신뢰 구간을 보고하지 않거나, 훨씬 간결한 형식으로 제시하는 경우가 많습니다. 예를 들어, 평균 차이를 보고한 후 통계 블록 안에 신뢰 구간을 포함하는 방식도 일반적입니다.\n\\[t(19)=2.25, p = .036, CI_{95} = [0.34, 9.26]\\]\n이렇게 반 줄에 엄청난 양의 전문 용어를 집어넣으면 똑똑해 보이는 효과가 있죠.9\n\n\n11.2.3 단일 표본 \\(t\\)-검정의 가정\n그렇다면 단일 표본 \\(t\\)-검정은 어떤 가정을 할까요? 기본적으로 \\(t\\)-검정은 \\(z\\)-검정에서 “모집단의 표준편차를 알고 있다”는 가정을 제거한 버전이므로, \\(z\\)-검정과 동일한 가정을 하지만, 알려진 표준편차에 대한 가정만 빠졌다고 보면 됩니다. 즉, 다음과 같은 가정을 합니다.\n\n정규성. 여전히 모집단 분포가 정규분포를 따른다고 가정합니다.10 앞서 언급했듯이, 이 가정이 충족되는지 확인할 수 있는 표준적인 도구들이 있으며([표본의 정규성 확인하기]), 이 가정이 위배될 경우 사용할 수 있는 대체 검정 방법도 있습니다([비정규 데이터 검정하기]).\n\n독립성. 마찬가지로 표본 내의 각 관측값이 서로 독립적으로 생성되었다고 가정해야 합니다. 자세한 내용은 앞서 논의한 \\(z\\)-검정의 가정을 참고하세요([\\(z\\)-검정의 가정]).\n\n전반적으로 이 두 가지 가정은 크게 무리가 없는 편이며, 그 결과 단일 표본 \\(t\\)-검정은 표본 평균을 가설적인 모집단의 평균과 비교하는 데 널리 사용됩니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>두 평균 비교하기</span>"
    ]
  },
  {
    "objectID": "11-Comparing-two-means.html#sec-the-independent-samples-t-test-student-test",
    "href": "11-Comparing-two-means.html#sec-the-independent-samples-t-test-student-test",
    "title": "11  두 평균 비교하기",
    "section": "11.3 독립 표본 \\(t\\)-검정 (Student 검정)",
    "text": "11.3 독립 표본 \\(t\\)-검정 (Student 검정)\n단일 표본 \\(t\\)-검정도 유용하게 쓰이지만, 가장 일반적인 \\(t\\)-검정의 예는 아닙니다.11 훨씬 더 흔한 경우는 두 개의 서로 다른 관측 집단이 있을 때입니다. 심리학에서는 보통 두 개의 서로 다른 참가자 집단이 존재하며, 각 집단은 연구에서 서로 다른 조건에 해당합니다. 연구에서는 각 참가자에 대해 특정한 결과 변수를 측정하고, 두 집단의 모집단 평균이 동일한지 조사하는 것이 핵심적 질문이 됩니다. 독립 표본 \\(t\\)-검정은 바로 이러한 상황을 다루도록 설계되었습니다.\n\n11.3.1 데이터\nHarpo 박사의 통계 강의를 듣는 학생이 33명 있다고 가정해 봅시다. Harpo 박사는 성적을 곡선 조정을 하여 매기지 않습니다. 사실, Harpo 박사의 성적 부여 방식은 꽤 미스터리하기 때문에 전체 반의 평균 성적이 어느 정도인지도 잘 모릅니다. 이 강의에는 두 명의 튜터, Anastasia와 Bernadette가 있습니다. Anastasia의 수업을 듣는 학생은 \\(N_1 = 15\\)명이고, Bernadette의 수업을 듣는 학생은 \\(N_2 = 18\\)명입니다. 여기서 우리가 궁금한 것은 Anastasia가 Bernadette보다 더 나은 튜터인지, 아니면 별 차이가 없는지입니다.\nHarpo 작사가 harpo.csv 파일로 성적 데이터를 이메일로 보내주었습니다. 평소처럼 jamovi에 파일을 로드하고, 포함된 변수를 살펴보았습니다. 데이터에는 세 개의 변수가 있습니다: ID, grade(성적), tutor(튜터).\n\ngrade 변수에는 각 학생의 성적이 들어 있지만, jamovi에서 올바른 측정 유형으로 설정되어 있지 않았습니다. 따라서 이를 ’연속변수’로 변경해야 합니다(데이터의 측정 수준 변경 참고).\n\ntutor 변수는 각 학생이 어떤 튜터(Anastasia 또는 Bernadette)에게 배정되었는지를 나타내는 범주형 변수입니다.\n\n평균과 표준편차를 계산하기 위해 jamovi에서 ‘탐색’-’기술분석’에서 평균과 표준편차를 계산하면, 아래의 요약 표(Table 11.2)가 생성됩니다.\n\n\n\n\nTable 11.2. 기술 통계 요약 표\n\n\n\n\n\n평균표준편차\\( N \\)\n\nAnastasia의 학생74.539.0015\n\nBernadette의 학생69.065.7718\n\n\n\n\n\n\n\n데이터의 분포를 보다 직관적으로 보여주기 위해, jamovi에서 박스 도표와 바이올린 도표를 그려 보았습니다. 여기에 평균 점수를 작은 실선 사각형으로 표시했습니다. 이 도표은 두 튜터 집단의 성적 분포를 나타내며(Figure 11.7),\n\n\n\n\n\n\n\n\nFigure 11.7. jamovi에서 생성한 박스 도표와 바이올린 도표. Anastasia와 Bernadette의 수업을 듣는 학생들의 성적 분포를 보여줍니다. 그래프를 보면, Anastasia 반의 학생들이 평균적으로 약간 더 높은 성적을 받는 것처럼 보이지만, 변동성이 더 커 보입니다.\n\n\n\n\n\n\n\n\n\n\n\n실습: 튜터 별 점수 비교\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Harpo’를 선택합니다.\n스프레드시트에서 grade의 열이름을 더블클릭합니다. 그리고 grade의 척도유형을 ’명명척도’에서 ’연속변수’로 바꿉니다.\n‘탐색’-‘기술통계’ 메뉴를 선택합니다.\ntutor 별로 grade에 대한 기술통계를 하기 위하여, 왼편의 ‘기술통계’ 창에서 grade를 ‘변수’ 상자로, tutor를 ‘Split by’ 상자로 이동합니다. 그리고 tutor 별로 평균 등의 기술통계량을 비교하기 좋도록 한 행에 나타나도록, ‘기술통계’ 드롭다운 박스에서 ’Variables across rows’를 선택합니다.\n‘도표’ 옵션을 확장하여 ‘박스 도표’, ‘Violin’, ‘데이터’, ’평균’을 체크합니다. 그러면 다음 같이 grade가 tutor 별로 그룹화되어 박스와 바이올린 도표가 그려지고, 데이터(둥근 점)와 평균치(사각형 점)도 표시됩니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.3.2 검정 소개\n독립 표본 \\(t\\)-검정에는 두 가지 형태가 있습니다: Student 검정과 Welch 검정입니다. 이 장에서 설명할 Student \\(t\\)-검정은 두 가지 중 더 간단한 방법이지만, Welch \\(t\\)-검정보다 훨씬 더 엄격한 가정을 필요로 합니다. 우선 양측 검정을 수행한다고 가정하면, 두 개의 “독립적인 표본”이 평균이 같은 모집단에서 추출되었는지(귀무가설) 아니면 서로 평균이 다른 모집단에서 추출되었는지(대립가설)를 판단하는 것이 목표입니다. 여기서 “독립적”이라는 표현은 두 표본 내의 관측값들이 서로 특별한 관계를 갖지 않는다는 의미입니다. 이것이 지금 당장은 직관적으로 이해되지 않을 수 있지만, 나중에 대응 표본 \\(t\\)-검정을 설명할 때 더 명확해질 것입니다. 지금은 참가자들이 무작위로 두 집단 중 하나에 할당되고, 두 집단 간의 평균 성과를 비교하려는 실험 설계라면 독립 표본 \\(t\\)-검정을 사용해야 한다는 것만 언급해 두겠습니다.\n이제, 집단 1(예: Anastasia의 학생들)의 모집단 평균을 \\(\\mu_1\\), 집단 2(예: Bernadette의 학생들)의 모집단 평균을 \\(\\mu_2\\)라고 하고,12 그리고 각 집단의 관측된 표본 평균을 \\(\\bar{X_1}\\), \\(\\bar{X_2}\\)라고 하겠습니다. 그러면 귀무가설은 두 모집단 평균이 같다는 것이고(\\(\\mu_1 = \\mu_2\\)), 대립가설은 두 모집단 평균이 다르다는 것입니다(\\(\\mu_1 \\neq \\mu_2\\))(Figure 11.8). 이를 수식으로 표현하면 다음과 같습니다:\n\\[H_0: \\mu_1=\\mu_2 \\]\n\\[H_A: \\mu_1 \\neq \\mu_2 \\]\n만약 귀무가설이 참이라면 모집단 평균의 차이는 정확히 0이어야 합니다(\\(\\mu_1 - \\mu_2 = 0\\)). 따라서, 검정 통계량은 두 표본 평균 간의 차이를 기반으로 계산되어야 할 것입니다. 왜냐하면 귀무가설이 참이라면 \\(\\bar{X}_1 - \\bar{X}_2\\) 값은 0에 가까울 것으로 예상되기 때문입니다. 그러나 단일 표본 \\(z\\)-검정 및 단일 표본 \\(t\\)-검정에서 봤듯이, 이 차이가 0에 얼마나 가까워야 하는지를 명확히 해야 합니다. 이 문제를 해결하는 방법은 이전과 거의 동일합니다. 표준오차(SE)를 추정한 후, 표본 평균 차이를 표준 오차로 나누는 것입니다. 즉, 독립 표본 검정의 \\(t\\)-통계량은 다음과 같이 정의됩니다:\n\\[t=\\frac{\\bar{X_1}-\\bar{X_2}}{SE}\\]\n\n\n\n\n\n\n\n\nFigure 11.8. Student \\(t\\)-검정의 귀무가설과 대립가설을 그래픽으로 표현한 그림. 귀무가설에서는 두 집단의 평균이 동일한 \\(\\mu\\)라고 가정하지만, 대립가설에서는 서로 다른 평균 \\(\\mu_1\\)과 \\(\\mu_2\\)를 가정합니다. 이때 모집단 분포는 정규성을 띄며, 대립가설에서는 평균이 다를 수 있지만 표준편차는 동일하다고 가정했습니다.\n\n\n\n\n\n이제, 남은 과제는 표준오차의 추정값을 정확히 계산하는 것입니다. 이 과정은 지금까지 다룬 다른 검정보다 조금 더 복잡하기 때문에, 좀 더 신중하게 살펴볼 필요가 있습니다.\n\n\n11.3.3 표준 편차의 “합동 추정치”\n원래의 “Student \\(t\\)-검정”에서는 두 모집단이 동일한 표준편차를 가진다고 가정합니다. 즉, 모집단 평균이 동일한지 여부와 관계없이 모집단의 표준편차가 동일하다고 가정하며, 이를 수식으로 나타내면 \\(\\sigma_1 = \\sigma_2\\)입니다. 두 표준편차가 동일하다고 가정하기 때문에 첨자를 생략하고 둘 다 \\(\\sigma\\)로 표기합니다. 그렇다면 이를 어떻게 추정해야 할까요? 두 개의 표본이 있을 때 단일한 표준편차 추정치를 어떻게 구성해야 할까요? 기본적으로는 평균을 내는 방식으로 사용합니다. 정확히는 표본들의 분산 추정치를 가중 평균하여 합동 분산 추정치(pooled estimate of the variance)를 사용합니다. 각 표본에 할당되는 가중치는 해당 표본의 관측치 개수에서 1을 뺀 값과 같습니다.\n수학적으로 이를 다음과 같이 표현할 수 있습니다. \\[w_1=N_1-1\\] \\[w_2=N_2-1\\]\n이제 각 표본에 가중치를 할당했으므로 두 분산 추정치 \\(\\hat{\\sigma}_{1}^{2}\\)와 \\(\\hat{\\sigma}_{2}^{2}\\)의 가중 평균을 취하여 합동 분산 추정치를 계산할 수 있습니다. \\[\\hat{\\sigma}_p^2=\\frac{w_1\\hat{\\sigma}_1^2+w_2\\hat{\\sigma}_2^2}{w_1+w_2}\\]\n마지막으로, 결합된 분산 추정치의 제곱근을 취하여 합동 표준편차 추정치를 구합니다.13 \\[\\hat{\\sigma}_p=\\sqrt{\\frac{w_1\\hat{\\sigma}_1^2+w_2\\hat{\\sigma}_2^2}{w_1+w_2}}\\]",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>두 평균 비교하기</span>"
    ]
  },
  {
    "objectID": "11-Comparing-two-means.html#검정-수행하기",
    "href": "11-Comparing-two-means.html#검정-수행하기",
    "title": "11  두 평균 비교하기",
    "section": "11.4 검정 수행하기",
    "text": "11.4 검정 수행하기\n어떤 방식으로 생각하든 이제 우리는 표준 편차의 합동 추정치를 구했습니다. 이제부터는 귀찮은 하위 첨자 \\(p\\) 를 생략하고, 이 추정값을 단순히 \\(\\hat{\\sigma}\\)라고 부르겠습니다. 좋습니다. 이제 다시 귀찮은 가설 검정으로 돌아가 봅시다. 우리가 이 합동 추정치를 계산한 이유는 표준오차를 구하는 데 유용하기 때문이었습니다. 하지만 무엇에 대한 표준오차일까요? 단일 표본 \\(t\\)-검정에서 우리는 표본평균의 표준오차 \\(se(\\bar{X})\\)를 사용했습니다. \\(se(\\bar{X}) = \\frac{\\sigma}{\\sqrt{N}}\\)이므로 \\(t\\)-통계량의 분모는 이 값으로 구성되었습니다. 하지만 이번에는 두 개의 표본평균을 가지고 있습니다. 그리고 우리가 관심 있는 것은 두 평균의 차이 \\(\\bar{X}_1 - \\bar{X}_2\\)입니다. 따라서 우리가 나누어야 할 표준오차는 두 표본평균의 차이의 표준 오차 입니다.\n두 변수가 실제로 동일한 표준 편차를 가진다고 가정하면, 표준오차의 추정값은 다음과 같습니다: \\[SE(\\bar{X}_1-\\bar{X}_2)=\\hat{\\sigma}\\sqrt{\\frac{1}{N_1}+\\frac{1}{N_2}}\\]\n따라서 우리의 \\(t\\)-통계량은 다음과 같이 주어집니다: \\[t=\\frac{\\bar{X}_1-\\bar{X}_2}{SE(\\bar{X}_1-\\bar{X}_2)}\\]\n단일 표본 검정에서 봤던 것처럼, 만약 귀무가설이 참이고 검정의 모든 가정이 충족된다면, 이 \\(t\\) -통계량의 표본 분포는 \\(t\\)-분포를 따릅니다(놀랍죠?). 하지만 자유도는 약간 다릅니다. 일반적으로 자유도는 데이터 포인트의 개수에서 제약 조건의 개수를 뺀 값으로 생각할 수 있습니다. 이번 경우에는 총 \\(N\\) 개의 관측값(\\(N_1\\) 개는 표본 1에서, \\(N_2\\) 개는 표본 2에서)을 가지고 있으며, 두 개의 제약 조건(표본평균들)이 존재합니다. 따라서 이 검정의 총 자유도는 \\(N - 2\\)가 됩니다.\n\n11.4.1 jamovi에서 검정 수행하기\n예상대로, jamovi에서 독립 표본 \\(t\\)-검정을 쉽게 수행할 수 있습니다. 이 검정에서 종속 변수는 학생들의 성적이며, 집단은 각 반의 담당 튜터에 의해 정의됩니다. 따라서 jamovi에서 해야 할 일은 ‘분석)’-‘T-검정’-‘독립 표본 T-검정’으로 이동한 후, grade 변수를 ’종속변수’ 상자로, tutor 변수를 ‘집단 변수’ 상자로 이동시키는 것입니다. Figure 11.9 에 이 과정이 나타나 있습니다.[^11-comparing-two-means-k-2] [^11-comparing-two-means-k-2]: &lt;역주&gt; Figure 11.9 의 \\(t\\)-검정 결과를 보면 ’표준오차의 차이’라는 항목이 나옵니다. 이 항목은 두 표본평균의 차이의 표준오차인 \\[SE(\\bar{X}_1-\\bar{X}_2)\\]를 의미합니다. 그러므로 차이의 표준오차라고 번역했어야 하는 용어입니다.\n\n\n\n\n\n\n\n\nFigure 11.9. jamovi에서 독립 표본 \\(t\\)-검정을 수행하는 인터페이스. 유용한 결과를 얻기 위해 옵션이 선택되어 있음.\n\n\n\n\n\n출력 결과는 매우 익숙한 형식을 띱니다. 먼저, 어떤 검정을 수행했는지, 그리고 사용한 종속 변수의 이름을 알려줍니다. 그런 다음, 검정 결과를 제공합니다. 지난번과 마찬가지로, 검정 결과에는 \\(t\\) -통계량, 자유도, \\(p\\)-값이 포함됩니다. 마지막 부분에서는 두 가지 정보를 제공합니다. 하나는 신뢰 구간이고, 다른 하나는 효과 크기입니다. 효과 크기에 대해서는 나중에 설명하겠습니다. 하지만 신뢰 구간에 대해서는 지금 이야기해야 할 것 같습니다.\n이 신뢰 구간이 정확히 무엇을 의미하는지 명확히 이해하는 것이 중요합니다. 이 신뢰 구간은 집단 평균 사이의 차이에 대한 신뢰 구간입니다. 예제에서 Anastasia의 학생들의 평균 성적은 74.53, Bernadette 학생들의 평균 성적은 69.06이므로, 두 표본 평균의 차이는 5.48입니다. 그러나 모집단 평균의 차이는 이것보다 클 수도, 작을 수도 있습니다. Figure 11.10 에서 제시된 신뢰 구간은 만약 이 연구를 반복적으로 수행한다면, 95% 정도 실제 평균 차이가 신뢰구간 안에 있을 것을 의미합니다. 이 예에서 신뢰구간은 0.20에서 10.76까지입니다. 신뢰 구간이 무엇을 의미하는지 다시 확인하고 싶다면 Section 8.5 을 참조하세요.\n어쨌든, 두 집단 사이의 차이는 (아슬아슬하게) 유의합니다. 따라서 결과를 다음과 같은 형식으로 기술할 수 있습니다.\n\nAnastasia 반의 평균 성적은 74.5(표준 편차 = 9.0)이었으며, Bernadette 반의 평균 성적은 69.1 (표준 편차 = 5.8)였습니다. 스튜던트의 독립 표본 \\(t\\)-검정 결과, 이 5.4의 차이는 통계적으로 유의한 것으로 나타났습니다(\\(t(31) = 2.1, p&lt;.05, CI_{95} = [0.2, 10.8], d = .74\\)). 이는 학습 결과에서 실제 차이가 발생했을 가능성을 시사합니다.\n\n여기서 신뢰구간과 효과 크기를 통계 블록에 포함시켰습니다. 하지만 사람들은 항상 이렇게 하지는 않습니다. 최소한 \\(t\\)-통계량, 자유도, \\(p\\)-값은 포함해야 합니다. 따라서 최소한 다음과 같은 내용을 포함해야 합니다: \\(t(31) = 2.1, p&lt; .05\\).\n통계학자들이 원하는 방식대로라면, 모든 사람이 신뢰구간과 효과 크기 역시 보고해야 합니다. 왜냐하면 이 값들은 유용한 정보이기 때문입니다. 그러나 현실에서는 통계학자들이 원하는 방식대로 항상 이루어지지는 않습니다. 따라서 독자가 필요로 할지를 기준으로 정보를 제공하는 것이 좋은 판단일 것입니다. 만약 과학 논문을 작성하고 있다면, 해당 저널의 편집 기준을 따르는 것이 중요합니다. 일부 저널은 효과 크기 보고를 요구하지만, 다른 저널은 그렇지 않습니다. 또한 일부 학문 공동체에서는 신뢰구간을 보고하는 것이 표준이지만, 다른 곳에서는 그렇지 않습니다. 결국, 청중이 기대하는 것이 무엇인지 파악하는 것이 중요합니다. 그러나 한 가지 명확한 점은, 제 수업을 듣고 있다면 신뢰구간과 효과 크기를 포함하는 것이 일반적으로 바람직하다는 것이 제 기본 입장 이라는 것입니다.\n\n\n\n\n\n\n실습: 독립표본 Student t-검정\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Harpo’를 선택합니다.\n스프레드시트에서 grade의 열이름을 더블클릭합니다. 그리고 grade의 척도유형을 ’명명척도’에서 ’연속변수’로 바꿉니다.\n‘분석’-‘T-검정’-‘독립표본 T-검정’ 메뉴를 선택합니다.\n왼편의 ‘독립표본 T-검정’ 창에서 다음을 수행합니다. 그러면 아래 그림과 같은 결과가 나타납니다.\n\n\ngrade를 ‘종속변수’ 상자로, tutor를 ‘집단변수’ 상자로 이동합니다.\n‘추가 통계’에서 ’평균 차이’와 그 아래의 ’신뢰구간’, ’효과 크기’를 체크합니다.\n’가정검정’에서 ’동질성 검정’과 ’정규분포성 검정’을 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.4.2 양수 및 음수의 \\(t\\)-값\n\\(t\\)-검정의 가정을 논의하기 전에, 실제로 \\(t\\)-검정을 사용할 때 고려해야 할 추가적인 사항이 있습니다. 그중 하나는 \\(t\\)-통계량의 부호(즉, 양수인지 음수인지)와 관련이 있습니다. 처음 \\(t\\)-검정을 수행하는 학생들이 흔히 걱정하는 부분 중 하나는 \\(t\\)-통계량이 음수 값으로 나타나는 경우입니다. 어떻게 해석해야 할지 몰라 당황하는 경우가 많죠. 사실, 서로 독립적으로 작업한 두 사람이 거의 동일한 결과를 얻었음에도 불구하고, 한 사람은 양수 \\(t\\) 값을, 다른 사람은 음수 \\(t\\) 값을 얻는 일은 흔한 일입니다. 이 경우, 양측 검정을 수행하고 있다면 \\(p\\)-값은 동일하게 나타납니다. 조금 더 자세히 들여다보면, 신뢰 구간(confidence interval) 또한 서로 반대 부호를 가지는 것을 알 수 있습니다. 이는 전혀 문제가 되지 않습니다. 이러한 상황이 발생하는 이유는 \\(t\\)-검정을 수행하는 방식이 약간씩 다를 수 있기 때문입니다.\n이는 매우 간단한 원리에서 비롯됩니다. 우리가 계산하는 \\(t\\)-통계량의 일반적인 형태는 다음과 같습니다.\n\\[t=\\frac{\\text{평균 1 - 평균 2}}{SE}\\]\n즉, “평균 1”이 “평균 2”보다 크면 \\(t\\)-통계량은 양수가 되고, 반대로 “평균 2”가 더 크다면 \\(t\\)-통계량은 음수가 됩니다. 마찬가지로, jamovi에서 보고하는 신뢰 구간은 “(평균 1) - (평균 2)”에 대한 신뢰 구간이므로, “(평균 2) - (평균 1)”을 기준으로 신뢰 구간을 계산했다면 부호가 반대가 되었을 것입니다.\n이제, Anastasia 반과 Bernadette 반의 성적을 비교하는 \\(t\\)-검정을 수행한다고 가정해 봅시다. 여기서 어느 반을 “평균 1”로, 어느 반을 “평균 2”로 지정해야 할까요? 사실, 이는 임의적으로 정할 수 있습니다. 하지만 어떤 방식이든 한 그룹을 “평균 1”로, 다른 그룹을 “평균 2”로 지정해야 합니다.\njamovi에서는 이 과정을 비교적 임의적으로 처리합니다. 이전 버전의 책에서는 이를 설명하려 했지만, 결국 포기했습니다. 사실, 이 문제는 크게 중요하지 않으며, 솔직히 말해 저조차도 매번 기억하지 못하기 때문입니다. 저는 유의미한 \\(t\\)-검정 결과를 얻었을 때, 어느 평균이 더 큰지를 확인하려면 굳이 \\(t\\)-통계량을 살펴보지 않습니다. 그럴 필요가 있을까요? 어리석은 일이죠. jamovi 출력에서 실제 그룹의 평균 값을 직접 확인하는 것이 훨씬 쉽습니다! 여기서 중요한 점은 jamovi에서 어떤 결과를 보여주든 상관없이, 저는 보통 \\(t\\)-통계량을 보고서의 텍스트와 일치하도록 정리한다는 것입니다. 예를 들어, 보고서에 다음과 같이 작성하고 싶다고 가정해 봅시다.\n“Anastasia 반은 Bernadette 반보다 더 높은 성적을 기록했다.”\n여기서 “더 높은”이라는 표현은 Anastasia 반이 먼저 등장한다는 것을 의미합니다. 따라서, \\(t\\)-통계량을 Anastasia 반이 그룹 1에 해당하는 것처럼 보고하는 것이 논리적으로 맞습니다. 즉, 다음과 같이 작성하는 것이 자연스럽습니다.\n“Anastasia 반은 Bernadette 반보다 더 높은 성적을 기록했다 \\((t(31) = 2.1, p = .04)\\).” (실제로 “더 높은”이라는 단어에 밑줄을 치지는 않겠지만, 여기서는 강조하기 위해 표시한 것입니다.)\n반면, 문장을 다르게 구성하여 Bernadette 반을 먼저 언급하고 싶다면, Bernadette 반을 집단 1로 지정하는 것이 더 적절할 것입니다. 이 경우, 보고서는 다음과 같이 작성할 수 있습니다.\n“Bernadette 반은 Anastasia 반보다 더 낮은 성적을 기록했다 \\((t(31) = -2.1, p = .04)\\).”\n여기서는 “더 낮은”이라는 표현을 사용했기 때문에, \\(t\\)-통계량을 음수 형태로 제시하는 것이 보다 자연스럽습니다. 이렇게 하면 문장이 훨씬 깔끔하게 읽힙니다.\n마지막으로 한 가지 더 말씀드리자면, 이러한 방식은 다른 유형의 검정 통계량에는 적용할 수 없습니다. 이는 \\(t\\)-검정에서는 유효하지만, 카이제곱(chi-square) 검정, \\(F\\)-검정, 혹은 이 책에서 다룰 대부분의 다른 검정에서는 의미가 없습니다. 그러니 이 조언을 과도하게 일반화하지 마세요! 저는 오직 \\(t\\)-검정에 대해서만 이야기하고 있습니다!ㅐ\n\n\n11.4.3 Student \\(t\\)-검정의 가정\n항상 그렇듯이, 가설 검정은 몇 가지 가정에 의존합니다. 그렇다면 Student \\(t\\)-검정에서 필요한 가정은 무엇일까요? Student \\(t\\)-검정에는 세 가지 가정이 있으며, 일부는 이전에 단일 표본 \\(t\\)-검정을 논의할 때도 등장했습니다(참고: 단일 표본 \\(t\\)-검정의 가정).\n\n정규성. 단일 표본 \\(t\\)-검정과 마찬가지로, 데이터가 정규 분포를 따른다고 가정합니다. 구체적으로는 두 집단 모두 정규 분포를 따른다고 가정합니다.14 표본의 정규성 검토 절에서 정규성을 검정하는 방법을 논의할 것이며, 비정규 분포 데이터 검정 절에서는 해결 방법을 다룰 것입니다.\n\n독립성. 마찬가지로, 관측값이 독립적으로 표본추출되었다고 가정합니다. Student \\(t\\)-검정에서는 이 가정이 두 가지 측면에서 적용됩니다. 첫째, 각 표본 내의 관측값이 서로 독립적이어야 합니다(이는 단일 표본 검정과 동일합니다). 둘째, 표본 간에 의존성이 없어야 합니다. 예를 들어, 연구에서 동일한 참가자가 실수로 서로 다른 실험 조건의 표본에 여러 번 참여하도록 허용되었다면, 표본 사이에 의존성이 발생하게 되며, 그런 경우에는 분석에서 이를 고려해야 합니다.\n분산의 동질성 (또는 “등분산성(homoscedasticity)”). 세 번째 가정은 두 집단의 모집단 표준편차가 동일하다는 것입니다. 이 가정은 Levene 검정을 사용하여 확인할 수 있으며, 이에 대해서는 책의 후반부에서 자세히 설명할 것입니다(Section 13.6.1). 하지만, 이 가정이 걱정된다면 이를 해결할 수 있는 간단한 방법이 있으며, 다음 절에서 설명하겠습니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>두 평균 비교하기</span>"
    ]
  },
  {
    "objectID": "11-Comparing-two-means.html#sec-the-independent-samples-t-test-welch-test",
    "href": "11-Comparing-two-means.html#sec-the-independent-samples-t-test-welch-test",
    "title": "11  두 평균 비교하기",
    "section": "11.5 독립 표본 \\(t\\)-검정 (Welch 검정)",
    "text": "11.5 독립 표본 \\(t\\)-검정 (Welch 검정)\n실제 분석에서 Student 검정을 사용할 때 가장 큰 문제는 앞서 설명한 세 번째 가정입니다. 즉, 두 그룹이 동일한 표준편차를 가진다고 가정하는 것입니다. 하지만 현실에서는 이 가정이 거의 성립하지 않습니다. 두 표본이 평균이 다르다면, 표준편차도 다를 가능성이 높습니다. 이러한 가정이 성립해야 할 이유는 없습니다. 이 가정을 확인하는 방법에 대해서는 이후에 다루겠습니다. 왜냐하면 이는 \\(t\\)-검정뿐만 아니라 여러 다른 분석에서도 등장하기 때문입니다. 하지만 지금은 이 가정을 필요로 하지 않는 다른 형태의 \\(t\\)-검정(Welch, 1947)에 대해 설명하겠습니다. 데이터에 대해 Welch \\(t\\)-검정이 가정하는 내용을 시각화한 것이 Figure 11.10 이며, 이는 Student 검정의 가정(Figure 11.8)과 비교할 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 11.10. Welch \\(t\\)-검정이 가정하는 귀무가설과 대립가설의 그래픽적 표현. Student 검정(Figure 11.9)과 마찬가지로 두 표본이 정규분포에서 추출되었다고 가정하지만, 대립가설에서는 두 모집단이 동일한 분산을 가진다는 가정을 필요로 하지 않음.\n\n\n\n\n\n등분산성에 대한 진단을 설명하기 전에 그 해결책부터 설명하는 것이 다소 이상하게 보일 수도 있습니다. 하지만 jamovi에서는 Welch 검정을 ‘독립 표본 T-검정’ 옵션 중 하나로 선택할 수 있기 때문에, 여기에서 논의하는 것이 가장 적절할 것입니다.\nWelch 검정은 Student 검정과 매우 유사합니다. 예를 들어, Welch 검정에서 사용하는 \\(t\\)-통계량은 Student 검정에서와 거의 동일한 방식으로 계산됩니다. 즉, 표본 평균의 차이를 구한 후, 그 차이에 대한 표준 오차의 추정값으로 나누는 방식입니다.\n\\[t=\\frac{\\bar{X}_1-\\bar{X}_2}{SE(\\bar{X}_1-\\bar{X}_2)}\\]\n주된 차이점은 표준오차 계산 방식이 다르다는 것입니다. 만약 두 모집단의 표준편차가 서로 다르다면, 두 표본의 표준편차를 단순히 평균 내어 ’합동 표준편차’를 계산하는 것은 비합리적입니다. 이는 마치 사과와 오렌지를 평균 내는 것과 같습니다.15\n하지만 표본 평균 차이에 대한 표준 오차는 여전히 추정할 수 있으며, 계산 방식이 다를 뿐입니다. 그 공식은 다음과 같습니다.\n\\[SE(\\bar{X}_1-\\bar{X}_2)=\\sqrt{\\frac{\\hat{\\sigma}_1^2}{N_1}+\\frac{\\hat{\\sigma}_2^2}{N_2}}\\]\n이 방식으로 계산하는 이유는 이 책의 범위를 벗어나는 내용이므로 깊이 다루지는 않겠습니다. 중요한 것은 Welch \\(t\\)-검정에서 도출된 \\(t\\)-통계량이 Student \\(t\\)-검정에서 나온 것과 다소 다르다는 점입니다.\nWelch 검정과 Student 검정의 두 번째 차이점은 자유도를 계산하는 방식입니다. Welch 검정에서는 자유도가 반드시 정수일 필요가 없으며, 지금까지 사용했던 “데이터 개수에서 제약 개수를 뺀 값”이라는 직관적인 계산 방식과도 크게 일치하지 않습니다.\n\n11.5.1 jamovi에서 Welch 검정 수행하기\n위에서 수행한 분석에서 Welch 검정 옵션(‘Welch’s’)을 체크하면, 다음과 같은 결과를 얻을 수 있습니다 (Figure 11.11).\n\n\n\n\n\n\n\n\nFigure 11.11. jamovi에서 기본 Student \\(t\\)-검정과 함께 표시된 Welch 검정 결과\n\n\n\n\n\n이 출력 결과의 해석은 비교적 간단합니다. Welch 검정의 결과를 Student 검정의 결과와 동일한 방식으로 읽으면 됩니다. 기술 통계, 검정 결과 및 기타 정보가 제공되므로 해석하기 어렵지 않습니다.\n그런데, 이번 결과는 유의하지 않게 나왔습니다. 앞서 Student 검정을 실행했을 때는 유의한 효과가 있었지만, 같은 데이터 세트에 대해 Welch 검정을 실행하니 그렇지 않습니다\\((t(23.02) = 2.03, p = .054)\\). 이게 무슨 의미일까요? 당황해야 할까요? 하늘이 무너지는 걸까요? 아마 아닐 겁니다. 한 검정에서는 유의한 결과가 나오고 다른 검정에서는 나오지 않는다는 사실 자체는 큰 의미를 갖지 않습니다. 특히, 이번 데이터는 의도적으로 이런 차이가 나타나도록 조정한 것이므로 더욱 그렇습니다. 일반적으로, \\(p\\)-값이 \\(.049\\)일 때와 \\(.051\\)일 때의 차이를 해석하거나 설명하려고 하는 것은 좋은 아이디어가 아닙니다. 현실에서 이런 일이 발생한다면, 이러한 \\(p\\)-값 차이는 거의 확실히 우연 때문일 것입니다.\n중요한 것은 어떤 검정을 사용할지 신중히 고려하는 것입니다. Student 검정과 Welch 검정은 각각의 강점과 약점이 있습니다. 만약 두 모집단의 분산이 실제로 동일하다면, Student 검정이 Welch 검정보다 조금 더 검정력이 강합니다(즉, 2종 오류율이 더 낮음). 하지만 두 모집단의 분산이 동일하지 않다면, Student 검정의 가정이 위배되므로 신뢰할 수 없게 됩니다. 이 경우 1종 오류율이 높아질 위험이 있습니다. 결국, 어느 검정을 선택할지는 균형을 고려해야 합니다. 그러나 현실에서는 대부분 Welch 검정을 선호하는 편입니다. 왜냐하면 모집단의 분산이 완전히 동일하다고 믿는 사람은 거의 없기 때문입니다.\n\n\n\n\n\n\nTip 11.2. 실습: 독립표본 Welch t-검정\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Harpo’를 선택합니다.\n스프레드시트에서 grade의 열이름을 더블클릭합니다. 그리고 grade의 척도유형을 ’명명척도’에서 ’연속변수’로 바꿉니다.\n‘분석’-‘T-검정’-‘독립표본 T-검정’ 메뉴를 선택합니다.\n왼편의 ‘독립표본 T-검정’ 창에서 다음을 수행합니다. 그러면 아래 그림과 같은 결과가 나타납니다.\n\n\ngrade를 ‘종속변수’ 상자로, tutor를 ‘집단변수’ 상자로 이동합니다.\n’검정’에서 ’Welch’s’를 체크합니다.\n‘추가 통계’에서 ’평균 차이’와 그 아래의 ’신뢰구간’, ’효과 크기’를 체크합니다.\n’가정검정’에서 ’동질성 검정’과 ’정규분포성 검정’을 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.5.2 Welch 검정의 가정\nWelch 검정의 가정은 Student \\(t\\)-검정의 가정과 매우 유사합니다(Student \\(t\\)-검정의 가정 참조). 다만, Welch 검정은 분산의 동질성을 가정하지 않는다는 점에서 차이가 있습니다. 따라서 남는 가정은 정규성과 독립성뿐입니다. 이 가정들의 구체적인 내용은 Student 검정과 Welch 검정 모두 동일합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>두 평균 비교하기</span>"
    ]
  },
  {
    "objectID": "11-Comparing-two-means.html#sec-paired-samples-t-test",
    "href": "11-Comparing-two-means.html#sec-paired-samples-t-test",
    "title": "11  두 평균 비교하기",
    "section": "11.6 대응 표본 \\(t\\)-검정",
    "text": "11.6 대응 표본 \\(t\\)-검정\nStudent 검정이든 Welch 검정이든, 독립 표본 \\(t\\)-검정은 두 개의 표본이 서로 독립적일 때 사용하도록 설계되었습니다. 실험 참가자가 두 개의 실험 조건 중 하나에 무작위로 할당되는 경우에는 이 가정이 자연스럽게 충족됩니다. 그러나 다른 연구 설계에서는 이 가정이 적절하지 않을 수 있습니다. 특히, 반복 측정 설계(repeated measures design)에서는 각 참가자가 두 실험 조건에서 동일한 종속 변수로 측정되므로, 독립 표본 \\(t\\)-검정을 적용하는 것이 적절하지 않습니다.\n예를 들어, 음악을 듣는 것이 사람들의 작업 기억(working memory) 용량을 감소시키는지 알고 싶다고 가정해 보겠습니다. 이를 위해, 우리는 각 참가자의 작업 기억 용량을 두 가지 조건(음악을 들을 때와 음악을 듣지 않을 때)에서 측정할 수 있습니다. 이러한 실험 설계에서는 각 참가자가 두 집단 모두에 속하게 됩니다.16 따라서 이 경우에는 문제를 다르게 접근해야 하며, 대응 표본 \\(t\\)-검정(paired samples \\(t\\)-test)을 사용해야 합니다.\n\n\n\n\n\n\n반복 측정 설계란?\n\n\n\n반복 측정 설계(Repeated Measures Design)는 동일한 참가자에게 여러 조건에서 반복적으로 측정을 수행하는 연구 설계입니다. 즉, 동일한 참가자를 여러 번 측정되므로, 실험 내에서 집단에 참여하는 개인 사이의 차이를 통제할 수 있습니다.\n반복 측정 설계의 예는 다음과 같습니다.\n\n음악과 작업 기억 용량 연구\n\n연구자가 한 그룹의 참가자들에게 음악을 들을 때와 음악을 듣지 않을 때 각각 작업 기억 용량을 측정한다고 가정해 보겠습니다.\n\n각 참가자는 두 가지 조건에서 측정되므로, 개인 사이의 차이를 고려하지 않고도 음악의 영향을 직접 비교할 수 있습니다.\n\n운동 프로그램이 체력에 미치는 영향 연구\n\n연구자가 참가자들의 체력을 운동 프로그램 시작 전과 8주 후에 각각 측정하는 경우\n\n동일한 참가자를 두 번 측정하여 운동 프로그램의 효과를 분석할 수 있습니다.\n\n\n반복 측정 설계는 다음과 같은 장점이 있습니다.\n\n개인차 통제: 같은 참가자가 여러 조건에서 측정되므로, 집단별로 다른 참가자일 발생하는 개인별 차이가 분석에 미치는 영향을 줄일 수 있습니다.\n적은 표본 크기: 독립 표본 설계보다 적은 표본으로도 충분한 통계적 검정을 수행할 수 있습니다.\n\n더 높은 검정력: 개인차 변동을 줄이므로, 차이를 감지할 확률(통계적 검정력)이 증가합니다.\n\n그러나 반복 측정 설계에는 다음과 같은 단점이 있습니다.\n\n순서 효과(Order Effect): 참가자가 여러 조건을 경험하면서 피로, 학습 효과 등이 결과에 영향을 미칠 수 있습니다.\n\n예: 첫 번째 실험에서 배운 내용이 두 번째 실험 결과에 영향을 줄 수 있습니.\n\n해결 방법: 조건의 순서를 무작위로 배정하는 대조(counterbalancing) 기법을 사용합니다.\n\n\n이월 효과(Carryover Effect): 이전 조건의 영향이 이후 조건에 남아 있을 수 있습니다.\n\n예: 약물 실험에서 첫 번째 약물의 효과가 사라지기 전에 두 번째 약물을 복용하는 경우\n\n해결 방법: 세척 기간(washout period)을 두어 첫 번째 조건의 효과가 사라진 후 다음 실험을 진행합니다.\n\n\n반복 측정 설계와 독립 표본 설계의 차이를 표로 정리하면 다음과 같습니다.\n\n\n\n\n\n\n\n\n\n반복 측정 설계\n독립 표본 설계\n\n\n\n\n참가자 배정\n동일한 참가자가 여러 조건에 참여\n서로 다른 참가자들이 각각 한 조건에만 참여\n\n\n개인차 통제\n개인차가 줄어듦\n개인차가 분석에 영향을 줄 수 있음\n\n\n표본 크기\n비교적 적은 표본으로도 충분\n더 많은 참가자가 필요\n\n\n검정력\n더 높음\n상대적으로 낮음\n\n\n순서 효과\n발생 가능\n없음\n\n\n\n결론적으로, 반복 측정 설계는 집단의 참가자 차이를 최소화하고 검정력을 높이는 장점이 있지만, 순서 효과나 이월 효과를 고려해야 합니다. 실험의 특성과 연구 목표에 따라 반복 측정 설계를 사용할지, 독립 표본 설계를 사용할지를 결정하는 것이 중요합니다.\n\n\n\n11.6.1 데이터\n이번에 사용할 데이터셋은 Chico 박사의 수업에서 가져왔습니다.17 그녀의 수업에서는 학생들이 학기 초에 한 번, 학기 후반에 한 번, 총 두 번의 시험을 봅니다. 그녀의 말에 따르면, 이 수업은 매우 어렵고 대부분의 학생들은 큰 도전으로 느낍니다. 하지만 그녀는 어려운 평가 기준을 설정하면 학생들이 더 열심히 공부하게 된다고 주장합니다. 그녀의 이론은 첫 번째 시험이 학생들에게 일종의 “경각심을 주는 계기”가 된다는 것입니다. 즉, 학생들이 수업이 얼마나 어려운지 깨닫고 두 번째 시험을 위해 더 열심히 공부하여 더 좋은 점수를 받을 것이라는 것이죠. 과연 그녀의 주장이 맞을까요? 이를 검정하기 위해 chico.csv 파일을 jamovi로 불러옵니다. 이번에는 jamovi가 데이터를 불러오면서 측정 수준을 정확하게 할당하는 데 성공했습니다.\nchico 데이터셋에는 세 개의 변수가 포함되어 있습니다.\n1. id: 각 학생을 식별하는 변수\n2. grade_test1: 첫 번째 시험의 성적\n3. grade_test2: 두 번째 시험의 성적\njamovi 스프레드시트를 살펴보면 이 수업이 정말 어려운 것처럼 보입니다(대부분의 성적이 50%~60% 사이). 하지만 첫 번째 시험보다 두 번째 시험에서 점수가 향상된 것처럼 보입니다.\nFigure 11.12 에서 보듯이 기술통계를 빠르게 살펴보면 이러한 인상이 어느 정도 뒷받침됩니다. 20명의 학생을 대상으로 한 평균 점수는 첫 번째 시험에서 57%였지만, 두 번째 시험에서는 58%로 올랐습니다. 그러나 표준 편차가 각각 6.6%와 6.4%인 점을 고려하면, 이 향상이 단순한 착시 효과일 수도 있다는 느낌이 듭니다. 이 인상은 Figure 11.13 (a) 에서 평균과 신뢰 구간을 나타낸 그래프를 보면 더욱 강화됩니다. 신뢰 구간이 넓은 것을 보면, 학생들의 성적이 실제로 향상되었다기보다는 단순한 우연일 가능성이 높다고 생각할 수도 있습니다.\n\n\n\n\n\n\n\n\nFigure 11.12. chico 데이터의 두 시험 성적 변수에 대한 기술 통계\n\n\n\n\n\n하지만, 이 첫인상은 잘못되었습니다. 그 이유를 이해하려면 Figure 11.13 (b) 에서 보여주는 첫 번째 시험 성적과 두 번째 시험 성적 간의 산점도를 살펴보세요. 이 그래프에서 각 점은 한 학생의 두 시험 성적을 나타냅니다. 첫 번째 시험 성적(\\(x\\) 좌표)이 두 번째 시험 성적(\\(y\\) 좌표)과 같다면, 해당 점은 대각선 위에 위치합니다. 대각선 위에 있는 점들은 두 번째 시험에서 성적이 향상된 학생들을 나타냅니다. 중요한 점은, 대부분의 데이터 포인트가 대각선 위에 있다는 것입니다. 즉, 거의 모든 학생이 두 번째 시험에서 성적이 향상되었습니다.\n이러한 결과를 바탕으로, 우리는 개별 학생이 시험 간에 얼마나 향상했는지를 분석해야 합니다. 따라서 이를 새로운 데이터로 취급하여, chico 데이터에 각 학생의 향상 정도를 나타내는 새로운 변수를 추가해야 합니다. 가장 쉬운 방법은 새로운 변수를 만들어 grade_test2 - grade_test1을 계산하는 것입니다.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigure 11.13. 첫 번째 시험과 두 번째 시험의 평균 성적 및 95% 신뢰 구간(a). 각 학생의 첫 번째 시험과 두 번째 시험 성적을 나타낸 산점도(b).\n\n\n\n이제 학생들의 향상 점수를 나타내는 변수(improvement)를 계산했으므로, Figure 11.14 에서 보여주는 것처럼 향상 점수의 분포를 나타내는 히스토그램을 그릴 수 있습니다. 히스토그램을 보면 학생들의 성적이 실제로 향상되었음을 명확히 알 수 있습니다. 대부분의 학생들이 두 번째 시험에서 더 높은 점수를 받았으며, 이는 히스토그램의 거의 모든 부분이 0 이상의 값을 갖고 있는 것으로 나타납니다.\n\n\n\n\n\n\nFigure 11.14. Dr Chico의 수업에서 각 학생이 향상한 정도를 나타내는 jamovi 히스토그램. 대부분의 분포가 0 이상에 위치하며, 이는 대부분의 학생들이 첫 번째 시험보다 두 번째 시험에서 더 높은 성적을 기록했음을 나타냄.\n\n\n\n\n\n\n\n\n\nTip 11.3. 실습: chico 데이터에 대한 기술통계\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Chico’를 선택합니다.\n다음을 수행하며 두 시험 성적에 대한 Figure 11.12 같은 기술통계를 얻을 수 있습니다.\n\n\n‘분석’-‘기술통계’-‘기술통계’ 메뉴를 선택합니다.\ngrade_test1과 grade_test2를 ‘변수’ 상자로 이동합니다.\n\n\n학생의 향상 정도를 나나태는 새로운 변수를 다음과 같이 추가합니다.\n\n\n‘데이터’-‘추가’-‘다중 계산 변수’-’추가’를 선택합니다.\n추가된 변수를 더블클릭하여 이름을 ’향상 점수’로 설정합니다.\n\\(f_x\\) 열의 =가 표시된 상자에 grade_test2 - grade_test1 계산식을 입력합니다.\n\n\n\n\n\n\n\n\n\n\n\n새롭게 추가한 향상 점수에 대한 기술통계를 수행하면 다음과 같은 결과를 얻을 수 있습니다.\n\n\n‘분석’-‘기술통계’-‘기술통계’- 메뉴를 선택합니다.\n향상 점수를 ‘변수’ 상자로 이동합니다.\n‘도표’ 옵션을 확장하여 ’히스토그램’을 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.6.2 대응 표본 \\(t\\)-검정이란?\n앞서 살펴본 내용을 바탕으로, 적절한 \\(t\\)-검정을 구성하는 방법을 생각해 보겠습니다. 한 가지 가능성은 grade_test1과 grade_test2를 결과변수로 사용하여 독립 표본 \\(t\\)-검정을 실행하는 것입니다. 그러나 이것은 명백히 잘못된 접근 방식이라는 점을 알 수 있습니다. 독립 표본 \\(t\\)-검정은 두 표본 간에 특정한 관계가 없다고 가정하기 때문입니다. 하지만 이번 경우에는 데이터가 반복 측정 구조를 가지고 있으므로 이 가정은 성립하지 않습니다.\n앞서 소개한 용어를 사용하자면, 만약 우리가 독립 표본 \\(t\\)-검정을 시도한다면, 우리가 실제로 관심을 두어야 하는 개인 내 차이(within-subject differences)와 우리가 고려하지 말아야 할 개인 간 변동성(between-subject variability)을 혼동하는 셈이 됩니다.\n이 문제의 해결책은 명확합니다. 이미 이전 절에서 모든 어려운 작업을 마쳤기 때문이죠. grade_test1과 grade_test2에 대해 독립 표본 \\(t\\)-검정을 수행하는 대신, 우리는 개인 내 차이 변수인 향상 점수에 대해 단일 표본 \\(t\\)-검정을 수행하면 됩니다.\n이를 조금 더 정식화하면 다음과 같습니다. \\(X_{i1}\\)은 \\(i\\)번째 참가자의 첫 번째 변수의 값이고, \\(X_{i2}\\)는 같은 참가자의 두 번째 변수의 값이라 할 때, 차이는 다음과 같이 정의됩니다.\n\\[D_i=X_{i1}-X_{i2}\\]\n여기서 차이 점수는 “변수 1 - 변수 2”의 형태로 정의됩니다. 즉, 향상이 양수 값이 되도록 하려면 “시험 2”를 “변수 1”로 설정해야 합니다. 동일한 방식으로, 모집단 평균 차이 변수는 다음과 같이 정의할 수 있습니다.\n\\[\\mu_D = \\mu_1 - \\mu_2\\]\n이를 가설 검정으로 변환하면, 모딥단의 평균의 차이에 대한 귀무가설과 대립가설은 다음과 같습니다.\n\\[H_0:\\mu_D=0\\]\n\\[H_1:\\mu_D \\neq 0\\]\n여기서는 양측 검정을 가정하고 있습니다. 이는 단일 표본 \\(t\\)-검정의 가설을 설정하는 방식과 거의 동일합니다. 단 하나의 차이점은, 귀무가설에서 예측하는 특정한 값이 0이라는 것입니다. 따라서, \\(t\\)-통계량도 거의 동일한 방식으로 정의됩니다. 차이 점수의 평균을 \\(\\bar{D}\\)라고 하면, 검정 통계량은 다음과 같습니다.\n\\[t=\\frac{\\bar{D}}{SE(\\bar{D})}=\\frac{\\bar{D}}{\\frac{\\hat{\\sigma}_D}{\\sqrt{N}}}\\]\n여기서 \\(\\hat{\\sigma}_D\\)는 차이의 표준 편차입니다. 이는 특별한 점이 없는 일반적인 단일 표본 \\(t\\)-검정에 해당하므로, 자유도는 여전히 \\(N - 1\\)입니다.\n결국, 대응 표본 \\(t\\)-검정은 완전히 새로운 검정이 아닙니다. 단일 표본 \\(t\\)-검정을 두 변수 간의 차이에 적용한 것일 뿐입니다. 사실 매우 간단한 개념입니다. 다만, 대응 표본 검정을 언제 사용해야 하는지, 그리고 독립 표본 \\(t\\)-검정보다 왜 더 적절한지를 이해하는 것이 중요하기 때문에 이에 대한 논의가 길어졌을 뿐입니다.\n\n\n11.6.3 jamovi에서 검정 수행하기\njamovi에서 대응 표본 \\(t\\)-검정을 수행하는 방법은 무엇일까요? 한 가지 방법은 앞서 설명한 과정을 따르는 것입니다. 즉, “차이” 변수를 만든 다음, 그 변수에 대해 단일 표본 \\(t\\)-검정을 실행하는 것이죠. 우리는 이미 향상 점수라는 변수를 생성했으므로, 이를 사용하여 검정을 수행한 결과를 Figure 11.15 에서 확인할 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 11.15. 대응 차이 점수에 대한 단일 표본 \\(t\\)-검정 결과\n\n\n\n\n\nFigure 11.15 에 표시된 결과는 (당연히) 우리가 이전에 단일 표본 \\(t\\)-검정을 수행했을 때의 형식과 동일합니다(Section 11.2 참고). 그리고 이 결과는 우리의 직관을 확인해 줍니다. 시험 1에서 시험 2로 평균 1.4의 향상이 있었으며, 이는 0과 유의하게 다릅니다\\((t(19) = 6.48, p &lt; .001)\\).\n하지만, 만약 새로운 변수를 생성하는 것이 귀찮다면 어떻게 할까요? 또는 단일 표본 \\(t\\)-검정과 대응 표본 \\(t\\)-검정의 차이를 명확히 구분하고 싶다면? 그럴 경우, jamovi에서 제공하는 ‘대응 표본 T-검정’ 분석을 사용할 수 있습니다. 이 방법을 사용하면 Figure 11.16 결과를 얻을 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 11.16. 대응 표본 \\(t\\)-검정 결과. Figure 11.15 와 비교해 보세요.\n\n\n\n\n\n결과 값들은 단일 표본 검정에서 얻은 값들과 완전히 동일합니다. 이는 당연한 일입니다. 대응 표본 \\(t\\)-검정은 결국 단일 표본 \\(t\\)-검정을 변형한 형태에 불과하기 때문입니다.\n\n\n\n\n\n\nTip 11.4. 실습: 대응 표본 \\(t\\)-검정\n\n\n\nTip 11.3 실습을 이어서 다음을 수행합니다.\n\nTip 11.3 에서 만든 향상 점수로 다음처럼 단일 표본 T-검정을 수행합니다.\n\n\n‘분석’-‘T-검정’-‘단일표본 T-검정’ 메뉴를 선택합니다.\n향상 점수를 ‘변수’ 상자로 이동합니다.\n’가설’의 검정 값이 0으로 설정되어 있는지 확인합니다.\n‘추가 통계’에서 ’평균차이’와 그 아래 ’신뢰구간’, 그리고 ’효과 크기’를 체크합니다.\n\n\n\n\n\n\n\n\n\n\n2.향상 점수 변수 없이, 원래의 변수인 grade_test1과 grade_test2를 사용하여 대응 표본 T-검정을 하려면, 다음과 같이 수행합니다. - ‘분석’-‘T-검정’-‘대응표본 T-검정’ 메뉴를 선택합니다. - grade_test2를 ‘대응 변수’ 상자로 이동합니다. 그 다음 grade_test1를 ‘대응 변수’ 상자로 이동합니다. (이 순서로 해야 grade_test2 - grade_test1을 ‘평균 차이’로 계산합니다.) - ’추가 통계’에서 ’평균차이’와 그 아래 ’신뢰구간’, 그리고 ’효과 크기’를 체크합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>두 평균 비교하기</span>"
    ]
  },
  {
    "objectID": "11-Comparing-two-means.html#단측-검정",
    "href": "11-Comparing-two-means.html#단측-검정",
    "title": "11  두 평균 비교하기",
    "section": "11.7 단측 검정",
    "text": "11.7 단측 검정\n귀무가설 검정 이론을 소개할 때, 특정한 상황에서는 단측 검정을 지정하는 것이 적절할 수 있다고 언급한 바 있습니다(Section 9.4.3 참조). 지금까지 수행한 모든 \\(t\\)-검정은 양측 검정이었습니다. 예를 들어, Zeppo 박사의 수업에서 성적에 대한 단일 표본 \\(t\\)-검정을 수행할 때, 귀무가설은 실제 평균이 \\(67.5\\)라는 것이었고, 대립가설은 실제 평균이 \\(67.5\\)보다 크거나 작다는 것이었습니다. 하지만 우리가 실제 평균이 \\(67.5\\)보다 큰지에만 관심이 있고, 실제 평균이 \\(67.5\\)보다 낮은지를 검정하는 데는 관심이 없다고 가정해봅시다. 이 경우, 귀무가설은 실제 평균이 \\(67.5\\) 이하라는 것이 되고, 대립가설은 실제 평균이 \\(67.5\\)보다 크다는 것이 됩니다. jamovi에서 ‘단일 표본 T-검정’ 분석을 수행할 때, ‘가설’ 옵션에서 ‘\\(&gt;\\) 검정(테스트) 값’ 옵션을 선택하면 이를 지정할 수 있습니다. 이렇게 설정하면 Figure 11.17 결과를 얻을 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 11.17. 단측 가설(즉, 실제 평균이 \\(67.5\\)보다 크다는 가설)을 사용하는 ’단일 표본 T-검정’의 jamovi 결과\n\n\n\n\n\n이전과 비교했을 때 몇 가지 변화가 있다는 점을 주목하세요. 가장 중요한 점은 실제 가설이 변경되어 다른 검정을 반영하고 있다는 것입니다. (Figure 11.17 하단의 \\(H_a\\)는 대립가설을 나타냅니다.). 두 번째로, \\(t\\)-통계량과 자유도는 변하지 않았지만, \\(p\\)-값이 변경되었습니다. 이는 단측 검정이 양측 검정과 다른 기각역을 가지기 때문입니다. 왜 그런지 기억이 나지 않는다면 Chapter 9 와 특히 Section 9.4.3 를 다시 읽어보는 것이 도움이 될 것입니다. 세 번째로, 신뢰구간이 달라졌습니다. 이제 양측 신뢰구간이 아닌 단측 신뢰구간을 보고합니다. 양측 신뢰구간에서는 숫자 \\(a\\)와 \\(b\\)를 찾아 여러 번 연구를 반복할 경우 \\(95\\%\\)의 확률로 평균이 \\(a\\)와 \\(b\\) 사이에 존재한다는 것입니다. 반면, 단측 신뢰구간에서는 단일 숫자 \\(a\\)를 찾아 \\(95\\%\\)의 확률로 실제 평균이 \\(a\\)보다 클 것이라는(또는 ‘가설’ 섹션에서 ’&lt; 검정(테스트) 값’을 선택한 경우 \\(a\\)보다 작을 것이라는) 것입니다.\n\n\n\n\n\n\nTip 11.5. 실습: 단일 표본 단측 \\(t\\)-검정\n\n\n\nTip 11.1 실습을 이어서 다음 가설에 대한 단측 검정을 수행합니다.\n\\[H_0: \\mu \\le 67.5\\] \\[H_1: \\mu &gt; 67.5\\]\n\n‘분석’-‘T-검정’-‘단일표본 T-검정’ 메뉴를 선택합니다.\n‘단일표본 T 검정’ 창에서 다음을 설정합니다.\n\n\nx를 ‘종속변수’ 상자로 이동합니다.\n‘가설’ 옵션의 ‘검정 값’에 67.5를 입력하고, 그 아래에서 대립가설로’&gt; 테스트 값’을 선택합니다.\n\n‘추가 통계’에서 ’평균차이’와 그 아래 ’신뢰구간’, 그리고 ’효과 크기’를 체크합니다.\n\n\n오른쪽 ‘결과’ 창에서 대립 가설이 \\(H_a \\, \\mu &gt; 67.5\\)로 표시되었는지 확인하고 다른 결과들이 기존 결과에서 어떻게 변화하였는지 확인해 봅니다. (대립가설 설정을 ’ \\(\\neq\\) 검정 값’으로 원래대로 바꾸었을 때와의 차이를 확인해 봅니다.)\n\n\n\n\n\n\n\n\n\n\n\n\n지금까지 단일 표본 단측 \\(t\\)-검정을 수행하는 방법을 살펴보았습니다만, 모든 유형의 \\(t\\)-검정에서 단측 검정을 수행할 수 있습니다. 독립 표본 \\(t\\)-검정에서도 마찬가지입니다. 예를 들어, 집단 A가 집단 B보다 높은 점수를 받는지에만 관심이 있고, 집단 B가 집단 A보다 높은지 여부는 신경 쓰지 않는 경우, 단측 검정을 수행할 수 있습니다. Harpo 박사의 수업에서, Anastasia의 학생들이 Bernadette의 학생들보다 높은 성적을 받았는지를 확인하고 싶다고 가정해봅시다. 이 분석에서는 ‘가설’ 옵션에서 ’집단 1 &gt; 집단 2’를 지정하면 됩니다. 그러면 Figure 11.18 에 나타난 결과를 얻게 됩니다.\n\n\n\n\n\n\n\n\nFigure 11.18. Anastasia의 학생들이 Bernadette의 학생들보다 높은 성적을 받았다는 단측 가설을 사용하는 ’독립 표본 T-검정’의 jamovi 결과\n\n\n\n\n\n결과는 예상한 방식으로 변경된다. 대립가설의 정의가 변경되었으며, \\(p\\)-값이 달라졌고, 이제 양측 신뢰구간 대신 단측 신뢰구간을 보고합니다.\n\n\n\n\n\n\n실습: 독립 표본 단측 \\(t\\)-검정\n\n\n\nTip 11.2 실습을 이어서 다음 가설에 대한 단측 검정을 수행합니다.\n\\[H_0: \\mu_{Anastasia} \\le \\mu_{Bernadette}\\] \\[H_1: \\mu_{Anastasia} &gt; \\mu_{Bernadette}\\]\n\n오른쪽 결과 창에서 ‘독립표본 T 검정’ 부분을 선택하면 왼쪽에 ‘독립표본 T 검정’ 창이 나타납니다.\n‘단일표본 T 검정’ 창에서 다음 설정을 변경하여 양측 검정을 단측 검정으로 바꿉니다.\n\n\n‘가설’ 옵션에서 대립가설로 ’집단 1 &gt; 집단 2’를 선택합니다.\n\n’추가 통계’에서 ’신뢰구간’을 선택하여 신뢰구간도 같이 표시되도록 합니다.\n\n\n오른쪽 ‘결과’ 창에서 대립 가설이 \\(H_a \\, \\mu_{Anastasia} &gt; \\mu_{Bernadette}\\)로 표시되었는지 확인하고 다른 결과들이 기존 결과에서 어떻게 변화하였는지 확인해 봅니다. (대립가설 설정을 ’집단 1 \\(\\neq\\) 집단 2’로 원래대로 바꾸었을 때와의 차이를 확인해 봅니다.)\n\n\n\n\n\n\n\n\n\n\n\n\n그렇다면 대응 표본 \\(t\\)-검정의 경우는 어떨까요? Chico 박사의 수업에서 시험 1보다 시험 2의 성적이 향상된다는 가설을 검정하고 싶고, 성적이 감소할 가능성은 고려하지 않는다고 가정합시다. jamovi에서 ‘가설’ 옵션에서 grade_test2(‘측정 1’, 첫 번째로 대응 변수 상자로 설정된 값)가 grade_test1(‘측정 2’)보다 크다고 지정하면 됩니다. 그러면 Figure 11.19 에 나타난 결과를 얻게 됩니다.\n\n\n\n\n\n\n\n\nFigure 11.19. grade_test2(‘측정 1’)가 grade_test1(‘측정 2’)보다 크다는 단측 가설을 사용하는 ’대응 표본 T-검정’의 jamovi 결과\n\n\n\n\n\n또한 결과는 예측 가능한 방식으로 변경됩니다. 가설이 변경되었으며, \\(p\\)-값이 변경되었고, 신뢰구간도 이제 단측 신뢰구간으로 보고됩니다.\n\n\n\n\n\n\n실습: 대응 표본 단측 \\(t\\)-검정\n\n\n\nTip 11.4 실습을 이어서 다음 가설에 대한 단측 검정을 수행합니다.\n\\[H_0: \\mu_{\\text{grad test2}} \\le \\mu_{\\text{grade test1}}\\] \\[H_1: \\mu_{\\text{grade test2}} &gt; \\mu_{\\text{grade test1}}\\]\n\n오른쪽 결과 창에서 ‘대응표본 T 검정’ 부분을 선택하면 왼쪽에 ‘대응표본 T 검정’ 창이 나타납니다.\n‘대응표본 T 검정’ 창에서 다음 설정을 변경하여 양측 검정을 단측 검정으로 바꿉니다.\n\n\n‘가설’ 옵션에서 대립가설로 ’측정 1 &gt; 측정 2’를 선택합니다.\n\n\n오른쪽 ‘결과’ 창에서 대립 가설이 \\(H_a \\, \\mu_{측정 1} &gt; \\mu_{측정 2}\\)로 표시되었는지 확인합니다. 그리고 측정 1이 grade_test2고, 측정 2가 grade_tet1인지 확인합니다. 다른 결과들이 기존 결과에서 어떻게 변화하였는지 확인해 봅니다. (대립가설 설정을 ’측정 1 \\(\\neq\\) 측정 2’로 원래대로 바꾸었을 때와의 차이를 확인해 봅니다.)",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>두 평균 비교하기</span>"
    ]
  },
  {
    "objectID": "11-Comparing-two-means.html#효과-크기",
    "href": "11-Comparing-two-means.html#효과-크기",
    "title": "11  두 평균 비교하기",
    "section": "11.8 효과 크기",
    "text": "11.8 효과 크기\n\\(t\\)-검정에서 가장 일반적으로 사용되는 효과 크기 측도는 Cohen의 d입니다 (Cohen, 1988). 원칙적으로 매우 간단한 측도이지만, 세부적으로 살펴보면 여러 가지 복잡한 요소가 있습니다. Cohen 자신은 이를 주로 독립 표본 \\(t\\)-검정, 특히 Student 검정의 맥락에서 정의했습니다. 이 경우, 효과 크기를 정의하는 자연스러운 방법은 평균 간 차이를 표준 편차의 추정치로 나누는 것입니다. 즉, 다음과 같은 계산을 수행합니다: \\[d=\\frac{(\\text{평균 1})-(\\text{평균 2})}{\\text{표준 편차}}\\]\n그는 Table 11.3 에서 \\(d\\)를 해석하는 대략적인 가이드를 제시했습니다.\n\n\n\n\nTable 11.3. Cohen의 \\(d\\)를 해석하기 위한 (매우) 대략적인 가이드. 개인적으로는 이를 맹목적으로 사용하지 않는 것을 권장합니다. \\(d\\) 통계량은 자체적으로 자연스러운 해석을 제공합니다. 즉, 평균 차이를 표준 편차 단위로 변환하여 설명합니다. 따라서 이를 실제적인 의미에서 어떻게 해석할지 고려하는 것이 일반적으로 좋은 접근 방식입니다. 어떤 맥락에서는 “작은” 효과라도 실질적으로 중요한 의미를 가질 수 있습니다. 반면, 어떤 경우에는 “큰” 효과가 그다지 흥미롭지 않을 수도 있습니다.\n\n\n\n\n\n\\(d\\)-값대략적 해석\n\n약 0.2\\(\\text{``}\\)작은\\(\\text{''}\\) 효과\n\n약 0.5\\(\\text{``}\\)중간\\(\\text{''}\\) 효과\n\n약 0.8\\(\\text{``}\\)큰\\(\\text{''}\\) 효과\n\n\n\n\n\n\n\n이러한 정의는 명확해 보이지만, 실제로는 그렇지 않습니다. 이는 주로 Cohen이 표준 편차를 측정하는 방식에 대해 구체적으로 명시하지 않았기 때문입니다(그의 입장에서 보면, 그는 책에서 더 넓은 논점을 다루고 있었으며 사소한 세부 사항을 지나치게 따지는 것이 목적이 아니었습니다). McGrath & Meyer (2006) 에서 논의된 바와 같이, 일반적으로 사용되는 여러 가지 버전이 존재하며, 각 저자는 약간씩 다른 표기법을 채택하는 경향이 있습니다. 단순성을 위해(정확성보다는), 나는 표본에서 계산한 통계를 나타낼 때 \\(d\\)를 사용하고, 이론적인 모집단 효과를 나타낼 때는 \\(\\delta\\)를 사용하겠습니다. 이는 결국 여러 가지 서로 다른 개념이 모두 \\(d\\)로 불릴 수 있음을 의미합니다.\n내 생각에는 Cohen의 \\(d\\)가 필요한 경우는 오직 \\(t\\)-검정을 수행할 때뿐이며, jamovi는 다양한 \\(t\\)-검정에 대해 효과 크기를 계산하는 옵션을 포함하고 있습니다.\n\n11.8.1 단일 표본에서의 Cohen의 \\(d\\)\n가장 단순한 상황은 단일 표본 \\(t\\)-검정과 관련된 경우입니다. 이 경우, 비교 대상은 단일 표본 평균 \\(\\bar{X}\\)와 하나의 (가설적) 모집단 평균 \\(\\mu_0\\)입니다. 뿐만 아니라, 모집단의 표준 편차를 추정하는 유일한 합리적인 방법이 존재합니다. 즉, 우리는 단순히 일반적인 추정치 \\(\\hat{\\sigma}\\)를 사용하면 됩니다. 따라서 \\(d\\)를 계산하는 유일한 방법은 다음과 같습니다:\n\\[d=\\frac{\\bar{X}-\\mu_0}{\\hat{\\sigma}}\\]\nFigure 11.6 결과를 보면, 효과 크기 값은 Cohen의 \\(d = 0.50\\)입니다. 전체적으로 보면, Zeppo 박사의 심리학 수업을 듣는 학생들의 평균 성적(\\(mean = 72.3\\))은, 만약 이들이 다른 학생들과 동일한 수준에서 수행했다면 예상되는 수준(\\(67.5\\))보다 약 0.5 표준편차 더 높습니다. Cohen의 대략적인 가이드에 따르면, 이는 중간 정도의 효과 크기에 해당합니다.\n\n\n11.8.2 Student의 \\(t\\)-검정에서의 Cohen의 \\(d\\)\nCohen의 \\(d\\)에 대한 논의의 대부분은 Student의 독립 표본 \\(t\\)-검정과 유사한 상황에 초점을 맞추고 있으며, 이 맥락에서는 여러 가지 다른 버전의 \\(d\\)를 사용할 수 있기 때문에 더 복잡해집니다. 여러 버전의 \\(d\\)가 존재하는 이유를 이해하려면, 모집단 효과 크기 \\(\\delta\\)에 해당하는 공식을 작성해보는 것이 도움이 됩니다. 이는 다음처럼 비교적 단순한 개념입니다:\n\\[\\delta=\\frac{\\mu_1-\\mu_2}{\\sigma}\\]\n여기서, \\(\\mu_1\\)과 \\(\\mu_2\\)는 각각 집단 1과 집단 2에 해당하는 모집단 평균이며, \\(\\sigma\\)는 두 모집단의 공통된 표준 편차를 의미합니다. \\(\\delta\\)를 추정하는 가장 명확한 방법은 \\(t\\)-검정에서 수행한 것과 동일한 방식으로, 즉, 분자의 경우 표본 평균을 사용하고, 분모에는 합동 표준편차 추정치를 사용하는 것입니다:\n\\[d=\\frac{\\bar{X}_1-\\bar{X}_2}{\\hat{\\sigma}_p}\\]\n여기서 \\(\\hat{\\sigma}_p\\)는 \\(t\\)-검정에서 사용된 것과 동일한 합동 표준편차 측정값입니다. 이는 Student의 \\(t\\)-검정 결과에 적용할 때 가장 일반적으로 사용되는 Cohen의 \\(d\\) 버전이며, jamovi에서 제공하는 버전이기도 합니다. 때때로 Hedges의 \\(g\\) 통계량이라고도 불립니다(Hedges, 1981).\n그러나 다른 가능한 버전도 존재하므로 이를 간략히 설명하겠습니다. 첫째, 표준편차를 계산할 때 두 집단 중 하나만 기준으로 사용할 이유가 있을 수도 있습니다. 이 접근법(Glass의 \\(\\triangle\\), 델타라고 발음함)은 두 그룹 중 하나가 다른 그룹보다 “자연스러운 변동”을 더 잘 반영한다고 여겨질 때만 의미가 있습니다. 예를 들어, 한 집단이 대조군(control group)일 때가 그러한 경우입니다. 둘째, 일반적인 합동 표준편차 계산에서 표본분산의 편향을 보정하기 위해 \\(N - 2\\)로 나누는 과정이 있습니다. Cohen의 \\(d\\)의 한 버전에서는 이 보정을 생략하고 대신 \\(N\\)으로 나눕니다. 이 버전은 모집단의 효과 크기를 추정하기보다는 표본 내 효과 크기를 계산하려고 할 때 유용합니다. 마지막으로, Hedges의 \\(g\\)라는 버전이 있으며, 이는 Hedges & Olkin (1985) 에서 제안한 것으로, 기존의 Cohen의 \\(d\\) 추정치에 약간의 편향이 있음을 지적하고 이를 수정하기 위한 작은 보정값을 도입한 것입니다.18\n어쨌든, 위에서 설명한 다양한 변형을 무시하고 jamovi에서 기본적으로 제공하는 버전을 살펴봅시다. Figure 11.10 에서는 Cohen의 \\(d = 0.74\\)이며, 이는 Anastasia 교수의 반 학생들의 평균 성적이 Bernadette 교수의 반 학생들보다 평균적으로 \\(0.74\\) 표준편차 더 높다는 것을 의미한다. Welch 검정에서도 추정된 효과 크기도 유사하게 계산합니다(Figure 11.11).\n\n\n11.8.3 대응 표본 \\(t\\)-검정에서의 Cohen의 \\(d\\)\n마지막으로, 대응 표본 \\(t\\)-검정의 경우에는 어떻게 해야 할까요? 이 경우, 답은 여러분이 무엇을 하려는지에 따라 달라집니다. jamovi에서는 효과 크기를 차이 분포를 기준으로 측정하려 한다고 가정하며, 이에 따라 계산되는 \\(d\\) 값은 다음과 같습니다.\n\\[d=\\frac{\\bar{D}}{\\hat{\\sigma}_D}\\]\n여기서 \\(\\hat{\\sigma}_D\\)는 두 시험의 점수 차이의 표준편차에 대한 추정치입니다. Figure 11.16 에서 Cohen의 \\(d = 1.45\\)이며, 이는 두 번재 시험 점수가 평균적으로 첫 번째 시험 점수보다 \\(1.45\\) 표준 편차만큼 높다는 것을 의미합니다.\n이것이 jamovi의 ‘대응 표본 T-검정’ 분석에서 보고되는 Cohen의 \\(d\\) 값입니다. 다만, 이것이 여러분이 원하는 측도인지 판단하는 것이 관건입니다. 연구의 실질적인 의미에 관심이 있다면, 효과 크기를 차이 변수가 아니라 원래 변수를 기준으로 측정하는 것이 중요합니다. (예를 들어, Chico 박사의 수업에서 시간 경과에 따른 1점의 성적 향상은 학생 사이의 성적 변동성을 기준으로 볼 때 매우 작은 변화일 수 있습니다.) 평균의 차이가 원래 변수 측면에서의 효과를 탐색하기를 원한다면, Student 또는 Welch 검정에서 사용하는 것과 동일한 Cohen의 \\(d\\) 값을 사용해야 합니다. 그러나 jamovi에서는 이를 간단히 수행할 수 있는 방법이 없습니다. 기본적으로 데이터 스프레드시트의 구조를 변경해야 하므로 여기서는 다루지 않겠습니다.19 하지만 이 관점에서의 Cohen의 \\(d\\) 값은 \\(0.22\\)이며, 원래 변수의 척도에서 평가할 경우 상당히 작은 값입니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>두 평균 비교하기</span>"
    ]
  },
  {
    "objectID": "11-Comparing-two-means.html#sec-Checking-the-normality-of-a-sample",
    "href": "11-Comparing-two-means.html#sec-Checking-the-normality-of-a-sample",
    "title": "11  두 평균 비교하기",
    "section": "11.9 표본의 정규성 검토",
    "text": "11.9 표본의 정규성 검토\n지금까지 이 장에서 논의한 모든 검정은 데이터가 정규 분포를 따른다고 가정하고 있습니다. 이 가정은 종종 합리적인데, 이는 중심 극한 정리(see Section 8.3.3)에 따라 많은 실제 세계의 변수들이 정규 분포를 따르는 경향이 있기 때문입니다. 여러분이 다루는 변수가 실제로 많은 다른 요소들의 평균이라고 생각되는 경우, 해당 변수가 정규 분포를 따를 가능성이 높으며, 적어도 \\(t\\)-검정을 사용할 수 있을 정도로 정규 분포에 가까울 가능성이 큽니다. 하지만 현실에서는 항상 그렇다는 보장이 있는 것이 아니며, 매우 비정규적인 변수들이 만들어지는 다양한 방식들이 존재합니다. 예를 들어, 여러분이 다루는 변수가 사실상 여러 요소들의 최소값이라면, 해당 변수의 분포는 한 쪽으로 편향되어 있을 가능성이 큽니다. 심리학에서 반응 시간(RT) 데이터는 이러한 경우의 좋은 예입니다. 인간 참여자의 반응을 유발할 수 있는 여러 요인이 있다고 가정하면, 실제 반응은 이러한 유발 사건 중 하나가 처음 발생한 시점에서 이루어집니다.20 따라서 RT 데이터는 체계적으로 정규성을 따르지 않습니다.\n그렇다면, 지금까지 본 모든 검정들이 정규성을 가정하고 있으며, 현실 세계의 데이터가 대체로(적어도 근사적으로) 이 가정을 만족하지만 항상 그런 것은 아니라면, 우리는 표본의 정규성을 어떻게 확인할 수 있을까요? 이 절에서는 두 가지 방법, QQ 도표과 Shapiro-Wilk 검정을 다룹니다.\n\n11.9.1 QQ 도표\n표본이 정규성 가정을 위반하는지 확인하는 한 가지 방법은 “QQ 도표”(Quantile-Quantile plot)를 그리는 것입니다. 이를 통해 정규성에 대한 체계적인 위반이 있는지 시각적으로 확인할 수 있습니다. QQ 도표에서는 각 관측값이 하나의 점으로 표시됩니다. \\(x\\) 좌표는 데이터가 (표본으로부터 평균과 분산을 추정한) 정규 분포를 따른다고 가정했을 때 해당 관측값이 위치해야 하는 이론적 분위(quantile)를 나타내며, \\(y\\) 좌표는 표본 내에서 실제 데이터의 분위를 나타냅니다. 데이터가 정규 분포를 따른다면, 점들은 직선 모양을 형성해야 합니다. 예를 들어, 정규 분포에서 표본을 추출한 후 QQ 도표을 그리면 어떻게 되는지 확인해 보겠습니다. 결과는 Figure 11.20 에 있습니다.\n\n\n\n\n\n\n\n\nFigure 11.20. 정규 분포를 따르는 100개의 관측값을 포함한 normal.data의 히스토그램(왼쪽 그림)과 정규 QQ 도표(오른쪽 그림). 이 데이터에 대한 Shapiro-Wilk 통계량은 \\(W = .99\\)이며, 이는 정규성에서 유의미한 이탈이 없음을 나타낸다 (\\(p = .54\\)).\n\n\n\n\n\n보시다시피, 이 데이터는 거의 직선을 형성하고 있습니다. 이는 우리가 데이터를 정규 분포에서 표본추출했기 때문에 당연한 결과입니다! 반면, Figure 11.21 에서 두 개의 데이터를 살펴보겠습니다. 상단 그림은 심하게 한쪽으로 치우친(skewed) 데이터 집합에 대한 히스토그램과 QQ 도표을 보여줍니다. 이 경우 QQ 도표이 위쪽으로 휘어지는 것을 볼 수 있습니다. 하단 그림은 첨도가 높은(heavy-tailed, 즉, 높은 kurtosis를 가진) 데이터에 대한 동일한 그래프를 보여줍니다. 이 경우 QQ 도표이 중앙에서 평평해지고 양 끝에서 급격히 휘어지는 모습을 보입니다.\n\n\n\n\n\n\n\n\nFigure 11.21. 상단 행은 100개의 관측값을 가진 왜곡된 데이터 집합의 히스토그램과 정규 QQ 도표. 데이터의 왜도(skewness)는 \\(1.88\\)이며, QQ 도표이 위쪽으로 휘어지는 형태로 반영. 그 결과, Shapiro-Wilk 통계량은 \\(W = .80\\)이며, 이는 정규성에서 유의미한 이탈을 나타냄(\\(p&lt; .001\\)). 하단 행은 동일한 도표을 높은 첨도를 가진 데이터 집합(100개의 관측값 포함)의 히스토그램과 정규 QQ 도표. 이 경우 데이터의 높은 첨도(\\(6.57\\))가 QQ 도표을 중앙에서 평평하게 만들고 양 끝에서 급격히 휘어지게 함. 결과적인 Shapiro-Wilk 통계량은 \\(W = .75\\)이며, 역시 정규성에서 유의미한 이탈을 반영(\\(p&lt;.001)\\).\n\n\n\n\n\n\n\n11.9.2 독립 및 대응 \\(t\\)-검정을 위한 QQ 도표\n이전 분석에서 우리는 jamovi를 사용하여 독립 \\(t\\)-검정(Figure 11.10)과 대응 표본 \\(t\\)-검정(Figure 11.16)을 수행하는 방법을 설명했습니다. 이러한 분석에서 jamovi는 ’표준화 잔차(standardized residuals)’에 대한 QQ 도표을 표시합니다. 이는 정규성 가정을 확인하는 더 나은 방법입니다. 이러한 분석에서 해당 옵션을 선택하면 Figure 11.22 와 Figure 11.23 에 표시된 QQ 도표을 얻을 수 있습니다. 제 해석에 따르면, 이 도표들은 모두 비교적 정규 분포를 따르고 있음을 보여주므로, 분석을 진행해도 무방합니다!\n\n\n11.9.3 Shapiro-Wilk 검정\nQQ 도표는 데이터의 정규성을 비공식적으로 확인하는 좋은 방법이지만, 때로는 좀 더 공식적인 방법이 필요할 때가 있습니다. 그럴 때 사용할 수 있는 검정이 바로 Shapiro-Wilk 검정(Shapiro & Wilk, 1965)입니다.21 이 검정의 귀무가설은 주어진 \\(N\\)개의 관측값이 정규 분포를 따른다는 것입니다.\n[추가적인 기술적 설명22]\njamovi의 \\(t\\)-검정에서 Shapiro-Wilk 통계량을 얻으려면 ‘가정검정’ 옵션에서 ’정규분포성 검정’을 체크하면 됩니다. QQ 도표를 위해 사용한 무작위 샘플 데이터(\\(N = 100\\))에서 Shapiro-Wilk 검정 통계량은 \\(W = 0.99\\), \\(p\\)-값은 \\(0.54\\)였습니다. 따라서 예상한 대로, 이 데이터가 정규성에서 벗어난다는 증거는 없습니다. Shapiro-Wilk 검정 결과를 보고할 때는 (항상 그렇듯이) 검정 통계량 \\(W\\)와 \\(p\\)-값을 포함해야 하며, 표본 분포가 \\(N\\)에 크게 의존하므로 가능하면 \\(N\\) 값도 함께 제시하는 것이 좋습니다.\n\n\n\n\n\n\n\n\nFigure 11.22. 독립 \\(t\\)-검정 분석(Figure 11.10)에 대한 jamovi QQ 도표\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 11.23. 대응 표본 \\(t\\)-검정 분석(Figure 11.16)에 대한 jamovi QQ 도표\n\n\n\n\n\n\n\n\n\n\n\n실습: \\(t\\)-검정의 정규성 검정\n\n\n\n\nTip 11.5 실습에서 다음을 수행하여 단일 표본 \\(t\\)-검정의 정규성을 검토해 봅니다.\n\n\n오른쪽 결과 창에서 ‘단일표본 T 검정’ 부분을 선택하면 왼쪽에 ‘단일표본 T 검정’ 창이 나타납니다.\n‘단일표본 T 검정’ 창의 ‘가정검정’ 옵션에서 ’정규분포성 검증’과 ’Q-Q 도표’를 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\nTip 11.2 실습에서 다음을 수행하여 독립 표본 \\(t\\)-검정의 정규성을 검토해 봅니다.\n\n\n오른쪽 결과 창에서 ‘독립표본 T 검정’ 부분을 선택하면 왼쪽에 ‘독립표본 T 검정’ 창이 나타납니다.\n‘독립표본 T 검정’ 창의 ‘가정검정’ 옵션에서 ’정규분포성 검증’과 ’Q-Q 도표’를 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\nTip 11.4 실습에서 다음을 수행하여 대응 표본 \\(t\\)-검정의 정규성을 검토해 봅니다.\n\n\n오른쪽 결과 창에서 ‘대응표본 T 검정’ 부분을 선택하면 왼쪽에 ‘대응표본 T 검정’ 창이 나타납니다.\n‘대응표본 T 검정’ 창의 ‘가정검정’ 옵션에서 ’정규분포성 검증’과 ’Q-Q 도표’를 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.9.4 예제\n이제 데이터가 정규성을 따르지 않을 때 QQ 도표와 Shapiro-Wilk 검정이 어떻게 변하는지 예제를 통해 살펴보겠습니다. 이를 위해 AFL 경기 승리 마진 데이터의 분포를 확인해 보겠습니다. 앞서 Chapter 4에서 살펴본 바와 같이, 이 데이터는 정규 분포를 따르는 것처럼 보이지 않았습니다. QQ 플롯의 결과는 다음과 같습니다(Figure 11.24).\n\n\n\n\n\n\n\n\nFigure 11.24. AFL 승리 마진 데이터에서 정규성을 따르지 않는 모습을 보여주는 jamovi QQ 플롯\n\n\n\n\n\n또한, afl.margins 데이터에 대해 Shapiro-Wilk 검정을 수행하면 정규성 검정 통계량의 값이 \\(W = 0.94\\)이고, \\(p\\)-값이 \\(9.481 \\times 10^{-07}\\)로 나타납니다. 분명히 정규 분포에서 유의한 차이가 존재하는 결과입니다!\n\n\n\n\n\n\n실습: AFL Margins 정규성 검정\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’AFL Margins’를 선택합니다.\n‘분석’-‘T-검정’-‘단일표본 T-검정’ 메뉴를 선택합니다.\n왼편의 ‘단일표본 T-검정’ 창에서 다음을 수행하여 정규성을 검정합니다.\n\n\nafl.margins 변수를 ‘종속변수’ 상자로 이동합니다.\n‘가정검정’ 옵션에서 ’정규분포성 검정’과 ’Q-Q 도표’를 체크합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>두 평균 비교하기</span>"
    ]
  },
  {
    "objectID": "11-Comparing-two-means.html#비정규-분포-데이터-검정",
    "href": "11-Comparing-two-means.html#비정규-분포-데이터-검정",
    "title": "11  두 평균 비교하기",
    "section": "11.10 비정규 분포 데이터 검정",
    "text": "11.10 비정규 분포 데이터 검정\n만약 데이터가 상당히 정규성을 따르지 않는 경우에도 \\(t\\)-검정과 같은 분석을 수행하고 싶다면 어떻게 해야 할까요? 이런 상황은 실제 연구에서 자주 발생합니다. 예를 들어, AFL 승리 점수 차이 데이터를 보면 Shapiro-Wilk 검정 결과가 정규성 가정을 명확히 위배함을 보여주었습니다. 이럴 때 Wilcoxon 검정을 사용할 수 있습니다.\nWilcoxon 검정은 \\(t\\)-검정과 마찬가지로 단일 표본과 두 표본 검정의 형태로 나뉘며, 이에 대응되는 \\(t\\)-검정과 동일한 상황에서 사용할 수 있습니다. 그러나 \\(t\\)-검정과 달리, Wilcoxon 검정은 정규성을 가정하지 않으며, 이는 큰 장점입니다. 사실, Wilcoxon 검정은 데이터가 따르는 분포에 대한 어떠한 가정도 하지 않습니다. 이러한 특성 때문에 비모수 검정(nonparametric test)으로 분류됩니다.\n하지만 정규성 가정을 회피하는 것이 항상 좋은 것만은 아닙니다. Wilcoxon 검정은 일반적으로 \\(t\\)-검정보다 검정력이 낮습니다. (즉, 제2종 오류가 증가할 가능성이 있습니다.) 여기서는 Wilcoxon 검정을 \\(t\\)-검정만큼 자세히 설명하지는 않고, 간략한 개요만 제공합니다.\n\n11.10.1 두 표본 Mann-Whitney \\(U\\) 검정\n우선, Mann-Whitney \\(U\\) 검정을 설명하겠습니다. 이는 단일 표본 Wilcoxon 검정보다 상대적으로 더 간단합니다. 예를 들어, 10명의 사람들에게 특정 시험을 보게 했다고 가정합시다. 제 상상력이 한계에 다다랐으니, 이 시험을 “멋짐(awesomeness) 테스트”라고 해보죠. 그리고 참가자들은 두 집단 “A”와 “B”로 나뉘어 있습니다. 저는 어떤 집단이 더 멋진지 알고 싶습니다. 이 데이터는 awesome.csv 파일에 저장되어 있으며, 일반적인 ID 변수 외에도 점수(scores)와 집단(group) 변수가 포함되어 있습니다.\n만약 동일한 점수를 가진 사람들이 없다고 가정한다면, Mann-Whitney 검정 과정은 매우 간단합니다. 집단 A의 모든 데이터와 집단 B의 모든 데이터를 비교하는 표를 만든 후, 집단 B의 값이 더 큰 경우 체크 표시(✓)를 합니다. 그 결과는 Table 11.4 같습니다.\n\n\n\n\nTable 11.4. 두 표본 Mann-Whitney U 검정을 위한 그룹별 관측값 비교\n\n\n\n\n\n집단 B\n\n14.510.412.411.713.0\n\n집단 A6.4.....\n\n10.7.\\( \\checkmark \\)...\n\n11.9.\\( \\checkmark \\).\\( \\checkmark \\).\n\n7.3.....\n\n10.....\n\n\n\n\n\n\n\n이제 체크 표시의 개수를 세면 됩니다. 이 값이 우리가 사용할 검정 통계량 \\(U\\)입니다. 23 실제로 \\(U\\)의 표본 분포는 다소 복잡하지만, 여기서는 상세한 설명을 생략하겠습니다. 우리가 알아야 할 핵심은 \\(U\\)의 해석 방식이 \\(t\\)-검정의 \\(t\\)값 또는 \\(z\\)-검정의 \\(z\\)값과 개념적으로 동일하다는 것입니다. 즉,\n- 양측 검정에서는 \\(W\\) 값이 매우 크거나 매우 작을 때 귀무가설을 기각합니다.\n- 단측 검정에서는 한쪽 방향의 값만 고려합니다.\njamovi에서 Mann-Whitney \\(U\\) 검정을 수행하려면 다음 단계를 따릅니다.\n1. ‘독립표본 T-검정’ 분석을 실행합니다.\n2. scores를 종속 변수 상자에 설정합니다.\n3. group을 집단 변수 상장에 설정합니다.\n4. ‘검정’ 옵션에서 ’Mann-Whitney U’를 선택합니다.\n이렇게 하면 Figure 11.25 에서 볼 수 있듯이 \\(U = 3\\) (체크 표시의 개수와 동일)과 \\(p\\)-값 = \\(0.05556\\)의 결과를 얻습니다. 앞서 설명한 것처럼, 양측 검정에서는 \\(U\\) 값이 매우 크거나 매우 작을 때 귀무가설을 기각합니다.\n\n\n\n\n\n\n\n\nFigure 11.25. jamovi에서 Mann-Whitney \\(U\\) 검정 결과 화면\n\n\n\n\n\n\n\n\n\n\n\n실습: Mann-Whitney U 검정\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Awesome’을 선택합니다.\n‘분석’-‘기술통계’-‘기술통계’ 메뉴를 선택합니다.\n왼편의 ‘기술통계’ 창에서 다음처럼 scores를 group으로 나누어 기술통계 분석을 수행합니다.\n\n\nscores를 ‘변수’ 상자로 이동합니다.\ngroup를 ‘Split by’ 상자로 이동합니다.\n‘기술통계’ 드롭다운 박스에서 ’Variable across rows’를 선택하여 group 별 통계량을 비교하기 좋게 행으로 배열합니다.\n‘도표’ 옵션을 확장하여 ’박스 도표’를 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n’ 분석’-‘T-검정’-‘독립표본 T-검정’ 메뉴를 선택합니다.\n왼편의 ‘독립표본 T-검정’ 창에서 다음 검정을 수행합니다.\n\n\nscores를 ‘종속변수’ 상자로 이동합니다.\ngroup를 ‘집단 변수’ 상자로 이동합니다.\n‘검정’ 옵션에서 ’Mann-Whitney U’를 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.10.2 단일 표본 Wilcoxon 검정\n그렇다면 단일 표본 Wilcoxon 검정(또는 대응 표본 Wilcoxon 검정)은 어떻게 수행할까요? 예를 들어, 저는 통계 수업을 듣는 것이 학생들의 행복도에 영향을 미치는지 알고 싶습니다. 데이터를 happiness.csv 파일에 저장해 두었습니다. 여기서 측정한 것은 학생들이 수업을 듣기 전(before)과 후(after)의 행복도이며, 행복도 변화(change)는 두 측정값의 차이입니다.\n앞에서 \\(t\\)-검정을 다룰 때와 마찬가지로, 사전-사후 행복도 이용해 대응 표본 검정을 수행하는 것과, 행복도 변화를 사용하여 단일 표본 검정을 수행하는 것은 근본적으로 동일한 과정입니다.\n이번에도 가장 간단한 방식은 비교표를 작성하는 것입니다. 이때 양의 변화 점수를 가진 데이터들을 전체 표본과 비교하여 표를 구성합니다. 그 결과 Table 11.5 같은 표가 만들어집니다.\n\n\n\n\nTable 11.5. 단일 표본 Wilcoxon \\(W\\) 검정을 위한 그룹별 관측값 비교\n\n\n\n\n\n차이\n\n\\(-24\\)\\(-14\\)\\(-10\\)7\\(-6\\)\\(-38\\)2\\(-35\\)\\(-30\\)5\n\n양의 차이7...\\( \\checkmark \\)\\( \\checkmark \\).\\( \\checkmark \\)..\\( \\checkmark \\)\n\n2......\\( \\checkmark \\)...\n\n5......\\( \\checkmark \\)..\\( \\checkmark \\)\n\n\n\n\n\n\n\njamovi에서 이 검정을 실행하는 방법은 예상과 크게 다르지 않습니다. 먼저 ‘단일표본 T-검정’ 분석 창을 엽니다. 그리고 ‘검정’ 옵션에서 ’Wilcoxon rank’를 선택합니다. 이렇게 하면 Wilcoxon \\(W = 7\\), \\(p\\)-값 = \\(0.03711\\)의 결과를 줍니다. 이 결과는 통계적으로 유의한 효과가 있음을 보여줍니다. 즉, 통계 수업을 듣는 것이 학생들의 행복도에 영향을 미친다는 증거가 있습니다. 물론, 대응 표본 버전의 Wilcoxon 검정을 수행해도 동일한 결과를 얻게 됩니다. Figure 11.26 을 참고하세요.\n\n\n\n\n\n\n\n\nFigure 11.26. jamovi에서 단일 표본 및 대응 표본 Wilcoxon 비모수 검정 결과 화면\n\n\n\n\n\n\n\n\n\n\n\n실습: Wilcox 검정\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Happiness’를 선택합니다.\n‘분석’-‘기술통계’-‘기술통계’ 메뉴를 선택합니다.\n왼편의 ‘기술통계’ 창에서 다음처럼 change에 대한 기술통계 분석을 수행합니다.\n\n\nchange를 ‘변수’ 상자로 이동합니다.\n‘기술통계’ 드롭다운 박스에서 ’Variable across rows’를 선택하여 통계량을 한 행으로 배열합니다.\n‘도표’ 옵션을 확장하여 ’히스토그램’을 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n‘분석’-‘T-검정’-‘단일표본 T-검정’ 메뉴를 선택합니다.\n왼편의 ‘단일표본 T-검정’ 창에서 다음 검정을 수행합니다.\n\n\nchange를 ‘종속변수’ 상자로 이동합니다.\n‘검정’ 옵션에서 ’Wilcoxon rank’를 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n동일한 검정을 ‘대응표본 검정’으로 수행한다. ’분석’-‘T-검정’-‘대응표본 T-검정’ 메뉴를 선택한 후, 왼편의 ‘대응표본 T-검정’ 창에서 다음을 수행한다.\n\n\n‘after’를 먼저 ’대응 변수’ 상자로 이동한다.\n그 다음 ‘before’를 ’대응 변수’ 상자로 이동한다.\n‘검정’ 옵션에서 ’Wilcoxon rank’를 체크합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>두 평균 비교하기</span>"
    ]
  },
  {
    "objectID": "11-Comparing-two-means.html#요약",
    "href": "11-Comparing-two-means.html#요약",
    "title": "11  두 평균 비교하기",
    "section": "11.11 요약",
    "text": "11.11 요약\n\n단일 표본 \\(t\\)-검정은 단일 표본의 평균을 가설의 모집단 평균과 비교하는 데 사용됩니다.\n\n독립 표본 \\(t\\)-검정은 두 집단의 평균을 비교하여 동일한 평균을 가진다는 귀무가설을 검정합니다. 독립 표본 검정은 두 가지 버전이 있습니다. 독립 표본 \\(t\\)-검정 (Student 검정)은 두 집단의 표준편차가 동일하다고 가정하는 반면, 독립 표본 \\(t\\)-검정 (Welch 검정)은 그렇지 않습니다.\n\n대응 표본 \\(t\\)-검정은 동일한 개인에게서 두 개의 측정값을 얻어 두 측정의 평균의 차이가 없다는 귀무가설을 검정합니다. 이는 두 측정의 차이 변수를 구한 후 단일 표본 \\(t\\)-검정을 수행하는 것과 동일합니다.\n\n단측 검정은 (모든 검정이 그러하듯이) 사전에 계획된 경우 정당하게 사용할 수 있습니다.\n\n효과 크기는 두 평균 간 차이에 대한 Cohen의 \\(d\\) 값으로 계산이 가능합니다.\n\n표본의 정규성 검토를 위해 QQ 도표와 Shapiro-Wilk 검정을 사용합니다\n\n데이터가 정규성을 따르지 않는 경우, \\(t\\)-검정 대신 비정규 분포 데이터 검정에서 논의한 Mann-Whitney 또는 Wilcoxon 검정을 사용할 수 있습니다.\n\n\n\n\n\nBox, J. F. (1987). Guinness, gosset, fisher, and small samples. Statistical Science, 2, 45–52. https://doi.org/10.1214/ss/1177013437\n\n\nCohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Lawrence Erlbaum. https://doi.org/10.4324/9780203771587\n\n\nHedges, L. V. (1981). Distribution theory for glass’s estimator of effect size and related estimators. Journal of Educational Statistics, 6, 107–128. https://doi.org/10.2307/1164588\n\n\nHedges, L. V., & Olkin, I. (1985). Statistical methods for meta-analysis. Academic Press. https://doi.org/10.1016/C2009-0-03396-0\n\n\nMcGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree: The case of \\(r\\) and \\(d\\). Psychological Methods, 11, 386–401. https://doi.org/10.1037/1082-989x.11.4.386\n\n\nShapiro, S. S., & Wilk, M. B. (1965). An analysis of variance test for normality (complete samples). Biometrika, 52, 591–611. https://doi.org/10.1093/biomet/52.3-4.591\n\n\nStudent, A. (1908). The probable error of a mean. Biometrika, 6, 1–2. https://doi.org/10.1093/biomet/6.1.1\n\n\nWelch, B. L. (1947). The generalization of “Student’s” problem when several different population variances are involved. Biometrika, 34, 28–35. https://doi.org/10.1093/biomet/34.1-2.28",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>두 평균 비교하기</span>"
    ]
  },
  {
    "objectID": "11-Comparing-two-means.html#footnotes",
    "href": "11-Comparing-two-means.html#footnotes",
    "title": "11  두 평균 비교하기",
    "section": "",
    "text": "내 정원에서의 비공식적인 실험에 따르면, 그렇습니다. 호주 자생 식물은 지구상의 다른 지역보다 낮은 인 수준에 적응했기 때문에, 이국적인 식물이 심어진 집을 구입하고 자생 식물을 심고 싶다면 이를 분리해야 합니다. 유럽 식물에 필요한 영양소는 호주 식물에게는 독이 될 수 있습니다.↩︎\n이를 수행하려면 \\(X\\)의 측정 수준을 ’연속형’으로 변경해야 했습니다. CSV 파일을 열거나 가져올 때 jamovi가 이를 명목 변수로 설정했는데, 이는 내 분석에 적절하지 않기 때문입니다.↩︎\nSection 7.5 에서 사용된 표기법을 따르면, 통계학자는 이를 다음과 같이 표현할 수 있습니다: \\[X \\sim Normal(\\mu_0,\\sigma^2)\\]↩︎\n다시 말해, 귀무가설이 참이라면 표본 평균의 표본 분포는 다음과 같이 표현할 수 있습니다: \\[\\bar{X} \\sim Normal(\\mu_0,SE(\\bar{X})) \\]↩︎\n왜 그런지 잘 모르겠다면 Section 4.5 의 설명을 다시 참고하세요.↩︎\n사실, 이 가정은 너무 강합니다. 엄밀히 말하면, \\(z\\)-검정이 요구하는 것은 평균의 표본 분포가 정규분포를 따른다는 것뿐입니다. 모집단이 정규분포를 따른다면, 평균의 표본 분포도 반드시 정규성을 가지게 됩니다. 하지만 중심극한정리(central limit theorem)에서 보았듯이, 모집단 분포가 정규성을 가지지 않더라도 표본 분포가 정규성을 가질 가능성이 충분히 큽니다. 하지만 모집단의 표준편차를 알고 있다는 가정 자체가 터무니없기 때문에, 이 부분을 더 깊이 논의하는 것은 무의미합니다!↩︎\n제가 이해하기로는, Gosset은 문제의 부분적인 해결책만 제시했으며, 이 문제의 일반적인 해법은 Sir Ronald Fisher에 의해 제공되었습니다.↩︎\njamovi의 한국어 판에서 ‘검정’을 ’검증’이라고 번역한 경우가 많습니다. 그러나 통계의 가설 검정에서는 ’검증’이라는 말을 거의 사용하지 않습니다. 그러므로 이는 오역이라 할 수 있어서 jamovi에서 ’검증’이라고 한 부분은 이 책에서는 모두 ’검정’으로 표현했습니다. 그러므로 책에서는 ’분석’-‘T-검정’이라고 표시된 메뉴는 실제 한국어 jamovi에서는 ’분석’-’T-검증’이라고 되어 있습니다.↩︎\n농담이 아니라, 저는 오히려 그 반대가 진실이라고 생각하는 편입니다. 결과 절이 숫자로만 가득 찬 기술 보고서를 보면 의심이 듭니다. 제가 오만한 사람이라서 그런 걸 수도 있지만, 독자에게 분석 결과를 설명하고 해석하려는 노력을 전혀 하지 않는 저자는 스스로 분석을 제대로 이해하지 못했거나, 그냥 귀찮아서 그러는 것이라고 생각이 들 때가 많습니다. 독자들은 똑똑하지만, 무한한 인내심을 가지고 있지는 않습니다. 가능하면 그들을 짜증 나게 하지 마세요.↩︎\n기술적 주석. \\(z\\)-검정의 정규성 가정을 완화하여 모집단에 대한 가정이 아니라 표본 분포에 대한 가정으로 바꿀 수 있었던 것처럼, \\(t\\)-검정의 가정도 완화할 수 있습니다. 그러나 \\(t\\)-검정의 경우 조금 복잡합니다. 앞서서 모집단의 정규성에 대한 가정을 표본 평균 \\(\\bar{X}\\)의 정규성의 가정으로 대체하였습니다. 그런데, \\(t\\)-검정에서는 표준편차의 표본 추정치를 사용하기 때문에 \\(\\hat{\\sigma}\\)의 표본 분포가 카이제곱 분포를 따라야 한다는 추가적인 가정이 필요합니다. 이로 인해 계산이 복잡해지며, 이러한 형태의 \\(t\\)-검정은 실무에서 거의 사용되지 않습니다. 다행히도, 모집단이 정규분포를 따른다면 이 두 가지 가정은 모두 자동으로 충족됩니다.↩︎\n하지만 가장 단순한 형태이기 때문에 먼저 설명했습니다.↩︎\n여기서 종종 나오는 흥미로운 질문이 있습니다. “이 경우 모집단(population)이 정확히 무엇인가요?” Harpo 박사의 수업을 듣는 33명의 학생 전체가 모집단인가요? 아니면 이 수업을 들을 가능성이 있는 (몇 명인지 알 수 없는) 모든 사람들인가요? 혹은 다른 개념인가요? 이 중 어떤 개념을 선택하는지가 중요할까요? 행동과학의 기본 통계 수업에서는 보통 이 질문에 대해 얼버무리고 넘어갑니다. 하지만 매년 학생들에게 받는 질문이므로 짧게 답변해 보겠습니다. 기술적으로 보면, 네, 중요합니다. “현실 세계의 모집단”을 어떻게 정의하느냐에 따라 관측된 평균 \\(\\bar{X}\\)의 표본 분포가 달라집니다. \\(t\\)-검정은 무한히 큰 모집단에서 표본을 무작위로 추출한다고 가정합니다. 현실 세계에서는 이런 가정이 완벽하게 충족되지 않으므로, \\(t\\)-검정이 완전히 정확하지 않을 수 있습니다. 그러나 실질적으로는 이 문제가 큰 영향을 미치지는 않습니다. 이 가정이 거의 항상 엄밀하게 맞지는 않지만, 그렇다고 해서 검정 결과가 심각하게 왜곡되지는 않습니다. 그래서 보통 이 부분은 그냥 무시하고 넘어갑니다.↩︎\n이 식에 \\((w_1 = N_1 - 1)\\) 및 \\((w_2 = N_2 - 1)\\)을 대입하면 매우 복잡한 수식이 도출됩니다. 이 복잡한 수식이 실제로 합동 표준편차 추정치를 설명하는 “표준적인” 방식입니다. 하지만 저는 합동 표준 편차를 다음처럼 생각하는 것이 더 낫다고 생각합니다. 우리의 데이터 집합은 사실상 두 개의 집단으로 정렬된 \\(N\\)개의 관측치로 구성됩니다. 따라서 \\(X_{ik}\\)라는 표기법을 사용하여 \\(k\\)번째 집단에서 \\(i\\)번째 학생이 받은 성적을 나타냅시다. 즉, \\(X_{11}\\)은 Anastasia의 수업에서 첫 번째 학생이 받은 성적이고, \\(X_{21}\\)은 그녀의 두 번째 학생이 받은 성적입니다. 두 집단의 표본 평균 \\(\\bar{X}_1\\)과 \\(\\bar{X}_2\\)을 보다 일반적으로 \\(\\bar{X}_k\\)라고 표기할 수 있습니다. 즉, \\(\\bar{X}_k\\)는 \\(k\\)번째 집단의 평균 성적을 의미합니다. 이제 모든 학생이 두 개의 집단 중 하나에 속하기 때문에, 한 집단에서 평균과의 편차를 다음과 같이 정의할 수 있습니다. \\[X_{ik}-\\bar{X}_k\\] 그렇다면 이 편차를 사용하면 어떨까요? 즉, 각 학생의 성적이 속한 집단의 평균 성적과 얼마나 차이가 나는지를 측정하는 것입니다. 분산은 단순히 여러 개의 제곱 편차의 평균이므로 이를 계산해 봅시다. 수학적으로 다음과 같이 표현할 수 있습니다. \\[\\frac{\\sum_{ik}(X_{ik}-\\bar{X}_k)^2}{N}\\] 여기서 “\\(\\sum_{ik}\\)” 표기법은 “모든 집단의 모든 학생을 대상으로 합계를 계산하라”는 의미를 간략하게 나타낸 것입니다.\\(^a\\) 그러나 Chapter 8 에서 살펴본 것처럼, \\(N\\)으로 나누어 분산을 계산하면 모집단 분산에 대한 편향된 추정치가 생성됩니다. 따라서 이전에는 \\((N - 1)\\)로 나누어 이를 보정해야 했습니다. 그때 언급했듯이, 이러한 편향이 존재하는 이유는 분산 추정치가 표본 평균에 의존하기 때문입니다. 그리고 표본 평균이 모집단 평균과 다를 가능성이 있기 때문에 체계적으로 분산 추정치를 왜곡할 수 있습니다. 하지만 이번에는 두 개의 표본 평균을 사용하고 있습니다! 그러면 더 큰 편향이 발생할까요? 네, 그렇습니다. 그러면 결합된 분산 추정치를 계산할 때 \\((N - 1)\\) 대신 \\((N - 2)\\)로 나누어야 할까요? 맞습니다. \\[\\hat {\\sigma}_p^2=\\frac{\\sum_{ik}(X_{ik}-\\bar{X}_k)^2}{N-2}\\] 그리고 이 값의 제곱근을 취하면 \\(\\hat{\\sigma}_p\\), 즉 결합된 표준 편차 추정치를 얻게 됩니다. 즉, 결합된 표준 편차 계산은 특별한 것이 아닙니다. 일반적인 표준 편차 계산과 크게 다르지 않습니다.— \\(^a\\) 더 정확한 표기법은 Chapter 13 에서 소개됩니다.↩︎\n엄밀히 말하면, 정규성을 가져야 하는 것은 두 평균 사이의 차이입니다. 하지만 두 집단의 데이터가 각각 정규 분포를 따른다면, 평균의 차이 역시 정규 분포를 따르게 됩니다. 실제로 중심극한정리에 따르면, 두 표본의 크기가 충분히 크다면 표본 평균의 분포는 원래 데이터의 분포 형태와 관계없이 정규 분포에 가까워집니다.↩︎\n물론 사과와 오렌지를 섞으면 맛있는 과일 스무디가 되겠지만, 아무도 과일 스무디가 원래의 개별 과일을 잘 설명한다고 생각하지는 않겠죠.↩︎\n이 설계는 McNemar 검정을 필요로 했던 설계(Section 10.7)와 매우 유사합니다. 이는 놀라운 일이 아닙니다. 두 검정 모두 두 번의 측정을 포함하는 표준 반복 측정 설계에서 사용됩니다. 유일한 차이점은 이번 경우에는 종속 변수가 명목척도(예/아니오 질문)가 아니라, 구간척도(작업 기억 용량)라는 점입니다.↩︎\n현재까지 Harpo, Chico, Zeppo 박사가 등장했습니다. Groucho 박사가 누구일지는 쉽게 짐작할 수 있을 겁니다. (역주: 이 이름들은 Marx Brothers라는 가족 코미디 그룹에 속한 형제들의 이름이다.)↩︎\n\\(d\\) 값에 \\(\\frac{(N - 3)}{(N - 2.25)}\\)를 곱하는 방식으로 작은 보정을 도입하였습니다.↩︎\n관심이 있다면, chico2.omv 파일에서 이를 어떻게 수행했는지 확인할 수 있습니다.↩︎\n이는 매우 단순화된 설명입니다.↩︎\n또는 Kolmogorov-Smirnov 검정을 사용할 수도 있습니다. Kolmogorov-Smirnov 검정은 아마도 Shapiro-Wilk 검정보다 더 전통적인 방법일 것입니다. 하지만 대부분의 문헌에서는 Shapiro-Wilk 검정이 정규성을 확인하는 데 더 적합하다고 제안하고 있습니다. 반면, Kolmogorov-Smirnov 검정은 분포의 동등성을 검정하는 일반적인 방법으로, 다른 유형의 분포 검정에도 적용될 수 있습니다. jamovi에서는 Shapiro-Wilk 검정을 기본적으로 선호합니다.↩︎\n이 검정에서 계산되는 검정 통계량은 일반적으로 \\(W\\)로 표기되며, 다음과 같이 계산됩니다. 먼저, 관측값을 크기 순서대로 정렬하고, \\(\\bar{X_1}\\)을 표본에서 가장 작은 값, \\(X_2\\)를 두 번째로 작은 값 등으로 정의합니다. 그런 다음, \\(W\\) 값은 다음 식으로 계산됩니다.\n\\[W=\\frac{(\\sum_{i=1}^N a_iX_i)^2}{\\sum_{i=1}^N(X_i-\\bar{X})^2}\\]\n여기서 \\(\\bar{X}\\)는 관측값의 평균이고, \\(a_i\\) 값들은 초급 수준에서는 다루기에는 다소 복잡한 개념이라 설명을 생략합니다.↩︎\n실제로, Mann-Whitney 검정에는 서로 다른 두 가지 방식의 검정 통계량이 있으며, 이들은 일정한 상수 차이를 가집니다. 여기서 설명하는 방법은 jamovi에서 계산하는 방식과 동일합니다.↩︎",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>두 평균 비교하기</span>"
    ]
  },
  {
    "objectID": "12-Correlation-and-linear-regression.html",
    "href": "12-Correlation-and-linear-regression.html",
    "title": "12  상관관계와 선형회귀",
    "section": "",
    "text": "12.1 상관관계\n이 절에서는 데이터의 변수들 사이의 관계를 설명하는 방법에 대해 논의하겠습니다. 이를 위해 주로 변수들 사이의 상관관계 에 대해 이야기하려고 합니다. 이를 위해 데이터가 좀 필요할 것 같습니다(Table 12.1).",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>상관관계와 선형회귀</span>"
    ]
  },
  {
    "objectID": "12-Correlation-and-linear-regression.html#상관관계",
    "href": "12-Correlation-and-linear-regression.html#상관관계",
    "title": "12  상관관계와 선형회귀",
    "section": "",
    "text": "12.1.1 데이터\n\n\n\n\nTable 12.1. 상관관계 분석을 위한 데이터 – parenthood 데이터의 기술 통계량\n\n\n\n\n\n변수최소값최대값평균중앙값표준 편차사분위 범위 (IQR)\n\ndani.grump419163.716210.0514\n\ndani.sleep4.849.006.977.031.021.45\n\nbaby.sleep3.2512.078.057.952.073.21\n\n\n\n\n\n\n\n모든 부모들에게 중요한 주제인 수면에 대해 이야기해 봅시다. 우리가 사용할 데이터는 가상의 것이지만 실제 사건을 기반으로 합니다. 가령, 내 유아기 아들의 수면 습관이 내 기분에 얼마나 영향을 미치는지 궁금하다고 가정해 보겠습니다. 내 성마름 또는 예민한 정도를 0 (전혀 예민하지 않음)에서 100 (매우, 매우 예민한 상태)까지의 척도로 매우 정밀하게 평가할 수 있다고 가정해 봅시다. 또한, 나는 내 예민함 정도와 수면 패턴, 그리고 내 아들의 수면 패턴을 꽤 오랜 기간 동안 측정해 왔다고 가정해 봅시다. 이를 100일 동안 측정했다고 하겠습니다. 그리고, 나는 데이터 괴짜이므로 이 데이터를 parenthood.csv 라는 파일로 저장해 두었습니다. 데이터를 로드하면 이 파일에는 dani.sleep, baby.sleep, dani.grump, day라는 네 개의 변수가 포함되어 있음을 알 수 있습니다. 이 데이터를 처음 로드할 때 jamovi가 각 변수의 데이터 유형을 올바르게 추정하지 못할 수도 있으므로 이를 수정해야 합니다. dani.sleep, baby.sleep, dani.grump, day는 연속형 변수로 지정할 수 있으며, ID는 명목형(정수) 변수로 지정할 수 있습니다.1\n다음으로, 기본적인 기술 통계를 살펴보고, 세 가지 주요 변수 각각에 대한 그래픽 표현을 제공하기 위해 Figure 12.1 처럼 히스토그램을 그립니다. 한 가지 주의할 점은 jamovi가 수십 개의 서로 다른 통계를 계산할 수 있다고 해서 모든 통계를 보고해야 하는 것은 아니라는 것입니다. 만약 내가 이 내용을 보고서에 작성한다고 하면, 나와 독자들에게 가장 흥미로운 통계들을 선택하고, 그것들을 Table 12.1 같이 깔끔하고 단순한 표로 정리할 것입니다.2 표를 만들 때 모든 항목에 “사람이 읽기 쉬운” 이름을 부여하는 것이 항상 좋은 습관입니다. 또한, 내가 충분한 수면을 취하지 못하고 있다는 것도 알 수 있습니다. 이것은 좋은 습관은 아니지만, 다른 부모들에게 물어보면 일반적인 일이라고 합니다.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\nFigure 12.1. parenthood 데이터 세트의 세 가지 주요 변수에 대한 jamovi의 히스토그램\n\n\n\n\n\n\n\n\n\nTip 12.1. 실습: Parenthood 데이터\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Parenthood’를 선택합니다.\n스프레드시트 창에서 각 변수의 이름을 더블클릭하여 각 변수의 척도유형과 데이터 유형이 제대로 설정되어 있는지 확인하고 필요하면 이를 정정합니다.\n\n\nID: 아이디, 정수\ndan.sleep, baby.sleep: 연속변수, 소수\ndan.grump: 명명척도, 정수\nday: 연속변수, 정수\n\n\n다음 단계를 거쳐 주요 변수에 대한 기술통계를 수행합니다.\n\n\n‘분석’-‘기술통계’-‘기술통계’ 메뉴를 선택합니다.\ndan.sleep, baby.sleep, dan.grump를 ‘변수’ 상자로 이동합니다.\n‘기술통계’ 드롭다운에서 ’Variable across rows’로 하여 기술통계량이 행으로 배열되도록 합니다.\n‘도표’ 옵션에서의 ’히스토그램’을 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12.1.2 관계의 강도와 방향\n두 변수가 얼마나 밀접한 관계가 있는지 대략적으로 알고자 한다면 산점도를 그려볼 수 있습니다. 이에 대해 조금 더 구체적으로 말해 보죠. 예를 들어, baby.sleep과 dani.grump 사이의 관계(Figure 12.2 (a), 왼쪽)와 dani.sleep과 dani.grump 사이의 관계(Figure 12.2 (b), 오른쪽)를 비교해 봅시다. 이 두 그래프를 나란히 보면, 두 경우 모두 질적으로 같은 관계를 보입니다: 더 많은 수면은 더 적은 예민함과 관련이 있습니다! 그러나, dani.sleep과 dani.grump 사이의 관계가 baby.sleep과 dani.grump 사이의 관계보다 더 강하다는 것도 분명합니다. 오른쪽 그래프가 왼쪽 그래프보다 “깔끔한” 형태를 보입니다. 즉, 내 기분을 예측하려면 내 아들이 몇 시간 잤는지를 아는 것이 조금은 도움이 되지만, 내가 몇 시간 잤는지를 아는 것이 더 유용합니다.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigure 12.2. jamovi에서 생성된 baby.sleep과 dani.grump (왼쪽) 및 dani.sleep과 dani.grump (오른쪽) 사이의 관계를 보여주는 산점도\n\n\n\n반면, Figure 12.3 의 두 산점도를 살펴보겠습니다. baby.sleep과 dani.grump 사이의 산점도(왼쪽)와 baby.sleep과 dani.sleep 사이의 산점도(오른쪽)를 비교하면, 관계의 강도는 비슷하지만 방향이 다릅니다. 즉, 내 아들이 더 많이 잘수록 나는 더 많이 잘 수 있습니다(오른쪽, 양의 관계). 하지만 내 아들이 더 많이 잘수록 나는 덜 예민하게 됩니다(왼쪽, 음의 관계).\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigure 12.3. jamovi에서 생성된 baby.sleep과 dani.grump (왼쪽) 및 baby.sleep과 dani.sleep (오른쪽) 사이의 관계를 보여주는 산점도\n\n\n\n\n\n\n\n\n\nTip 12.2. 실습: 산점도 그리기\n\n\n\nTip 12.1 실습을 이어서 다음 변수들에 대한 산점도를 그려봅니다.\n\ndan.sleep이 dan.grump에 영향을 미치는지를 살펴보기 위해 두 변수의 산점도를 그려봅니다.\n\n\n‘분석’-‘기술통계’-‘산포도’ 메뉴를 선택합니다. (만약 이 메뉴가 보이지 않으면, + 모듈을 클릭하여 ‘자모비 라이브러리’를 선택한 후, ’설치가능’ 탭에서 scatr 모듈을 찾아서 ‘설치’합니다. 설치한 후에 jamovi를 다시 시작하면 ’산포도’ 메뉴를 찾을 수 있을 것입니다.)\n왼편 ‘산포도’ 창에서 dan.sleep을 ‘X-축’ 상자로 이동합니다.\n왼편 ‘산포도’ 창에서 dan.grump를 ‘Y-축’ 상자로 이동합니다.\n\n\n\n\n\n\n\n\n\n\n\nbaby.sleep이 dan.grump에 영향을 미치는지를 살펴보기 위해 두 변수의 산점도를 그려봅니다.\n\n\n‘분석’-‘기술통계’-‘산포도’ 메뉴를 선택합니다.\n왼편 ‘산포도’ 창에서 baby.sleep을 ‘X-축’ 상자로 이동합니다.\n왼편 ‘산포도’ 창에서 dan.grump를 ‘Y-축’ 상자로 이동합니다.\n\n\n\n\n\n\n\n\n\n\n\nbaby.sleep이 dan.sleep에 영향을 미치는지를 살펴보기 위해 두 변수의 산점도를 그려봅니다.\n\n\n‘분석’-‘기술통계’-‘산포도’ 메뉴를 선택합니다.\n왼편 ‘산포도’ 창에서 baby.sleep을 ‘X-축’ 상자로 이동합니다.\n왼편 ‘산포도’ 창에서 dan.sleep을 ‘Y-축’ 상자로 이동합니다.\n왼편 ‘산포도’ 창에서 ‘회귀선’ 옵션에서 ’Smooth’를 선택하여 두 변수의 관계를 설명하는 추세선을 그려봅니다.\n왼편 ‘산포도’ 창에서 ‘Marginal’ 옵션에서 ’Box 도표’를 선택하여 각 변수의 박스 도표를 그려봅니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12.1.3 상관계수\n지금까지 살펴본 내용을 보다 명확하게 설명하기 위해 상관계수(correlation coefficient)(더 정확하게 말하자면 피어슨 상관계수)라는 개념을 도입해 봅시다. 상관계수는 전통적으로 \\(r\\)이라는 기호로 표현됩니다. 두 변수 \\(X\\) 와 \\(Y\\) 사이의 상관계수(때때로 \\(r_{XY}\\) 로 표기됨)는 -1에서 1 사이의 값을 가지는 척도로, 다음 절에서 보다 정확히 의미를 논의할 것이지만. \\(r = -1\\) 이면 완벽한 음의 관계를 의미하고, \\(r = 1\\) 이면 완벽한 양의 관계를 의미합니다. \\(r = 0\\) 이면 관계가 전혀 없음을 의미합니다. Figure 12.4 를 보면 다양한 상관관계가 어떻게 보이는지 확인할 수 있습니다.\n피어슨 상관계수의 계산 공식은 여러 가지 방식으로 표현할 수 있습니다. 가장 간단한 방법은 두 단계로 나누어 설명하는 것입니다. 먼저, 공분산 개념을 소개하겠습니다. 두 변수 \\(X\\) 와 \\(Y\\)의 공분산은 분산을 일반화한 개념으로, 수학적으로는 간단하지만 직관적으로 해석하기에는 어려운 방식으로 두 변수 사이의 관계를 설명하는 방법입니다: \\[Cov(X,Y)=\\frac{1}{N-1}\\sum_{i=1}^N(X_i-\\bar{X})(Y_i-\\bar{Y})\\] \\(X\\)와 \\(Y\\)의 평균에서의 편차를 곱한 후 평균을 내는 방식이므로,3 공분산 공식은 \\(X\\) 와 \\(Y\\) 사이의 “평균 교차 곱”으로 생각할 수 있습니다. 공분산은 \\(X\\) 와 \\(Y\\) 가 전혀 관련이 없으면 정확히 0이 됩니다. 관계가 양의 방향이면 공분산도 양수이고, 관계가 음의 방향이면 공분산도 음수가 됩니다. 즉, 공분산은 상관관계의 기본적인 정성적 개념을 포착합니다. 그러나 공분산의 크기는 변수 \\(X\\) 와 \\(Y\\)의 단위에 따라 달라지므로 해석하기 어렵습니다. 더욱이, 공분산의 단위 자체가 이상합니다. 예를 들어, \\(X\\) 가 dani.sleep(단위: 시간)이고, \\(Y\\) 가 dani.grump(단위: 예민함 정도)라면, 공분산의 단위는 \\(시간 \\times 예민한 정도\\)가 됩니다. 이게 무슨 의미인지 전혀 감이 오지 않습니다. 피어슨 상관계수 r은 공분산을 표준화하여 이러한 해석 문제를 해결합니다. 이는 \\(z\\)-점수가 원 점수를 표준화하는 방식과 거의 동일하게 표준편차로 나누어 값을 표준화합니다. 단, 공분산의 계산에는 두 변수가 기여하므로 표준화하려면 두 변수의 표준편차로 나누어야 합니다.4 즉, \\(X\\) 와 \\(Y\\) 사이의 상관관계는 다음과 같이 표현될 수 있습니다: \\[r_{XY}=\\frac{Cov(X,Y)}{\\hat{\\sigma}_X\\hat{\\sigma}_Y}\\]\n\n\n\n\n\n\n\n\nFigure 12.4. 상관관계의 강도와 방향이 변할 때의 영향을 보여주는 그림. 왼쪽 열은 상관계수가 \\(0, .33, .66\\) 및 \\(1\\)입니다. 오른쪽 열은 상관계수가 \\(0, -.33, -.66\\) 및 \\(-1\\)입니다.\n\n\n\n\n\n공분산을 표준화함으로써 앞서 논의한 공분산의 모든 좋은 특성을 유지하면서도 \\(r\\) 값 자체가 의미 있는 척도로 표현됩니다. \\(r = 1\\)은 완벽한 양의 관계를, \\(r = -1\\)은 완벽한 음의 관계를 나타냅니다. 이에 대한 해석을 [상관계수 해석하기] 절에서 더 자세히 설명하겠습니다. 그러나 그 전에 jamovi에서 상관계수를 계산하는 방법을 살펴보겠습니다.\n\n\n12.1.4 jamovi에서 상관관계 계산하기\njamovi에서 상관관계를 계산하려면 ‘회귀분석’-‘상관행렬’ 메뉴를 클릭하면 됩니다. 네 개의 연속형 변수를 모두 오른쪽 박스로 이동시키면, Figure 12.5 같은 출력이 나타납니다.\n\n\n\n\n\n\n\n\nFigure 12.5. parenthood.csv 파일의 변수들 사이의 상관관계\n\n\n\n\n\n\n\n\n\n\n\nTip 12.3. 실습: 피어슨 상관계수 구하기\n\n\n\nTip 12.2 실습을 이어서 다음 연속형 변수 사이의 피어슨 상관계수를 구해봅니다.\n\n‘분석’-‘회귀분석’-‘상관 행렬’ 메뉴를 선택합니다.\n왼편의 ‘상관 행렬’ 창에서 다음을 수행하면 Figure 12.5 같은 결과를 얻을 수 있습니다.\n\n\n상관계수를 계산할 dan.sleep, baby.sleep, day, dan.grump 변수를 오른편 상자로 이동합니다.\n‘상관계수’ 옵션이 ’피어슨’으로 설정되었는지 확인합니다.\n\n\n\n\n\n12.1.5 상관관계 해석하기\n실제 데이터에서는 \\(1\\)과 같은 완벽한 상관관계를 거의 볼 수 없습니다. 그렇다면, 예를 들어 \\(r = 0.4\\)인 상관관계를 어떻게 해석해야 할까요? 정직한 답변은, 데이터의 용도와 해당 분야에서 일반적으로 나타나는 상관관계의 강도에 따라 다르다는 것입니다.\n제 친구 중 한 명은 공학 분야에서 일하는데, 그는 상관계수가 \\(0.95\\)보다 낮으면 쓸모가 없다고 주장한 적이 있습니다(아마 과장이었겠지만요). 반면, 심리학에서도 특정 경우에는 이처럼 높은 상관관계를 기대할 수 있습니다. 예를 들어, 사람들이 유사성을 판단하는 방식을 테스트하는 대표적인 데이터 중 하나는 매우 정제되어 있어서, 이론적으로 상관계수가 \\(0.9\\) 이상 나오지 않으면 성공적인 모형으로 간주되지 않습니다. 하지만 지능과 관련된 기본적인 변인(예: 검사 시간, 반응 속도)을 찾을 때는 상관계수가 \\(0.3\\) 이상이라면 상당히 높은 값이라고 볼 수 있습니다. 즉, 상관관계의 해석은 맥락에 따라 크게 달라집니다. 그렇긴 해도, Table 12.2 에 제시된 대략적인 가이드는 일반적으로 많이 사용됩니다.\n\n\n\n\nTable 12.2. 상관관계 해석을 위한 대략적인 가이드\n\n\n\n\n\n상관 계수강도방향\n\n-1.00 ~ -0.90매우 강함음\n\n-0.90 ~ -0.70강함음\n\n-0.70 ~ -0.40중간음\n\n-0.40 ~ -0.20약함음\n\n-0.20 ~ 0.00무시 가능음\n\n0.00 ~ 0.20무시 가능양\n\n0.20 ~ 0.40약함양\n\n0.40 ~ 0.70중간양\n\n0.70 ~ 0.90강함양\n\n0.90 ~ 1.00매우 강함양\n\n이 가이드는 어디까지나 대략적인 것입니다. 강한 관계와 약한 관계를 구분하는 절대적인 기준은 없으며, 맥락에 따라 다를 수 있습니다.\n\n\n\n\n\n\n\n그러나 여기서 절대 간과해서는 안 되는 중요한 점이 있습니다. 상관계수를 해석하기 전에 반드시 산점도를 확인해야 한다는 것입니다. 상관관계는 우리가 생각하는 의미와 다를 수 있습니다. 이를 설명하는 대표적인 예가 “Anscombe’s Quartet”(Anscombe, 1973)입니다.\nAnscombe의 사분위 데이터는 네 개의 서로 다른 데이터로 구성되어 있으며, 각 데이터에는 \\(X\\) 변수와 \\(Y\\) 변수가 있습니다. 이 네 개의 데이터 모두에서 \\(X\\)의 평균값은 \\(9\\), \\(Y\\)의 평균값은 \\(7.5\\)입니다. \\(X\\) 변수의 표준편차는 거의 동일하며, \\(Y\\) 변수의 표준편차도 마찬가지입니다. 그리고 각 데이터에서 \\(X\\)와 \\(Y\\) 사이의 상관계수는 모두 \\(r = 0.816\\)입니다.\n이 정보를 바탕으로 네 개의 데이터가 매우 유사할 것이라고 예상할 수도 있습니다. 하지만 실제로 산점도를 그려보면 전혀 다른 패턴을 보인다는 사실을 알 수 있습니다(Figure 12.6 참조). 따라서 “항상 원래 데이터를 그래프로 확인하라”는 교훈을 잊지 말아야 합니다(자세한 내용은 Chapter 5 에서 다룹니다).\n\n\n\n\n\n\n\n\nFigure 12.6. Anscombe의 사분위 데이터셋의 산점도. 네 개의 데이터셋 모두에서 피어슨 상관계수 \\(r = 0.816\\)이지만, 서로의 특성이 완전히 다름.\n\n\n\n\n\n\n\n\n\n\n\n상관계수는 두 변수의 선형 상관성의 강도만을 포착한다\n\n\n\n그런데 피어슨 상관계수는 두 변수 사이의 선형 상관성에 대한 통계량이기 때문에 비선형적인 관계는 잘 포착하지는 못합니다. 다음 그림은 두 변수 사이의 피어슨 상관계수와 산점도를 보여줍니다.\n\n그래프의 첫 번째 행은 선형 상관성이 높을수록 상관계수의 절대값이 커지는 것을 보여줍니다. 즉, 직선에 가까운 관계일수록 상관계수의 절대값은 1에 가까워집니다.\n그래프의 두 번째 행은 두 변수의 관계를 나타내는 선의 기울기와 상관계수의 값은 관계가 없음을 보여줍니다. 왜냐하면 상관계수는 두 변수의 관계가 얼만큼 직선에 가까운지를 나타내므로 직선의 기울기와는 상관이 없기 때문입니다. 단, 직선의 기울기가 0이면 가로축의 변수의 변화가 세로축 변수에 전혀 영향을 주지 못하므로 두 변수의 상관계수는 0이 됩니다.\n그래프의 마지막 행처럼 비선형적 관계가 있지만 선형 관계가 없으면 0에 가까운 상관계수 값이 나오는 것을 확인할 수 있습니다. 즉, 상관계수는 두 변수의 비선형관계를 포착하지 못합니다. 그러므로 비선형 관계는 산점도 등을 사용하여 파악해야 합니다.\n\n\n\n\n\n\n피어슨 상관계수 (출처: 위키피디아)\n\n\n\n\n\n\n\n\n12.1.6 스피어만 순위 상관계수\n피어슨 상관계수는 매우 유용한 도구이지만, 몇 가지 단점이 있습니다. 그중에서도 가장 두드러지는 한 가지 문제는 이것이 두 변수 사이의 선형 관계의 강도만을 측정한다는 점입니다. 즉, 피어슨 상관계수는 데이터가 얼마나 완벽하게 직선 위에 놓이는지를 나타냅니다. 일반적으로 우리가 “관계”라고 말할 때, 이러한 선형 관계는 꽤 좋은 근사값을 제공하기 때문에 피어슨 상관계수를 계산하는 것이 유용합니다. 하지만, 항상 그런 것은 아닙니다.\n피어슨 상관계수를 사용하는 것이 적절하지 않은 대표적인 사례는 한 변수(\\(X\\))의 증가가 다른 변수(\\(Y\\))의 증가로 이어지지만, 그 관계가 반드시 선형적이지는 않은 경우입니다. 예를 들어, 시험 공부에서 노력과 보상의 관계를 생각해 봅시다. 만약 어떤 과목을 공부하는 데 전혀 노력을 기울이지 않는다면(\\(X = 0\\)), 시험 점수(\\(Y\\))도 당연히 \\(0\\)이 될 것입니다. 그러나 약간의 노력만으로도 성적이 크게 향상될 수 있습니다. 예를 들어, 강의에 참석하기만 해도 어느 정도 내용을 배우게 되고, 수업에 참석해서 몇 가지 메모만 해도 성적이 \\(35\\)까지 오를 수 있습니다. 하지만 상위 성적에서는 그렇지 않습니다. 성적을 \\(55\\)에서 \\(95\\)로 끌어올리는 데는 훨씬 더 많은 노력이 필요합니다. 즉, 노력과 성적 사이의 관계를 나타내는 데이터가 있다면, 피어슨 상관계수를 적용하는 것이 오해를 불러일으킬 가능성이 큽니다.\n이를 설명하기 위해 Figure 12.7 을 살펴보겠습니다. 이 그림은 어떤 수업을 듣는 10명의 학생을 대상으로, 공부한 시간과 받은 성적 사이의 관계를 나타냅니다. 이 (완전히 가상의) 데이터에서 주목할 점은 노력이 증가하면 성적도 항상 증가한다는 것입니다. 증가 폭이 크든 작든, 노력이 늘어나면 성적이 감소하는 경우는 없습니다.\n이러한 데이터에 대해 표준 피어슨 상관계수를 계산하면, 학습 시간과 성적 사이의 강한 상관관계를 보여주는 상관계수 \\(r = 0.91\\)이 나옵니다. 그러나 이 값은 “노력이 증가하면 반드시 성적도 증가한다”는 점을 반영하지 않습니다. 여기서 우리가 진짜로 원하는 것은, 순위 관계(ordinal relationship)가 예외 없이 작동한다는 사실을 포착하는 것입니다. 즉, 학생 1이 학생 2보다 더 많은 시간을 공부했다면, 학생 1의 성적은 학생 2보다 반드시 더 높을 것이라는 사실을 보장해야 합니다. 하지만 \\(r = 0.91\\)은 이러한 관계를 보장하지 않습니다.\n\n\n\n\n\n\n\n\nFigure 12.7. jamovi에서 10명의 학생을 대상으로 학습 시간과 성적 사이의 관계를 나타낸 그래프 (각 점은 한 명의 학생을 의미). 중앙의 직선은 두 변수 사이의 선형 관계를 나타내며, 피어슨 상관계수 \\(r = 0.91\\)을 보여준다. 그러나 중요한 점은, 이 예제에서는 두 변수 간에 완벽한 단조(monotonic) 관계가 존재한다는 것이다. 즉, 공부한 시간이 증가하면 성적도 반드시 증가한다. 이는 스피어만 상관계수 \\(\\rho = 1\\)로 반영된다. 하지만 이렇게 작은 데이터셋에서는 어떤 방법이 실제 관계를 더 잘 설명하는지 논란의 여지가 있을 수 있다.\n\n\n\n\n\n이 문제를 해결하는 방법은 매우 간단합니다. 순위 관계를 찾고 싶다면, 데이터를 서열척도(ordinal scale)로 다루면 됩니다! 즉, “공부한 시간”을 직접 측정하는 대신, 학생들을 공부한 시간에 따라 순위(rank)로 정렬합니다. 예를 들어, 가장 적은 시간(2시간) 공부한 학생 1은 가장 낮은 순위(rank = 1)를 받습니다. 그다음으로 적게 공부한 학생 4(6시간)는 rank = 2를 받습니다. 여기서 주의할 점은 “rank = 1”이 가장 낮은 순위를 의미한다는 것입니다. 일상적으로는 “rank = 1”을 가장 높은 순위(1등)로 사용할 수도 있기 때문에, 헷갈리지 않도록 조심해야 합니다. 일반적으로 순위를 작은 값부터 큰 값으로 정렬할 수도 있고, 큰 값부터 작은 값으로 정렬할 수도 있습니다. 여기서는 작은 값에서 큰 값으로 정렬하고 있으며, 이를 잊지 않도록 신경 써야 합니다.\n이제, 학생들을 공부한 시간과 성적에 따라 최저 순위에서 최고 순위로 정렬한 결과를 Table 12.3 에서 확인해 보겠습니다**.\n\n\n\n\nTable 12.3. 학생들의 공부한 시간과 성적을 순위로 정렬한 표\n\n\n\n\n\n순위 (공부 시간)순위 (받은 성적)\n\n학생 111\n\n학생 21010\n\n학생 366\n\n학생 422\n\n학생 533\n\n학생 655\n\n학생 744\n\n학생 888\n\n학생 977\n\n학생 1099\n\n\n\n\n\n\n\n놀랍게도, 이 두 개의 순위는 완전히 동일합니다. 즉, 가장 많은 노력을 기울인 학생이 가장 높은 성적을 받았으며, 가장 적게 노력한 학생이 가장 낮은 성적을 받았습니다. 위의 표에서 보듯이, 학습 시간과 성적의 순위가 완전히 동일하기 때문에, 이 두 순위 변수의 상관성을 분석하면 완벽한 상관관계(상관계수 = 1.0)가 나타납니다.\n사실, 우리가 방금 다시 발견한 개념이 바로 스피어만 순위 상관계수(Spearman’s rank order correlation)입니다. 이는 보통 \\(\\rho\\) (rho)로 표기되며, 피어슨 상관계수(\\(r\\))와 구별됩니다.\njamovi에서 스피어만의 \\(\\rho\\)를 계산하는 방법은 간단합니다. ‘상관 행렬’ 화면에서 ‘Spearman’ 체크박스를 선택하기만 하면 됩니다.\n\n\n\n\n\n\nTip 12.4. 실습: 피어슨 상관계수 구하기\n\n\n\nTip 12.2 실습을 이어서 다음 연속형 변수 사이의 피어슨 상관계수를 구해봅니다.\n\n‘분석’-‘회귀분석’-‘상관 행렬’ 메뉴를 선택합니다.\n왼편의 ‘상관 행렬’ 창에서 다음을 수행하면 다음 결과를 얻을 수 있습니다.\n\n\n상관계수를 계산할 dan.sleep, baby.sleep, day, dan.grump 변수를 오른편 상자로 이동합니다.\n‘상관계수’ 옵션에서 ’Spearman’을 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n피어슨 선형 상관계수 대 스피어만 순위 상관계수\n\n\n\n피어슨 상관계수와 스피어만 상관계수는 모두 두 변수 사이의 관계를 측정하는 통계적 방법이지만, 그 계산 방식과 해석하는 방식이 다릅니다. 두 상관계수의 차이점은 다음과 같습니다.\n\n\n\n\n\n\n\n\n\n피어슨 상관계수 (Pearson’s \\(r\\))\n스피어만 상관계수 (Spearman’s \\(\\rho\\))\n\n\n\n\n정의\n두 변수 사이의 선형 관계 강도를 측정\n두 변수 사이의 순위 관계 강도를 측정\n\n\n적용 가능한 데이터\n등간척도(interval scale), 비율척도(ratio scale)\n서열척도(ordinal scale) 이상이면 사용 가능\n\n\n값의 범위\n-1 ~ +1\n-1 ~ +1\n\n\n해석\n0에 가까울수록 선형 관계가 약함, ±1에 가까울수록 강한 선형 관계\n0에 가까울수록 순위 관계가 약함, ±1에 가까울수록 강한 단조(monotonic) 관계\n\n\n\n스피어만 상관계수와 피어슨 상관계수의 차이를 보여주는 예를 살펴봅시다. 다음은 위키피디아에 있는 세 가지 예입니다.\n\n\n\n두 변수 X와 Y가 선형 관계가 아니더라도 순위가 유지되면 스피어만 상관계수는 1이 될 수 있습니다. 하지만 +1의 피어슨 상관계수를 보장하지는 않습니다. (출처: 위키피디아 스피어먼 상관계수)\n\n\n\n\n\n데이터가 타원형으로 분포되어 있고 뚜렷한 특이치가 보이지 않으면 스피어만 상관계수와 피어슨 상관계수는 비슷한 값을 가집니다. (출처: 위키피디아 스피어먼 상관계수)\n\n\n\n\n\n스피어만 상관계수은 피어슨 상관계수보다 양 극단의 특이치에 덜 민감합니다. 왜냐하면 스피어만 상관계수는 값 자체가 아니라 순위만으로 상관계수를 계산하기 때문입니다. (출처: 위키피디아 스피어먼 상관계수)\n\n\n이러한 특성 때문에 두 상관계수가 사용되는 경우가 다릅니다.\n\n\n\n\n\n\n\n\n사용 상황\n상관계수 종류\n사용 이유\n\n\n\n\n두 변수 사이의 선형 관계를 알고 싶을 때\n피어슨 상관계수 (\\(r\\))\n변수 간에 일정한 증가(혹은 감소) 관계가 있는지 확인 가능\n\n\n두 변수 사이의 순위 관계(단조 관계)를 알고 싶을 때\n스피어만 상관계수 (\\(\\rho\\))\n선형이 아닐 수도 있지만, 증가/감소 경향이 있는지 확인 가능\n\n\n데이터가 정규분포를 따르지 않을 때\n스피어만 상관계수 (\\(\\rho\\))\n순위만 사용하므로 정규성을 가정할 필요 없음\n\n\n특이치가 있는 경우\n스피어만 상관계수 (\\(\\rho\\))\n순위를 기반으로 계산하므로 특이치에 덜 민감함\n\n\n등간척도 또는 비율척도 데이터\n피어슨 상관계수 (\\(r\\))\n변수 간 거리 차이를 그대로 활용 가능\n\n\n서열척도 데이터\n스피어만 상관계수 (\\(\\rho\\))\n원래 값의 크기를 고려하지 않고 순위만 비교\n\n\n\n결론적으로, 피어슨 상관계수 \\(r\\)은 선형 관계를 측정하고, 등간척도 이상에서 사용 가능하나, 특이치에 민감하게 변화합니다. 반면, 스피어만 상관계수 \\(\\rho\\)는 순위 관계(단조 관계)를 측정하고 서열척도 이상에서 사용 가능하고, 특이치에 덜 민감합니다. 따라서 데이터의 특성에 따라 적절한 방법을 선택하는 것이 중요합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>상관관계와 선형회귀</span>"
    ]
  },
  {
    "objectID": "12-Correlation-and-linear-regression.html#산점도",
    "href": "12-Correlation-and-linear-regression.html#산점도",
    "title": "12  상관관계와 선형회귀",
    "section": "12.2 산점도",
    "text": "12.2 산점도\n산점도(Scatterplots)는 두 변수 사이의 관계를 시각화하는 간단하지만 효과적인 도구입니다. 이는 상관관계 섹션에서 본 그림들과 같은 방식으로 활용됩니다. 일반적으로 “산점도”라는 용어를 사용할 때는 이러한 관계를 시각화하는 경우를 의미합니다.\n이런 유형의 그래프에서 각 관측값은 하나의 점으로 표현됩니다. 점의 가로 위치(x 축)는 한 변수의 값을 나타내고, 세로 위치(y 축)는 다른 변수의 값을 나타냅니다.\n많은 경우, 변수 사이의 인과관계(예: A가 B를 유발하는지, B가 A를 유발하는지, 또는 어떤 다른 변수 C가 A와 B를 모두 조절하는지)에 대한 명확한 의견이 없을 수 있습니다. 이러한 경우에는 어느 변수를 x축과 y축에 놓을지 크게 중요하지 않습니다.\n그러나 특정 변수의 인과적 역할에 대해 강한 가설을 가지고 있거나, 어느 정도의 추측을 하고 있는 경우라면 원인(cause)이 되는 변수는 x 축에, 결과(effect)가 되는 변수는 y 축에 배치하는 것이 일반적입니다. 이를 염두에 두고, jamovi에서 산점도를 그리는 방법을 살펴보겠습니다. 이때, 상관관계를 소개할 때 사용했던 parenthood 데이터(즉, parenthood.csv)를 활용하겠습니다.\n예를 들어, 나의 수면량(dani.sleep)과 다음 날 얼마나 예민한지(dani.grump)의 관계를 나타내는 산점도를 그리고 싶다고 가정해 봅시다. 이를 위해 jamovi에서 두 가지 방법을 사용할 수 있습니다. 첫 번째 방법은 ‘회귀’-‘상관 행렬’ 메뉴를 이용하여 ‘도표’ 옵션을 사용하는 것입니다. 이를 통해 Figure 12.8 같은 출력을 얻을 수 있습니다.\n참고로, jamovi는 데이터 포인트 사이를 관통하는 선을 추가하는데, 이는 선형회귀 모형이란? 절에서 더 자세히 다룰 것입니다. 또한, 이 방법을 사용하면 ‘변수 밀도(Densities for variables)’ 옵션을 설정할 수 있으며, 이를 통해 각 변수의 데이터 분포를 나타내는 밀도 곡선을 추가할 수도 있습니다.\n\n\n\n\n\n\n\n\nFigure 12.8. jamovi의 ‘상관 행렬(Correlation Matrix)’ 명령을 사용하여 생성한 산점도\n\n\n\n\n\n두 번째 방법은 jamovi의 추가 모듈 중 하나를 이용하는 것입니다. 이 모듈의 이름은 scatr이며, 이를 설치하려면 jamovi 화면 오른쪽 상단에 있는 ‘\\(+\\)’ 모듈 아이콘을 클릭하여 ‘자모비 라이브러리’ 메뉴를 엽니다. 그런 다음 ‘사용가능’ 탭에서 ‘scatr’을 찾고 ’설치’ 버튼을 누르면 됩니다.5\n설치가 완료되면, ‘기술통계’ 메뉴 아래에 새로운 ‘산포도’ 명령어가 추가됩니다. 이 방법을 사용하면 Figure 12.9 같은 산점도를 생성할 수 있습니다. 첫 번째 방법과는 다소 다른 스타일이지만, 중요한 정보는 동일합니다.\n\n\n\n\n\n\n\n\nFigure 12.9. jamovi의 ‘scatr’ 추가 모듈을 사용하여 생성한 산점도\n\n\n\n\n\n\n12.2.1 더 정교한 옵션\n종종 여러 변수 사이의 관계를 한 번에 살펴보고 싶을 때가 있습니다. 이때 산점도 행렬을 사용할 수 있습니다. jamovi에서는 ‘상관 행렬’-‘도표’ 명령을 통해 이를 생성할 수 있습니다. 예를 들어, baby.sleep 변수를 상관 분석 변수 목록에 추가하면, jamovi가 Figure 12.10 같은 산점도 행렬을 생성해 줍니다.\n\n\n\n\n\n\nTip 12.5. 실습: 산점도 그리기 - 회귀분석 메뉴 사용하기\n\n\n\nTip 12.2 실습을 이어서 ‘회귀분석’ 메뉴를 사용하여 산점도를 그려봅니다.\n\n‘분석’-‘회귀분석’-‘상관 행렬’ 메뉴를 선택합니다.\n왼편의 ‘상관 행렬’ 창에서 다음을 수행하면 다음 같은 결과를 얻을 수 있습니다.\n\n\n상관계수를 계산할 dan.sleep, baby.sleep, dan.grump 변수를 오른편 상자로 이동합니다.\n`추가 옵션’에서 ‘Flag significant correlations’만 체크하여 상관계수 값만 나오게 하고 유의한 상관계수에는’*’ 표시가 되도록 합니다.\n‘도표’ 옵션에서 ’상관 행렬’을 체크하여 산점도 행렬을 그립니다. 아울러 ’Densities for variables’와 ’통계’도 체크하여 산점도 행렬의 대각선에는 확률밀도 그래프를, 우상 부분에는 상관계수가 표시되록 합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>상관관계와 선형회귀</span>"
    ]
  },
  {
    "objectID": "12-Correlation-and-linear-regression.html#선형회귀-모형이란",
    "href": "12-Correlation-and-linear-regression.html#선형회귀-모형이란",
    "title": "12  상관관계와 선형회귀",
    "section": "12.3 선형회귀 모형이란?",
    "text": "12.3 선형회귀 모형이란?\n가장 기본적인 개념으로 보면, 선형회귀 모형은 피어슨 상관계수(상관관계 참고)의 조금 더 정교한 버전이라고 할 수 있습니다. 그러나 실제로는 훨씬 더 강력한 도구입니다.\n앞에서 상관관계를 설명하기 위해 사용했던 parenthood.csv 파일로 돌아가 보겠습니다. 우리는 이 데이터에서 다니(Dani)가 항상 왜 그렇게 예민한지 찾으려 했고, 우리의 가설은 “나는 충분한 수면을 취하지 못하고 있다”는 것이었습니다. 이 관계를 살펴보기 위해 Figure 12.9 같은 산점도를 그렸고, 상관계수는 \\(r = -0.90\\)이었습니다. 그러나 우리가 마음속으로 상상하는 관계는 Figure 12.11(a) 같은 것입니다. 즉, 우리는 데이터의 가운데를 통과하는 직선을 머릿속으로 그립니다.\n통계학에서는 이러한 선을 회귀선(regression line)이라고 합니다. 우리는 바보가 아니므로, 이 회귀선이 데이터의 가운데를 지나가도록 그립니다. 반면, Figure 12.11(b)처럼 이상한 방식으로 선을 그리는 것은 상상하기 어렵습니다.\n\n\n\n\n\n\n\n\nFigure 12.10. jamovi를 사용하여 생성한 산점도 행렬\n\n\n\n\n\nFigure 12.11(b)에서 내가 그린 선이 데이터를 잘 “맞추지(fit)” 못하고 있다는 것은 놀라운 일이 아닙니다. 이렇게 부적절한 선을 데이터 요약 방법으로 제안하는 것은 말이 되지 않겠죠?\n이것은 단순한 관찰이지만, 여기에 약간의 수학적 개념을 추가하면 매우 강력한 분석 도구가 됩니다. 이를 이해하기 위해, 고등학교 수학에서 배운 직선의 방정식을 떠올려 봅시다. 일반적으로 직선 방정식은 다음과 같이 표현됩니다.\n\\[y = a + bx\\]\n\n\n\n\n\n\n\n\nFigure 12.11. (a) 패널은 Figure 12.9 의 수면-예민함 산점도에 최적의 회귀선을 추가한 것. 예상대로 선은 데이터의 중앙을 지나감. 반면, (b) 패널은 같은 데이터를 사용하되, 매우 부적절한 회귀선을 그린 것.\n\n\n\n\n\n이 방정식에서 \\(x\\)와 \\(y\\)는 변수이며, \\(a\\)와 \\(b\\)는 계수(coefficient)입니다.6\n- \\(a\\)는 y 축 절편(intercept)으로, \\(x = 0\\)일 때 \\(y\\)의 값을 의미합니다.\n- \\(b\\)는 기울기(slope)로, \\(x\\) 값이 1 증가할 때 \\(y\\) 값이 얼마나 변하는지를 나타냅니다. 기울기가 양수이면 \\(x\\)가 증가하면 \\(y\\)가 증가하고, 음수이면 \\(y\\)가 감소합니다.\n회귀선도 이와 똑같은 식을 사용합니다. 회귀 분석에서는 결과변수(종속변수, DV)를 \\(Y\\)로, 예측변수(독립변수, IV)를 \\(X\\)로 두고, 이를 다음과 같이 나타냅니다.\n\\[\\hat{Y}_i = b_0 + b_1 X_i\\]\n이 방정식은 앞서 본 것과 거의 동일하지만, 몇 가지 추가적인 요소가 있습니다. 이를 하나씩 살펴보겠습니다.\n첫째, 일반적인 \\(X\\)와 \\(Y\\)가 아니라 \\(X_i\\)와 \\(Y_i\\)를 사용한 이유는, 우리가 실제 데이터 관측값을 사용하고 있기 때문입니다. 여기서 \\(X_i\\)는 \\(i\\) 번째 관측값의 예측변수(예: \\(i\\) 번째 날의 수면 시간)이고, \\(Y_i\\)는 \\(i\\) 번째 날의 결과변수(예: \\(i\\) 번째 날의 예민함 정도)입니다. 명시적으로 수식에 표현하지는 않았지만, 이 수식이 데이터의 모든 관측치에(즉, 모든 \\(i\\)에 대해) 적용될 것이라고 가정하고 있습니다.\n둘째, 수식의 좌변에 \\(Y_i\\) 대신 \\(\\hat{Y}_i\\)을 사용하고 있습니다. 그 이유는 실제 관측값 \\(Y_i\\)와 회귀선이 예측한 값 \\(\\hat{Y}_i\\) 사이의 차이를 들어내고자 하기 때문입니다.\n셋째, 회귀선의 계수의 표기 방식입니다. 이전에는 \\(a\\)와 \\(b\\)를 사용했지만, 회귀 분석에서는 보통 \\(b_0\\)(절편)과 \\(b_1\\)(기울기)로 표기합니다. 통계학자들이 왜 기울기를 \\(b_1\\)이라고 부르기로 했는지는 모르겠지만, 중요한 점은 \\(b_0\\)는 절편, \\(b_1\\)은 기울기라는 것입니다.\n이제 우리는 중요한 사실을 깨닫게 됩니다. 좋은 회귀선이든 나쁜 회귀선이든, 데이터가 선 위에 완벽하게 정확히 놓이지는 않는다는 것입니다. 즉, 실제 데이터 값 \\(Y_i\\)는 회귀 모형이 예측한 값 \\(\\hat{Y}_i\\)와 항상 일치하지는 않습니다. 통계학에서는 모든 것에 이름과 숫자를 붙이는 것을 좋아하기 때문에, 예측값과 실제값 사이의 차이를 잔차(residual)라고 하며, 이를 \\(\\epsilon_i\\)로 표기합니다.7\n잔차는 다음과 같이 정의됩니다.\n\\[\\epsilon_i = Y_i - \\hat{Y}_i\\]\n이를 이용하면 완전한 선형회귀 모형을 다음과 같은 수식으로 표현할 수 있습니다.\n\\[Y_i = b_0 + b_1 X_i + \\epsilon_i\\]",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>상관관계와 선형회귀</span>"
    ]
  },
  {
    "objectID": "12-Correlation-and-linear-regression.html#선형회귀-모형-추정하기",
    "href": "12-Correlation-and-linear-regression.html#선형회귀-모형-추정하기",
    "title": "12  상관관계와 선형회귀",
    "section": "12.4 선형회귀 모형 추정하기",
    "text": "12.4 선형회귀 모형 추정하기\n이제 그림을 다시 그려 보겠습니다. 하지만 이번에는 모든 관측값에 대한 잔차의 크기를 보여주는 선을 추가하겠습니다. 회귀선이 좋을 때는 잔차(굵은 검은 선의 길이)가 모두 작아 보입니다. 이는 Figure 12.12(a)에서 확인할 수 있습니다. 하지만 회귀선이 나쁠 경우, 잔차는 훨씬 더 커집니다. Figure 12.12(b)를 보면 이를 알 수 있습니다. 우리가 회귀 모형에서 원하는 것은 작은 잔차일 것입니다. 네, 이것은 타당해 보입니다. 사실, “가장 적합한” 회귀선이란 잔차가 가장 작은 선이라고 말해도 될 것 같습니다. 또는, 통계학자들이 모든 것을 제곱하는 것을 좋아하는 만큼 다음과 같이 말하면 더 좋을 것 같습니다.\n\n추정된 회귀계수 \\(\\hat{b}_0\\)와 \\(\\hat{b}_1\\)는 잔차제곱합을 최소화하는 값이며, 잔차제곱합은 \\(\\sum_i (Y_i - \\hat{Y}_i)^2\\) 또는 \\(\\sum_i \\epsilon_i^2\\)로 나타낼 수 있습니다.\n\n네, 이렇게 말하니 더 괜찮아 보입니다. 그리고 내가 이렇게 들여쓰기를 했으니, 아마도 이것이 정답일 가능성이 높습니다. 그리고 이것이 정답이라면, 우리의 회귀계수들이 추정치라는 사실을 명심할 가치가 있습니다. (우리는 모집단을 설명하는 모수를 추정하려고 하는 것이니까요!) 따라서 작은 모자를 추가하여 \\(b_0\\)과 \\(b_1\\) 대신 \\(\\hat{b}_0\\)과 \\(\\hat{b}_1\\)을 사용한 것입니다. 마지막으로, 사실 회귀 모형을 추정하는 방법은 여러 가지가 있기 때문에, 이 추정 과정을 보다 기술적으로 최소제곱법(ordinary least squares, OLS) 회귀라고 부른다는 점도 언급해 두어야겠습니다.\n\n\n\n\n\n\n\n\nFigure 12.12. 가장 적합한 회귀선과 관련된 잔차(a)와 부적절한 회귀선과 관련된 잔차(b). 좋은 회귀선에서는 잔차가 훨씬 더 작습니다. 이는 좋은 회귀선이 데이터의 중앙을 지나기 때문이라는 점에서 놀라운 일이 아닙니다.\n\n\n\n\n\n이제 우리는 “가장 적합한” 회귀계수 \\(\\hat{b}_0\\)과 \\(\\hat{b}_1\\)을 어떻게 정의해야 하는지 구체적으로 알게 되었습니다. 이제 자연스럽게 떠오르는 질문은, 잔차 제곱합을 최소화하는 최적의 회귀계수를 어떻게 찾을 수 있을지입니다. 이에 대한 실제 해답은 꽤 복잡하며, 회귀 분석의 논리를 이해하는 데 큰 도움은 되지 않습니다.8 그러므로 여러분을 힘들게 하지 않겠습니다. 길고 지루한 방법을 먼저 보여주고 나서 jamovi가 제공하는 멋진 단축키를 “공개”하는 방식 대신, 바로 결론으로 가서 jamovi가 모든 어려운 작업을 처리하도록 하겠습니다.\n\n12.4.1 jamovi에서의 선형회귀\n선형회귀 분석을 실행하려면 parenthood.csv 데이터 파일을 열고, jamovi의 ‘회귀분석’-‘선형회귀분석’ 메뉴를을 선택합니다. 그런 다음 ‘종속변수’에 dani.grump를, ’독립변수’9 상자에 dani.sleep을 입력합니다. 그러면 Figure 12.13 에 표시된 결과가 나타나며, 여기서 절편은 \\(\\hat{b}_0 = 125.96\\), 기울기는 \\(\\hat{b}_1 = -8.94\\)로 계산됩니다. 즉, Figure 12.12 에서 내가 그린 최적의 회귀선은 다음과 같은 수식을 갖습니다:\n\\[\\hat{Y}_i=125.96+(-8.94 X_i)\\]\n\n\n\n\n\n\n\n\nFigure 12.13. jamovi에서 수행한 단순 선형회귀 분석의 스크린샷\n\n\n\n\n\n\n\n\n\n\n\nTip 12.6. 실습: 단순 선형회귀 모형 추정하기\n\n\n\nTip 12.5 실습을 이어서 선형회귀 모형의 계수를 추정해 봅니다.\n\n‘분석’-‘회귀분석’-‘선형회귀분석’ 메뉴를 선택합니다.\n왼편의 ‘선형회귀분석’ 창에서 다음을 수행하면 Figure 12.13 같은 결과를 얻을 수 있습니다.\n\n\n선형회귀 모형의 결과변수인 dan.grump 변수를 ‘종속변수’ 상자로 이동합니다.\n선형회귀 모형의 예측변수인 dan.sleep 변수를 ‘독립변수’ 상자로 이동합니다.\n\n\n\n\n\n12.4.2 추정된 모형 해석하기\n이 모형에서 가장 중요한 것은 회귀계수를 어떻게 해석하느냐입니다. 먼저 기울기 \\(\\hat{b}_1\\)부터 살펴보겠습니다. 기울기의 정의를 떠올려 보면, 회귀계수가 \\(\\hat{b}_1 = -8.94\\)라는 것은 \\(X_i\\)가 1 증가할 때마다 \\(Y_i\\)가 8.94만큼 감소한다는 뜻입니다. 즉, 내가 추가로 1시간 더 수면을 취할 때마다 기분이 나아지고, 나의 예민함은 8.94 포인트 줄어든다는 의미입니다.\n그렇다면 절편은 어떨까요? 절편 \\(\\hat{b}_0\\)는 “\\(X_i\\)가 0일 때 \\(Y_i\\)의 기대값”을 의미합니다. 즉, 내가 한숨도 자지 못했을 경우(\\(X_i = 0\\)), 나의 투덜거림 지수는 \\(Y_i = 125.96\\)이라는 터무니없이 높은 값에 도달하게 됩니다. 음… 가능한 한 피해야겠네요.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>상관관계와 선형회귀</span>"
    ]
  },
  {
    "objectID": "12-Correlation-and-linear-regression.html#다중-선형회귀",
    "href": "12-Correlation-and-linear-regression.html#다중-선형회귀",
    "title": "12  상관관계와 선형회귀",
    "section": "12.5 다중 선형회귀",
    "text": "12.5 다중 선형회귀\n지금까지 다룬 단순 선형회귀(simple Linear Regression) 모형은 하나의 예측변수를 가정합니다. 즉, 우리가 관심을 가지는 예측변수가 하나입니다. 우리의 데이터에서는 dani.sleep입니다. 사실, 지금까지 언급한 모든 통계 기법은 하나의 예측변수와 하나의 결과변수만을 사용하였습니다. 그러나 대부분의 연구 프로젝트에서는 검토하고자 하는 여러 개의 예측변수가 있습니다. 그렇다면, 선형회귀 프레임워크를 확장하여 여러 개의 예측변수를 포함할 수 있도록 하면 좋을 것입니다. 그렇다면 일종의 다중 회귀 (multiple regression) 모형이 등장할 순서겠네요.\n다중 회귀는 개념적으로 매우 간단합니다. 회귀 방정식에 더 많은 항을 추가하면 됩니다. 예를 들어, 두 개의 예측변수에 관심이 있다고 가정해 보겠습니다. dani.sleep과 baby.sleep 두 예측변수를 사용하여 dani.grump 결과변수를 예측하고 싶다고 합시다. 이전과 마찬가지로, \\(Y_i\\)는 i번째 날의 나의 예민함 정도를 나타냅니다. 하지만 이제 두 개의 \\(X\\) 변수가 있습니다. 첫 번째 변수는 나의 수면 시간이고, 두 번째 변수는 내 아들의 수면 시간입니다. 따라서 \\(X_{i1}\\)은 i번째 날의 나의 수면 시간, \\(X_{i2}\\)는 i번째 날 아기의 수면 시간을 나타냅니다. 이를 바탕으로 회귀 모형을 다음과 같이 표현할 수 있습니다.\n\\[Y_i=b_0+b_1X_{i1}+b_2X_{i2}+\\epsilon_i\\]\n이전과 마찬가지로, \\(\\epsilon_i\\)는 \\(i\\) 번째 관측값에 대한 잔차이며, \\(\\epsilon_i = Y_i - \\hat{Y}_i\\)로 정의됩니다. 이 모형에서는 이제 세 개의 회귀계수를 추정해야 합니다. \\(b_0\\)는 절편, \\(b_1\\)은 나의 수면 시간과 관련된 계수, \\(b_2\\)는 내 아들의 수면 시간과 관련된 계수입니다. 추정해야 할 계수의 수는 증가했지만, 계수를 추정하는 기본 개념은 변하지 않습니다. 즉, 추정된 계수인 \\(\\hat{b}_0\\), \\(\\hat{b}_1\\), \\(\\hat{b}_2\\)는 잔차 제곱합을 최소화하는 값들입니다.\n\n12.5.1 jamovi에서 다중 회귀 수행하기\njamovi에서 다중 회귀를 수행하는 방법은 단순 회귀와 동일합니다. 다만 ‘독립변수’ 상자에 추가적인 변수를 넣기만 하면 됩니다. 예를 들어, dani.sleep과 baby.sleep 두 변수를 사용하여 내가 왜 이렇게 예민한지를 설명하고 싶다면, baby.sleep을 dani.sleep과 함께 ‘독립변수’ 상자로 이동시키면 됩니다. 기본적으로 jamovi는 모형에 절편을 포함시킵니다. 이번에 얻은 회귀계수는 Table 12.4 에 나타나 있습니다.\n\n\n\n\nTable 12.4. 회귀 분석에서 여러 변수를 예측변수로 추가하기\n\n\n\n\n\n(절편)dani.sleepbaby.sleep\n\n125.97-8.950.01\n\n\n\n\n\n\n\ndani.sleep과 관련된 계수는 상당히 크며, 이는 내가 한 시간 덜 잘 때마다 예민함이 훨씬 심해진다는 것을 시사합니다. 반면, baby.sleep의 계수는 매우 작아서 내 아들이 얼마나 자는지는 별로 중요하지 않다는 것을 보여줍니다. 결국, 내 예민함을 결정하는 것은 내 수면 시간입니다. 이 다중 회귀 모형이 어떤 모습인지 감을 잡기 위해, Figure 12.14 는 세 개의 변수를 3D 공간에 시각화하고, 회귀 모형도 시각화하여 보여줍니다.\n\n\n\n\n\n\n\n\nFigure 12.14. 다중 회귀 모형의 3D 시각화. 이 모형에는 두 개의 예측변수인 dani.sleep과 baby.sleep이 있으며, 결과변수는 dani.grump입니다. 이 세 변수가 함께 3D 공간을 형성합니다. 각 관측값(점)은 이 공간의 한 지점입니다. 단순 선형 회귀 모형이 2D 공간에서 선을 형성하는 것과 마찬가지로, 이 다중 회귀 모형은 3D 공간에서 평면을 형성합니다. 회귀계수를 추정할 때 우리가 시도하는 것은 모든 파란 점들과 최대한 가깝게 위치하는 평면을 찾는 것입니다.\n\n\n\n\n\n\n\n\n\n\n\nTip 12.7. 실습: 다중 선형회귀 모형 추정하기\n\n\n\nTip 12.5 실습을 이어서 선형회귀 모형의 계수를 추정해 봅니다.\n\n‘분석’-‘회귀분석’-‘선형회귀분석’ 메뉴를 선택합니다.\n왼편의 ‘선형회귀분석’ 창에서 다음을 수행하면 다음 같은 결과를 얻을 수 있습니다.\n\n\n선형회귀 모형의 결과변수인 dan.grump 변수를 ‘종속변수’ 상자로 이동합니다.\n선형회귀 모형의 예측변수인 dan.sleep과 baby.sleep 변수를 ‘독립변수’ 상자로 이동합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12.5.2 일반적인 경우의 회귀식\n본문에서 제시한 방정식은 두 개의 예측변수를 포함하는 다중 회귀 모형의 형태를 보여줍니다. 따라서, 두 개 이상의 예측변수를 포함하려면 추가적인 \\(X\\) 항과 \\(b\\) 계수를 포함하면 됩니다. 즉, 모형에 \\(K\\)개의 예측변수가 있을 경우, 회귀 방정식은 다음과 같이 표현됩니다.\n\\[Y_i=b_0+\\sum_{k=1}^{K}b_k X_{ik}+\\epsilon_i\\]",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>상관관계와 선형회귀</span>"
    ]
  },
  {
    "objectID": "12-Correlation-and-linear-regression.html#회귀-모형의-적합도-정량화하기",
    "href": "12-Correlation-and-linear-regression.html#회귀-모형의-적합도-정량화하기",
    "title": "12  상관관계와 선형회귀",
    "section": "12.6 회귀 모형의 적합도 정량화하기",
    "text": "12.6 회귀 모형의 적합도 정량화하기\n이제 우리는 선형 회귀 모형의 계수를 추정하는 방법을 알게 되었습니다. 하지만 문제는 이 회귀 모형이 얼마나 좋은지 아직 모른다는 것입니다. 예를 들어, regression.1 모형은 내가 한 시간 더 자면 기분이 크게 좋아진다고 주장하지만, 이 모형이 완전히 엉터리일 수도 있습니다. 회귀 모형은 단지 내 기분에 대한 예측값 \\(\\hat{Y}_i\\)를 제공할 뿐이며, 실제 기분은 \\(Y_i\\)입니다. 이 둘이 매우 가까우면 회귀 모형이 좋은 성과를 낸 것이고, 둘이 크게 다르면 성과가 나쁜 것입니다.\n\n12.6.1 \\(R^2\\) 값\n다시 한 번 수학적인 개념을 조금 적용해 보겠습니다. 먼저 잔차 제곱합을 계산해 봅시다.\n\\[SS_{res}=\\sum_i (Y_i-\\hat{Y}_i)^2\\]\n우리는 이 값이 가능한 작기를 바랍니다. 구체적으로 말하면, 다음과 같은 결과변수의 총 변동성에 비해 아주 작아야 합니다.\n\\[SS_{tot}=\\sum_i(Y_i-\\bar{Y})^2\\]\n\n\n\n\n\n\n\\(R^2\\) 계산식\n\n\n\n\\(R^2\\)는 다음과 같이 계산됩니다. \\[R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}\\]\n잔차 제곱합 \\(SS_{res}\\)가 작을수록 \\(R^2\\) 값은 커집니다. 모형이 실제 데이터를 완벽하게 설명하면 잔차 제곱합은 0이 되므로 \\(R^2 = 1\\)이 됩니다. 모형이 실제 데이터를 전혀 설명하지 못하여 예측변수의 값에 무관하게 평균으로 결과변수를 설명한다면 \\(\\hat{Y}_i = \\bar{Y}\\)가 되어 \\(R^2 = 0\\)이 됩니다. \\(R^2\\)는 0부터 1 사이의 값을 가지며, 결과변수의 분산을 모형이 설명하는 비율을 나타냅니다.\n\n\n여기서 직접 이 값을 계산해 보겠습니다. 손으로 계산하는 대신 Excel이나 다른 표준적인 스프레드시트 프로그램을 사용할 것입니다. 나는 parenthood.csv 파일을 Excel에서 열어 parenthood rsquared.xls로 저장한 후 작업을 진행했습니다. 단일 예측변수를 사용하는 단순 모형의 경우, 다음과 같은 단계를 수행해야 합니다.\n\n새로운 열 ’Y.pred’를 만들고, 다음 수식을 입력합니다: = 125.97 + (-8.94 × dani.sleep)\n잔차 제곱합 \\(SS_{resid}\\)을 계산하기 위해 ’(Y-Y.pred)^2’라는 새로운 열을 만들고, 다음 수식을 입력합니다: = (dani.grump - Y.pred)\\^2\n이 열의 맨 아래에서 값의 합계를 계산합니다. 즉, = sum( ( Y-Y.pred)\\^2 )을 입력합니다.\ndani.grump 열의 맨 아래에서 dani.grump의 평균값을 계산합니다. (참고: Excel에서는 ‘mean’ 대신 ‘AVERAGE’ 함수를 사용합니다.)\n새로운 열 ’(Y - mean(Y))^2’을 만들고, 다음 수식을 입력합니다: = (dani.grump - AVERAGE(dani.grump))\\^2\n이 열의 맨 아래에서 값의 합계를 계산합니다. 즉, sum( (Y - mean(Y))\\^2 )을 입력합니다.\n빈 셀에 다음 수식을 입력하여 \\(R^2\\) 값을 계산합니다: = 1 - (SS(resid) / SS(tot) )\n\n이 과정을 수행하면 \\(R^2\\) 값은 0.8161018이 됩니다. \\(R^2\\) 값은 가끔 결정 계수(coefficient of determination)10라고도 불리며, 간단히 해석하면 예측변수가 결과변수의 분산을 얼마나 설명하는지를 나타냅니다. 즉, 여기서 \\(R^2 = .816\\)이라는 결과는 예측변수(my.sleep)가 결과변수(my.grump)의 분산 중 81.6%를 설명한다는 것을 의미합니다.\n물론 회귀 모형의 \\(R^2\\) 값을 얻기 위해 직접 Excel에 모든 명령을 입력할 필요는 없습니다. 나중에 [jamovi에서 가설 검정을 실행하기] 절에서 살펴보겠지만, jamovi에서는 옵션만 지정하면 쉽게 \\(R^2\\) 값을 얻을 수 있습니다. 하지만 지금은 잠시 그 이야기를 미뤄두고, \\(R^2\\)의 또 다른 특성에 대해 살펴보겠습니다.\n\n\n12.6.2 회귀와 상관관계의 관련성\n이제 앞서 언급한 주장을 다시 살펴볼 수 있습니다. 즉, 지금까지 논의한 아주 단순한 형태의 회귀 분석은 기본적으로 상관 분석과 동일하다는 것입니다. 이전에 피어슨 상관 계수를 나타내기 위해 기호 \\(r\\)을 사용했는데, 그렇다면 상관 계수 \\(r\\)과 선형 회귀에서의 \\(R^2\\) 값 사이에 어떤 관계가 있을까요? 당연히 있습니다. 상관 계수를 제곱한 값 \\(r^2\\)은 단일 예측변수를 사용하는 다순 선형 회귀에서의 \\(R^2\\) 값과 동일합니다. 다시 말해, 피어슨 상관 분석을 하는 것과 단일 예측변수를 사용하는 선형 회귀 모형을 수행하는 것은 (원리 상으로는) 거의 동일하다 할 수 있습니다.\n\n\n12.6.3 보정된 \\(R^2\\) 값\n다음 내용으로 넘어가기 전에 한 가지 더 짚고 넘어갈 것이 있습니다. 모형 성능을 평가할 때, 단순한 \\(R^2\\) 값이 아니라 “수정된(adjusted) \\(R^2\\)” 값을 보고하는 경우가 흔합니다.\n수정된 \\(R^2\\) 값을 계산하는 이유는 모형에 예측변수를 추가하면 \\(R^2\\) 값이 항상 증가하거나 최소한 감소하지 않기 때문입니다.\n수정된 \\(R^2\\) 값은 다음과 같이 \\(R^2\\) 계산 방식에서 약간의 조정을 가합니다. 예측변수의 수가 \\(K\\)인 회귀 모형을 \\(N\\) 개의 관측값이 있는 데이터에 적합시켰을 때, 수정된 \\(R^2\\) 값은 다음과 같이 정의됩니다.\n\\[\\text{adj.}R^2=1-\\left(\\frac{SS_{res}}{SS_{tot}} \\times \\frac{N-1}{N-K-1}\\right)\\]\n이 조정은 자유도를 반영하기 위한 것입니다. 수정된 \\(R^2\\) 값의 가장 큰 장점은 새로운 예측변수를 추가했을 때, 단순히 변수 수가 많아져서가 아니라 실제로 모형 성능이 개선된 경우에만 값이 증가한다는 점입니다. 하지만 단점도 있습니다. 수정된 \\(R^2\\) 값은 일반 \\(R^2\\) 값 같은 직관적인 해석을 하기는 어렵다는 것입니다. \\(R^2\\) 값은 회귀 모형이 결과변수의 분산을 얼마나 설명하는지에 대한 명확한 해석이 가능하지만, 수정된 \\(R^2\\) 값에는 이에 해당하는 간단한 해석이 존재하지 않습니다.\n그렇다면, 보고할 때 \\(R^2\\) 값과 수정된 \\(R^2\\) 값 중 어느 것을 선택해야 할까요? 이는 개인적인 선호의 문제일 가능성이 큽니다. 해석 가능성을 더 중요하게 생각한다면 \\(R^2\\) 값을 보고하는 것이 좋습니다. 편향을 보정하는 것이 더 중요하다고 생각된다면 수정된 \\(R^2\\) 값이 적절할 수 있습니다. 개인적으로 저는 \\(R^2\\) 값을 선호합니다. 모형 성능을 측정하는 지표는 해석 가능성이 가장 중요하다고 생각하기 때문입니다. 게다가, 회귀 모형의 가설 검정에서 살펴보겠지만, 만약 새로운 예측변수를 추가했을 때 \\(R^2\\) 값이 단순히 우연에 인해 증가한 것이 아닌지 걱정된다면, 이를 검정할 수 있는 가설 검정 방법이 이미 존재합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>상관관계와 선형회귀</span>"
    ]
  },
  {
    "objectID": "12-Correlation-and-linear-regression.html#회귀-모형의-가설-검정",
    "href": "12-Correlation-and-linear-regression.html#회귀-모형의-가설-검정",
    "title": "12  상관관계와 선형회귀",
    "section": "12.7 회귀 모형의 가설 검정",
    "text": "12.7 회귀 모형의 가설 검정\n지금까지 우리는 회귀 모형이 무엇인지, 회귀 모형의 계수를 어떻게 추정하는지, 그리고 모형의 성능을 어떻게 정량화하는지에 대해 이야기했습니다. (참고로, 모형의 성능을 정량화하는 것은 기본적으로 효과 크기를 측정하는 것입니다.) 이제 우리가 논의해야 할 다음 주제는 가설 검정입니다.\n회귀 모형에 대한 가설 검정에는 상호 관련성이 있는 두 가지 유형의 검정이 있습니다. 1. 회귀 모형이 전체적으로 귀무 모형(null model)보다 유의하게 더 나은 성능을 보이는지 검정 2. 특정 회귀계수가 0과 유의하게 다른지를 검정\n\n12.7.1 모형 전체에 대한 검정\n자, 이제 회귀 모형을 추정했다고 가정해 봅시다. 가장 먼저 수행할 수 있는 가설 검정은 다음과 같습니다. - 귀무 가설 (\\(H_0\\)): 예측변수와 결과변수 사이에 아무런 관계가 없다. - 대립 가설 (\\(H_1\\)): 데이터가 회귀 모형이 예측하는 방식과 일치하게 분포되어 있다.\n수학적으로 정식화하면, “귀무 모형(null model)”은 예측변수가 0 개이고 절편(intercept) \\(b_0\\)만 포함하는 매우 단순한 “회귀 모형”에 해당합니다. \\[H_0: Y_i = b_0 + \\epsilon_i\\]\n반면, 우리가 추정한 회귀 모형에 \\(K\\)개의 예측변수가 포함되어 있다면, “대립 모형(alternative model)”은 일반적인 다중 회귀 모형의 수식과 동일합니다. \\[H_1: Y_i = b_0 + \\sum_{k=1}^{K} b_k X_{ik} + \\epsilon_i\\]\n그렇다면, 이 두 가설을 어떻게 비교할 수 있을까요? 핵심은 결과변수의 평균에서의 총 변동(\\(SS_{tot}\\))을 잔차의 변동(\\(SS_{res}\\))과 회귀 모형의 변동(\\(SS_{mod}\\))으로 분해할 수 있다는 점입니다. 여기서는 수학적인 세부 사항을 생략하겠습니다. 이러한 내용은 Chapter 13 에서 ANOVA를 다룰 때 자세히 살펴볼 것입니다. 하지만 다음의 중요한 개념 하나만 기억하세요.\n\\[SS_{mod} = SS_{tot} - SS_{res}\\]\n그리고 위의 제곱합(sums of squares)을 자유도로 나누어 평균제곱(mean squares, MS)을 구할 수 있습니다.\n\\[MS_{mod} = \\frac{SS_{mod}}{df_{mod}}\\] \\[MS_{res} = \\frac{SS_{res}}{df_{res}}\\]\n여기서 자유도(degrees of freedom, df)는 어떻게 계산할까요?\n- 모형과 관련된 자유도는 예측변수의 개수(\\(K\\))와 관련이 있으며, 정확히 \\(df_{mod} = K\\)입니다. - 잔차의 자유도는 \\(df_{res} = N - K - 1\\)입니다.\n이제 평균제곱 값을 이용하여 \\(F\\)-통계량(F-statistic)을 계산할 수 있습니다. \\[F = \\frac{MS_{mod}}{MS_{res}}\\] 그리고 이 \\(F\\)-통계량의 자유도는 \\(K\\) 및 \\(N - K - 1\\)입니다.\n우리는 Chapter 13 에서 \\(F\\)-통계량을 훨씬 더 자세히 살펴볼 것입니다. 하지만 지금은 단순히 \\(F\\) 값이 클수록 귀무 가설이 기각되고 대립 가설이 채택될 가능서이 크다는 것을 의미한다는 점만 이해하면 충분합니다. 잠시 후, jamovi를 사용하여 이 검정을 쉽게 수행하는 방법을 보여드리겠습니다. 하지만 그 전에 개별 회귀계수에 대한 가설 검정을 먼저 살펴보겠습니다.\n\n\n12.7.2 개별 계수에 대한 검정\n앞서 소개한 \\(F\\)-검정은 회귀 모형이 전체적으로 우연 이상의 성능을 보이는지를 확인하는 데 유용합니다. 만약 회귀 모형이 \\(F\\)-검정에서 유의한 결과를 산출하지 못한다면, 아마도 좋은 회귀 모형이 아닐 가능성이 큽니다 (혹은 데이터의 질이 좋지 않을 가능성도 있습니다). 그러나 이 검정을 통과하지 못하면 모형에 문제가 있다는 강력한 신호가 되지만, 검정을 통과한다고 해서 반드시 좋은 모형이라는 의미는 아닙니다! 왜 그런지 궁금할 것입니다. 그 이유는 우리가 이미 살펴본 [다중 선형 회귀] 모형의 계수를 보면 알 수 있습니다(Table 12.4).\nTable 12.4 를 보면, dani.sleep 변수의 추정 회귀계수는 \\(-8.95\\)인 반면, baby.sleep 변수의 계수는 \\(0.01\\)로 매우 작다는 점에 주목하게 될 것입니다. 이 두 변수는 동일한 척도(둘 다 “수면 시간” 단위)로 측정되었기 때문에, 이 차이가 두드러지게 보입니다. 사실, 내 예민함을 예측하는 데 있어 중요한 것은 나의 수면 시간뿐이라는 의심이 들기 시작합니다. 이를 확인하기 위해, 앞서 논의한 \\(t\\)-검정을 다시 활용할 수 있습니다. 여기서 관심사는, 특정한 예측변수 \\(X_i\\)의 회귀계수의 실제 값이 0이라는 귀무가설(\\(b_i = 0\\))과 이에 반대되는 대립가설(\\(b_i \\neq 0\\))을 검정하는 것입니다. 즉, \\[H_0:b_i=0\\] \\[H_1:b_i \\neq 0\\]\n이를 어떻게 검정할 수 있을까요? 중심극한정리가 우리에게 유리하게 작용한다면, 추정된 회귀계수 \\(\\hat{b}_i\\)의 표본분포가 \\(b_i\\)를 평균으로 한 정규분포를 따를 것이라고 가정할 수 있습니다. 이는 귀무가설이 참이라면, \\(\\hat{b_i}\\)의 표본 분포는 평균이 0이고 표준편차는 알 수 없는 정규분포를 따른다는 것을 의미합니다. 만약 회귀계수의 표준오차 \\(SE(\\hat{b}_i)\\)를 적절하게 추정할 수 있다면, 우리가 Chapter 11 에서 소개한 단일 표본 \\(t\\)-검정과 정확히 같은 상황이 됩니다. 따라서 \\(t\\)-통계를 다음과 같이 정의할 수 있습니다:\n\\[t=\\frac{\\hat{b}_i}{SE(\\hat{b}_i)}\\] 왜 그런지는 언급하지 않겠지만, 여기서 자유도는 \\(df = N - K - 1\\)입니다. 다소 성가신 점은, 회귀계수의 표준오차 \\(SE(\\hat{b}_i)\\)를 추정하는 과정이 Chapter 11 에서 사용한 평균의 표준오차보다 계산하기 훨씬 까다롭다는 점이다. 사실, 계산 공식은 다소 복잡하고, 굳이 여기서 살펴볼 만한 가치는 없을 것 같습니다.11 여기서 중요한 점은, 추정된 회귀계수의 표준오차는 예측변수와 결과변수 모두에 의존하며, 분산 동질성 가정이 위배되면 이에 민감하게 반응한다는 것입니다(이 내용은 곧 논의할 것입니다).\n어쨌든, 이 \\(t\\)-통계량은 Chapter 11 에서 논의한 \\(t\\)-통계량과 동일한 방식으로 해석할 수 있습니다. 양측 검정을 수행한다고 가정하면 (즉, \\(b &gt; 0\\)인지 또는 \\(b &lt; 0\\)인지에는 관심이 없고, 단순히 \\(b\\)가 0이 아닌지만 확인하는 경우), \\(t\\)-값이 극단적으로 작거나 크면 귀무가설을 기각합니다.\n\n\n\n\n\n\n개별 계수에 대한 \\(t\\)-검정의 의미\n\n\n\n다중 회귀 모형에서 개별 계수에 대한 \\(t\\)-검정을 해석할 때 주의할 점이 있습니다. \\(K\\) 개의 예측변수가 있는 다중 선형 회귀 모형에서 귀무 가설 \\(H_0: b_i = 0\\)는, \\(i\\) 번째 예측변수를 제외한 나머지 \\(K-1\\) 개의 예측변수가 모형에 있을 때 \\(X_i\\)는 결과변수 \\(Y\\)에 유의한 영향력이 없다라는 의미입니다. 즉 \\(H_0: b_i = 0\\)이라는 귀무가설의 검정은 모형에 다른 예측변수로 무엇이 포함되었는지에 영향을 받습니다.\n예를 들어 다음의 모형을 고려해 봅시다. \\[\n\\text{dani.grump} = b_0 + b_1 \\, \\text{baby.sleep} + b_2 \\, \\text{dani.sleep}\n\\] 이 모형에서 \\(H_0: b_1 = 0\\)에 대한 가설 검정은 dani.sleep(다니의 수면시간)이 dani.grump(다니의 예민함)를 설명하고 있을 때 baby.sleep(아이의 수면시간)이 dani.grump(다니의 예민함)에 유의한 영향력이 있는지를 묻는 것입니다.\n반면, 다음과 같은 모형을 고려해 봅시다. \\[\n\\text{dani.grump} = b_0 + b_1 \\, \\text{baby.sleep}\n\\] 이 모형에서 \\(H_0: b_1 = 0\\)에 대한 가설 검정은 다른 예측변수가 없을 때 baby.sleep이 dani.grump에 유의한 영향력이 있는지를 묻는 것입니다.\n이 두 가설 검정은 동일한 예측변수의 결과변수에 대한 영향력을 검정하지만 결과가 다를 수 있습니다. 결국 Dani의 예민함은 Dani의 수면시간에 관련이 깊습니다. 그러므로 Dani의 수면시간이 모형에 도입되어 있으면 아기의 수면시간은 Dani의 예민함에 영향을 주지 못할 것입니다. 그러나, Dani의 수면시간이 모형에 없으면 아기의 수면시간은 Dani의 예민함을 예측하는데 중요한 변수가 됩니다. 왜냐하면 Figure 12.10 에서 보았듯이 Dani의 수면시간은 아기의 수면시간과 상관성이 있습니다. 그러므로 Dani의 수면시간을 직접적으로 알 수 없는 상태에서는 아기의 수면시간이 Dani의 수면시간의 대리 변수로서 작용하므로 Dani의 예민함에 영향력이 있다라고 나올 수 있습니다.\n이렇듯 다중 선형회귀 모형에서 개별 회귀계수에 대한 검정은 나머지 예측변수가 모형에 있다는 가정 하에 해당 예측변수의 영향력 유무를 검정하는 것이라는 것을 이해하는 것이 중요합니다.\n\n\n\n\n12.7.3 jamovi에서 가설 검정 수행하기\n지금까지 설명한 모든 통계량을 계산하려면, jamovi에서 관련 옵션을 선택한 후 ’회귀분석’을 실행하면 됩니다. 이렇게 하면 Figure 12.15 같이 유용한 출력 결과를 얻을 수 있습니다.\nFigure 12.15 에 표시된 jamovi 분석 결과 하단의 ‘모형계수(Model Coefficients)’ 표에는 회귀 모형의 계수가 제공됩니다. 이 표의 각 행은 회귀 모형의 개별 계수를 나타냅니다. 첫 번째 행은 절편 항(intercept)이고, 이후 행들은 각 예측변수를 나타냅니다. 열에는 관련된 모든 정보가 포함되어 있습니다. 첫 번째 열은 실제 회귀계수 \\(b\\)의 추정값(예: 절편의 경우 \\(125.97\\), dani.sleep 변수의 경우 \\(-8.95\\))을 나타냅니다. 두 번째 열은 표준오차 추정값 \\(SE({\\hat{b}})\\)입니다. 세 번째와 네 번째 열은 \\(b\\) 추정값을 중심으로 한 95% 신뢰구간의 하한과 상한을 제공합니다(이에 대해서는 나중에 더 설명하겠습니다). 다섯 번째 열은 \\(t\\)-통계량을 나타내며, 이 표에서는 항상 \\(t=\\frac{\\hat{b}} {SE({\\hat{b}})}\\) 관계가 성립합니다. 마지막 열은 각 검정의 \\(p\\)-값을 제공합니다.12\n\n\n\n\n\n\n\n\nFigure 12.15. 여러 유용한 옵션이 선택된 다중 선형 회귀 분석을 보여주는 jamovi 스크린샷\n\n\n\n\n\n모형계수 표에서 유일하게 제공되지 않는 정보는 \\(t\\)-검정에서 사용된 자유도로, 이는 항상 \\(N - K - 1\\)이며, 출력 결과 상단의 ‘모형 적합도 값(Model Fit Measures)’ 표에 표시됩니다. 이 표를 보면, 모형이 우연보다 유의하게 더 나은 성능을 보인다는 것을 확인할 수 있습니다 (\\(F(2,97) = 215.24, p&lt; .001\\)). 이는 그리 놀라운 결과가 아닙니다. \\(R^2 = .81\\)이라는 값은 회귀 모형이 결과변수의 변동성 중 81%를 설명한다는 것을 의미하며, 수정된 \\(R^2\\) 값은 82%입니다. 그러나 개별 계수에 대한 \\(t\\)-검정을 다시 살펴보면, baby.sleep 변수는 유의한 영향을 미치지 않는다는 강력한 증거가 있습니다. 이 모형에서 실제로 중요한 역할을 하는 변수는 dani.sleep뿐입니다.\n이 결과를 종합하면, 현재의 회귀 모형은 데이터에 적합하지 않은 모형이라는 결론을 내릴 수 있습니다. baby.sleep 예측변수를 완전히 제거하는 것이 더 나을 것입니다. 다시 말해, 처음 시작했던 단순 회귀 모형이 더 적합한 모형이라고 할 수 있습니다.\n\n\n\n\n\n\nTip 12.8. 실습: 선형회귀 모형의 적합도와 가설검정\n\n\n\nTip 12.7 실습을 이어서 선형회귀 모형의 적합도와 가설검정 결과의 옵션을 추가해 봅니다.\n\n오른쪽 ‘선형 회귀분석’ 결과를 클릭합니다. 그러면 왼편에 ‘선형 회귀분석’ 설정 창이 나타납니다.\n왼편의 ‘선형 회귀분석’ 창에서 다음 옵션을 조정하면 Figure 12.15 같은 결과를 얻을 수 있습니다.\n\n\n‘모형 적합도’ 옵션을 확장한 후, ‘조정된 \\(R^2\\)’, ’F 검정’을 체크합니다.\n‘모형 계수’ 옵션을 확장한 후, ’신뢰구간’을 체크합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>상관관계와 선형회귀</span>"
    ]
  },
  {
    "objectID": "12-Correlation-and-linear-regression.html#회귀계수에-관하여",
    "href": "12-Correlation-and-linear-regression.html#회귀계수에-관하여",
    "title": "12  상관관계와 선형회귀",
    "section": "12.8 회귀계수에 관하여",
    "text": "12.8 회귀계수에 관하여\n선형 회귀의 기본 가정을 논의하고 해당 가정이 충족되는지 확인하는 방법을 살펴보기 전에, 회귀계수와 관련된 두 가지 주제를 간략히 다루고자 합니다. 첫 번째로 다룰 내용은 회귀계수의 신뢰구간을 계산하는 방법입니다. 그다음으로, 어떤 예측변수가 가장 중요한지를 판단하는 문제에 대해 논의하겠습니다.\n\n12.8.1 회귀계수의 신뢰구간\n다른 추정의 모집단의 모수와 마찬가지로, 회귀계수 \\(b\\) 역시 표본 데이터를 사용하여 완벽한 정확도로 추정할 수는 없습니다. 그렇기 때문에 가설 검정이 필요한 것입니다. 이런 점을 고려할 때, \\(b\\)의 실제 값에 대한 불확실성을 반영하는 신뢰구간을 보고하는 것은 매우 유용합니다. 특히, 연구 질문이 변수 \\(X\\)와 변수 \\(Y\\)가 얼마나 강하게 관련되어 있는지를 탐구하는 데 중점을 두고 있다면, 관심의 초점은 주로 회귀계수 \\(b\\)에 맞춰지므로 신뢰구간이 더욱 중요합니다.\n다행히도, 회귀계수의 신뢰구간은 일반적인 방식으로 구성할 수 있습니다. 즉, \\(CI(b)=\\hat{b} \\pm (t_{crit} \\times SE(\\hat{b}))\\)입니다. 여기서 \\(SE(\\hat{b})\\)는 회귀계수의 표준오차이며, \\(t_{crit}\\)는 적절한 \\(t\\)-분포의 임계값입니다. 예를 들어, 95% 신뢰구간을 구하려면, 임계값은 자유도가 \\(N - K - 1\\)인 \\(t\\)-분포의 97.5 분위수입니다. 즉, 이는 우리가 지금까지 사용해 온 신뢰구간 계산 방식과 기본적으로 동일합니다.\njamovi 예제에서 Figure 12.15 에서 볼 수 있듯이 이미 ’95% 신뢰구간’을 지정하였습니다. 물론, 필요에 따라 ’99% 신뢰구간’과 같이 다른 값을 선택할 수도 있습니다.\n\n\n12.8.2 표준화 회귀계수 계산하기\n회귀 분석에서 종종 수행되는 것 중 하나가 “표준화된” 회귀계수(보통 \\(\\beta\\)로 표시)를 계산하는 것입니다. 표준화 계수의 논리는 다음과 같습니다. 많은 경우, 변수들은 근본적으로 다른 척도를 가지고 있습니다. 예를 들어, 어떤 회귀 모형이 사람들의 \\(IQ\\) 점수를 예측하는데, 예측변수로 교육 수준(교육 년수)과 소득을 사용한다고 가정해 보겠습니다. 교육 수준과 소득은 서로 다른 척도를 가지고 있습니다. 교육 년수는 보통 10년 단위로 변화하는 반면, 소득은 수만 달러(또는 그 이상) 단위로 변화할 수 있습니다. 측정 단위는 회귀계수에 큰 영향을 미치므로, \\(b\\) 계수는 예측변수와 결과변수의 단위를 고려해야만 의미를 가집니다. 따라서 서로 다른 예측변수의 계수를 비교하는 것은 매우 어렵습니다. 하지만 예측변수 사이의 비교가 필요한 경우도 있습니다. 특히, 어떤 예측변수가 결과변수와 가장 강한 관계를 가지는지를 표준적인 방법으로 측정하고 싶을 수 있습니다. 표준화 계수(standardized coefficients)는 바로 이 목적을 위해 사용됩니다.\n기본 개념은 매우 간단합니다. 표준화 계수는 회귀 분석을 수행하기 전에 모든 변수를 \\(z\\)-점수로 변환했을 때 얻어지는 계수입니다.13 이렇게 하면 모든 예측변수가 동일한 척도로 변환되므로, 변수 사이의 척도 차이에 따른 문제를 제거할 수 있습니다. 원래 변수가 무엇이든 상관없이, \\(\\beta\\) 값이 1이라는 것은 예측변수가 1 표준편차 증가할 때 결과변수도 1 표준편차만큼 증가한다는 의미입니다. 따라서 변수 \\(A\\)의 \\(\\beta\\) 값의 절댓값이 변수 \\(B\\)보다 크다면, 변수 \\(A\\)가 결과변수와 더 강한 관계를 가진다고 판단할 수 있습니다. 적어도 이론적으로는 그렇습니다. 하지만 여기서 주의해야 할 점은 “1 표준편차 변화”가 모든 변수에서 동일한 의미를 갖는다는 가정에 크게 의존한다는 것입니다. 이는 항상 명확한 사실은 아닙니다.\n해석상의 문제를 잠시 제쳐두고, 표준화 계수가 어떻게 계산되는지 살펴보겠습니다. 가장 간단한 방법은 모든 변수를 직접 표준화한 후 회귀 분석을 수행하는 것입니다. 하지만 더 쉬운 방법이 있습니다. 예측변수 \\(X\\)와 결과변수 \\(Y\\)에 대한 \\(\\beta\\) 계수는 간단한 공식으로 계산할 수 있습니다. \\[\n\\beta_X = b_X \\times \\frac{\\sigma_X}{\\sigma_Y}\n\\] 여기서 \\(\\sigma_X\\)는 예측변수의 표준편차이고, \\(\\sigma_Y\\)는 결과변수 \\(Y\\)의 표준편차입니다. 이 공식을 사용하면 계산이 훨씬 간단해집니다.\n더욱 간편하게 하려면, jamovi에서 ‘모형 계수’ 옵션의 ‘표준화 추정값’ 체크박스를 사용하면 \\(\\beta\\) 계수를 자동으로 계산할 수 있습니다. Figure 12.16 에서 그 결과를 확인할 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 12.16. 다중 선형 회귀 분석에서 95% 신뢰 구간을 포함한 표준화 계수\n\n\n\n\n\n이 결과에서 dani.sleep 변수가 baby.sleep 변수보다 훨씬 강한 영향을 미친다는 점이 명확하게 드러납니다. 하지만 이 사례는 원래의 회귀계수 \\(b\\)를 사용하는 것이 \\(\\beta\\) 계수를 사용하는 것보다 더 적절한 경우입니다. 결국, 저의 수면 시간과 아기의 수면 시간은 동일한 척도(수면 시간, 즉 “시간”)로 측정됩니다. 그렇다면 \\(z\\)-점수로 변환하여 복잡하게 만들 필요가 있을까요?",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>상관관계와 선형회귀</span>"
    ]
  },
  {
    "objectID": "12-Correlation-and-linear-regression.html#선형회귀의-가정",
    "href": "12-Correlation-and-linear-regression.html#선형회귀의-가정",
    "title": "12  상관관계와 선형회귀",
    "section": "12.9 선형회귀의 가정",
    "text": "12.9 선형회귀의 가정\n제가 설명한 선형회귀 모형은 여러 가지 가정에 의존합니다. 모형 진단에서 이러한 가정이 충족되는지를 확인하는 방법에 대해 논의하기 전에, 먼저 각각의 가정을 살펴보겠습니다.\n\nLinearity (선형성): 선형 회귀 모형에서 가장 기본적인 가정은 \\(X\\)와 \\(Y\\) 사이의 관계가 실제로 선형이라는 것입니다! 단순 회귀든 다중 회귀든 관계없이, 우리가 다루는 관계는 선형이라고 가정합니다.\n\nIndependence (독립성): 잔차들은 상호 독립적이어야 합니다. 이는 본질적으로 “잔차에서 이상한 특징이 없다”는 것을 의미하는 포괄적인 가정입니다. 만약 잔차들이 어떤 다른 미측정 변수에 의해 강하게 영향을 받는다면, 회귀 분석 결과가 왜곡될 수 있습니다. 독립성은 진단 도구를 사용해 직접적으로 확인할 수 있는 것은 아니지만, 회귀 진단 결과가 이상하다면 관측치와 잔차의 독립성에 대해 신중히 검토해야 합니다.\n\nNormality (정규성): 통계학에서 많이 사용되는 모형들처럼, 기본적인 단순 및 다중 선형회귀는 정규성 가정에 의존합니다. 구체적으로, 잔차가 정규 분포를 따라야 합니다. 예측변수 \\(X\\)와 결과변수 \\(Y\\)가 반드시 정규 분포를 따를 필요는 없지만, 잔차 \\(\\epsilon\\)이 정규 분포를 따르는 것이 중요합니다. 자세한 내용은 [잔차의 정규성 확인] 절을 참조하십시오.\n\nEquality (등분산성, 또는 “분산의 동질성”): 엄밀히 말하면, 회귀 모형은 각 잔차 \\(\\epsilon_i\\)가 평균이 0이고 (이것도 중요하지만), 표준편차 \\(\\sigma\\)가 동일한 정규 분포에서 생성된다고 가정합니다. 실제로 모든 잔차가 동일한 분포에서 생성되었는지를 테스트하는 것은 불가능합니다. 대신, 우리가 관심을 두는 것은 잔차의 표준편차가 모든 \\(\\hat{Y}\\) 값에서 동일한지, 그리고 (좀 더 엄밀하게 보자면) 모형의 모든 예측변수 \\(X\\) 값에서도 동일한지 여부입니다.\n\n즉, 선형 회귀를 수행할 때는 위 네 가지 주요 가정을 고려해야 하며, 이를 약자로 정리하면 LINE이 됩니다. 또한, 추가적으로 확인해야 할 몇 가지 사항이 더 있습니다.\n\n예측변수 사이의 상관관계가 높지 않아야 합니다. 다중 회귀 모형에서는 예측변수들이 서로 너무 강하게 상관관계를 가지지 않아야 합니다. 이는 “기술적으로” 회귀 모형의 가정은 아니지만, 실무에서는 반드시 고려해야 합니다. 예측변수들 사이의 상관관계가 너무 높으면(이를 “다중공선성”이라고 합니다) 모형을 평가할 때 문제가 발생할 수 있습니다. 자세한 내용은 [다중공선성 확인] 절을 참조하십시오.\n\n“나쁜” 특이치가 없어야 합니다. 이 또한 엄밀히 말해 모형의 공식적인 가정은 아닙니다(혹은 다른 가정들에 의해 암묵적으로 포함되는 부분이기도 합니다). 그러나 몇 개의 특이치가 회귀 모형에 지나치게 강한 영향을 미쳐서는 안 됩니다. 특이치가 너무 강한 영향을 미친다면, 모형의 적절성과 데이터의 신뢰성에 대한 의문이 제기될 수 있습니다. 이에 대한 자세한 내용은 [특이치 및 예외적 데이터] 절을 참조하십시오.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>상관관계와 선형회귀</span>"
    ]
  },
  {
    "objectID": "12-Correlation-and-linear-regression.html#sec-Model-checking",
    "href": "12-Correlation-and-linear-regression.html#sec-Model-checking",
    "title": "12  상관관계와 선형회귀",
    "section": "12.10 모형 진단",
    "text": "12.10 모형 진단\n이 절에서는 회귀 진단(regression diagnostics)을 중점적으로 다룹니다. 회귀 진단이란 회귀 모형의 가정이 충족되었는지를 확인하고, 만약 가정이 위반되었을 경우 모형을 수정하는 방법을 찾으며, 전반적으로 모형에 이상한 점이 없는지 점검하는 작업을 의미합니다. 저는 이를 “모형 진단의 기술(art)”이라고 부르는데, 그만한 이유가 있습니다. 이 작업은 쉽지 않으며, 회귀 모형에 영향을 미칠 수 있는 문제를 진단하고 (문제가 있을 경우에 한해서!) 이를 해결하는 다양한 도구가 존재하지만, 이를 수행할 때는 일정 수준의 판단력이 필요합니다.\n이 절에서는 회귀 모형이 올바르게 작동하는지를 확인하는 여러 가지 방법을 설명합니다. 여기서 다루는 내용이 가능한 모든 방법을 포함하는 것은 아니지만, 실무에서 흔히 수행되는 작업보다는 훨씬 자세한 내용을 담고 있습니다. 안타깝게도, 실무에서는 종종 충분한 진단이 이루어지지 않기도 합니다. 하지만 어떤 도구를 사용할 수 있는지 알고 있는 것이 중요하므로, 여기에서 여러 도구를 소개하려고 합니다. 마지막으로, 이 절은 Fox & Weisberg (2011) 의 내용을 상당 부분 참고하고 있음을 밝혀 둡니다. Fox & Weisberg (2011) 은 \\(R\\)에서 회귀 분석을 수행하는 데 사용되는 “car” 패키지와 관련된 책입니다. “car” 패키지는 회귀 진단을 위한 훌륭한 도구들을 제공하며, 책 자체도 진단 방법을 경탄스러울 만큼으로 명확하게 설명하고 있습니다. 지나치게 극찬하는 것처럼 들릴 수도 있지만, Fox & Weisberg (2011) 은 읽어볼 가치가 있는 책이라고 생각합니다. 다만, 일부 고급 진단 기법은 jamovi가 아니라 “R”에서만 사용할 수 있다는 점을 유념해야 합니다.\n\n12.10.1 세 가지 종류의 잔차\n대부분의 회귀 진단은 잔차를 분석하는 데 초점을 맞추며, 우리가 고려할 수 있는 잔차에는 여러 가지 종류가 있습니다. 특히, 이 절에서는 다음 세 가지 종류의 잔차를 다룹니다: 통상적인 잔차(ordinary residuals), 표준화 잔차(standardized residuals), 그리고 스튜던트화 잔차(Studentized residuals)입니다. 또한 일부 그림에서는 Pearson 잔차라는 용어가 등장할 수도 있습니다. 그러나 이 장에서 다루는 모형의 경우 Pearson 잔차는 통상적인 잔차와 동일합니다.\n우리가 가장 먼저 고려하는 잔차는 통상적인 잔차입니다. 이는 지금까지 이 장에서 계속 언급한 원래의 잔차입니다. 잔차는 예측값 \\(\\hat{Y}_i\\)와 실제 관측값 \\(Y_i\\)의 차이를 의미하며, 이를 나타내는 간단한 수식은 다음과 같습니다.\n\\[\\epsilon_i=Y_i-\\hat{Y_i}\\]\n이 공식은 앞서 설명했던 내용과 동일하며, 특별히 다른 종류의 잔차를 언급하지 않는 한, 이 잔차를 의미한다고 보면 됩니다. 여기서 중요한 점은, 잔차는 결과변수의 단위와 모형의 성능에 따라 항상 다른 척도를 가지기 때문에, 다름 모형 사이의 잔차를 직접 비교하기 어렵다는 것입니다. 일반적으로 회귀 모형에서 절편을 포함하는 경우, 잔차의 평균은 0이 되지만, 분산은 회귀 모형마다 다릅니다. 따라서 특정한 잔차의 패턴을 분석할 때, 표준화 잔차를 사용하는 것이 더 편리할 수 있습니다. 표준화 잔차는 표준 편차가 1이 되도록 정규화된 잔차입니다.\n표준화 잔차를 계산하는 방법은 잔차를 잔차의 (모집단) 표준편차의 추정값으로 나누는 것입니다. 기술적인 이유로, 표준화 잔차는 다음과 같은 수식을 사용하여 계산됩니다.\n\\[\\epsilon_i^{'}=\\frac{\\epsilon_i}{\\hat{\\sigma}\\sqrt{1-h_i}}\\]\n여기서 \\(\\hat{\\sigma}\\)는 일반 잔차의 모집단 표준 편차 추정값이며, \\(h_i\\)는 \\(i\\)번째 관측치의 “해트 값(hat value)”입니다. 해트 값에 대한 설명은 아직 하지 않았기 때문에, 이 수식이 완전히 이해되지 않을 수도 있습니다. 지금은 표준화 잔차가 일반 잔차를 \\(z\\)-점수로 변환한 것과 유사하게 해석할 수 있다고 생각하면 됩니다.\n세 번째 잔차 유형은 스튜던트화 잔차이며, 이 잔차는 표준화 잔차보다 한층 더 정교한 방법으로 계산됩니다. 기본 개념은 잔차를 어떤 값으로 나누어 표준화된 잔차의 개념을 추정하는 것입니다. 스튜던트화 잔차를 계산하는 수식은 표준화 잔차를 계산하는 식에서 약간만 다릅니다.\n\\[\\epsilon _i^*=\\frac{\\epsilon_i}{\\hat{\\sigma}_{(-i)}\\sqrt{1-h_i}}\\]\n여기서 \\(\\hat{\\sigma}_{(-i)}\\)는 \\(i\\)-번째 관측치를 데이터에서 제거했을 때 얻을 수 있는 잔차의 표준 편차 추정값을 의미합니다. 이 계산을 위해서는 관측치 \\(i\\)를 제거한 상태에서 새로운 회귀 모형을 \\(N\\)번 실행해야 하는 것처럼 보일 수 있습니다. 데이터가 매우 크다면, 최신 컴퓨터라도 이 연산을 수행하는 데 부담을 느낄 수 있습니다. 다행히도, 이 표준 편차 추정값은 다음 수식을 사용하여 효율적으로 계산할 수 있습니다.\n\\[\\hat{\\sigma}_{(-i)}= \\hat{\\sigma}\\sqrt{\\frac{N-K-1-{\\epsilon_i^{'}}^2}{N-K-2}}\\]\n마지막으로, 이러한 잔차를 직접 계산해야 하는 경우는 많지 않다는 점을 언급하고자 합니다. 대부분의 회귀 진단 도구나 가정 검정 기능은 이러한 계산을 자동으로 수행해 줍니다. 그러나 가끔은 표준적인 방법을 벗어난 특별한 분석이 필요할 수도 있으므로, 이러한 잔차를 직접 계산하는 방법을 알고 있는 것이 도움이 될 수 있습니다.\n\n\n12.10.2 관계의 선형성 검토하기\n예측변수와 결과변수 사이의 관계가 선형성을 만족하는지 확인해야 합니다. 이를 점검하기 위해 수행할 수 있는 몇 가지 방법이 있습니다. 우선, 예측값 \\(\\hat{Y}_i\\)과 결과변수의 실제 관측값 \\(Y_i\\) 사이의 관계를 단순히 그래프로 그려보는 것은 언제나 유용합니다. Figure 12.17 에 이를 예시한 그림이 있습니다. jamovi에서 이를 그리기 위해 예측값을 데이터에 저장한 후, 관측값과 예측(적합)값 사이의 산점도를 작성하였습니다. 이 그래프는 전체적인 관계를 확인할 수 있는 “큰 그림”을 제공합니다. 만약 이 그래프가 대략적으로 선형적인 형태를 띤다면, 모형이 크게 잘못된 것은 아닐 가능성이 큽니다(물론, 문제가 전혀 없다는 뜻은 아닙니다). 하지만 여기에서 선형성에서 크게 벗어나는 패턴이 보인다면, 모형을 수정해야 할 필요가 있음을 강하게 시사합니다.\n\n\n\n\n\n\n\n\nFigure 12.17. 결과변수의 관측값과 예측값을 비교한 jamovi 산점도. 여기에서 우리가 기대하는 것은 직선(또는 직선에 가까운) 형태입니다. 이 그래프는 상당히 양호해 보이며, 큰 문제가 없음을 시사합니다.\n\n\n\n\n\n보다 상세한 분석을 위해서는 예측값과 잔차 사이의 관계를 살펴보는 것이 더 유용할 때가 많습니다. jamovi에서는 잔차 값을 데이터에 저장한 후, 예측값과 잔차 사이의 산점도를 그릴 수 있습니다. Figure 12.18 에서 이를 예시하고 있습니다. 이 그래프는 예측값과 잔차 사이의 산점도를 보여줄 뿐만 아니라, 두 변수 사이의 관계를 나타내는 선을 추가로 그려줍니다. 이상적으로, 이 선은 완전히 수평을 이루어야 합니다. 현실적으로는, 대체로 직선에 가깝거나 평평한 형태라면 적절하다고 판단할 수 있습니다. 하지만 최종적인 해석은 어느 정도의 주관적 판단이 필요한 부분입니다.\n\n\n\n\n\n\n\n\nFigure 12.18. 예측값과 잔차 사이의 관계를 나타낸 jamovi 산점도. 그래프에 표시된 선이 수평이며 직선에 가까울 경우, 모든 예측값에 대한 “평균 잔차”가 대체로 일정하다고 볼 수 있습니다.\n\n\n\n\n\n이와 같은 그래프의 더욱 정교한 버전은 jamovi의 회귀 분석 “가정검증(Assumption checks)” 옵션에서 “잔차 도표(Residuals plots)”를 선택하여 생성할 수 있습니다. 이러한 그래프는 선형성, 정규성 및 분산 동질성 가정을 확인하는 데 유용하며, 이에 대한 자세한 내용은 Section 12.10.3 에서 살펴보겠습니다. 이 옵션을 사용하면 예측값과 잔차를 비교하는 그래프를 생성할 뿐만 아니라, 각 개별 예측변수에 대한 잔차 그래프도 함께 작성할 수 있습니다.\n\n\n12.10.3 잔차의 정규성 검토하기\n이 책에서 다룬 여러 통계 도구와 마찬가지로, 회귀 모형도 정규성 가정을 따릅니다. 이 경우, 우리는 잔차가 정규 분포를 따른다고 가정합니다. 이를 확인하는 첫 번째 방법은 ‘선형회귀 분석’-‘가정검증’ 메뉴에서 ‘잔차 Q-Q 도표(Q-Q plot of residuals)’ 옵션을 선택하여 QQ-도표를 그리는 것입니다. Figure 12.19 에 해당 결과가 제시되어 있으며, 표준화된 잔차가 회귀 모형의 이론적 분위수에 따라 시각화된 모습을 보여줍니다.\n또한, 예측(적합)값과 잔차 사이의 관계도 점검해야 합니다. jamovi에서는 ‘잔차 도표’ 옵션을 통해 이를 수행할 수 있으며, 각 예측변수, 결과변수 및 예측값과 잔차 사이의 관계를 나타내는 산점도를 제공합니다. Figure 12.20 에서 해당 그래프를 확인할 수 있습니다. 이러한 그래프에서 우리는 점들이 비교적 균일하게 분포하는지를 살펴봐야 하며, 특정한 패턴이나 밀집된 영역이 없어야 합니다. 이 그래프들을 보면, 점들이 전체적으로 균등하게 분포되어 있으며, 특별히 걱정할 만한 요소는 보이지 않습니다. 다만, (b) 그래프에서는 약간의 비균일성이 보이지만, 강한 편향은 아니므로 크게 신경 쓸 필요는 없을 것입니다.\n\n\n\n\n\n\n\n\nFigure 12.19. 회귀 모형에 따른 이론적 분위수와 표준화된 잔차의 분위수를 비교한 jamovi의 Q-Q 도표\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 12.20. jamovi에서 생성된 잔차 도표\n\n\n\n만약 잔차의 정규성에 문제가 있다고 판단된다면, 이를 해결하는 방법 중 하나는 변수를 변환하는 것입니다. 변수 변환의 기본 개념에 대해서는 Section 6.3 에서 논의하였지만, 여기에서 특별히 추가적으로 언급하고 싶은 방법은 Box-Cox 변환입니다. Box-Cox 변환은 비교적 간단하면서도 널리 사용되는 기법입니다.14\njamovi에서는 ‘Compute’ 변수 설정 화면에서 BOXCOX() 함수를 사용하여 이를 계산할 수 있습니다.\n\n\n\n\n\n\nTip 12.9. 실습: 선형회귀 모형의 가정 검토 - 선형성과 정규성\n\n\n\nTip 12.8 실습을 이어서 선형회귀의 선형성과 정규성의 가정을 검토해 봅니다.\n\n오른쪽 ‘선형 회귀분석’ 결과를 클릭합니다. 그러면 왼편에 ‘선형 회귀분석’ 설정 창이 나타납니다.\n왼편의 ‘선형 회귀분석’ 창에서 다음 옵션을 조정하면 다음과 같은 정규성과 선형성과 관련된 도표를 그립니다.\n\n\n‘가정검증’ 옵션을 확장한 후, ‘정규분포성 검정’, ‘잔차 Q-Q 도표’, ’잔차 도표’를 체크합니다.\n오른쪽 결과 창의 ’정규분포성 검증(Shaprio-Wilk)’는 잔차가 정규성에 대한 가설검정을 수행한 결과입니다.\n오른쪽 결과 창의 ’Q-Q 도표’는 표준화 잔차와 이론적 정규분포의 Q-Q 도표를 그린 것입니다.\n오른쪽 결과 창의 ’잔차 도표’는 잔차를 예측값, 결과변수, 예측변수의 관계를 시각화한 그래프입니다(Figure 12.20 참조).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12.10.4 등분산성 검토하기\n이 책에서 다룬 모든 회귀 모형은 등분산성(분산의 동질성)을 전제로 합니다. 즉, 잔차의 분산이 일정하다고 가정합니다. 이를 jamovi에서 시각화하려면 먼저 잔차의 (절대값의) 제곱근을 계산해야 합니다15. 그런 다음, 이를 예측값과 비교하여 산점도를 그리면 됩니다(Figure 12.21). 이 도표에서는 원래 잔차가 아니라 표준화 잔차를 사용하지만, 우리의 목적에서는 큰 차이가 없습니다. 이 도표에서 확인하고자 하는 것은 도표의 중앙을 가로지르는 수평선입니다16.\n\n\n\n\n\n\n\n\nFigure 12.21. jamovi에서 생성된 예측값(모형 예측값)과 절대 표준화 잔차의 제곱근 사이의 도표. 이 도표은 분산의 동질성 가정 위반 여부를 진단하는 데 사용됩니다. 분산이 정말로 일정하다면, 도표 중앙을 가로지르는 선이 수평이어야 합니다.\n\n\n\n\n\n\n\n\n\n\n\nTip 12.10. 실습: 선형회귀 모형의 가정 검토 - 등분산성\n\n\n\nTip 12.9 실습을 이어서 선형회귀의 등분산성의 가정을 검토해 봅니다. 등분산성을 정규성이나 선현성처럼 이를 분석하는 그래프가 ‘가설검정’ 옵션에서 제공하지 않습니다. 그러므로 등분산성을 검토하는 그래프를 직접 생성해야 한다. 등분산성 그래프의 가로축은 모형의 예측값이고 세로축은 잔차의 절대값의 제곱근입니다. 이 두 종류의 값을 데이터에 추가한 후 등분산성을 검토하는 산점도를 생성해봅시다.\n\n오른쪽 ‘선형 회귀분석’ 결과를 클릭합니다. 그러면 왼편에 ‘선형 회귀분석’ 설정 창이 나타납니다.\n왼편의 ‘선형 회귀분석’ 창에서 다음 옵션을 선택하여 회귀모형의 ’예측값’과 ’잔차’를 데이터에 추가합니다.\n\n\n‘저장’ 옵션을 확장하여 ’예측값’과 ’잔차’를 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n스프레드시트 창에 ‘예측값’과 ’잔차’ 열이 만들어진 것을 확인합니다. 다음을 수행하여 ’잔차 절대값의 제곱근’이라는 열을 추가합니다.\n\n\n‘데이터’-‘추가’-‘다중 계산 변수’-‘추가’ 메뉴를 선택하여 계산 변수를 추가합니다.\n추가된 열의 이름을 클릭하여 이름을 ’잔차 절대값 제곱근’이라하고, \\(f_x\\) 옆의 계산식에 SQRT(ABS(잔차))를 입력합니다.\n\n\n\n\n\n\n\n\n\n\n\n‘잔차 절대값의 제곱근’ vs. ’예측값’의 산점도를 그립니다.\n\n\n‘분석’-‘기술통계’-‘산포도’ 메뉴를 선택합니다.\n왼편의 ‘산포도’ 창에서 ‘예측값’을 ’X-축’ 상자에, ‘잔차 절대값 제곱근’을 ’Y-축’ 상자로 이동합니다.\n‘회귀선’ 옵션에서 ’Smooth’를 선택하여 데이터의 관계를 설명하는 추세선을 그립니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12.10.5 다중공선성 검토하기\n또 다른 회귀 진단 방법으로 분산 팽창 계수(Variance Inflation Factors; VIFs)가 있습니다. VIF는 회귀 모형 내의 예측변수들이 서로 과도하게 상관되어 있는지를 판단하는 데 유용합니다. 각 예측변수 \\(X_k\\)에는 해당 변수와 관련된 VIF 값이 존재합니다17.\n예측변수가 두 개뿐이라면, VIF 값은 서로 동일합니다. jamovi의 ‘선형회귀 분석’ 메뉴에서 ‘가설검증’ 탭의 ‘공선성 통계값’ 체크박스를 선택하면 이를 확인할 수 있습니다. 예를 들어, dani.sleep과 baby.sleep의 VIF 값은 각각 \\(1.65\\)입니다. 그리고 \\(\\sqrt{1.65} \\approx 1.28\\)이므로, 두 예측변수 사이의 상관관계가 크게 문제를 일으키지는 않음을 알 수 있습니다.\n좀 더 심각한 다중공선성 문제가 발생하는 경우를 살펴보기 위해, 이 데이터 모든 변수들을 사용하여 데이터가 수집된 날짜(day)를 예측하는 다소 의미 없는 회귀 모형을 실행한다고 가정해 보겠습니다. 왜 이 데이터에서 문제가 발생하는지 이유를 확인하기 위해, 네 개의 변수 전체에 대한 상관 행렬을 살펴보겠습니다(Figure 12.22).\n\n\n\n\n\n\n\n\nFigure 12.22. jamovi에서 생성된 네 개 변수 사이의 상관 행렬\n\n\n\n\n\n예측변수들 사이에 상당히 높은 상관관계가 존재하는 것을 확인할 수 있습니다! 회귀 모형을 실행한 후 VIF 값을 살펴보면, 다중공선성이 계수 추정값에 많은 불확실성을 초래하고 있음을 알 수 있습니다. 먼저, 회귀 분석을 실행한 후 결과를 확인하면(Figure 12.23), 높은 다중공선성이 존재한다는 사실을 쉽게 파악할 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 12.23. jamovi에서 생성된 다중 회귀 분석의 다중공선성 통계\n\n\n\n\n\n\n\n\n\n\n\nTip 12.11. 실습: 선형회귀 모형의 가정 검토 - 다중공선성\n\n\n\nTip 12.10 실습을 이어서 선형회귀의 다중공선성을 검토해 봅니다. 먼저 기존의 회귀 모형에서 다중공선성을 확인하고, 그 다음으로 day를 나머지 변수로 예측하는 선형회귀 모형에서 다중공선성을 확인해 봅시다.\n\n오른쪽 ‘선형 회귀분석’ 결과를 클릭합니다. 그러면 왼편에 ‘선형 회귀분석’ 설정 창이 나타납니다.\n왼편의 ‘선형 회귀분석’ 창에서 ‘가설검증’ 옵션을 확장하여 ‘공선성 통계값’을 체크하면, 오른편의 결과 참의 ’가설검증’ 부분에 ‘공선성 통계값’ 표가 표시됩니다.\n\n\n\n\n\n\n\n\n\n\n\nday를 결과변수로 나머지 변수를 예측변수로 하는 선형회귀 모형을 만들고 다중공선성을 확인합니다.\n\n\n‘분석’-‘회귀분석’-‘선형회귀 분석’ 메뉴를 선택합니다.\nday 변수를 ‘종속변수’ 상자로 이동합니다.\ndani.sleep, baby.sleep, dani.grump 변수를 ‘독립변수’ 상자로 이동합니다.\n‘모형 적합도’ 옵션에서 ’조정된 \\(R^2\\)’와 ’F 검정’을 체크합니다.\n‘모형 계수’ 옵션에서 ’신뢰구간’을 체크합니다.\n’가정검증’에서 ’공선성 통계값’을 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 12.24. 특이치 예시. 실선은 특이치를 포함한 경우의 회귀선을, 점선은 특이치를 제외한 경우의 회귀선을 나타냅니다. 특이치와 점선 사이의 수직선은 해당 특이치가 갖는 큰 잔차 오류를 보여줍니다.\n\n\n\n\n\n\n\n12.10.6 특이치와 예외적 데이터\n선형 회귀 모형을 사용할 때 발생할 수 있는 위험 중 하나는 분석이 소수의 “예외적” 혹은 “이상한” 관측치에 지나치게 민감할 수 있다는 점입니다. 이 개념은 이전에 Section 5.2.3 에서 ’기술통계’의 박스 도표 옵션을 통해 자동으로 식별되는 특이치를 논의하는 과정에서 다루었습니다. 그러나 이번에는 보다 정밀하게 살펴보겠습니다.\n선형 회귀의 맥락에서 어떤 관측치가 “예외적”이라고 불릴 수 있는 개념적으로 구별되는 세 가지 유형이 있습니다. 이 세 가지 모두 흥미로운 개념이지만, 분석에 미치는 영향은 각각 다릅니다.\n첫 번째 유형의 예외적 관측치는 특이치(outlier) 입니다. 이 문맥에서 특이치의 정의는 회귀 모형이 예측하는 값과 매우 다른 값을 갖는 관측치입니다. 예를 들어, Figure 12.24 에서 볼 수 있듯이, 특이치는 결과변수(종속 변수, y축 위치)에서 예외적 값을 가지지만, 예측변수(독립 변수, x축 위치)에서는 그렇지 않으며, 회귀선으로부터 멀리 떨어져 있습니다. 실제로 우리는 특이치를 잔차 \\(\\epsilon_i^*\\)가 매우 큰 관측치로 정의하여 이를 정량화합니다. 또한, Anscombe의 사중표(Anscombe’s quartet) 중 왼쪽 아래 그래프(Figure 12.6)에서도 이러한 특이치를 확인할 수 있습니다.\n특이치는 흥미로운 특징을 가집니다. 큰 특이치는 데이터 오류일 가능성이 있으며, 예를 들어 데이터에서 변수가 잘못 기록되었거나 다른 결함이 있을 수도 있습니다. 그러나 단순히 특이치라는 이유만으로 관측치를 삭제해서는 안 됩니다. 다만, 특이치라는 사실은 해당 사례를 더 면밀히 조사하고, 왜 그렇게 다른지 파악하는 계기가 될 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 12.25. 높은 지렛값(high leverage point)의 예시. 이 관측치는 예측변수(x축)와 결과변수(y축) 모두에서 예외적 값을 가지지만, 다른 관측치 간의 상관 패턴과 매우 일관적입니다. 이 관측치는 회귀선에 매우 가까이 위치하며, 회귀선을 크게 왜곡시키지는 않습니다.\n\n\n\n\n\n두 번째 유형의 예외적 관측치는 높은 레버리지(지렛대값)(leverage)를 갖는 경우입니다. 이는 해당 관측치가 예측변수 측면에서 다른 모든 관측치들과 매우 다른 특성을 가지는 경우 발생합니다. 그러나 높은 레버리지를 가지는 것이 반드시 큰 잔차를 의미하는 것은 아닙니다. 만약 특정 관측치가 모든 변수에서 동일한 방식으로 예외적이라면, 실제로 회귀선에 매우 가깝게 위치할 수도 있습니다. 이러한 예시는 Figure 12.25 에서 확인할 수 있습니다.\n관측치의 레버리지는 해트 값(hat value)으로 정량화되며, 보통 \\(h_i\\)로 표기됩니다. 해트 값에 대한 수식은 다소 복잡하지만18, 해석 자체는 어렵지 않습니다. \\(h_i\\)는 해당 관측치가 회귀선의 위치를 결정하는 데 얼마나 영향을 미칠 수 있는지를 나타내는 척도입니다.\n일반적으로 어떤 관측값이 예측변수의 측면에서 다른 값들로부터 멀리 떨어져 있으면, 해당 관측값의 해트 값이 클 것입니다(대략적으로 해트 값이 평균의 2~3배를 초과하면 높은 레버리지로 간주됩니다. 또한 hat 값의 합은 \\(K + 1\\)과 같아야 한다는 제약이 있습니다). 높은 레버리지를 가진 점들도 자세히 살펴볼 가치가 있지만, 이러한 점들이 특이치인 경우가 아니라면 크게 문제가 되지는 않습니다.\n이제 세 번째 유형의 특이성을 나타내는 영향력(influence) 개념을 살펴보겠습니다. 높은 영향력을 가진 관측값이란 높은 레버리지를 가진 특이치입니다. 즉, 다른 관측값들과 예측변수 측면에서 매우 다르면서도 동시에 회귀선에서 크게 벗어난 값입니다. 이는 Figure 12.26 에서 볼 수 있습니다. 앞의 두 그림과 비교해 보십시오. 특이치이기만 하면 회귀선에 큰 영향을 미치지는 않으며, 높은 레버리지만 있는 점도 마찬가지입니다. 하지만 어떤 점이 특이치이면서 동시에 높은 레버리지를 가진다면, 회귀선에 매우 큰 영향을 받습니다. 이러한 점들을 “영향점(influential points)”이라고 하며, 이 유형은 가장 큰 우려 요소입니다. 영향력은 쿡의 거리(Cook’s distance)라는 척도로 측정됩니다.19\n\n\n\n\n\n\n\n\nFigure 12.26. 높은 영향력을 가진 점의 예시. 이 경우, 이상 관측값은 예측변수(x축)에서 매우 특이하며, 회귀선에서도 멀리 떨어져 있습니다. 그 결과, 회귀선이 크게 왜곡됩니다. 하지만 이 관측값은 결과변수(y축) 측면에서는 다른 점들과 크게 다르지 않습니다.\n\n\n\n\n\n쿡의 거리가 크려면, 해당 관측값이 상당한 특이치이면서 높은 레버리지를 가져야 합니다. 대략적으로 쿡의 거리가 1을 초과하면 큰 값으로 간주됩니다(이는 간단한 경험적 규칙입니다).\njamovi에서 쿡의 거리 정보를 확인하려면 ‘가정검증’-‘데이터 요약’ 옵션에서 ‘Cook’s Distance’ 체크박스를 선택하면 됩니다. 이 장에서 사용한 다중 회귀 모형의 경우, 해당 결과는 Figure 12.27 에서 볼 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 12.27. jamovi에서 쿡의 거리 통계를 표시한 표\n\n\n\n\n\n위 표에서 볼 수 있듯이, 이 예제에서 쿡의 거리의 평균값은 \\(0.01\\)이며, 최소값은 \\(0.00\\), 최대값은 \\(0.11\\)입니다. 따라서 앞서 언급한 “쿡의 거리가 1을 초과하면 크다”는 기준에 비해 상당히 낮은 값임을 알 수 있습니다.\n다음으로 궁금해지는 점은, 만약 쿡의 거리가 크다면 어떻게 해야 하는가입니다. 항상 그렇듯이, 정해진 규칙은 없습니다. 가장 먼저 해야 할 일은 쿡의 거리가 가장 큰 특이치를 제외하고 회귀 분석을 수행하여 모형 성능과 회귀계수가 어떻게 변하는지를 확인하는 것입니다.20 만약 결과가 상당히 다르게 나타난다면, 데이터와 연구 과정에서 작성한 메모를 다시 살펴보면서 왜 이 값이 다른 점들과 크게 다른지를 조사해야 합니다. 만약 이 특정 데이터 포인트가 결과를 심각하게 왜곡한다고 판단된다면, 해당 값을 제외하는 것도 고려할 수 있습니다. 그러나 이 경우에도 해당 관측값이 다른 데이터와 본질적으로 다르며, 별도로 처리할 만한 타당한 이유가 있는지 확실히 해야 합니다.\n\n\n\n\n\n\nTip 12.12. 실습: 선형회귀 모형의 가정 검토 - 영향점\n\n\n\nTip 12.11 실습을 이어서 영향점을 검토해 봅니다.\n\n오른쪽 결과 창에서 dani.grump를 결과변수로 하는 ‘선형 회귀분석’ 결과를 클릭합니다. 그러면 왼편에 ‘선형 회귀분석’ 설정 창이 나타납니다.\n왼편의 ‘선형 회귀분석’ 창에서 ‘가설검증’ 옵션을 확장하여 ‘데이터 요약’-‘Cook’s distance’를 체크하면, 오른편의 결과 참의 ’가설검증’ 부분에 ‘Cook’s distance’ 표가 표시됩니다.\n\n\n\n\n\n\n\n\n\n\n\n데이터에 쿡의 거리를 추가하여 쿡의 거리에 대한 박스 도표를 그려봅니다.\n\n\n‘저장’ 옵션에서 ’Cook’s distance’를 체크합니다.\n‘기술통계’ 메뉴를 선택합니다.\n‘Cook’s distance’를 ’변수’ 상자로 이동합니다.\n‘도표’ 옵션을 확장하여 ’박스 도표’를 클릭합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>상관관계와 선형회귀</span>"
    ]
  },
  {
    "objectID": "12-Correlation-and-linear-regression.html#모형-선택",
    "href": "12-Correlation-and-linear-regression.html#모형-선택",
    "title": "12  상관관계와 선형회귀",
    "section": "12.11 모형 선택",
    "text": "12.11 모형 선택\n여전히 남아 있는 상당히 중요한 문제 중 하나는 모형 선택(model selection)의 문제입니다. 즉, 여러 변수를 포함하는 데이터가 있을 때, 어떤 변수를 예측변수로 포함하고 어떤 변수를 제외해야 할까요? 다시 말해, 변수 선택(variable selection)의 문제가 있습니다. 일반적으로 모형 선택은 복잡한 작업이지만, 모형에 포함해야 할 변수의 부분 집합을 선택하는 문제로 제한하면 다소 단순해집니다. 그럼에도 불구하고, 저는 이 축소된 주제조차도 세부적으로 다루지는 않을 것입니다. 대신, 고려해야 할 두 가지 기본 원칙을 설명하고, jamovi에서 모형에 포함할 변수의 부분 집합을 선택하는 데 도움이 되는 하나의 구체적인 도구를 소개하겠습니다. 먼저, 두 가지 원칙을 살펴보겠습니다.\n\n선택의 근거가 실질적인 것이어야 합니다. 많은 상황에서 연구자는 이론적으로 중요한 몇 가지 회귀 모형을 선택할 충분한 이유가 있습니다. 이러한 모형들은 연구 분야의 맥락에서 합리적인 해석으로 뒷받침될 것입니다. 이것의 중요성을 절대 간과해서는 안 됩니다. 통계학은 과학적 과정에 봉사하는 것이지, 그 반대가 아닙니다.\n통계적 추론에 의존하는 선택일 경우, 단순성과 적합도 사이의 절충(trade-off)이 존재합니다. 모형에 더 많은 예측변수를 추가하면 모형이 더욱 복잡해집니다. 각 예측변수는 새로운 자유 모수(즉, 새로운 회귀 계수)를 추가하며, 새로운 모수가 추가될 때마다 모형이 무작위 변동을 “흡수”할 수 있는 능력이 증가합니다. 따라서 적합도(예: \\(R^2\\))는 예측변수를 추가할 때마다 계속 증가하는데, 이는 때때로 사소한 증가이거나 단순한 우연일 수도 있습니다. 모형이 새로운 관측값에 대해 일반화될 수 있도록 하려면 너무 많은 변수를 포함하지 않도록 주의해야 합니다.\n\n이 두 번째 원칙은 흔히 오컴의 면도날(Ockham’s razor)이라고 불리며, 다음과 같은 간결한 문장으로 요약됩니다. “필요 이상으로 요소를 추가하지 말라.” 이 문맥에서는, 단순히 \\(R^2\\) 값을 높이기 위해 관련성이 낮은 예측변수를 무분별하게 추가하지 말라는 의미입니다.\n어쨌든, 우리는 회귀 모형을 선택하는 과정에서 오컴의 면도날 원칙을 수학적으로 구현할 수 있는 실제적인 기준이 필요합니다. 여러 가지 가능성이 있지만, 여기서는 Akaike 정보 기준(AIC, Akaike Information Criterion)(Akaike, 1974)에 대해 설명하겠습니다. 왜냐하면 이는 jamovi에서 옵션으로 제공하기 때문입니다.\n선형 회귀 모형의 맥락에서 (그리고 모형과 무관한 항을 무시하면), \\(K\\)개의 예측변수와 절편(intercept)을 포함하는 모형의 AIC는 다음과 같이 정의됩니다.\n\\[\nAIC = \\frac{SS_{res}}{\\hat{\\sigma}^2} + 2K\n\\]\nAIC 값이 작을수록 모형 성능이 더 좋습니다. 저수준의 세부 사항을 무시하면, AIC가 하는 일은 비교적 명확합니다. 첫 번째 항은 모형의 예측 성능이 나빠질수록 증가하고, 두 번째 항은 모형의 복잡성이 증가할수록 증가합니다. 따라서 가장 좋은 모형은 가능한 한 적은 수의 예측변수를 사용하면서도 데이터를 잘 적합하는 모형(즉, 잔차가 적고, \\(K\\)가 낮은 모형)입니다. 즉, 이는 오컴의 면도날을 단순하게 구현한 것입니다.\nAIC는 ‘모형 적합도’ 옵션에서 ‘AIC’ 체크박스를 클릭하면 ‘모형 적합도’ 결과 표에 추가할 수 있으며, 모형을 비교하는 다소 투박한 방법이지만 특정 예측변수를 제거하거너 추가했을을 때 AIC 값이 더 낮아지거나 높아지는지를 확인할 수 있습니다. 현재 jamovi에서 구현된 모형 선택 방법은 이것뿐이지만, R과 같은 더 강력한 프로그램에서는 다른 방법들이 존재합니다. 이러한 대안적인 방법들은 특정 예측변수를 자동으로 추가하거나 제거하여 최적의 AIC 값을 찾을 수 있도록 합니다. 비록 jamovi에는 이러한 방법이 구현되어 있지 않지만, 여러분이 알고 있으면 좋을 것 같아 간략히 언급하겠습니다.\n\n12.11.1 후진 소거법\n후진 소거법(Backward elimination)에서는 모든 가능한 예측변수를 포함하는 완전한 회귀 모형에서 시작합니다. 그런 다음, 각 “단계”에서 하나의 변수를 제거하는 모든 가능한 방법을 시도하고, AIC 값이 가장 낮아지는 방법을 선택합니다. 이렇게 선택된 모형이 새로운 회귀 모형이 되며, 다시 이 새로운 모형에서 제거할 수 있는 변수들을 고려하여 AIC 값이 가장 낮아지는 옵션을 선택합니다. 이 과정을 반복하여, 더 이상 어떤 예측변수를 제거해도 AIC 값이 낮아지지 않는 모형에 도달할 때까지 진행합니다.\n\n\n12.11.2 전진 선택법\n다른 방법으로 전진 선택법(Forward selection)을 사용할 수도 있습니다. 이 방법에서는 가능한 한 가장 작은 모형에서 시작하고, 변수 추가만을 고려합니다. 하지만 여기에는 한 가지 복잡한 요소가 있습니다. 즉, 고려할 수 있는 가장 큰 모형이 무엇인지도 미리 결정해야 합니다.\n후진 소거법과 전진 선택법이 같은 결론에 도달할 수도 있지만, 항상 그런 것은 아닙니다.\n\n\n\n\n\n\nTip 12.13. 실습: 모형의 선택 - 전진 선택법\n\n\n\nTip 12.5 실습을 이어서 전진 선택법으로 최적 모형을 선택해 봅니다. ID 변수와 결과변수인 dani.grump를 제외한 나머지 변수를 사용하여 변수 선택을 수햅합니다.\n\n‘분석’-‘회귀분석’-‘선형 회귀분석’ 메뉴를 선택합니다.\n왼편의 ‘선형 회귀분석’ 창에서 다음을 수행합니다.\n\n\ndani.grump를 ’종속변수’로 이동합니다.\n‘모형 적합도’ 옵션을 확장하여 ’AIC’를 체크합니다.\n\n\n한 예측변수로 이루어진 다음 세 모형을 만들어 가장 낮음 AIC를 가진 모형이 무엇인지 확인합니다.\n\n\n’독립변수’에 dan.sleep만 있는 모형\n’독립변수’에 baby.sleep만 있는 모형\n’독립변수’에 day만 있는 모형\n\n\n앞 단계를 수행하면 dan.sleep을 가진 모형이 가장 AIC가 낮으므로 이 모형을 선택합니다. 그러면 현재 baby.sleep과 day 변수가 남아 있습니다. 그러면 현재의 모형과 이 두 변수 중 하나를 추가하여 두 예측변수 모형을 만든 후 어떤 모형이 가장 낮은 AIC를 가지는지를 비교합니다.\n\n\n현재의 모형\n현재의 모형의 ’독립변수’에 baby.sleep을 추가한 모형\n현재의 모형의 ’독립변수’에 day를 추가한 모형\n\n\n앞 단계의 비교 대상 모형들의 AIC는 거의 비슷하지만 그래도 dan.sleep만 예측변수로 있는 모형의 AIC가 가장 낮으므로 더 이상 변수를 추가하지 않고 변수 선택을 종료합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12.11.3 주의할 점\n자동화된 변수 선택 방법은 강력한 통계 소프트웨어에서 (비교적) 간단한 함수로 제공되므로 특히 매력적으로 보일 것입니다. 이러한 방법은 모형 선택에 객관성을 부여하므로 이는 꽤 좋은 일입니다. 그러나 종종 이러한 방법이 깊이 생각하지 않는 것에 대한 핑계로 사용되기도 합니다. 더 이상 어떤 예측변수를 추가할지, 그리고 그것이 이론적으로 어떤 의미를 가지는지를 신중히 고려하지 않게 됩니다. AIC의 “마법”이 모든 문제를 해결해 준다고 생각할 수도 있습니다. 그리고 오컴의 면도날 같은 표현을 사용하며 마치 모든 것이 완벽하게 정리된 것처럼 보일 수도 있습니다.\n하지만, 실제는 꼭 그렇지는 않습니다. 첫째, 실제 적절한 모형 선택 기준이 무엇인지에 대해서는 학자들 사이에 거의 합의가 이루어지지 않았습니다. 제가 학부 시절에는 후진 소거법을 배울 때는 \\(F\\)-검정을 사용했는데, 당시 사용하던 소프트웨어의 기본 방법이었기 때문입니다. 여기서는 AIC를 사용한 방법을 설명했으며, 이 텍스트가 입문서이므로 다른 방법은 다루지 않았습니다. 그러나 AIC가 통계의 절대적인 기준은 아닙니다. AIC는 특정한 가정하에서 도출된 근사값이며, 이러한 가정이 충족되는 경우에만 큰 표본에서 신뢰할 수 있는 결과를 보장합니다. 이러한 가정을 변경하면 다른 기준이 나오는데, 예를 들어 베이지안 정보 기준(BIC, Bayesian Information Criterion) 등이 있습니다(jamovi에서도 사용할 수 있습니다). 또 다른 접근법으로는 정규화 최대 우도(NML, Normalized Maximum Likelihood) 기준이 있습니다. 베이지안 관점에서는 후행 오즈 비율(posterior odds ratios)을 기반으로 한 모형 선택도 이루어집니다. 그리고 여기서 언급하지 않은 여러 가지 회귀 모형 전용 도구들도 존재합니다. 이처럼 다양한 방법들은 각각 장점과 단점이 있으며, 계산의 난이도도 다릅니다(AIC는 아마도 가장 계산이 쉬운 방법이기 때문에 널리 사용될 가능성이 큽니다). 대부분의 방법은 “정답”이 명확한 경우에는 동일한 결론을 내리지만, 모형 선택이 어려운 문제일 때는 상당한 차이를 보입니다.\n그렇다면 실질적으로 이 문제가 의미하는 바는 무엇일까요? 모형 선택 이론을 몇 년간 공부하면서 그 모든 개념을 익히고, 결국 어떤 방법이 옳은지 스스로 결정할 수도 있습니다. 실제로 그렇게 해 본 사람으로서 말하자면, 저는 그렇게 하기를 권장하지 않습니다. 오히려 공부를 시작하기 전보다 더 혼란스러워질 가능성이 큽니다. 더 나은 전략은 상식을 활용하는 것입니다. 만약 자동화된 후진 소거법 또는 전진 선택법 절차의 결과를 보고 있는데, 해석적으로 적절한 모형이 가장 작은 AIC 값을 가진 모형과 AIC의 차이가 거의 없으나, 의미 없는 모형이 간발의 차이로 AIC가 더 낮다면, 본능을 따르는 것이 좋습니다. 통계적 모형 선택은 완벽한 도구가 아니며, 처음에 언급했듯이 모형의 해석 가능성이 중요합니다.\n\n\n12.11.4 두 회귀 모형 비교하기\n자동화된 모형 선택 절차를 사용하는 대신, 연구자가 두 개 이상의 회귀 모형을 명시적으로 선택하여 서로 비교할 수도 있습니다. 연구 질문에 따라 이를 수행하는 방법에는 몇 가지가 있습니다. 예를 들어, 나의 수면량으로 나의 예민함을 설명한 후에도, 내 아들이 얼마나 잠을 잤는지가 나의 예민함과 관계가 있는지 알고 싶다고 합시다., 그리고 측정한 날짜가 이 관계에 영향을 미치지 않는지도 확인하고 싶습니다. 즉, 우리는 baby.sleep과 dani.grump 간의 관계에 관심이 있으며, dani.sleep과 day는 통제해야 할 공변량(covariates) 또는 성가신 변수(nuisance variables)로 간주됩니다. 이러한 상황에서 우리가 알고 싶은 것은 dani.grump \\~ dani.sleep + day + baby.sleep(이를 모형 2 또는 M2라 하겠습니다)이 dani.grump \\~ dani.sleep + day(이를 모형 1 또는 M1이라 하겠습니다)보다 더 나은 회귀 모형인지 여부입니다. 두 개의 모형을 비교하는 방법에는 모형 선택 기준(AIC) 기반 방법과 명시적인 가설 검정을 사용하는 방법이 있습니다. 먼저 AIC 기반 접근법을 설명하겠습니다. 이는 더 간단하며, 앞 절의 논의를 자연스럽게 이어가는 방법입니다. 먼저 두 개의 회귀 분석을 실행하고, 각 모형의 AIC 값을 기록한 다음, AIC 값이 더 작은 모형을 더 적합한 모형으로 선택하면 됩니다. 하지만 지금 바로 실행하지는 마십시오. jamovi에서는 여러 모형의 AIC 값을 하나의 표로 확인할 수 있는 쉬운 방법이 있기 때문에, 이에 대해 더 읽어보시기 바랍니다.21\n가설 검정의 틀에서 접근하는 약간 다른 방법도 있습니다. 두 개의 회귀 모형이 주어졌을 때, 한 모형(모형 1)이 다른 모형(모형 2)의 일부 예측변수를 포함하는 부분 모형(submodel)인 경우를 가정해 보겠습니다. 즉, 모형 2는 모형 1에 포함된 모든 예측변수뿐만 아니라 추가적인 예측변수도 포함하고 있습니다. 이러한 경우, 모형 1이 모형 2에 포함된다고 하거나, 모형 1이 모형 2의 부분 모형이라고 할 수 있습니다. 용어와 관계없이, 이는 모형 1을 귀무 가설 로, 모형 2를 대립 가설 로 간주할 수 있음을 의미합니다. 그리고 사실, 이에 대한 \\(F\\)-검정을 비교적 간단하게 구성할 수 있습니다.[^12-correlation-and-linear-regression-30]\n두 모형을 데이터에 적합시킨 후, 각각의 잔차 제곱합(residual sum of squares)을 구할 수 있습니다. 이를 각각 \\(SS_{res}^{(1)}\\) 및 \\(SS_{res}^{(2)}\\)라고 하겠습니다. 위첨자는 해당 모형을 나타냅니다. 그러면 \\(F\\) 통계량은 다음과 같이 계산됩니다:\n\\[\nF= \\frac {\\frac {SS _{res}^{(1)} - SS_{res}^{(2)}} {k}}   {\\frac{SS_{res}^2} {N-p-1} }\n\\] 여기서 \\(N\\)은 관측치 개수, \\(p\\)는 전체 모형(절편 제외)에서의 예측변수 개수, \\(k\\)는 두 모형 간의 모수 개수 차이입니다. 자유도(degrees of freedom)는 \\(k\\)와 \\(N - p - 1\\)입니다. 이때 두 개의 \\(SS\\) 값의 차이를 하나의 제곱합으로 간주하는 것이 더 편리할 때가 많습니다. 즉, \\[\nSS_\\Delta=SS_{res}^{(1)}-SS_{res}^{(2)}\n\\] 이러한 방식이 유용한 이유는 \\(SS_\\Delta\\)가 두 모형이 결과변수에 대해 얼마나 다른 예측을 하는지를 측정하는 지표로 사용할 수 있기 때문입니다. 구체적으로: \\[\nSS_\\Delta=\\sum_i{(\\hat{y}_i^{(2)}-\\hat{y}_i^{(1)})^2}\n\\] 여기서 \\(\\hat{y}_{i^{(1)}}\\)는 모형 \\(M_1\\)에 따른 \\(y_i\\)의 예측값이고, \\(\\hat{y}_{i^{(2)}}\\)는 모형 \\(M_2\\)에 따른 \\(y_i\\)의 예측값입니다.\n한 가지 덧붙이자면, 위 \\(F\\) 통계량은 여기에서 설명한 것보다 훨씬 더 다양한 가설 검정에 사용할 수 있습니다. 간단히 말하면, 포함된 모형 \\(M_1\\)은 전체 모형 \\(M_2\\)에서 일부 회귀 계수를 0으로 제한한 형태로 볼 수 있습니다. 특정 계수가 0이 되도록 제한하는 것이 아니라, 두 개의 계수가 합해서 0이 되도록 설정하는 것과 같은 다른 종류의 제한을 적용하여 부분 모형을 구성할 수도 있습니다. 이러한 제한에 대한 가설 검정도 가능하지만, 이는 다소 복잡해지며 \\(F\\) 통계량의 표본 분포가 비중심 \\(F\\)-분포(non-central \\(F\\)-distribution)로 바뀔 수도 있습니다. 이에 대한 논의는 이 책의 범위를 벗어나므로, 여기서는 이러한 가능성이 있다는 점만 언급하고 넘어가겠습니다.\n이제 두 회귀 모형을 비교하는 가설 검정이 어떻게 이루어지는지 설명하였습니다. 그렇다면 이를 jamovi에서 수행하는 방법은 ‘모형 분석 상자’ 옵션을 사용하는 것입니다. 모형 1의 예측변수인 dani.sleep과 day를 ‘Block 1’에 지정한 후, 모형 2에서 추가되는 예측변수인 baby.sleep을 ’Block 2’에 추가하면 됩니다. 이렇게 하면 ’모형 비교’ 표에서 모형 1과 모형 2의 비교 결과가 표시됩니다. 예를 들어, \\(F(1,96) = 0.00\\), \\(p = 0.954\\)로 나타난다면, \\(p\\) 값이 0.05보다 크므로 귀무 가설(M1)을 유지해야 합니다.\n이러한 회귀 분석 접근법은 먼저 모든 공변량을 포함한 귀무 모형 을 설정한 후, 관심 있는 변수를 추가하여 대립 모형 을 만들고, 두 모형을 가설 검정 틀에서 비교하는 방식이므로, 계층적 회귀(hierarchical regression) 라고 합니다.\n또한, jamovi의 ‘모형 적합도’ 옵션을 사용하면 각 모형의 AIC 및 BIC 값을 포함한 표를 생성하여, 가장 낮은 값을 가진 모형을 쉽게 비교하고 선택할 수 있습니다(Figure 12.28 참고).\n\n\n\n\n\n\n\n\nFigure 12.28. jamovi에서 ‘Model Builder’ 옵션을 사용한 모형 비교\n\n\n\n\n\n\n\n\n\n\n\n실습: 모형 비교\n\n\n\nTip 12.5 실습을 이어서 두 모형을 비교해 봅니다.\n\n‘분석’-‘회귀분석’-‘선형 회귀분석’ 메뉴를 선택합니다.\n왼편의 ‘선형 회귀분석’ 창에서 다음을 수행합니다.\n\n\ndani.grump를 ‘종속변수’ 상자로로 이동합니다.\ndan.sleep, baby.sleep, day를 ‘독립변수’ 상자로 이동합니다.\n\n\n‘모형 분석 상자’ 옵션을 확장하여 두 모형을 만듭니다.\n\n\n’Block 1’으로 dan.sleep과 day를 이동하여 모형 1의 블록을 만듭니다.\n’새 블록 추가’를 클릭하여 ’Block 2’를 만듭니다.\n’Block 2’으로 baby.sleep을 이용하여 모형 2에 추가될 변수를 설정합니다.\n\n\n‘모형 적합도’ 옵션을 확장하여 ‘조정된 \\(R^2\\)’, ‘AIC’, ‘BIC’, ‘RMSE’ 등을 체크합니다. 그러면 Figure 12.28 같은 결과가 나타납니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>상관관계와 선형회귀</span>"
    ]
  },
  {
    "objectID": "12-Correlation-and-linear-regression.html#요약",
    "href": "12-Correlation-and-linear-regression.html#요약",
    "title": "12  상관관계와 선형회귀",
    "section": "12.12 요약",
    "text": "12.12 요약\n\n두 변수 사이의 관계의 강도를 알고 싶다면 상관관계 분석\n산점도 그리기\n선형회귀 모형이란? 및 선형회귀 모형 추정하기에 대한 기본 개념.\n다중 선형회귀.\n\\(R^2\\)을 사용하여 회귀 모형의 적합도 정량화하기.\n회귀 모형의 가설 검정.\n회귀계수에 대하여 회귀계수의 신뢰구간 구하기와 표준화 회귀계수 계산하기.\n선형회귀의 가정에 대한 모형 진단.\n회귀 모형 선택.\n\n\n\n\n\nAkaike, H. (1974). A new look at the statistical model identification. IEEE Transactions on Automatic Control, 19, 716–723. https://doi.org/10.1109/TAC.1974.1100705\n\n\nAnscombe, F. J. (1973). Graphs in statistical analysis. American Statistician, 27, 17–21. https://doi.org/10.1080/00031305.1973.10478966\n\n\nFox, J., & Weisberg, S. (2011). An R companion to applied regression (2nd ed.). Sage.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>상관관계와 선형회귀</span>"
    ]
  },
  {
    "objectID": "12-Correlation-and-linear-regression.html#footnotes",
    "href": "12-Correlation-and-linear-regression.html#footnotes",
    "title": "12  상관관계와 선형회귀",
    "section": "",
    "text": "jamovi에서는 ‘ID’ 변수 유형을 지정할 수도 있지만, 우리의 분석에서는 ID 변수를 포함하지 않을 것이므로 이를 어떻게 지정하는지는 중요하지 않습니다.↩︎\n사실, 이 표조차도 내가 작성할 것보다 많은 정보를 담고 있습니다. 실제로 대부분의 사람들은 하나의 중심 경향 측정값과 하나의 변동성 측정값만 선택합니다.↩︎\n분산과 표준편차에서 본 것처럼, 실제로는 \\(N - 1\\) 로 나누는 것이 일반적입니다.↩︎\n이는 다소 단순화한 설명이지만, 우리의 목적에는 충분합니다.↩︎\n&lt;역주&gt; jamovi 설치했을 때 scatr 모듈이 이미 설치되어 있을 수 있습니다. ‘분석’-‘기술통계’ 메뉴 아래에 ‘산포도’ 메뉴가 있으면 이미 설치되어 있는 것입니다.↩︎\n이 방정식은 때때로 \\(y = mx + c\\)의 형태로 쓰기도 합니다. 여기서 \\(m\\)은 기울기, \\(c\\)는 절편을 의미합니다:\n\\[\\hat{Y}_i = b_0 + b_1 X_i\\]↩︎\n여기서 \\(\\epsilon\\) 기호는 그리스 문자 엡실론(epsilon)입니다. 전통적으로 회귀 모형에서 잔차는 \\(\\epsilon_i\\) 또는 \\(e_i\\)로 나타냅니다.↩︎\n혹시나 이 내용을 읽는 사람이 선형대수의 진정한 고수일 경우 도움이 될 수 있는 내용입니다. 회귀계수 추정 문제의 해는 \\(\\hat{b} = (X^{'}X)^{-1}X^{'}y\\)로 주어지며, 여기서 \\(\\hat{b}\\)는 추정된 회귀계수를 포함하는 벡터, \\(X\\)는 예측변수와 모든 요소가 1인 벡터를 포함하는 “설계 행렬”이고 \\(y\\)는 결과변수를 포함하는 벡터입니다. 하지만 대부분의 사람들에게는 도움이 되지 않을 수 있습니다. 선형회귀에서 몇 가지 개념은 선형대수로 표현되므로, 본 장에서는 이러한 내용을 포함한 각주를 여러 개 보게 될 것입니다. 이해할 수 있다면 좋고, 아니라면 무시해도 괜찮습니다.↩︎\n&lt;역주&gt; jamovi의 메뉴에서 ’Covariates’를 ’독립변수’라고 번역한 것이다. 그러나 ’Covariates’는 ’공변량’으로 번역하는 것이 옳다.↩︎\n그리고 “가끔”이라고 했지만, 사실 거의 아무도 그렇게 부르지 않습니다. 실무에서는 그냥 “R-squared”라고 부릅니다.↩︎\n고급자를 위한 내용. 잔차 벡터를 \\(\\epsilon=y - X\\hat{b}\\)라고 할 때, 절편을 포함한 \\(K\\)개의 예측변수가 있으면 잔차 분산의 추정값은 \\(\\hat{\\sigma}^2 = \\frac{\\epsilon^{'}\\epsilon}{(N - K - 1)}\\)이 됩니다. 계수의 공분산 행렬의 추정값은 \\(\\hat{\\sigma}^{2}(X^{'}X)^{-1}\\)이며, 이 행렬의 주대각 성분이 \\(SE(\\hat{b})\\), 즉 우리의 추정된 표준오차입니다.↩︎\n참고로, jamovi는 여기서 여러 개의 검정을 수행했지만, 본페로니 보정(Bonferroni correction) 등은 적용하지 않았습니다(Chapter 13 참고). 이는 양측 대립가설을 사용하는 표준 단일 표본 \\(t\\)-검정입니다. 다중 검정에 대한 보정을 적용하려면 직접 수행해야 합니다.↩︎\n엄밀히 말하면, 표준화하는 것은 모든 회귀 변수(regressors)입니다. 즉, 모형에서 회귀계수가 할당된 모든 요소를 표준화하는 것입니다. 지금까지 다룬 회귀 모형에서는 각 예측변수가 정확히 하나의 회귀 변수에 대응되지만, 이는 일반적인 경우가 아닙니다. 나중에 Chapter 14 에서 예외적인 사례를 보게 될 것입니다. 하지만 현재로서는 이러한 구분을 크게 신경 쓸 필요는 없습니다.↩︎\nBox-Cox 변환은 \\(\\lambda \\neq 0\\)인 경우 \\(f(x,\\lambda)=\\frac{x^{\\lambda}-1}{\\lambda}\\) 로 정의됩니다. 단, \\(\\lambda = 0\\)일 때는 자연로그(ln(\\(x\\)))를 취합니다.↩︎\njamovi에서는 SQRT(ABS(잔차)) 공식을 사용하여 이 새로운 변수를 계산할 수 있습니다.↩︎\n분산 동질성 가정이 위반될 경우 이를 처리하는 방법에 대한 논의는 이 장의 범위를 벗어나지만, 고려해야 할 핵심 사항을 간략히 설명드리겠습니다. 가장 중요한 점은, 분산 동질성이 위반될 경우 회귀계수와 관련된 표준오차 추정값이 더 이상 신뢰할 수 없으며, 따라서 계수에 대한 \\(t\\)-검정 결과도 정확하지 않을 수 있다는 점입니다. 이 문제를 간단히 해결하는 방법은 표준오차를 추정할 때 “이분산성 보정 공분산 행렬(heteroscedasticity corrected covariance matrix)”을 사용하는 것입니다. 이러한 보정 방법은 흔히 샌드위치 추정량(sandwich estimators)이라고 불리며, \\(R\\)에서는 이를 추정할 수 있지만, jamovi에서는 직접 제공하지 않습니다.↩︎\n\\(k\\)번째 VIF는 다음 공식으로 계산됩니다: \\(VIF_k=\\frac{1}{1-R^2_{(-k)}}\\) 여기서 \\(R^2_{(-k)}\\)는 \\(X_k\\)를 종속 변수로 하고, 나머지 \\(X\\) 변수들을 독립 변수로 설정하여 회귀 분석을 수행했을 때 얻어지는 결정계수 값입니다. 이 값은 \\(X_k\\)가 모형 내의 다른 변수들과 얼마나 상관되어 있는지를 측정하는 데 유용합니다. 더 나아가, VIF의 제곱근은 해당 계수 \\(b_k\\)에 대한 신뢰 구간이 얼마나 더 넓어지는지를 나타내므로 해석이 용이합니다.↩︎\n선형 대수에 익숙한 독자를 위해 설명하자면, “모자 행렬(해트 행렬)(hat matrix)”은 관측된 값 벡터 \\(y\\) 를 예측된 값 벡터 \\(\\hat{y}\\) 로 변환하는 행렬 \\(H\\) 로 정의됩니다. 즉, \\(\\hat{y} = Hy\\) 입니다. “모자(hat)”라는 이름은 이 행렬이 \\(y\\) 에 “모자(hat)”를 씌우는 역할을 하기 때문에 붙여졌습니다. i 번째 관측치의 모자 값은 이 행렬의 i 번째 대각 원소이므로, 정확하게는 \\(h_{ii}\\) 로 표기해야 하지만, 일반적으로 \\(h_i\\)로 씁니다. 수식으로는 다음과 같이 계산됩니다:\n\\[\nH = X(X^{'}X)^{-1}X^{'}\n\\]↩︎\n\\(D_i=\\frac{{\\epsilon_i^*}^2}{K+1} \\times \\frac{h_i}{1-h_i}\\) 여기서 왼쪽 항은 해당 관측값이 특이치인지 여부를 측정하는 요소이며, 오른쪽 항은 해당 관측값의 레버리지를 측정하는 요소입니다.↩︎\njamovi에서는 쿡의 거리 값을 데이터에 저장한 후, 쿡의 거리를 박스플롯으로 시각화하여 특정 특이치를 식별할 수 있습니다. 또는 R의 “car” 패키지와 같은 더 강력한 회귀 분석 프로그램을 사용하여 고급 회귀 진단 분석을 수행할 수도 있습니다.↩︎\n이와 관련하여 한 가지 짚고 넘어갈 점은, 실증적 증거에 따르면 BIC가 AIC보다 더 나은 기준이라는 것입니다. 제가 본 대부분의 시뮬레이션 연구에서는 BIC가 올바른 모형을 선택하는 데 있어 더 우수한 성능을 보였습니다.↩︎",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>상관관계와 선형회귀</span>"
    ]
  },
  {
    "objectID": "13-Comparing-several-means-one-way-ANOVA.html",
    "href": "13-Comparing-several-means-one-way-ANOVA.html",
    "title": "13  여러 평균 비교하기 - 일원분산분석",
    "section": "",
    "text": "13.1 예제 데이터\n새로운 항우울제 Joyzepam의 임상 시험에 참여하게 되었다고 가정해 봅시다. 이 약의 효과를 공정하게 평가하기 위해 연구에서는 세 가지 약물을 투여합니다. 하나는 위약(placebo)이며, 다른 하나는 기존의 항우울제 및 항불안제인 Anxifree입니다. 초기 실험을 위해 중등도에서 중증 수준의 우울증을 가진 참가자 18명을 모집합니다. 항우울제가 심리 치료와 함께 사용되는 경우도 있기 때문에, 연구에서는 인지행동치료(CBT)를 받는 참가자 9명과 치료를 받지 않는 참가자 9명을 포함합니다. 참가자들은 무작위로 배정되며(물론 이중 맹검 방식으로 진행됩니다), 각 약물 집단에 CBT를 받는 사람 3명과 치료를 받지 않는 사람 3명이 할당됩니다. 실험 후 심리학자가 참가자의 기분 향상도를 평가하며, 3개월 동안 약물을 복용한 후 각 참가자의 기분 개선 정도를 -5에서 +5까지의 척도로 측정합니다.\n이제 clinicaltrial.csv 파일에서 데이터를 불러옵니다. 해당 데이터 세트에는 세 가지 변수인 drug, therapy, mood.gain이 포함되어 있습니다.\n본 장에서 우리가 관심을 가지는 주요한 질문은 drug가 mood.gain에 미치는 영향입니다. 첫 번째 단계는 기술 통계를 계산하고 그래프를 그리는 것입니다. [기술 통계] 장에서 이를 수행하는 방법을 설명하였으며, jamovi에서 계산한 일부 기술 통계 결과를 Figure 13.1 에서 확인할 수 있습니다. 그래프를 보면 Joyzepam 집단에서 다른 두 집단(즉, Anxifree 집단과 위약 집단)보다 기분 개선 효과가 더 크다는 것을 알 수 있습니다. 또한 Anxifree 집단이 위약 집단보다 더 큰 기분 개선 효과를 보이지만, 그 차이는 상대적으로 작습니다. 우리가 대답하고자 하는 질문은 이러한 차이가 “실제” 차이인지, 아니면 단순한 우연에 의한 것인지입니다.\nFigure 13.1. 기분 개선에 대한 기술 통계 및 약물별 박스 도표",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>여러 평균 비교하기 - 일원분산분석</span>"
    ]
  },
  {
    "objectID": "13-Comparing-several-means-one-way-ANOVA.html#예제-데이터",
    "href": "13-Comparing-several-means-one-way-ANOVA.html#예제-데이터",
    "title": "13  여러 평균 비교하기 - 일원분산분석",
    "section": "",
    "text": "Tip 13.1. 실습: Clinical Trial 데이터\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Clinical Trial’을 선택합니다.\n스프레드시트 창에서 각 변수의 이름을 더블클릭하여 각 변수의 척도유형과 데이터 유형이 제대로 설정되어 있는지 확인하고 필요하면 이를 정정합니다.\n\n\nID: 아이디, 정수\ndrug, therapy: 명명척도, 문자\nmood.gain: 연속변수, 소수\n\n\n다음 단계를 거쳐 drug 별로 나누어 mood.gain의 기본 통계와 분포를 확인합니다. 그러면 Figure 13.1 같은 결과과 나타납니다.\n\n\n‘분석’-‘기술통계’-‘기술통계’ 메뉴를 선택합니다.\nmood.gain을 ‘변수’ 상자로 이동합니다.\ndrug을 ‘Split by’ 상자로 이동합니다.\n‘기술통계’ 드롭다운에서 ’Variable across rows’로 하여 기술통계량이 행으로 배열되도록 합니다.\n‘도표’-‘박스 도표’ 옵션에서 ’박스 도표’와 ’평균’을 체크합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>여러 평균 비교하기 - 일원분산분석</span>"
    ]
  },
  {
    "objectID": "13-Comparing-several-means-one-way-ANOVA.html#sec-How-ANOVA-works",
    "href": "13-Comparing-several-means-one-way-ANOVA.html#sec-How-ANOVA-works",
    "title": "13  여러 평균 비교하기 - 일원분산분석",
    "section": "13.2 ANOVA의 작동 원리",
    "text": "13.2 ANOVA의 작동 원리\n임상 시험 데이터를 바탕으로 질문에 답하기 위해 일원분산분석을 수행할 것입니다. 먼저, ANOVA의 내장 기능을 사용하지 않고 기본적인 통계 도구를 직접 구축하는 방법을 보여드리겠습니다. 이를 통해 ANOVA의 작동 원리를 깊이 이해해 봅시다. 처음 몇 번은 직접 해보면서 이 과정을 익히는 것이 중요합니다.\n이전 절에서 설명한 실험 설계에 따르면, 세 가지 약물에 따른 기분 향상도의 평균을 비교하는 것이 주요 관심사입니다. 이는 두 집단의 평균을 비교하는 \\(t\\)-검정과 유사하지만(Chapter 11 참고), 세 개 이상의 집단을 포함한다는 점에서 차이가 있습니다. \\(\\mu_P\\)가 위약 모집단에서 기분 향상도의 평균을 나타내고, \\(\\mu_A\\)와 \\(\\mu_J\\)가 각각 Anxifree와 Joyzepam 모집단의 기분 향상도의 평균을 나타낸다면, 우리가 검정하려는 귀무가설은 세 모집단의 평균이 동일하다는 것입니다. 즉, 두 약물 모두 위약보다 효과적이지 않다는 것입니다. 이를 수식으로 표현하면 다음과 같습니다.\n\\[H_0: \\mu_P=\\mu_A=\\mu_J\\text{는 사실이다.}\\]\n이와 반대로, 대립가설은 세 가지 치료 중 적어도 하나가 다른 것과 다르다는 것입니다. 이 가설을 수학적으로 표현하는 것은 다소 까다로운데, 이는 귀무가설이 틀릴 수 있는 다양한 방식이 존재하기 때문입니다. 따라서, 우선 대립가설을 다음과 같이 기술하겠습니다.\n\\[H_1:  \\mu_P=\\mu_A=\\mu_J\\text{는 사실이 아니다.}\\]\n이 귀무가설을 검정하는 것은 우리가 이전에 본 것들보다 훨씬 어렵습니다. 본 장의 제목을 고려하면 “ANOVA를 수행하면 된다”는 것이 자연스러운 답처럼 보이지만, “분산분석”이 평균에 대한 정보를 제공하는 방식은 직관적으로 명확하지 않을 수 있습니다. 사실, 이것이 ANOVA를 처음 접하는 사람들이 가장 많이 어려움을 느끼는 개념적인 부분 중 하나입니다. 이를 이해하기 위해서는 분산에 대하여, 특히 집단 간 변동성(between-group variability)과 집단 내 변동성(within-group variability)에 대해 논의하는 것이 중요합니다(Figure 13.2 참고).\n\n\n\n\n\n\n\n\nFigure 13.2. 집단 간 변동(a)과 집단 내 변동(b)의 그래프 표현. 왼쪽 그래프의 화살표는 집단 평균 사이의 차이를 나타내며, 오른쪽 그래프의 화살표는 각 집단 내 변동성을 나타냄.\n\n\n\n\n\n\n13.2.1 \\(Y\\)의 분산을 구하는 두 가지 공식\n먼저, 몇 가지 표기법을 도입하겠습니다. 전체 집단의 수를 \\(G\\)라고 하겠습니다. 우리의 데이터에서는 세 가지 약물이 있으므로 \\(G = 3\\)입니다. 다음으로, 전체 표본 크기를 나타내는 기호로 \\(N\\)을 사용하겠습니다. 우리의 데이터에는 총 \\(N = 18\\)명의 참여자가 있습니다. 마찬가지로, \\(N_k\\)를 \\(k\\)번째 집단에 속한 사람들의 수로 정의하겠습니다. 우리의 가상의 임상 실험에서는 모든 세 집단에서 표본 크기가 \\(N_k = 6\\)입니다.1 마지막으로, 결과변수를 \\(Y\\)로 나타내겠습니다. 여기서 \\(Y\\)는 기분 향상도를 의미합니다. 구체적으로, \\(Y_{ik}\\)는 \\(k\\)번째 집단의 \\(i\\)번째 구성원이 경험한 기분 향상도를 나타냅니다. 또한, \\(\\bar{Y}\\)는 실험에 참여한 전체 18명의 평균 기분 향상도를 나타내며, \\(\\bar{Y}_k\\)는 집단 \\(k\\)에 속한 6명의 평균 기분 향상도를 나타냅니다.\n이제 표기법이 정리되었으므로 공식을 작성할 수 있습니다. 먼저, 우리가 Section 4.2 에서 사용했던 분산 공식을 다시 떠올려 보겠습니다. \\(Y\\)의 표본 분산은 다음과 같이 정의됩니다.\n\\[Var(Y)=\\frac{1}{N}\\sum_{k=1}^{G}\\sum_{i=1}^{N_k}(Y_{ik}-\\bar{Y})^2\\]\n이 공식은 Section 4.2 에서 사용했던 분산 공식과 거의 동일합니다. 단지 이번에는 두 개의 합산 기호가 추가되었는데, 하나는 집단에 대한 합산(\\(k\\)의 값)이고, 다른 하나는 집단 내 개인에 대한 합산(\\(i\\)의 값)입니다. 하지만 이는 단순히 표기 방식의 차이일 뿐입니다. 만약 우리가 결과변수를 표본의 개인 \\(p\\)에 대한 값인 \\(Y_p\\)로 표기했다면, 단일 합산만 필요했을 것입니다. 여기서 두 개의 합산을 사용한 이유는 사람들이 집단으로 분류되었으며, 집단 내에서 개별적으로 번호가 부여되었기 때문입니다.\n구체적인 예를 들어보겠습니다. Table 13.1 을 고려해 보면, 총 \\(N = 5\\)명의 사람들이 \\(G = 2\\)개의 집단으로 분류되었습니다. 임의로 “쿨한(cool)” 사람들을 집단 1, “쿨하지 않은(uncool)” 사람들을 집단 2로 지정하겠습니다. 결과적으로, 쿨한 집단에는 세 명(\\(N_1 = 3\\)), 쿨하지 않은 집단에는 두 명(\\(N_2 = 2\\))이 포함되어 있습니다.\n여기서 두 가지 서로 다른 라벨링 방식을 사용할 수 있습니다. 우리는 “개인(person)” 변수 \\(p\\)를 사용하여 \\(p\\)번째 개인의 예민함을 \\(Y_p\\)로 나타낼 수 있습니다. 예를 들어, 표에서 Tim은 네 번째 사람으로 표시되어 있으므로, \\(p = 4\\)라고 할 수 있습니다. 따라서 Tim의 예민함 \\(Y\\)를 나타낼 때, \\(p = 4\\)인 사람의 예민함은 \\(Y_p = 91\\)로 표기할 수 있습니다.\n\n\n\n\nTable 13.1. 쿨한 집단과 쿨하지 않은 집단의 예민함\n\n\n\n\n\n이름사람 \\(P\\)집단집단 번호 \\(k\\)집단 내 인덱스예민함 \\( Y_{ik} \\) or \\( Y_p \\)\n\nAnn1cool1120\n\nBen2cool1255\n\nCat3cool1321\n\nTim4uncool2191\n\nEgg5uncool2222\n\n\n\n\n\n\n\n그러나 Tim을 나타내는 또 다른 방법도 있습니다. Tim이 “쿨하지 않은(uncool)” 집단(\\(k = 2\\))에 속하며, 이 집단에서 첫 번째로 나열된 사람(\\(i = 1\\))이라는 점을 이용할 수도 있습니다. 따라서 Tim의 예민함을 나타낼 때, \\(k = 2\\)이고 \\(i = 1\\)일 때 \\(Y_{ik} = 91\\)로 표기할 수도 있습니다. 즉, 각 개인 \\(p\\)는 특정한 \\(ik\\) 조합과 일대일로 대응되므로, 위에서 제시한 공식은 원래의 분산 공식과 사실상 동일합니다.\n\\[Var(Y)=\\frac{1}{N}\\sum_{p=1}^{N}(Y_p-\\bar{Y})^2\\]\n두 공식 모두 동일한 표본 내 모든 관측값의 편차의 제곱을 합산하는 과정입니다. 일반적으로는 더 간단한 \\(Y_p\\) 표기법을 사용하는 것이 일반적이며, \\(Y_p\\)를 사용하는 식이 더 간결합니다. 하지만 ANOVA를 수행할 때는 각 참가자가 속한 집단을 명확히 구분하는 것이 중요하므로, \\(Y_{ik}\\) 표기법을 사용해야 합니다.\n\n\n13.2.2 분산에서 제곱합으로\n이제 분산이 어떻게 계산되는지 충분히 이해했으므로, 총제곱합(total sum of squares)이라는 개념을 정의하겠습니다. 이는 \\(SS_{tot}\\)로 표기됩니다. 매우 간단합니다. 분산을 계산할 때는 제곱된 편차들의 평균을 구하지만, 여기서는 단순히 그것들을 더합니다. 따라서 총제곱합의 공식은 분산의 공식과 거의 동일합니다: \\[SS_{tot}=\\sum_{k=1}^{G} \\sum_{i=1}^{N_k} (Y_{ik} - \\bar{Y})^2\\]\nANOVA의 맥락에서 분산을 분석한다고 말할 때, 실제로 우리가 다루는 것은 분산 자체가 아니라 총제곱합입니다. 총제곱합의 아주 유용한 점은 이를 두 가지 다른 종류의 변동으로 나눌 수 있다는 것입니다. 먼저, 집단 내 제곱합(within-group sum of squares)을 정의할 수 있는데, 이는 각 개인이 자신의 집단 평균과 얼마나 다른지를 나타냅니다: \\[SS_{w}= \\sum_{k=1}^{G} \\sum_{i=1}^{N_k} (Y_{ik} - \\bar{Y}_k)^2\\]\n여기서 \\(\\bar{Y}_k\\)는 집단 평균입니다. 우리의 예제에서, \\(\\bar{Y}_k\\)는 k번째 약을 복용한 사람들이 경험한 평균 기분 향상도입니다. 즉, 모든 실험 참가자의 평균과 비교하는 것이 아니라, 같은 집단 내 사람들끼리만 비교하는 것입니다. 따라서 \\(SS_w\\) 값은 총제곱합보다 작을 것으로 예상됩니다. 왜냐하면 \\(SS_w\\)는 약물이 사람들의 기분에 미치는 차이를 완전히 무시하기 때문입니다.\n다음으로, 집단 간의 차이만을 포착하는 세 번째 변동 개념을 정의할 수 있습니다. 이를 위해 집단 평균 \\(\\bar{Y}_k\\)와 전체 평균 \\(\\bar{Y}\\) 간의 차이를 살펴봅니다. 이 변동의 크기를 정량화하기 위해 집단 간 제곱합(between-group sum of squares)을 계산합니다: \\[\\begin{aligned} SS_{b} &= \\sum_{k=1}^{G} \\sum_{i=1}^{N_k} ( \\bar{Y}_{k} - \\bar{Y} )^2 \\\\\n&= \\sum_{k=1}^{G} N_k ( \\bar{Y}_{k} - \\bar{Y} )^2 \\end{aligned}\\]\n총제곱합 \\(SS_{tot}\\)은 사실 집단 간 변동 \\(SS_b\\)와 집단 내 변동 \\(SS_w\\)의 합이라는 것을 어렵지 않게 증명할 수 있습니다. 즉: \\[SS_w+SS_b=SS_{tot}\\]\n그렇다면 우리가 발견한 것은 무엇일까요? 결과변수와 관련된 총 변동(\\(SS_{tot}\\))은 “다른 집단의 표본 평균 차이에 따른 변동”(\\(SS_b\\))과 “그 외의 모든 변동”(\\(SS_w\\))의 합으로 수학적으로 분해될 수 있다는 것입니다.2\n그렇다면 이 정보는 집단 간 모평균이 다른지 여부를 파악하는 데 어떻게 도움이 될까요? 음. 잠깐만요. 가만히 생각해 보니, 바로 우리가 찾고 있던 내용이네요. 귀무가설이 참이라면 모든 표본 평균이 서로 비슷할 것으로 예상되지 않습니까? 그렇다면 \\(SS_b\\)는 매우 작을 것이고, 최소한 “그 외의 변동”(\\(SS_w\\))보다 훨씬 작을 것으로 기대됩니다. 흠. 가설 검정이 다가오고 있는 것이 느껴지는군요.\n\n\n13.2.3 제곱합에서 \\(F\\)-검정으로\n이전 절에서 본 것처럼, ANOVA의 정성적 개념은 두 제곱합 값인 \\(SS_b\\)와 \\(SS_w\\)를 서로 비교하는 것입니다. 만약 집단 간 변동(\\(SS_b\\))이 집단 내 변동(\\(SS_w\\))에 비해 크다면, 각 집단의 모집단 평균이 동일하지 않다고 의심할 만합니다. 이를 실질적인 가설 검정으로 변환하려면 약간의 “조정”이 필요합니다. 먼저 검정 통계량인 \\(F\\)-비율(\\(F\\)-ratio)을 계산하는 방법을 보여드린 후, 이를 이렇게 계산하는 이유를 생각해 보겠습니다.\n\\(SS\\) 값들을 \\(F\\)-비율로 변환하려면 먼저 \\(SS_b\\)와 \\(SS_w\\) 값과 관련된 자유도를 계산해야 합니다. 자유도는 특정 계산에 기여하는 고유한 “데이터 점”의 수에서 해당 점들이 만족해야 하는 “제약 조건”의 수를 뺀 값에 해당합니다. 집단 내 변동의 경우에는 개별 관측값(\\(N\\)개 데이터 점)의 변동을 집단 평균(\\(G\\)개의 제약 조건)과의 차이로부터 계산합니다. 반면, 집단 간 변동의 경우, 집단 평균(\\(G\\)개의 데이터 점)의 변동을 전체 평균(1개의 제약 조건)과의 차이로부터 계산합니다. 따라서 자유도는 다음과 같습니다. \\[df_b=G-1\\] \\[df_w=N-G\\]\n이제 간단한 과정입니다. 다음으로, 제곱합 값을 “평균제곱”으로 변환하는데, 이는 자유도로 나누어 계산합니다. \\[MS_b=\\frac{SS_b}{df_b}\\] \\[MS_w=\\frac{SS_w}{df_w}\\]\n마지막으로, 집단 간 \\(MS\\) 값을 집단 내 \\(MS\\) 값으로 나누어 \\(F\\)-비율을 계산합니다. \\[F=\\frac{MS_b}{MS_w}\\]\n아주 일반적인 수준에서 보면, \\(F\\)-통계량의 직관적인 의미는 명확합니다. \\(F\\) 값이 클수록 집단 간 변동이 집단 내 변동에 비해 크다는 뜻입니다. 따라서 \\(F\\) 값이 클수록 귀무가설을 기각할 근거가 더 많아집니다. 그러나 실제로 귀무가설을 기각하려면 \\(F\\) 값이 얼마나 커야 할까요? 이를 이해하려면 ANOVA가 무엇이며 평균 제곱값이 실제로 무엇을 의미하는지를 조금 더 깊이 이해해야 합니다.\n다음 절에서는 이를 좀 더 자세히 논의할 것입니다. 그러나 이론적 세부 사항에 관심이 없는 독자들을 위해 결론을 먼저 말씀드리겠습니다. 가설 검정을 완성하려면, 귀무가설이 참일 때 \\(F\\)-통계량의 표본 분포를 알아야 합니다. 놀랍지 않게도, 귀무가설 하에서 \\(F\\)-통계량의 표본 분포는 \\(F\\)-분포를 따릅니다. 확률 이론 소개(Chapter 7)에서 논의했듯이, \\(F\\)-분포에는 두 개의 매개변수가 있으며, 이는 관련된 두 자유도에 해당합니다. 첫 번째 자유도 \\(df_1\\)은 집단 간 자유도(\\(df_b\\)), 두 번째 자유도 \\(df_2\\)는 집단 내 자유도(\\(df_w\\))입니다.\n일원분산분석에서 사용되는 모든 주요 개념과 이를 계산하는 공식은 Table 13.2 에 요약되어 있습니다.\n\n\n\n\nTable 13.2. ANOVA에서 사용되는 모든 주요 개념을 “표준” ANOVA 표로 정리한 것입니다. \\(p\\)-값을 제외한 모든 값의 공식이 나와 있습니다 (\\(p\\)-값은 매우 복잡하여 컴퓨터 없이 계산하기 어렵습니다).\n\n\n\n\n\n집단 간집단 내\n\n\\( df \\)\\(  df_b=G-1  \\)\\(  df_w=N-G  \\)\n\n제곱합\\(  SS_b=\\sum_{k=1}^{G} N_k  (\\bar{Y}_k-\\bar{Y})^2  \\)\\(  SS_w=\\sum_{k=1}^{G} \\sum_{i=1}^{N_k}   (Y_{ik}-\\bar{Y}_k)^2  \\)\n\n제곱평균\\(  MS_b=\\frac{SS_b}{df_b}  \\)\\(  MS_w=\\frac{SS_w}{df_w}  \\)\n\n\\( F \\)-통계량\\(  F=\\frac{MS_b}{df_b}  \\)-\n\n\\(p\\)-값[복잡함]-\n\n\n\n\n\n\n\n\n기술적 세부사항\nANOVA는 근본적으로 두 개의 서로 다른 통계 모형, \\(H_0\\)와 \\(H_1\\), 간의 경쟁입니다. 이 절의 시작에서 귀무가설과 대립가설을 설명할 때, 이러한 모형이 실제로 무엇인지에 대해 다소 모호하게 설명했습니다. 이제 이를 바로잡겠습니다. 귀무가설이 참이라면, 모든 집단의 평균이 동일해야 합니다. 이 경우, 결과변수 \\(Y_{ik}\\)를 단일 모집단 평균 \\(\\mu\\)와 해당 평균에서의 편차로 표현하는 것이 자연스러운 접근 방식입니다. 이 편차는 일반적으로 \\(\\epsilon_{ik}\\)로 표시되며, 전통적으로 해당 관측값과 관련된 오차 또는 잔차라고 불립니다.\n그러나 주의해야 합니다. “오차”라는 단어는 통계학에서 기술적인 의미를 가지며, 일상적인 영어 단어 “error”와는 다소 다릅니다. 일상적으로 “error”는 실수를 의미하지만, 통계학에서는 그렇지 않습니다(또는 반드시 그렇다고 볼 수 없습니다). 이런 점을 고려하면, “잔차”라는 단어가 “오차”보다 더 적절한 용어입니다. 통계학에서 두 용어 모두 “설명되지 않은 변동성”, 즉 “모형이 설명할 수 없는 요소”를 의미합니다.\n어쨌든, 귀무가설을 통계 모형으로 표현하면 다음과 같습니다: \\[Y_{ik}=\\mu+\\epsilon_{ik}\\]\n여기서 잔차 값 \\(\\epsilon_{ik}\\)는 정규 분포를 따르며, 평균이 0이고 표준 편차가 \\(\\sigma\\)인 것으로 가정합니다. 즉, 다음과 같이 나타낼 수 있습니다: \\[\\epsilon_{ik} \\sim Normal(0,\\sigma^2)\\]\n그렇다면 대립가설 \\(H_1\\)은 어떻게 될까요? 유일한 차이점은 각 집단이 서로 다른 모집단 평균을 가질 수 있도록 허용한다는 점입니다. 즉, \\(k\\)번째 집단의 모집단 평균을 \\(\\mu_k\\)라고 하면, 대립가설의 통계 모형은 다음과 같이 표현됩니다: \\[Y_{ik}=\\mu_k+\\epsilon_{ik}\\]\n여기서도 마찬가지로 오차항이 평균 0이고 표준편차가 \\(\\sigma\\)인 정규 분포를 따른다고 가정합니다. 즉, 대립가설에서도 다음을 가정합니다: \\[\\epsilon_{ik} \\sim Normal(0,\\sigma^2)\\]\n이제 \\(H_0\\)와 \\(H_1\\)을 뒷받침하는 통계 모형을 보다 자세히 설명했으므로, 평균제곱(\\(MS\\)) 값들이 무엇을 측정하는지, 그리고 이것이 \\(F\\) 통계량의 해석에 어떤 의미를 가지는지 쉽게 이해할 수 있습니다. 이에 대한 증명 과정은 생략하겠지만, 집단 내 평균제곱(\\(MS_w\\))은 오차 분산 \\(\\sigma^2\\)의 추정량으로 볼 수 있습니다. 집단 간 평균제곱(\\(MS_b\\)) 또한 추정량이지만, 이 값은 오차 분산뿐만 아니라 집단 평균 간의 실제 차이에 따라 달라지는 어떤 값을 추가적으로 포함합니다. 이 값을 \\(Q\\)라고 하면, \\(F\\) 통계량은 기본적으로 다음과 같습니다:3 \\[F=\\frac{\\hat{Q}+\\hat{\\sigma}^2}{\\hat{\\sigma}^2}\\]\n여기서 귀무가설이 참일 경우 \\(Q = 0\\), 대립가설이 참일 경우 \\(Q &gt; 0\\)이 됩니다(e.g., Hays (1994), ch. 10). 따라서 최소한 \\(F\\) 값이 1보다 커야 귀무가설을 기각할 가능성이 있습니다. 이것이 \\(F\\) 값이 1보다 작을 수 없다는 의미는 아닙니다. 귀무가설이 참이라면 \\(F\\) 비율의 표본분포 평균은 1이므로,4 귀무가설을 안전하게 기각하려면 \\(F\\) 값이 1보다 커야 합니다.\n표본분포에 대해 좀 더 정확하게 말하면, 귀무가설이 참일 경우 \\(MS_b\\)와 \\(MS_w\\)는 모두 잔차 \\(ε_{ik}\\)의 분산을 추정합니다. 만약 이러한 잔차들이 정규 분포를 따른다면, \\(ε_{ik}\\)의 분산 추정값은 카이제곱(\\(χ^2\\)) 분포를 따를 것입니다. (이전에 언급한 Section 7.6 에서 설명한 바와 같이) 카이제곱 분포란 정규 분포를 따르는 여러 값을 제곱하여 합산한 값이 따르는 분포입니다. 그리고 \\(F\\) 분포란, (정의상) \\(χ^2\\) 분포를 따르는 두 값의 비율을 구할 때 따르는 분포이므로, 우리는 \\(F\\) 통계량의 표본분포를 알 수 있습니다. 물론 여기서 많은 세부 내용을 생략했지만, 전체적인 개념은 이렇습니다.\n\n\n\n13.2.4 예제 분석\n이전 논의는 다소 추상적이고 기술적인 측면이 많았으므로, 이제 실전 예제를 살펴보는 것이 유용할 것입니다. 이를 위해, 이 장의 처음에서 소개한 임상 시험 데이터를 다시 살펴보겠습니다. 우리가 처음에 계산한 기술 통계량에 따르면, 집단 평균은 다음과 같습니다: 위약 집단은 기분 향상(mood.gain)의 평균 값이 \\(0.45\\), Anxifree 집단은 \\(0.72\\), Joyzepam 집단은 \\(1.48\\)입니다. 이를 염두에 두고, 1899년처럼 손으로 계산을 시작해 봅시다5. 하지만 1899년이 아니고 저는 게으르므로, 첫 번째 5개 관측치만 계산해 보겠습니다. 먼저, 집단 내 제곱합(\\(SS_w\\))을 계산하는 것으로 시작하겠습니다. 이를 위해, 계산을 도와줄 표를 작성하겠습니다(Table 13.3).\n\n\n\n\nTable 13.3. 예제…1\n\n\n\n\n\n집단 \\( k \\)결과변수 \\( Y_{ik} \\)\n\nplacebo0.5\n\nplacebo0.3\n\nplacebo0.1\n\nanxifree0.6\n\nanxifree0.4\n\n\n\n\n\n\n\n이 단계에서 표에 포함된 유일한 정보는 데이터 자체입니다. 즉, 집단변수(즉, drug)와 결과변수(즉, mood.gain)입니다. 결과변수는 이전에 소개한 식에서 \\(\\bar{Y}_{ik}\\) 값에 해당합니다. 다음 단계는 연구에 포함된 각 개인에 대해 해당하는 집단 평균 \\(\\bar{Y}_k\\)를 기록하는 것입니다. 이는 약간 반복적이지만 어렵지는 않습니다. 이미 기술 통계를 계산할 때 집단 평균을 구했기 때문입니다(Table 13.4).\n\n\n\n\nTable 13.4. 예제…2\n\n\n\n\n\n집단 \\( k \\)결과변수 \\( Y_{ik} \\)집단 평균 \\( \\bar{Y}_k \\)\n\nplacebo0.50.45\n\nplacebo0.30.45\n\nplacebo0.10.45\n\nanxifree0.60.72\n\nanxifree0.40.72\n\n\n\n\n\n\n\n이제 이를 기록했으므로, 각 개인의 값에서 해당 집단 평균을 뺀 편차를 계산해야 합니다. 즉, \\(Y_{ik} - \\bar{Y}_k\\) 값을 구합니다. 그런 다음, 모든 값을 제곱합니다. 그 결과는 Table 13.5 에 있습니다.\n\n\n\n\nTable 13.5. 예제…3\n\n\n\n\n\n집단 \\( k \\)결과변수 \\( Y_{ik} \\)집단 평균  \\( \\bar{Y}_k \\)집단 평균으로부터의 편차  \\( Y_{ik} - \\bar{Y}_k \\)편차 제곱 \\(  (Y_{ik}-\\bar{Y}_k)^2 \\)\n\nplacebo0.50.450.050.0025\n\nplacebo0.30.45-0.150.0225\n\nplacebo0.10.45-0.350.1225\n\nanxifree0.60.72-0.120.0136\n\nanxifree0.40.72-0.320.1003\n\n\n\n\n\n\n\n이제 마지막 단계는 단순합니다. 집단 내 제곱합을 계산하기 위해 모든 관측치에 대해 제곱 편차를 합산하면 됩니다.\n\\[\n\\begin{split}\nSS_w & = 0.0025 + 0.0225 + 0.1225 + 0.0136 + 0.1003 \\\\\n& = 0.2614\n\\end{split}\n\\]\n물론, 실제로 정확한 값을 얻으려면 전체 18개 관측치를 포함해야 합니다. 손으로 계속 계산할 수도 있지만, 매우 지루한 작업이 될 것입니다. 대신, OpenOffice나 Excel 같은 스프레드시트 프로그램을 사용하면 쉽게 수행할 수 있습니다. 직접 시도해 보십시오. 제가 Excel에서 수행한 결과는 clinicaltrial_anova.xls 파일에 저장되어 있습니다. 이 방법을 사용하면 집단 내 제곱합 값이 \\(1.39\\)로 나옵니다.\n이제 집단 내 변동(\\(SS_w\\))을 계산했으므로, 집단 간 제곱합(\\(SS_b\\))을 계산할 차례입니다. 이 과정은 앞선 계산과 매우 유사합니다. 차이점은 개별 관측치 \\(Y_{ik}\\)와 집단 평균 \\(\\bar{Y}_k\\)의 차이를 계산하는 대신, 집단 평균 \\(\\bar{Y}_k\\)와 전체 평균 \\(\\bar{Y}\\) (이 경우 \\(0.88\\))의 차이를 계산한다는 점입니다(Table 13.6).\n\n\n\n\nTable 13.6. 예제…4\n\n\n\n\n\n집단 \\( k \\)집단 평균 \\( \\bar{Y}_k \\)전체 평균  \\( \\bar{Y} \\)편차  \\( \\bar{Y}_k - \\bar{Y} \\)편차 제곱 \\(  ( \\bar{Y}_k-\\bar{Y})^2 \\)\n\nplacebo0.450.88-0.430.19\n\nanxifree0.720.88-0.160.03\n\njoyzepam1.480.880.600.36\n\n\n\n\n\n\n\n그러나 집단 간 계산에서는 각 집단의 관측치 개수 \\(N_k\\)를 각 제곱 편차에 곱해야 합니다. 이는 각 집단의 모든 관측치(\\(N_k\\)개)가 집단 간 차이에 기여하기 때문입니다. 그러므로 위약 집단에 6 명의 사람이 있고 위약 집단의 평균이 전체 평균과 \\(0.19\\)의 차이가 있다면, 이 5 명과 관련된 집단 간 총변동은 \\(6 \\times 0.19 = 1.14\\)입니다. 따라서 우리의 계산 표를 확장해야 합니다(Table 13.7).\n\n\n\n\nTable 13.7. 예제…5\n\n\n\n\n\n집단 \\( k \\)...편차 제곱  \\( (\\bar{Y}_k-\\bar{Y})^2 \\)표본 크기  \\( N_k \\)가중 편차 제곱   \\(  N_k (\\bar{Y}_k-\\bar{Y})^2 \\)\n\nplacebo...0.1961.14\n\nanxifree...0.0360.18\n\njoyzepam...0.3662.16\n\n\n\n\n\n\n\n이제 집단 간 제곱합을 계산하기 위해 모든 집단에 대해 가중 제곱 편차를 합산하면 됩니다. \\[\n\\begin{aligned} SS_b & = 1.14 + 0.18 + 2.16 \\\\\n&= 3.48\n\\end{aligned}\n\\]\n보시다시피, 집단 간 계산이 훨씬 간단합니다6. 이제 \\(SS_b\\)와 \\(SS_w\\) 값을 계산했으므로, ANOVA의 나머지 과정은 매우 간단합니다. 다음 단계는 자유도를 계산하는 것입니다. 우리는 \\(G = 3\\)개의 집단과 \\(N = 18\\)개의 전체 관측치를 가지고 있으므로 자유도는 단순한 뺄셈으로 계산할 수 있습니다. \\[\n\\begin{split}\ndf_b & = G-1 = 2 \\\\\ndf_w & = N-G = 15\n\\end{split}\n\\]\n이제 집단 내 및 집단 간 변동에 대한 제곱합과 자유도를 계산했으므로, 이를 이용하여 평균제곱값을 구할 수 있습니다. \\[\n\\begin{split}\nMS_b & = \\frac{SS_b}{df_b} = \\frac{3.48}{2} = 1.74 \\\\\nMS_w & = \\frac{SS_w}{df_w} = \\frac{1.39}{15} = 0.09\n\\end{split}\n\\]\n이제 거의 끝났습니다. 평균제곱값을 이용하여 우리가 관심을 가지는 검정 통계량인 \\(F\\) 값을 계산할 수 있습니다. 이는 집단 간 평균제곱값을 집단 내 평균제곱값으로 나누어 계산합니다. \\[\n\\begin{split}\nF & = \\frac{MS_b}{MS_w}  = \\frac{1.74}{0.09} \\\\\n& = 19.3\n\\end{split}\n\\]\n드디어 검정 통계량을 얻었습니다! 마지막 단계는 이 검정이 유의한 결과를 주는지 확인하는 것입니다. 과거에는 통계 책을 펼쳐 자유도 2와 15에 대한 특정 유의수준(예: \\(0.05\\), \\(0.01\\), \\(0.001\\))에 해당하는 임계 \\(F\\) 값을 찾아야 했습니다. 이 방법을 따르면 \\(\\alpha = 0.001\\)일 때의 임계 \\(F\\) 값은 \\(11.34\\)로 나옵니다. 우리의 \\(F\\) 값이 이보다 크므로 \\(p &lt; 0.001\\)이라고 할 수 있습니다. 하지만 요즘에는 통계 소프트웨어가 정확한 \\(p\\) 값을 자동으로 계산해 줍니다. 이 경우 \\(p\\) 값은 \\(0.000071\\)입니다. 따라서, 우리가 1종 오류를 극단적으로 보수적으로 설정하지 않는 한, 귀무가설을 기각할 가능성이 매우 높습니다.\n이제 거의 끝났습니다. 계산을 완료한 후에는, 이러한 숫자들을 ANOVA 표로 정리하는 것이 전통적입니다. 우리 임상 시험 데이터에 대한 ANOVA 표는 Table 13.8 같습니다.\n\n\n\n\nTable 13.8. The ANOVA results table\n\n\n\n\n\n\\( df \\)제곱합제곱평균\\(F\\)-통계량\\(p\\)-값\n\n집단 간23.481.7419.30.000071\n\n집단 내151.390.09--\n\n\n\n\n\n\n\n요즘에는 직접 ANOVA 표를 작성할 일이 거의 없지만, 대부분의 통계 소프트웨어(jamovi 포함)는 ANOVA 결과를 표 형식으로 출력하므로 이를 읽는 법을 익혀 두는 것이 좋습니다. 그러나 보고서에 전체 표를 포함할 필요는 거의 없습니다. 일반적으로 결과를 다음과 같이 보고하면 충분합니다.\n\n일원분산분석 결과, 약물이 기분 향상에 미치는 효과가 유의한 것으로 나타났습니다 (\\(F(2,15) = 19.3, p &lt; .001\\)).\n\n이 짧은 문장을 얻기 위해 엄청난 계산을 했군요!",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>여러 평균 비교하기 - 일원분산분석</span>"
    ]
  },
  {
    "objectID": "13-Comparing-several-means-one-way-ANOVA.html#jamovi에서-anova-수행하기",
    "href": "13-Comparing-several-means-one-way-ANOVA.html#jamovi에서-anova-수행하기",
    "title": "13  여러 평균 비교하기 - 일원분산분석",
    "section": "13.3 jamovi에서 ANOVA 수행하기",
    "text": "13.3 jamovi에서 ANOVA 수행하기\n지난 절을 읽고 난 후 여러분이 어떤 생각을 하고 있을지 저는 잘 알고 있습니다. 특히, 제 조언을 따라 직접 종이에 적거나 스프레드시트에서 ANOVA 계산을 수행했다면 말이죠. 직접 ANOVA 계산을 하는 것은 정말 번거롭습니다. 우리가 수행해야 할 계산이 상당히 많고, ANOVA를 할 때마다 이 과정을 반복해야 한다면 매우 지루할 것입니다.\n\n13.3.1 jamovi를 사용하여 ANOVA 설정하기\n여러분의 삶을 더 편하게 하기 위해, jamovi에서 ANOVA를 수행할 수 있습니다. 멋지지 않나요! ‘분산분석’-‘분산분석’ 메뉴로 이동한 후, mood.gain 변수를 ‘종속변수’ 상자로 옮기고, drug 변수를 ‘고정요인’ 상자로 옮기십시오. 그러면 Figure 13.3 같은 결과를 얻을 수 있습니다.7 또한, 저는 ‘효과 크기’ 옵션에서 \\(\\eta^2\\) 체크박스를 선택하였으며, 결과 테이블에 이 값도 포함되어 있습니다. 효과 크기에 대해서는 조금 후에 다시 다루겠습니다.\njamovi 결과 테이블은 제곱합(Sums of Squares), 자유도(Degrees of Freedom), 그리고 현재 우리가 크게 관심을 두지 않는 몇 가지 추가 정보를 보여줍니다. 하지만, jamovi에서는 ’집단 간(Between Group)’과 ’집단 내(Within Group)’라는 용어를 사용하지 않는다는 점을 주목하십시오. 대신, 더 의미 있는 명칭을 사용하려고 합니다. 현재 예제에서는 집단 간 분산이 drug이 결과변수에 미치는 효과에 해당하고, 집단 내 분산이 “남은” 변동성에 해당하므로 이를 잔차라고 부릅니다.\n\n\n\n\n\n\n\n\nFigure 13.3. 약물에 따른 기분 향상의 ANOVA 결과 테이블(jamovi)\n\n\n\n\n\n이제 [예제 계산]에서 제가 직접 계산한 값과 비교해 보면, 반올림 오차를 제외하면 거의 동일하다는 것을 알 수 있습니다. 집단 간 제곱합(\\(SS_b\\))은 3.45이고, 집단 내 제곱합(\\(SS_w\\))은 1.39이며, 자유도는 각각 2와 15입니다. 또한, \\(F\\) 값과 \\(p\\) 값도 계산되며, 반올림 오차를 제외하면 우리가 직접 수행했던 길고 지루한 계산 과정에서 얻은 값과 거의 동일합니다.\n\n\n\n\n\n\nTip 13.2. 실습: 분산분석\n\n\n\nTip 13.1 실습을 이어서 분산분석을 수행해 봅니다.\n\n‘분석’-‘분산분석’-‘분산분석’ 메뉴를 선택합니다.\n왼편의 ‘분산분석’ 창에서 다음을 수행하면 ‘결과’ 창에 분산분석 결과가 출력됩니다.\n\n\nmood.gain을 ‘종속변수’ 상자로 이동합니다.\ndrug을 ‘고정요인’ 상자로 이동합니다.\n‘효과 크기’ 옵션 아래의 \\(\\eta^2\\)을 체크합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>여러 평균 비교하기 - 일원분산분석</span>"
    ]
  },
  {
    "objectID": "13-Comparing-several-means-one-way-ANOVA.html#sec-anova-effect-size",
    "href": "13-Comparing-several-means-one-way-ANOVA.html#sec-anova-effect-size",
    "title": "13  여러 평균 비교하기 - 일원분산분석",
    "section": "13.4 효과 크기",
    "text": "13.4 효과 크기\nANOVA에서 효과 크기를 측정하는 방법에는 여러 가지가 있지만, 가장 일반적으로 사용되는 척도는 \\(\\eta^2\\)과 부분(partial) \\(\\eta^2\\)입니다. 일원분산분석(one-way ANOVA)에서는 이 두 값이 동일하므로, 여기서는 우선 \\(\\eta^2\\)만 설명하겠습니다. \\(\\eta^2\\)의 정의는 매우 간단합니다.\n\\[\\eta^2=\\frac{SS_b}{SS_{tot}}\\]\n이것이 전부입니다. 따라서 Figure 13.3 ANOVA 테이블을 보면, \\(SS_b = 3.45\\)이고 \\(SS_{tot} = 3.45 + 1.39 = 4.84\\)입니다. 따라서 \\(\\eta^2\\) 값은 다음과 같습니다.\n\\[\\eta^2=\\frac{3.45}{4.84}=0.71\\]\n\\(\\eta^2\\)의 해석 또한 매우 간단합니다. 이는 결과변수(mood.gain)의 변동성 중에서 예측변수(drug)로 설명할 수 있는 비율을 나타냅니다. \\(\\eta^2=0\\)이면 두 변수 사이에 전혀 관계가 없다는 의미이며, \\(\\eta^2=1\\)이면 완벽한 관계가 있다는 의미입니다. 더욱이, \\(\\eta^2\\) 값은 이전에 논의한 \\(R^2\\) 값(Section 12.6.1)과 매우 밀접한 관련이 있으며, 해석 방식도 동일합니다.\n많은 통계 교재에서는 ANOVA에서 기본적인 효과 크기 척도로 \\(\\eta^2\\)를 권장하지만, 실제 데이터 분석에서는 \\(\\eta^2\\)가 편향된 추정량이 될 수 있기 때문에 최적의 효과 크기 척도가 아닐 수도 있다는 의견도 있습니다. 이에 대한 흥미로운 블로그 게시글8이 있으며, 이 글에서 Daniel Lakens는 \\(\\eta^2\\)의 문제점을 지적하고 있습니다. 다행히도, jamovi에는 \\(\\eta^2\\)과 함께 보다 편향이 적은 척도인 오메가 제곱(\\(\\omega^2\\))을 지정할 수 있는 옵션도 제공됩니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>여러 평균 비교하기 - 일원분산분석</span>"
    ]
  },
  {
    "objectID": "13-Comparing-several-means-one-way-ANOVA.html#다중-비교와-사후-검정",
    "href": "13-Comparing-several-means-one-way-ANOVA.html#다중-비교와-사후-검정",
    "title": "13  여러 평균 비교하기 - 일원분산분석",
    "section": "13.5 다중 비교와 사후 검정",
    "text": "13.5 다중 비교와 사후 검정\n두 개 이상의 집단을 포함하는 ANOVA를 수행한 후 유의한 효과가 나타난다면, 가장 먼저 알고 싶은 것은 어떤 집단들이 실제로 서로 다른지를 확인하는 것입니다. 우리 약물 예제에서 귀무가설은 세 가지 약물(플라시보, Anxifree, Joyzepam)이 기분에 미치는 효과가 정확히 동일하다는 것이었습니다. 그러나 이를 더 깊이 생각해 보면, 귀무가설은 사실상 세 가지 다른 주장들을 동시에 포함하고 있습니다. 즉, 다음을 주장하고 있습니다.\n\n경쟁사의 약물(Anxifree)은 플라시보보다 더 나은 효과를 보이지 않는다(즉, \\(\\mu_A = \\mu_P\\))\n우리의 약물(Joyzepam)은 플라시보보다 더 나은 효과를 보이지 않는다(즉, \\(\\mu_J = \\mu_P\\))\nAnxifree와 Joyzepam은 동일한 효과를 보인다(즉, \\(\\mu_J = \\mu_A\\))\n\n이 세 가지 주장 중 하나라도 거짓이라면, 귀무가설도 거짓이 됩니다. 따라서 귀무가설을 기각한 후에는 이 세 가지 주장 중 적어도 하나가 사실이 아님을 알게 됩니다. 하지만 정확히 어떤 주장이 거짓일까요? 이 세 가지 명제는 모두 중요한 의미를 갖습니다. 새로운 약물 Joyzepam이 플라시보보다 효과적인지 확인하는 것은 물론이고, 기존의 상업적 대안인 Anxifree와 비교했을 때 어떤지 아는 것도 중요합니다. 또한 Anxifree와 플라시보 간의 효과 차이를 확인하는 것도 유용할 수 있습니다. Anxifree가 이미 다른 연구자들에 의해 플라시보와 비교된 적이 있다 하더라도, 본 연구가 기존 연구와 유사한 결과를 도출하는지 확인하는 것은 여전히 가치가 있습니다.\n귀무가설을 이 세 가지 별개의 명제로 구성하여 살펴보면, 우리가 구별해야 할 여덟 가지 가능한 “세계의 상태”가 있다는 것이 명확해집니다 (Table 13.9 참고).\n\n\n\n\nTable 13.9. 귀무가설과 여덟 가지 가능한 “세계의 상태”\n\n\n\n\n\n가능한 경우:\\( \\mu_P = \\mu_A \\)인가?\\( \\mu_P = \\mu_J \\)인가?\\( \\mu_A = \\mu_J \\)인가?어떤 가설을 채택하는가?\n\n1\\( \\checkmark \\)\\( \\checkmark \\)\\( \\checkmark \\)귀무\n\n2\\( \\checkmark \\)\\( \\checkmark \\)대립\n\n3\\( \\checkmark \\)\\( \\checkmark \\)대립\n\n4\\( \\checkmark \\)대립\n\n5\\( \\checkmark \\)\\( \\checkmark \\)\\( \\checkmark \\)대립\n\n6\\( \\checkmark \\)대립\n\n7\\( \\checkmark \\)대립\n\n8대립\n\n\n\n\n\n\n\n귀무가설을 기각함으로써 우리는 #1이 실제 세계의 상태라고 믿지 않기로 결정한 것입니다. 다음으로 던질 질문은, 나머지 일곱 가지 가능성 중 어떤 것이 맞다고 생각하는가입니다? 이러한 상황에 직면했을 때, 데이터를 살펴보는 것이 일반적으로 도움이 됩니다. 예를 들어, Figure 13.1 도표를 보면 Joyzepam이 플라시보과 Anxifree보다 더 나아 보이지만, Anxifree와 플라시보 사이에는 실제적 차이가 없는 것으로 보입니다. 그러나 이를 보다 명확하게 확인하기 위해서는 추가적인 검정을 수행하는 것이 도움이 됩니다.\n\n13.5.1 두 집단 \\(t\\)-검정 수행하기\n이 문제를 어떻게 해결할 수 있을까요? 우리는 세 가지의 두 집단의 조합(플라시보 대 Anxifree, 플라시보 대 Joyzepam, Anxifree 대 Joyzepam)이 있으므로, 세 개의 개별적인 \\(t\\)-검정을 수행하여 결과를 확인할 수 있습니다. 이는 jamovi에서 쉽게 수행할 수 있습니다. ANOVA의 ‘사후 검정(Post Hoc Tests)’ 옵션으로 이동하여 drug 변수를 오른쪽의 상자로 이동한 후 ‘보정 없음(No correction)’ 체크박스를 클릭하면 됩니다. 그러면 Figure 13.4 같이 세 가지 약물 수준 간의 쌍별 \\(t\\)-검정을 보여주는 깔끔한 표가 생성됩니다.\n\n\n\n\n\n\n\n\nFigure 13.4. jamovi에서 사후 비교로 수행한 보정되지 않은 두 집단 \\(t\\)-검정\n\n\n\n\n\nㅓ ### 다중 검정에 대한 보정\n이전 절에서 저는 많은 \\(t\\)-검정을 실행하는 것에 문제가 있다는 점을 암시했습니다. 문제는 이러한 분석을 수행할 때 우리가 “낚시 탐색”을 하고 있다는 것입니다. 즉, 명확한 이론적 지침 없이 다수의 검정을 실행하여 유의미한 결과가 나오기를 기대하는 것입니다. 이러한 이론이 없는 집단 차이 탐색을 사후 분석(post hoc analysis) 이라고 합니다(라틴어로 “post hoc”은 “이후에”라는 의미입니다).9\n사후 분석을 수행하는 것은 괜찮지만, 많은 주의가 필요합니다. 예를 들어, 이전 절에서 수행한 분석은 피해야 합니다. 각 개별 \\(t\\)-검정은 5%의 제1종 오류율(즉, \\(\\alpha = .05\\))을 갖도록 설계되었으며, 저는 세 개의 검정을 수행했습니다. 만약 ANOVA에서 10개의 집단을 포함하고 있고, 45개의 “사후” \\(t\\)-검정을 실행하여 어떤 집단이 유의하게 다른지를 찾으려고 했다면, 2~3개의 검정은 단순히 우연 때문에 유의한 것으로 나타날 가능성이 있습니다. Chapter 9 에서 살펴본 것처럼, 귀무가설 검정의 중심 원리는 제1종 오류율을 통제하는 것이지만, 여러 개의 \\(t\\)-검정을 한 번에 실행하여 ANOVA 결과의 원인을 규명하려 할 경우, 전체적인 제1종 오류율이 통제 불능 상태가 됩니다.\n이 문제를 해결하는 일반적인 방법은 \\(p\\)-값에 대한 조정을 도입하여 동시에 수행되는 검정 가족 전체의 오류율을 통제하는 것입니다(Shaffer (1995) 참고). 이러한 형태의 조정은 일반적으로(항상은 아니지만) 사후 분석을 수행할 때 주로 적용되며, 이를 다중 비교 보정(correction for multiple comparisons)이라고 합니다. 때때로 “동시 추론(simultaneous inference)”이라고도 불립니다. 이 보정을 수행하는 방법은 여러 가지가 있으며, 본 절과 다음 장의 Section 14.8 에서 몇 가지를 논의하겠습니다. 하지만 이 외에도 다양한 방법이 존재한다는 점을 유념하시기 바랍니다(Hsu (1996) 참고).\n\n\n13.5.2 본페로니 보정\n이러한 조정 방법 중 가장 간단한 것은 본페로니 보정(Bonferroni correction) 입니다(Dunn, 1961). 이 방법은 매우 간단합니다. 사후 분석에서 \\(m\\)개의 개별 검정을 수행하는데, 전체 제1종 오류 확률이 최대 \\(\\alpha\\)가 넘지 않도록 보장하고 싶다고 가정해 보겠습니다.10 본페로니 보정은 단순히 “모든 원래 \\(p\\)-값에 \\(m\\)을 곱하라”고 제안합니다. 즉, 원래의 \\(p\\)-값을 \\(p\\)라 하고 보정된 값을 \\(p_j^{'}\\)라 하면, \\(m\\) 개의 가설을 동시에 검정할 때 본페로니 보정은 다음과 같이 표현됩니다. \\[p_j^{'}=m \\times p\\]\n본페로니 보정을 사용하고 있으면 각 가설의 귀무가설은 \\(p_j^{'} &lt; \\alpha\\)일 때 기각됩니다. 이 보정의 논리는 매우 간단합니다. 우리가 \\(m\\)개의 서로 다른 검정을 수행하고 있으므로, 각 검정의 제1종 오류율을 최대 \\(\\frac{\\alpha}{m}\\)로 설정하면 전체 검정 집합에서의 총 제1종 오류율은 \\(\\alpha\\)를 절대 초과하지 않게 됩니다. 본페로니 보정이 너무 단순해서, 원 논문의 저자는 다음과 같이 기술하고 있습니다:\n\n여기서 제시하는 방법은 너무나 간단하고 일반적이어서, 분명히 이전에도 사용되었을 것입니다. 그러나 이를 문서화한 기록을 찾지 못했으므로, 그 단순함이 통계학자들로 하여금 이 방법이 특정 상황에서 매우 유용하다는 사실을 인식하지 못하게 만든 것으로 보입니다 (Dunn (1961), pp. 52-53).\n\njamovi에서 본페로니 보정을 사용하려면 ‘교정’ 옵션에서 ‘Bonferroni’ 체크박스를 클릭하면 됩니다. 그러면 ANOVA 결과 표에 본페로니 보정된 \\(p\\)-값이 추가된 새로운 열이 나타나며, Figure 13.4 에서 보듯이 보정되지 않은 두 집단 \\(t\\)-검정 결과와 비교했을 때 jamovi가 단순히 \\(p\\)-값을 3배 곱한 것을 확인할 수 있습니다.\n\n\n\n\n\n\nTip 13.3. 실습: 분산분석\n\n\n\nTip 13.2 실습을 이어서 다중 비교를 위한 사후 검정을 수행해 봅니다.\n\n오른편의 ‘분산분석’ 결과를 클릭하면 왼편에 ‘분산분석’ 설정 창이 나타납니다.\n왼편의 ‘분산분석’ 창에서 ‘사후 검정’ 옵션을 확장한 후 다음을 수행합니다.\n\n\ndrug 변수를 오른쪽 상자로 이동합니다.\n‘교정’에서 ’No correction’, ‘Bonferroni’, ’Holm’을 체크합니다.\n\n\n(선택) \\(p\\)-값의 유효숫자를 증가시키려면 우상단의 점 세 개로 된 설정 메뉴를 선택하여 ’p-value 형식’에서 유효숫자를 증가시킵니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n13.5.3 Holm 보정\n본페로니 보정이 가장 단순한 조정 방법이지만, 일반적으로 가장 좋은 방법은 아닙니다. 대신 자주 사용되는 방법 중 하나가 Holm 보정(Holm, 1979)입니다. Holm 보정의 개념은 검정을 가장 작은 (원래) \\(p\\)-값부터 가장 큰 값까지 순차적으로 수행한다고 가정하는 것입니다. \\(j\\) 번째로 큰 \\(p\\)-값에 대한 조정은 다음 두 값 중 하나입니다. \\[p_j^{'}=j \\times p_j\\] (즉, 가장 큰 \\(p\\)-값은 변경되지 않고, 두 번째로 큰 \\(p\\)-값은 두 배, 세 번째로 큰 \\(p\\)-값은 세 배로 증가하는 방식), 또는 \\[p_j^{'}=p_{j+1}^{'}.\\] (즉, 자신보다 \\(p\\)-값이 한 단계 더 작은 \\(p\\)-값의 보정 수치.) 이 두 값 중 더 큰 값을 선택합니다. 이것이 다소 혼란스러울 수도 있으므로 천천히 살펴보겠습니다. Holm 보정의 과정은 다음과 같습니다. 먼저, 모든 \\(p\\)-값을 오름차순으로 정렬합니다. 가장 작은 \\(p\\)-값의 경우 \\(m\\)을 곱하는 것으로 끝납니다. 그러나 나머지 값들에 대해서는 두 단계의 과정이 필요합니다. 예를 들어, 두 번째로 작은 \\(p\\)-값을 처리할 때 먼저 \\(m - 1\\)을 곱합니다. 이 값이 이전 단계에서 얻은 조정된 \\(p\\)-값보다 크다면 유지합니다. 그러나 이전 단계 값보다 작다면 이전 단계를 복사합니다. 이러한 방식으로 다섯 개의 \\(p\\)-값에 대한 Holm 보정 계산을 나타낸 것이 Table 13.10 입니다. 이 표로서 이해가 더 명확해졌기를 바랍니다.\nHolm 보정은 계산이 다소 복잡하지만 매우 좋은 특성을 가집니다. 본페로니 보정보다 더 검정력이 좋으며(즉, 2종 오류율이 더 낮음), 직관적으로는 이상하게 보일 수 있지만 1종 오류율은 동일합니다. 따라서 실제 연구에서는 본페로니 보정을 사용할 이유가 없으며, 더 정교한 Holm 보정이 항상 더 좋은 선택입니다. 따라서 Holm 보정을 다중 비교 보정의 기본 방법으로 삼는 것이 좋습니다.\n\n\n\n\nTable 13.10. Holm 보정된 \\(p\\)-값\n\n\n\n\n\n원래 \\( p \\)순위 \\( j \\)\\( p \\times j \\)Holm \\( p \\)\n\n.0015.005.005\n\n.0054.020.020\n\n.0193.057.057\n\n.0222.044.057\n\n.1031.103.103\n\n\n\n\n\n\n\nFigure 13.4 에서 Holm 보정된 \\(p\\)-값을 볼 수 있으며, 가장 큰 \\(p\\)-값(Anxifree와 위약 비교)은 변경되지 않았습니다. 값이 .15로, 보정을 적용하지 않았을 때와 동일합니다. 반면, 가장 작은 \\(p\\)-값(Joyzepam과 위약 비교)은 세 배로 증가합니다.\n\n\n13.5.4 사후 검정 결과 작성하기\n마지막으로, 사후 분석을 수행하여 어떤 집단 간 차이가 유의한지를 확인한 후, 결과를 다음과 같이 기술할 수 있습니다:\n\n사후 검정(\\(p\\)를 Holm 보정)에 따르면, Joyzepam은 Anxifree (\\(p = .001\\)) 및 위약 (\\(p = 9.0 \\times{10^{-5}}\\))보다 유의하게 더 큰 기분 향상을 유발하였습니다. 반면, Anxifree가 위약보다 더 효과적이라는 증거는 발견되지 않았습니다(\\(p = .15\\)).\n\n또는, 정확한 \\(p\\)-값을 보고하는 것이 마음에 들지 않는다면, 해당 값을 각각 \\(p &lt; .01\\), \\(p &lt; .001\\), \\(p &gt; .05\\)로 변경할 수도 있습니다. 중요한 점은 Holm 보정을 사용하여 \\(p\\)-값을 조정했다는 사실을 명시하는 것입니다. 또한, 본문 어딘가에서 관련된 기술 통계(즉, 집단 평균 및 표준편차)를 제공해야 합니다. 단순한 \\(p\\)-값만으로는 충분한 정보를 제공하지 못하기 때문입니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>여러 평균 비교하기 - 일원분산분석</span>"
    ]
  },
  {
    "objectID": "13-Comparing-several-means-one-way-ANOVA.html#일원분산분석의-가정",
    "href": "13-Comparing-several-means-one-way-ANOVA.html#일원분산분석의-가정",
    "title": "13  여러 평균 비교하기 - 일원분산분석",
    "section": "13.6 일원분산분석의 가정",
    "text": "13.6 일원분산분석의 가정\n모든 통계 검정과 마찬가지로, 분산분석도 데이터, 특히 잔차에 대한 몇 가지 가정을 기반으로 합니다. 여기서 중요한 세 가지 가정은 정규성, 분산 동질성, 독립성입니다.\n[추가 기술적 설명11]\n그렇다면, 잔차에 대한 이 가정이 적절한지 어떻게 확인할 수 있을까요? 위에서 언급했듯이, 이 가정에는 세 가지 개별적인 주장이 포함되어 있으며, 이를 각각 살펴보겠습니다.\n\n분산 동질성(Homogeneity of variance)\n지금가지 모집단의 표준편차 값을 하나만 사용하고 있었습니다(즉, \\(\\sigma\\)). 만약 각 집단이 서로 다른 표준편차 값을 갖도록 허용한다면, \\(\\sigma_k\\)로 표현해야 될 것입니다. ANOVA는 모든 집단에서 표준편차가 동일하다고 가정하며, 이를 분산 동질성(또는 등분산성, homoscedasticity) 가정이라고 합니다. 이에 대해서는 분산 동질성 가정 확인하기 절에서 자세히 다룰 것입니다.\n정규성(Normality)\n잔차는 정규분포를 따른다고 가정됩니다. Section 11.9 에서 살펴본 것처럼, 이는 QQ 도표를 확인하거나 Shapiro-Wilk 검정을 수행하여 평가할 수 있습니다. ANOVA에서 정규성 가정을 확인하는 방법에 대해서는 정규성 가정 확인하기 절에서 더 자세히 다룰 것입니다.\n독립성(Independence)\n독립성 가정은 다소 까다롭습니다. 기본적으로, 한 잔차 값을 알게 되더라도 다른 잔차 값에 대해 아무런 정보도 제공하지 않아야 한다는 의미입니다. 즉, 모든 \\(\\epsilon_{ik}\\) 값들은 서로 아무런 관계 없이 생성되었다고 가정됩니다. 이를 간단하게 검정하는 방법은 없지만, 명백한 위반 사례들은 존재합니다. 예를 들어, 반복측정 설계에서는 동일한 참가자가 여러 조건에서 측정되므로 독립성 가정이 성립하지 않습니다. 이 경우, 특정 관측치들(동일한 참가자의 측정값들) 사이에 특별한 관계가 존재합니다. 이러한 상황에서는 반복측정 일원분산분석과 같은 대체 방법을 사용해야 합니다.\n\n\n13.6.1 분산 동질성 가정 확인하기\n\n분산에 대한 사전 검정을 수행하는 것은, 대형 유람선이 항구를 떠날 수 있을 만큼 바다가 충분히 잔잔한지 알아보기 위해 노 젓는 작은 배를 타고 나가는 것과 같습니다!\n– 조지 박스 (George Box) (Box, 1953)\n\n속담에 “고양이를 가죽으로 만드는 방법은 여러 가지가 있다”라는 말이 있듯이, 분산 동질성 가정을 검정하는 방법도 여러 가지가 있습니다. 하지만 이상하게도 이와 관련된 속담은 존재하지 않습니다. 문헌에서 가장 흔히 사용되는 검정 방법은 Levene 검정(Levene, 1960)이며, 이와 밀접하게 관련된 Brown-Forsythe 검정(Brown & Forsythe, 1974)도 자주 사용됩니다.\n표준 Levene 검정을 수행하든 Brown-Forsythe 검정을 수행하든, 검정 통계량(보통 \\(F\\)로 표기되지만 경우에 따라 \\(W\\)로도 표기됨)은 일반적인 ANOVA의 \\(F\\) 통계량과 동일한 방식으로 계산됩니다. 단, \\(Y_{ik}\\) 대신 \\(Z_{ik}\\)를 사용한다는 점이 다릅니다. 이를 염두에 두고, jamovi에서 이 검정을 수행하는 방법을 살펴볼 것입니다.\n\n기술적 세부사항\nLevene 검정은 놀라울 정도로 간단합니다. 종속 변수 \\(Y_{ik}\\)가 주어졌다고 가정합시다. 우리가 해야 할 일은, 각 집단의 평균으로부터의 절대 편차를 나타내는 새로운 변수 \\(Z_{ik}\\)를 정의하는 것입니다.\n\\[Z_{ik}= \\lvert Y_{ik}-\\bar{Y}_{k} \\rvert\\]\n이것이 무슨 의미를 가지며 어떤 역할을 할까요? \\(Z_{ik}\\) 값은 \\(k\\)번째 집단의 \\(i\\)-번째 관측값이 해당 집단 평균에서 얼마나 벗어나는지를 측정하는 값입니다. 그리고 우리가 검정하려는 귀무가설은 모든 집단이 동일한 분산을 가진다는 것입니다. 즉, 모든 집단이 평균으로부터 동일한 수준의 편차를 가진다는 것이죠. 따라서 Levene 검정의 귀무가설은 \\(Z\\)의 모집단 평균이 모든 집단에서 동일하다는 것입니다.\n그렇다면, 이러한 귀무가설을 검정할 통계적 방법이 필요합니다. 어디서 본 것 같지 않나요? 맞습니다. 바로 ANOVA입니다. 결국 Levene 검정은 새롭게 정의된 변수 \\(Z_{ik}\\)에 대해 ANOVA를 수행하는 것과 동일합니다.\nBrown-Forsythe 검정은 Levene 검정과 다른 점이 있을까요? 특별히 다를 것은 없습니다. 차이점은 변환된 변수 \\(Z\\)를 생성하는 방식에 있습니다. Levene 검정에서는 집단 평균으로부터의 편차를 사용하지만, Brown-Forsythe 검정에서는 집단 중앙값(median)으로부터의 편차를 사용합니다. 즉, Brown-Forsythe 검정에서 \\(Z_{ik}\\)는 다음과 같이 정의됩니다.\n\\[Z_{ik}= \\lvert Y_{ik}-median_k(Y) \\rvert\\]\n여기서 \\(median_k(Y)\\)는 \\(k\\)번째 집단의 중앙값을 의미합니다.\n\n\n\n13.6.2 jamovi에서 Levene 검정 실행하기\n그렇다면 Levene 검정을 실행하는 방법은 무엇일까요? 매우 간단합니다. ‘분산분석’의 ’가정검증’ 옵션에서 ‘등분산 검정’ 체크박스를 클릭하면 됩니다. 결과를 Figure 13.5 에서 확인할 수 있는데, 검정 결과는 유의하지 않습니다 (\\(F_{2,15} = 1.45, p = .266\\)). 따라서 분산 동질성 가정이 만족되는 것으로 보입니다.\n하지만 겉으로 보이는 결과가 항상 정확한 것은 아닙니다! 표본 크기가 매우 클 경우, 분산 동질성 가정이 크게 위배되지 않았더라도 Levene 검정이 유의한 결과(p &lt; .05)를 보일 수 있습니다. 이는 위의 조지 박스의 인용문에서 지적한 내용과 일맥상통합니다. 반대로, 표본 크기가 매우 작을 경우 분산 동질성 가정이 만족되지 않더라도 Levene 검정이 유의하지 않은 결과(p &gt; .05)를 보일 수도 있습니다.\n이러한 이유로, 통계 검정을 수행하는 것뿐만 아니라 분석에 포함된 각 집단/범주의 평균 주변에 대한 표준 편차를 시각적으로 확인하는 것이 중요합니다. 그래프를 통해 표준 편차가 대체로 유사한지(즉, 분산 동질성이 유지되는지)를 직접 확인하는 것이 필요합니다.\n\n\n\n\n\n\n\n\nFigure 13.5. jamovi에서 일원분산분석을 위한 Levene 검정 결과\n\n\n\n\n\n\n\n\n\n\n\nTip 13.4. 실습: 분산분석의 가정 검토 - 등분산성\n\n\n\nTip 13.2 실습을 이어서 다중 비교를 위한 사후 검정을 수행해 봅니다.\n\n오른편의 ‘분산분석’ 결과를 클릭하면 왼편에 ‘분산분석’ 설정 창이 나타납니다.\n왼편의 ‘분산분석’ 창에서 ‘가정검증’ 옵션을 확장한 ’등분산성 검증’을 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n13.6.3 분산 동질성 가정 제거하기\n우리의 예제에서는 분산 동질성 가정이 비교적 안전하게 유지되었습니다. Levene 검정 결과가 유의하지 않았으며(물론 표준편차 그래프도 확인해야 함), 따라서 큰 문제가 없을 것입니다. 하지만 현실에서는 항상 이렇게 운이 좋지는 않습니다. 그렇다면 분산 동질성 가정이 위배되었을 때 ANOVA를 어떻게 구할 수 있을까요?\n\\(t\\)-검정에서 이와 유사한 문제를 다루었음을 기억하실 것입니다. Student \\(t\\)-검정은 등분산을 가정하지만, 이를 만족하지 않을 경우 Welch \\(t\\)-검정을 사용할 수 있었습니다. 마찬가지로, Welch (1951) 는 ANOVA에서도 동일한 문제를 해결하는 방법을 제안하였습니다. 이를 Welch 일원분산분석(Welch one-way test)이라고 합니다.\nWelch 일원분산분석을 실행하려면 기존 ANOVA 분석을 수행하는 것과 동일한 절차를 따르되, jamovi에서 ‘일원 분산 분석’ 메뉴를 선택하고 Welch 검정 옵션을 활성화하면 됩니다. 이를 Figure 13.6 에서 확인할 수 있습니다.\n이제 이 결과를 이전에 jamovi에서 ANOVA를 실행했을 때의 결과와 비교해 보겠습니다. 다시 찾아보는 수고를 덜기 위해, 이전 결과를 다시 정리하면 다음과 같습니다:\n\\[F(2, 15) = 18.611, p = .00009\\]\n이는 Figure 13.6 에 표시된 Fisher 검정 결과와 동일합니다.\n\n\n\n\n\n\n\n\nFigure 13.6. jamovi에서 일원분산분석의 일부로 수행된 Welch 검정 결과\n\n\n\n\n\n즉, 기존 ANOVA 결과는 \\(F(2, 15) = 18.6\\)이었지만, Welch 일원분산분석 결과는 \\(F(2, 9.49) = 26.32\\)입니다. 다시 말해, Welch 검정에서는 집단 내 자유도가 15에서 9.49로 줄어들었으며, \\(F\\) 값은 18.6에서 26.32로 증가하였습니다.\n\n\n\n\n\n\nTip 13.5. 실습: Welch 일원분산분석\n\n\n\nTip 13.2 실습을 이어서 등분산성을 가정하지 않는 Welch 일원분산분석을 수행해 봅니다.\n\n‘분산분석’-‘일원 분산 분석’ 메뉴를 선택합니다.\n왼편의 ‘일원 분산 분석’ 창에서 다음을 수행하면 Figure 13.6 같은 결과를 얻습니다.\n\n\nmood.gain을 ‘종속변수’ 상자로 이동합니다.\ndrug를 ‘집단 변수’ 상자로 이동합니다.\n‘분산’ 옵션에서 ’등분산을 가정하지 않음(Welch’s)’와 ’등분산 가정(Fisher)’를 모두 체크합니다.\n‘가정검증’에서 ’등분산성 검증’, ’정규분포성 검증’을 체크합니다.\n\n\n\n\n\n13.6.4 정규성 가정 확인하기\n정규성 가정을 검정하는 것은 비교적 간단합니다. Section 11.9 에서 이미 대부분의 내용을 다루었습니다. 우리가 해야 할 일은 QQ 플롯을 그리고, 가능하다면 Shapiro-Wilk 검정을 실행하는 것입니다. QQ 플롯은 Figure 13.7 에서 확인할 수 있으며, 보기에는 상당히 정규분포를 따르는 것처럼 보입니다.\n\n\n\n\n\n\n\n\nFigure 13.7. jamovi에서 일원분산분석 수행 시 생성된 QQ 플롯\n\n\n\n\n\nShapiro-Wilk 검정의 결과가 유의하지 않다면(\\(p &gt; .05\\)), 이는 정규성 가정이 위배되지 않았음을 의미합니다. 그러나 Levene 검정과 마찬가지로, 표본 크기가 클 경우 유의한 Shapiro-Wilk 검정 결과가 나와도 실제로는 정규성 가정이 분석에 실질적으로 문제를 일으킬 정도로 위배되지 않았을 가능성이 있습니다. 반대로, 표본 크기가 매우 작을 경우 정규성을 위배하더라도 유의하지 않은 결과가 나올 수도 있습니다. 따라서 QQ 플롯을 시각적으로 확인하는 것이 중요합니다.\nQQ 플롯에서 정규성에서 벗어나는 패턴이 있는지 확인하는 것과 더불어, Shapiro-Wilk 검정 결과도 함께 고려해야 합니다. 우리의 데이터에 대한 Shapiro-Wilk 검정 결과는 \\(p = 0.6053\\)으로 유의하지 않았습니다(Figure 13.6 참조). 이는 QQ 플롯에서 확인한 결과와 일치하며, 두 가지 검정 모두 정규성이 위배되지 않았음을 시사합니다.\n\n\n13.6.5 정규성 가정 제거하기\n정규성을 검정하는 방법을 살펴보았으므로, 정규성 가정이 위배되었을 때 어떻게 대응할 수 있을지가 자연스럽게 궁금해집니다.\n일원분산분석에서 정규성 가정이 위배되었을 때 가장 쉬운 해결책은 아마도 비모수 검정(non-parametric test)으로 전환하는 것입니다. 비모수 검정은 분포에 대한 가정을 필요로 하지 않는 검정 방법입니다. 우리는 Chapter 11 에서 이미 비모수 검정을 다룬 적이 있습니다.\n집단이 두 개일 경우, Mann-Whitney 검정 또는 Wilcoxon 검정이 대안적인 비모수 검정이 될 수 있습니다. 만약 세 개 이상의 집단이 있다면, Kruskal-Wallis 순위합 검정(Kruskal-Wallis rank sum test)(Kruskal & Wallis, 1952)을 사용할 수 있습니다. 다음으로 이 검정에 대해 살펴보겠습니다.\n\n\n13.6.6 Kruskal-Wallis 검정의 논리\nKruskal-Wallis 검정은 몇 가지 면에서 ANOVA와 놀랍도록 유사합니다. ANOVA에서는 \\(Y_{ik}\\), 즉 k번째 집단에 속하는 \\(i\\)-번째 개인의 결과변수를 시작점으로 삼았습니다. Kruskal-Wallis 검정에서는 이러한 \\(Y_{ik}\\) 값들을 순위로 변환한 후, 순위화된 데이터를 이용하여 분석을 수행합니다.\n이제 \\(R_{ik}\\)을 \\(k\\)-번째 집단의 \\(i\\)-번째 구성원에게 부여된 순위라고 하겠습니다. 그리고 \\(k\\)-번째 집단의 평균 순위를 \\(\\bar{R}_k\\)라고 정의하면, 이는 다음과 같이 계산됩니다.\n\\[\\bar{R}_k=\\frac{1}{N_k}\\sum_i R_{ik}\\]\n또한, 전체 평균 순위 \\(\\bar{R}\\)는 다음과 같습니다.\n\\[\\bar{R}=\\frac{1}{N}\\sum_i\\sum_k R_{ik}\\]\n이제 전체 평균 순위 \\(\\bar{R}\\)로부터의 편차 제곱을 계산할 수 있습니다. 개별 점수에 대해 \\((R_{ik} - \\bar{R})^2\\)을 계산하면, 이는 개별 관측값이 전체 평균 순위에서 얼마나 멀리 떨어져 있는지를 측정하는 비모수적 척도가 됩니다.\n집단 평균과 전체 평균 간의 편차 제곱을 계산하면, 이는 집단이 전체 평균 순위에서 얼마나 멀리 떨어져 있는지를 측정하는 비모수적 척도가 됩니다. 이를 바탕으로 ANOVA에서와 동일한 논리를 따라 순위제곱합(ranked sums of squares)을 정의합니다. 먼저, 전체 순위 제곱합(total ranked sums of squares, RSS)은 다음과 같습니다.\n\\[RSS_{tot}=\\sum_k\\sum_i (R_{ik}-\\bar{R})^2\\]\n그리고 “집단 간 순위제곱합(between groups ranked sums of squares)”은 다음과 같이 정의됩니다.\n\\[\\begin{aligned}\nRSS_{b}& =\\sum{k}\\sum_{i}(\\bar{R}_{k}-\\bar{R})^2 \\\\\n&= \\sum_{k} N_k (\\bar{R}_{k}-\\bar{R})^2\n\\end{aligned}\\]\n귀무가설이 참이라면, 즉 집단 간 실제 차이가 없다면, 집단 간 순위제곱합 \\(RSS_b\\)는 전체 순위제곱합 \\(RSS_{tot}\\)에 비해 매우 작을 것입니다. 이 개념은 ANOVA의 \\(F\\)-통계를 구축할 때 사용했던 논리와 매우 유사합니다. 그러나 Kruskal-Wallis 검정 통계량(일반적으로 \\(K\\)로 표기)은 기술적인 이유로 약간 다르게 정의됩니다.\n\\[K=(N-1) \\times \\frac{RSS_b}{RSS_{tot}}\\]\n귀무가설이 참일 경우, \\(K\\)의 표본 분포는 자유도가 \\(G-1\\)인 카이제곱 분포를 따릅니다(여기서 \\(G\\)는 집단의 수). \\(K\\)의 값이 클수록 귀무가설과 데이터가 일치하지 않는 정도가 커지므로, 이는 단측 검정입니다. 따라서 \\(K\\) 값이 충분히 클 경우, 우리는 귀무가설을 기각하게 됩니다.\n\n추가적인 세부사항\n앞서 설명한 내용은 Kruskal-Wallis 검정의 논리를 개념적으로 이해하는 방식입니다.12\n하지만 여기서 끝이 아닙니다! 왜 항상 추가적인 내용이 있는 걸까요? 지금까지 설명한 내용은 데이터에 동률(ties)이 없는 경우에만 정확합니다. 즉, 동일한 값을 갖는 두 개 이상의 관측값이 존재하지 않는 경우에만 위의 식이 성립합니다. 만약 동일한 값을 가지는 관측값이 존재하면, 계산 과정에 교정 계수(correction factor)를 도입해야 합니다. 이 시점에서 대부분의 독자는 더 이상 관심이 없을 것이라고 가정하고(적어도 “교정 계수” 따위는 지금 당장 몰라도 된다”는 결론을 내렸을 것이라고 생각하고), 아주 간단히 설명하겠습니다.\n먼저, 원본 데이터에 대한 도수 분포표를 만들고, \\(f_j\\)를 \\(j\\)-번째 고유 값을 가지는 관측값의 개수라고 정의합니다. 아래는 clinicaltrials.csv 데이터셋에서 mood.gain 변수를 기준으로 한 도수 분포표의 예시입니다(Table 13.11).\n\n\n\n\nTable 13.11. clinicaltrials.csv 데이터의 mood.gain 도수 분포표\n\n\n\n\n\n0.10.20.30.40.50.60.80.91.11.21.31.41.71.8\n\n11211211112211\n\n\n\n\n\n\n\n이 표를 보면, 세 번째 항목의 빈고가 2임을 확인할 수 있습니다. 이는 mood.gain 값이 0.3인 사람이 두 명 존재한다는 것을 의미합니다. 다시 말해, 앞서 정의한 수학적 기호를 사용하면 \\(f_3 = 2\\)라는 의미입니다. 이제 이를 바탕으로 동률 교정 계수(Tie Correction Factor, TCF)를 계산할 수 있습니다. \\[TCF=1-\\frac{\\sum_j f_j^3 - f_j}{N^3 - N}\\] Kruskal-Wallis 검정 통계량의 동률 교정 값은 원래의 \\(K\\) 값을 이 교정 계수로 나누어 얻습니다. jamovi에서는 이 동률이 교정된 Kruskal-Wallis 검정 통계량을 사용합니다.\n마침내 Kruskal-Wallis 검정 이론에 대한 설명이 끝났습니다. 이제 여러분은 Kruskal-Wallis 검정에서 동률 교정 계수를 계산하는 방법을 몰라서 생기는 실존적 불안을 해소하게 되었습니다. 안심이 되시나요?\n\n\n\n13.6.7 jamovi에서 Kruskal-Wallis 검정을 실행하는 방법\nKruskal-Wallis 검정이 실제로 무엇을 하는지 이해하려고 고군분투했던 것과는 달리, jamovi에서 이 검정을 실행하는 것은 매우 간단합니다. jamovi에는 분산분석의 일부로 ‘비모수’-’일원 분산 분석(Kruskal-Wallis)’이 포함되어 있습니다. 대부분의 경우 clinicaltrial.csv 같은 데이터를 분석하게 될 것이고, 이러한 데이터에는 mood.gain 같은 결과변수와 drug 같은 집단변수가 있을 것입니다. 그런 경우라면 jamovi에서 바로 비모수 일원분산분석을 실행할 수 있습니다. 분석 결과는 Figure 13.8 같이 Kruskal-Wallis \\(\\chi^2 =12.076, df = 2, p = 0.00239\\)를 제공합니다.\n\n\n\n\n\n\n\n\nFigure 13.8. jamovi에서 Kruskal-Wallis 일원 비모수 ANOVA\n\n\n\n\n\n\n\n\n\n\n\nTip 13.6. 실습: Kruskal-Wallis 일원분산분석\n\n\n\nTip 13.2 실습을 이어서 비모수적 일원분산분석을 수행해 봅니다.\n\n‘분산분석’-‘비모수’-‘일원 분산 분석 (Kruskal-Wallis)’ 메뉴를 선택합니다.\n왼편의 ‘일원 분산 분석’ 창에서 다음을 수행하면 Figure 13.8 같은 결과를 얻습니다.\n\n\nmood.gain을 ‘종속변수’ 상자로 이동합니다.\ndrug를 ‘집단 변수’ 상자로 이동합니다.\n’효과 크기’와 ’DSCF pairwise comparisons’를 체크합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>여러 평균 비교하기 - 일원분산분석</span>"
    ]
  },
  {
    "objectID": "13-Comparing-several-means-one-way-ANOVA.html#반복측정-일원분산분석",
    "href": "13-Comparing-several-means-one-way-ANOVA.html#반복측정-일원분산분석",
    "title": "13  여러 평균 비교하기 - 일원분산분석",
    "section": "13.7 반복측정 일원분산분석",
    "text": "13.7 반복측정 일원분산분석\n반복측정 일원분산분석(Repeated Measures One-Way ANOVA)은 동일한 참가자가 각 집단에 속하거나, 각 참가자가 다른 실험 집단의 참가자와 밀접하게 매칭될 때, 세 개 이상의 집단 사이의 유의한 차이를 검정하는 통계적 방법입니다. 그러므로 각 실험 집단에는 서로 대응되는 항상 동일한 개수의 관측치(데이터 포인트)가 있어야 합니다. 이러한 연구 설계와 분석은 “연관 ANOVA(related ANOVA)” 또는 “피험자(참가자, 개인) 내 ANOVA (within-subjects ANOVA)”라고도 합니다.\n반복측정 ANOVA의 논리는 독립 표본 ANOVA(때때로 “피험자(참가자, 개인) 간 ANOVA (between-subjects ANOVA)”라고도 함)와 매우 유사합니다. 앞서 독립 표본 ANOVA에서 총 변동성을 집단 간 변동성(\\(SS_b\\))과 집단 내 변동성(\\(SS_w\\))으로 나눈 후, 각각의 자유도로 나누어 \\(MS_b\\)와 \\(MS_w\\)를 구하는 방법을 설명한 바 있습니다(Table 13.2 참조). 이후, \\(F\\) 비율은 다음과 같이 계산됩니다.\n\\[F=\\frac{MS_b}{MS_w}\\]\n반복측정 ANOVA에서도 \\(F\\) 비율은 유사하게 계산됩니다. 그러나 독립 표본 ANOVA에서는 집단 내 변동성(\\(SS_w\\))이 \\(MS_w\\)의 분모로 사용되는 반면, 반복측정 ANOVA에서는 \\(SS_w\\)를 두 개의 부분으로 나눕니다. 동일한 참가자를 각 집단에서 사용하기 때문에, 참가자 간 개별 차이에 의한 변동성(\\(SS_{subjects}\\))을 집단 내 변동성에서 제거할 수 있습니다.\n여기에서 너무 많은 기술적인 세부 사항을 다루지는 않겠지만, 기본적으로 각 참가자는 “참가자”라는 요인의 하나의 수준(level)이 됩니다. 그런 다음 이 내재 집단 요인의 변동성은 집단 간 요인과 동일한 방식으로 계산됩니다.\n그리고 \\(SS_{subjects}\\)를 \\(SS_w\\)에서 빼서 더 작은 \\(SS_{error}\\) 항을 얻을 수 있습니다.\n\\[\\text{독립 표본 ANOVA: } SS_{error} = SS_w\\] \\[\\text{반복측정 ANOVA: } SS_{error} = SS_w - SS_{subjects}\\]\n이러한 \\(SS_{error}\\) 항의 변화는 일반적으로 더 강력한 통계 검정을 가능하게 하지만, 오류 항의 자유도 감소가 오류 항의 감소보다 더 클 경우 반드시 그렇지는 않습니다(자유도는 \\((n - k)\\)13에서 \\((n - 1)(k - 1)\\)로 변경됨, 여기서 독립 표본 ANOVA 설계에서는 참가자의 수가 더 많음을 기억해야 합니다).\n\n13.7.1 jamovi에서 반복 측정 ANOVA\nGeschwind (1972) 는 뇌졸중 후 환자의 언어 결손 유형이 손상된 특정 뇌 영역을 진단하는 데 활용될 수 있다고 제안하였습니다. 어떤 연구자가 브로카 실어증(Broca’s Aphasia, 일반적으로 뇌졸중 후 경험하는 언어 결손)을 겪는 여섯 명의 환자가 경험하는 특정 종류의 의사소통 장애를 확인하고자 한다고 가정해 봅시다(Table 13.12).\n\n\n\n\nTable 13.12. 뇌졸중 환자의 단어 인식 과제 점수\n\n\n\n\n\n참가자음성 생성개념문법\n\n1876\n\n2786\n\n3953\n\n4545\n\n5662\n\n6874\n\n\n\n\n\n\n\n환자들은 세 가지 단어 인식 과제를 수행합니다. 첫 번째 과제(음성 생성 과제)에서는 연구자가 소리 내어 읽은 단어를 따라 말해야 했습니다. 두 번째 과제(개념적 과제)는 단어 이해력을 평가하는 것으로, 일련의 그림을 올바른 단어와 매칭해야 했습니다. 세 번째 과제(문법 과제)는 올바른 단어 순서를 평가하는 것으로, 문법적으로 틀린 문장을 올바르게 배열해야 했습니다. 모든 환자는 세 가지 과제를 모두 수행하였으며, 과제 수행 순서는 참가자 간 균형을 맞추어 배치하였습니다. 각 과제는 10번의 시도로 구성되었으며, 각 환자가 성공적으로 완료한 시도 횟수는 Table 13.12 에 나타나 있습니다. jamovi에서 분석을 수행할 수 있도록 이 데이터를 입력하거나, 간편하게 broca.csv 파일을 불러올 수도 있습니다.\njamovi에서 일원 반복측정 ANOVA를 수행하려면, ‘분산분석’-’반복측정 분산분석’을 선택하여 반복 측정 분산분석 창을 엽니다(Figure 13.9).\n\n\n\n\n\n\n\n\nFigure 13.9. jamovi에서 반복측정 분산분석 대화 상자\n\n\n\n\n\n그다음, 다음 단계를 수행합니다.\n\n’반복 측정 요인’의 이름을 입력합니다. 이 이름은 모든 참가자가 반복 수행한 조건을 설명하는 라벨입니다. 예를 들어, 모든 참가자가 수행한 음성 생성, 개념적, 문법적 과제를 설명하기 위해 ’과제’라는 적절한 라벨을 사용할 수 있습니다. 이 새로운 요인 이름은 분석에서 독립 변수로 사용됩니다.\n\n‘반복 측정 요인’ 텍스트 상자에 세 번째 수준을 추가합니다. 세 개의 과제(음성 생성, 개념, 문법)가 각각의 수준이므로, 수준의 라벨을 적절히 변경합니다.\n\n각 수준의 변수를 ‘반복 측정 셀(Repeated Measures Cells)’ 텍스트 상자로 이동합니다.\n\n마지막으로, ‘가정 검증’ 옵션에서 ’구형성 검정(Sphericity checks)’을 선택합니다.\n\njamovi에서 생성된 일원 반복 측정 ANOVA 출력 결과는 Figure 13.10 에서 Figure 13.13 까지 제시되어 있습니다. 가장 먼저 확인해야 할 것은 마우클리의 구형성 검정(Mauchly’s Test of Sphericity)으로, 조건 간 차이의 분산이 동일한지를 검정합니다(즉, 연구 조건 간 차이 점수의 분포가 대략 동일한지를 평가함). Figure 13.10 에서 마우클리 검정의 \\(p = .720\\)입니다. 마우클리 검정이 유의하지 않으면(즉, \\(p &gt; .05\\), 본 분석의 경우처럼), 차이 분산이 유의하게 다르지 않다고 결론 내릴 수 있으며, 즉 대략적으로 동일하므로 구형성을 가정할 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 13.10. 일원 반복측정 ANOVA 출력 - 마우클리 구형성 검정\n\n\n\n\n\n반면, 마우클리 검정이 유의했다면(\\(p\\) &lt; .05), 차이의 분산 사이에 유의한 차이가 존재하며 구형성 가정이 충족되지 않는다고 결론 내려야 합니다. 이 경우, 일원 반복측정 ANOVA에서 얻은 \\(F\\)-값에 대한 보정을 적용해야 합니다.\n\n‘구형성 검정’ 테이블에서 그린하우스-가이저 값이 &gt; .75이면 후인-펠트 보정을 사용합니다.\n\n그린하우스-가이저 값이 &lt; .75이면 그린하우스-가이저 보정을 사용합니다.\n\n이러한 보정된 \\(F\\)-값은 ‘가정 검증’ 옵션에서 ‘구형성 보정(Sphericity corrections)’ 체크 박스를 선택하여 지정할 수 있으며, 보정된 \\(F\\)-값이 결과 테이블에 표시됩니다(Figure 13.11).\n본 분석에서는 마우클리 구형성 검정의 \\(p = .720\\) (즉, \\(p &gt; 0.05\\))이므로, 구형성 가정이 충족되었으며 \\(F\\)-값에 대한 보정이 필요하지 않습니다. 따라서 반복측정 분산분석 결과의 ’과제’의 ’구형성 보정(Sphericity corrections)’이 ’없음(None)’인 행의 결과를 사용하면 됩니다. 그러면 \\(F = 6.93\\), \\(df = 2\\), \\(p = .013\\)로 나타나며, 과제 유형(음성 생성, 개념, 문법)에 따라 성공적으로 완료된 시도 횟수가 유의하게 다름을 결론 내릴 수 있습니다(\\(F(2, 10) = 6.93\\), \\(p = .013\\)).\n\n\n\n\n\n\n\n\nFigure 13.11. 일원 반복측정 ANOVA 출력 - 피험자 내 효과 검정\n\n\n\n\n\n반복측정 ANOVA에서 사후 검정을 수행할 수도 있으며, 이는 독립 표본 ANOVA와 동일한 방식으로 jamovi에서 이를 지정할 수 있습니다(Figure 13.12). 결과를 보면 음성 생성과 문법 과제 간에 유의한 차이가 있지만, 다른 수준 간에는 유의한 차이가 없음을 알 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 13.12. jamovi에서 반복측정 ANOVA의 사후 검정\n\n\n\n\n\n기술 통계(주변 평균)를 검토하여 결과를 해석할 수 있으며, jamovi 출력 결과는 Figure 13.13 에 제시되어 있습니다. 참가자들이 성공적으로 완료한 평균 시도 횟수를 비교하면, 브로카 실어증 환자는 음성 생성(평균 = 7.17)과 개념(평균 = 6.17) 과제에서 비교적 좋은 성과를 보였지만, 문법 과제(평균 = 4.33)에서는 상당히 낮은 성과를 보였습니다. 사후 검정 결과, 음성 생성과 문법 과제 사이의 차이가 유의하였습니다.\n\n\n\n\n\n\n\n\nFigure 13.13. 일원 반복측정 ANOVA 출력 - 기술 통계\n\n\n\n\n\n\n\n\n\n\n\nTip 13.7. 실습: 반복측정 일원분산분석\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Broca’s aphasia’을 선택합니다.\n스프레드시트 창에서 각 변수의 이름을 더블클릭하여 각 변수의 척도유형과 데이터 유형이 제대로 설정되어 있는지 확인하고 필요하면 이를 정정합니다.\n\n\nID: 아이디, 정수\nSpeech, Conceptual, Syntax: 연속변수, 정수\n\n\n‘분석’-‘분산분석’-‘반복측정 분산분석’ 메뉴를 선택합니다.\n‘반복측정 분산분석’ 창에서 반복 측정 요인을 설정합니다.\n\n\n‘반복 측정 요인’ 창에서 요인의 이름을 ’과제’로 설정합니다.\n’반복 측정 요인’에 세 개의 수준을 설정합니다.\n\n’수준 1’의 이름을 ’음성 생성’으로 바꿉니다.\n’수준 2’의 이름을 ’개념’으로 바꿉니다.\n세 번째 수준을 클릭하여 ’문법’이라는 이름으로 추가합니다.\n\n\n\n‘Repeated Measures Cells’ 창으로 앞에 만든 ’반복 측정 요인’의 수준의 순서에 따라 Speach, Conceptual, Syntax 변수를 차례로 이동시킵니다.\n\n\n\n\n\n\n\n\n\n\n\n‘가정검증’ 옵션을 확장한 후, ‘구형성 검증’을 체크합니다. 그리고 ’Sphericity corrections’ 아래의 ‘없음’, ‘Greenhouse-Geisser’, ’Huynh-Feldt’를 모두 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n반복측정 요인의 두 수준 사이의 차이를 사후 검정하기 위하여 ‘사후 검정’ 옵션을 확장합니다.\n\n\n‘과제’ 반복측정 요인을 오른쪽 상자로 이동시킵니다.\n‘교정’ 옵션에서 ’Tukey’와 ’Holm’을 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n반복측정 요인의 수준의 평균의 차이를 확인하기 위하여 ‘Estimated Marginal Means’ 옵션을 확장합니다.\n\n\n‘과제’ 요인을 ’Marginal Means’로 이동시킵니다.\n’결과’에서 ’Marginal means plots’와 ’Marginal means tables’를 체크합니다.\n’도표’에서 ’관찰점수’를 클릭하여 관측치를 점으로 표현합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>여러 평균 비교하기 - 일원분산분석</span>"
    ]
  },
  {
    "objectID": "13-Comparing-several-means-one-way-ANOVA.html#프리드먼-비모수-반복측정-anova-검정",
    "href": "13-Comparing-several-means-one-way-ANOVA.html#프리드먼-비모수-반복측정-anova-검정",
    "title": "13  여러 평균 비교하기 - 일원분산분석",
    "section": "13.8 프리드먼 비모수 반복측정 ANOVA 검정",
    "text": "13.8 프리드먼 비모수 반복측정 ANOVA 검정\n프리드먼 검정은 반복 측정 ANOVA의 비모수 버전이며, 동일한 참가자가 각 집단에 속해 있거나 각 참가자가 다른 조건의 참가자와 밀접하게 매칭되어 있을 때, 세 개 이상의 집단 사이의 차이를 검정하는 경우 크루스칼-왈리스(Kruskal-Wallis) 검정 대신 사용됩니다. 결과변수가 서열척도이거나 정규성 가정이 충족되지 않는 경우, 프리드먼 검정을 사용할 수 있습니다.\n크루스칼-왈리스 검정과 마찬가지로, 기저에 있는 수학적 원리는 복잡하여 여기에서는 설명하지 않습니다. 이 책의 목적을 위해서는 jamovi가 동률 보정된(tie-corrected) 프리드먼 검정을 계산한다는 점을 이해하는 것으로 충분합니다. Figure 13.14 에서는 이미 살펴본 브로카 실어증(Broca’s Aphasia) 데이터를 사용한 예제가 제시되어 있습니다.\n\n\n\n\n\n\n\n\nFigure 13.14. jamovi에서 ‘반복 측정 ANOVA (비모수)’ 대화 상자 및 결과\n\n\n\n\n\njamovi에서 프리드먼 검정을 실행하는 것은 매우 간단합니다. Figure 13.14 처럼 ‘분석’-‘분산분석’ -‘비모수’-‘반복측정 분산분석 (Friedman)’을 선택하십시오. 그런 다음 비교하고자 하는 반복 측정 변수(Speach, Conceptual, Syntax)를 ’측정값’ 텍스트 상자로 이동하십시오. 세 개의 반복 측정 변수에 대한 기술통계량(평균 및 중앙값)을 생성하려면 ’기술 통계’를 체크하십시오.\njamovi 결과에서는 기술통계, 카이제곱(\\(\\ci^2\\)) 값, 자유도(df), 그리고 \\(p\\)-값이 표시됩니다(Figure 13.14). \\(p\\)-값이 일반적으로 유의성을 결정하는 기준인 \\(p &lt; .05\\)보다 작으므로, 브로카 실어증 환자들은 언어 과제 유형별로 점수 차이가 있었던 것으로 판단됩니다. 이들은 음성 생성(중앙값 = 7.5) 및 개념(중앙값 = 6.5) 과제에서는 비교적 좋은 수행을 보였 수 있습니다. 그러나 문법 과제(중앙값 = 4.5)에서는 수행이 현저히 저조했으며, 사후 검정 결과 음성 생성과 문법 과제 사이의 수행 차이가 유의한 것으로 나타났습니다.\n\n\n\n\n\n\nTip 13.8. 실습: 프리드먼 비모수 반복측정 분산분석\n\n\n\nTip 13.7 수행에 이어 프리드먼 비모수 반복측정 분산분석을 수행합니다 .\n\n‘분석’-‘분산분석’-‘비모수’-‘반복측정 분산분석 (Friedman)’ 메뉴를 선택합니다.\n‘반복측정 분산분석(비모수)’ 창에서 다음을 수행하면 Figure 13.14 같은 결과를 얻을 수 있습니다.\n\n\nSpeach, Conceptual, Syntax 변수를 ‘측정값’ 상자로 이동시킵니다.\n’짝 비교’를 체크하여 두 수준 사이의 차이를 사후 검정합니다.\n’기술통계’를 체크하여 수준별 평균과 중위수를 비교합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>여러 평균 비교하기 - 일원분산분석</span>"
    ]
  },
  {
    "objectID": "13-Comparing-several-means-one-way-ANOVA.html#sec-On-the-relationship-between-ANOVA-and-the-Student-t-test",
    "href": "13-Comparing-several-means-one-way-ANOVA.html#sec-On-the-relationship-between-ANOVA-and-the-Student-t-test",
    "title": "13  여러 평균 비교하기 - 일원분산분석",
    "section": "13.9 ANOVA와 스튜던트 \\(t\\)-검정의 관계",
    "text": "13.9 ANOVA와 스튜던트 \\(t\\)-검정의 관계\n마지막으로 설명하고 싶은 중요한 사항이 있습니다. 많은 사람들이 이를 다소 놀랍게 여기지만, 알아 두면 유용합니다. 두 개의 집단을 비교하는 ANOVA는 스튜던트 \\(t\\)-검정과 동일합니다. 정말 그렇습니다. 단순히 비슷한 것이 아니라, 모든 의미에서 실제로 동등합니다. 이를 증명하지는 않겠지만, 하나의 구체적인 예를 보여드리겠습니다. 우리의 모형을 기분 향상(mood.gain) ~ 약물(drug)이 아니라 치료(therapy)를 예측변수로 사용하는 ANOVA를 수행한다고 가정해 보겠습니다. 이 경우, \\(F\\)-통계량이 \\(F(1,16) = 1.71\\)이고, \\(p\\)-값이 0.21로 나타납니다.\n이제, 집단이 두 개뿐이므로 ANOVA를 수행할 필요 없이 단순히 스튜던트 \\(t\\)-검정을 실행할 수도 있었습니다. 그렇다면 실제로 \\(t\\)-검정을 수행하면 어떤 결과가 나오는지 살펴보겠습니다. \\(t\\)-검정을 실행하면 \\(t\\)-통계량이 \\(t(16) = -1.3068\\), 그리고 \\(p\\)-값이 0.21로 나타납니다. 흥미롭게도, \\(p\\)-값이 동일합니다. 다시 한 번 \\(p = .21\\)이라는 값을 얻었습니다. 그렇다면 검정 통계량은 어떨까요? ANOVA 대신 \\(t\\)-검정을 실행한 결과 다소 다른 값인 \\(t(16) = -1.3068\\)을 얻었습니다. 그러나 여기에는 간단한 관계가 있습니다. \\(t\\)-통계량을 제곱하면 이전의 \\(F\\)-통계량을 얻을 수 있습니다: \\(-1.3068^2 = 1.7077\\).\n\n\n\n\n\n\n실습: 두 집단 일원분산분석과 t-검정\n\n\n\nTip 13.1 수행한 후에 therapy 변수로 두 집단으로 나누어 t-검정과 일원분산분석을 수행하여 비교해 봅니다.\n\ntherapy의 값별로 데이터를 나누어 mood.gain의 기술통계량을 비교합니다.\n\n\n‘분석’-‘기술통계’-‘기술통계’ 메뉴를 선택합니다.\n왼편 ‘기술통계’ 설정 창에서 다음을 수행합니다.\n\nmood.gain을 ’변수’로 이동합니다.\ntherapy을 ’Split by’로 이동합니다.\n‘도표’ 옵션을 확장하여 ’박스 도표’와 ’평균’을 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n\ntherapy로 나누어 mood.gain의 평균의 차이를 t-검정해 봅니다.\n\n\n‘분석’-‘T-검정’-‘독립표본 T 검정’ 메뉴를 선택합니다.\n왼편 ‘독립표본 T 검정’ 설정 창에서 다음을 수행합니다.\n\nmood.gain을 ’종속변수’로 이동합니다.\ntherapy을 ’집단 변수’로 이동합니다.\n‘추가통계’ 옵션에서 ’평균 차이’와 ’효과 크기’를 체크합니다.\n‘가정검증’ 옵션에서 ‘등분산 검증’, ‘정규분포성 검증’, ’Q-Q 도표’를 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n\ntherapy로 나누어 mood.gain의 평균의 차이를 일원분산분석을 수행해 봅니다.\n\n\n‘분석’-‘분산분석’-‘분산분석’ 메뉴를 선택합니다.\n왼편 ‘독립표본 T 검정’ 설정 창에서 다음을 수행합니다.\n\nmood.gain을 ’종속변수’로 이동합니다.\ntherapy을 ’고정요인’으로 이동합니다.\n‘효과크기’ 옵션에서 ’\\(\\eta^2\\)’를 체크합니다.\n‘가정검증’ 옵션을 확장하여 ‘등분산 검증’, ‘정규분포성 검증’, ’Q-Q 도표’를 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\\(t\\)-검정과 일원분산분석 결과를 비교합니다.\n\n\n두 분석의 \\(p\\)-값을 비교합니다.\n등분산 검정, 정규분포성 검정 등의 결과도 비교합니다.\n\\(t\\)-검정의 통계량을 제곱하면 일원분산분석의 \\(F\\)-통계량과 비교해 봅니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>여러 평균 비교하기 - 일원분산분석</span>"
    ]
  },
  {
    "objectID": "13-Comparing-several-means-one-way-ANOVA.html#요약",
    "href": "13-Comparing-several-means-one-way-ANOVA.html#요약",
    "title": "13  여러 평균 비교하기 - 일원분산분석",
    "section": "13.10 요약",
    "text": "13.10 요약\n이번 장에서는 많은 내용을 다루었지만, 여전히 다루지 않은 부분도 많습니다.14 가장 명확한 예로, 두 개 이상의 집단 변수를 포함하는 ANOVA 실행 방법을 설명하지 않았습니다. 이에 대해서는 Chapter 14 에서 자세히 논의할 것입니다. 이번 장에서 논의한 주요 개념은 다음과 같습니다:\n\nANOVA의 작동 원리과 jamovi에서 ANOVA 수행하기와 관련된 기본 논리.\nANOVA의 효과 크기 계산 방법.\n다중 검정을 위한 다중 비교와 사후 검정.\n일원분산분석의 가정.\n분산 동질성 가정 확인하기 및 위반 시 수행할 조치로 분산 동질성 가정 제거하기.\n정규성 가정 확인하기 및 위반 시 수행할 조치로 정규성 가정 제거하기.\n반복측정 일원분산분석 및 그 비모수적 대안인 프리드먼 비모수 반복측정 ANOVA 검정.\n\n\n\n\n\nBox, G. E. P. (1953). Non-normality and tests on variances. Biometrika, 40, 318–335. https://doi.org/10.2307/2333350\n\n\nBrown, M. B., & Forsythe, A. B. (1974). Robust tests for equality of variances. Journal of the American Statistical Association, 69, 364–367. https://doi.org/10.2307/2285659\n\n\nDunn, O. J. (1961). Multiple comparisons among means. Journal of the American Statistical Association, 56, 52–64. https://doi.org/10.1080/01621459.1961.10482090\n\n\nGeschwind, N. (1972). Language and the brain. Scientific American, 226(4), 76–83. https://doi.org/10.1038/scientificamerican0472-76\n\n\nHays, W. L. (1994). Statistics (5th ed.). Harcourt Brace.\n\n\nHolm, S. (1979). A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics, 6, 65–70. https://doi.org/10.2307/4615733\n\n\nHsu, J. C. (1996). Multiple comparisons: Theory and methods. Chapman & Hall. https://doi.org/10.1201/b15074\n\n\nKruskal, W. H., & Wallis, W. A. (1952). Use of ranks in one-criterion variance analysis. Journal of the American Statistical Association, 47, 583–621. https://doi.org/10.1080/01621459.1952.10483441\n\n\nLevene, H. (1960). Robust tests for equality of variances. In Olkin, I. and others (Ed.), Contributions to probability and statistics: Essays in honor of harold hotelling (pp. 278–292). Stanford University Press.\n\n\nShaffer, J. P. (1995). Multiple hypothesis testing. Annual Review of Psychology, 46, 561–584. https://doi.org/10.1146/annurev.ps.46.020195.003021\n\n\nWelch, B. L. (1951). On the comparison of several mean values: An alternative approach. Biometrika, 38, 330–336. https://doi.org/10.1093/biomet/38.3-4.330",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>여러 평균 비교하기 - 일원분산분석</span>"
    ]
  },
  {
    "objectID": "13-Comparing-several-means-one-way-ANOVA.html#footnotes",
    "href": "13-Comparing-several-means-one-way-ANOVA.html#footnotes",
    "title": "13  여러 평균 비교하기 - 일원분산분석",
    "section": "",
    "text": "모든 집단의 관측값 개수가 동일할 때, 실험 설계는 “균형(balance) 잡힌” 설계라고 합니다. 균형 여부는 이 장에서 다루는 일원분산분석에서는 큰 문제가 되지 않지만, 더 복잡한 ANOVA를 수행할 때 중요해집니다.↩︎\n\\(SS_w\\)는 독립 ANOVA에서 오차 분산(error variance) 또는 \\(SS_{error}\\)라고도 불립니다.↩︎\n만약 Chapter 14 에서 요인의 특정 수준 \\(k\\)에서 “처리 효과”가 \\(\\alpha_k\\) 값으로 정의되는 방식을 사용한다면([Factorial ANOVA 2: 균형 설계, 교차항 추가] 참조), \\(Q\\)는 처리 효과의 제곱에 대한 가중 평균으로 표현되됩니다:\\[Q = \\frac{(\\sum_{k=1}^{G}N_k \\alpha_k^2)}{(G-1)}\\].↩︎\n만약 Chapter 14 에서 요인의 특정 수준 \\(k\\)에서 “처리 효과”가 \\(\\alpha_k\\) 값으로 정의되는 방식을 사용한다면([Factorial ANOVA 2: 균형 설계, 교차항 추가] 참조), \\(Q\\)는 처리 효과의 제곱에 대한 가중 평균으로 표현되됩니다:\\[Q = \\frac{(\\sum_{k=1}^{G}N_k \\alpha_k^2)}{(G-1)}\\].↩︎\n정확히 말하면, “1899년이고 친구도 없고, 할 일도 없어서 1899년에는 존재하지도 않았을 ANOVA 계산이나 하는 상황”을 가정하는 것입니다.↩︎\nExcel의 clinicaltrial-anova.xls 파일에서 \\(SS_b\\) 값이 약간 다른 \\(3.45\\)로 나왔습니다. 이는 반올림 오차 때문입니다.↩︎\njamovi의 결과는 위 텍스트에서 계산한 값보다 더 정확합니다. 이는 반올림 오차 때문입니다.↩︎\nhttps://daniellakens.blogspot.com/2015/06/why-you-should-use-omega-squared.html↩︎\n특정 비교를 조사할 이론적 근거가 있다면 상황이 다릅니다. 이러한 경우, 이는 “사후 분석”이 아니라 “계획된 비교(planned comparisons)”가 됩니다. 이 상황에 대해서는 이후 장(Section 14.9)에서 다루지만, 여기서는 논의의 단순성을 유지하겠습니다.↩︎\n모든 조정 방법이 이 방식을 따르는 것은 아닙니다. 여기서 설명한 접근법은 “가족 단위 제1종 오류율(family-wise type I error rate)”을 통제하는 방식입니다. 그러나 “거짓 발견율(false discovery rate)”을 통제하는 것을 목표로 하는 다른 사후 검정 방법도 있습니다.↩︎\n예제 계산을 기억하신다면, 전부 읽지 않았더라도 최소한 훑어보셨기를 바랍니다. 그 내용에서 ANOVA를 뒷받침하는 통계적 모형을 다음과 같이 설명했습니다. \\[H_0:Y_{ik}=\\mu + \\epsilon_{ik}\\] \\[H_1:Y_{ik}=\\mu_k + \\epsilon_{ik}\\] 위 식에서 \\(\\mu\\)는 모든 집단에 대해 동일한 단일 모집단 평균을 의미하며, \\(\\mu_k\\)는 k번째 집단의 모집단 평균을 의미합니다. 지금까지 우리는 데이터가 단일 모집단 평균(귀무가설)으로 가장 잘 설명되는지, 아니면 집단별 평균(대립가설)으로 설명되는지에 주로 관심을 두었습니다. 물론, 이것이 중요한 연구 질문이기 때문에 당연한 접근 방식입니다. 그러나 우리가 수행한 모든 검정 절차는 암묵적으로 잔차 \\(\\epsilon_{ik}\\)에 대한 특정한 가정을 포함하고 있습니다. 즉, \\(\\epsilon_{ik} \\sim Normal(0,\\sigma^2)\\)이라는 가정이 필요합니다. 이 가정 없이는 수학적 계산이 제대로 작동하지 않습니다. 보다 정확히 말하면, 모든 계산을 수행할 수는 있지만, 그 결과로 얻은 \\(F\\) 통계량이 실제로 우리가 측정하려는 것을 반영한다는 보장이 없습니다. 따라서 \\(F\\) 검정을 기반으로 내리는 결론이 잘못될 가능성이 있습니다.↩︎\n그러나 수학적으로 보면, 위의 설명은 불필요하게 복잡합니다. 여기서 유도 과정은 생략하지만, 약간의 대수적 변형을 거치면 \\(K\\)의 공식은 다음과 같이 단순화될 수 있습니다. \\[K=\\frac{12}{N(N-1)}\\sum_k N_k \\bar{R}_k^2 -3(N+1)\\]\n일부 문헌에서는 이 식을 Kruskal-Wallis 검정 통계량 \\(K\\)의 공식으로 제시하기도 합니다. 위에서 설명한 방식보다 계산이 훨씬 간단하지만, 직관적으로 이해하기는 어렵습니다. 따라서 ANOVA의 순위 기반 대안으로서 Kruskal-Wallis 검정을 이해하는 것이 더 적절한 접근법입니다. 그러나 실제로 계산되는 검정 통계량은 ANOVA에서 사용했던 \\(F\\)-통계량과는 다른 형태를 취한다는 점을 기억해야 합니다.↩︎\n\\((n - k)\\): (참가자 수 - 집단 수)↩︎\n이 책의 모든 장과 마찬가지로, 본 장에서도 여러 출처를 참고하였으며, 특히 가장 큰 영향을 준 자료는 (Sahai200?) 입니다. 이는 초보자를 위한 책은 아니지만, ANOVA의 수학적 원리를 깊이 이해하고자 하는 고급 독자에게는 훌륭한 참고 자료입니다.↩︎",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>여러 평균 비교하기 - 일원분산분석</span>"
    ]
  },
  {
    "objectID": "14-Factorial-ANOVA.html",
    "href": "14-Factorial-ANOVA.html",
    "title": "14  요인분산분석",
    "section": "",
    "text": "14.1 요인분산분석 1: 균형 설계, 주효과 분석\nChapter 13 에서 분산분석을 논의할 때, 우리는 비교적 단순한 실험 설계를 가정하였습니다. 각 개인은 여러 집단 중 하나에 속하며, 우리는 이 집단들이 특정 결과변수에 대해 서로 다른 평균 점수를 가지는지 알고자 하였습니다. 이번 절에서는 요인 설계(factorial design)라고 알려진 더 넓은 범주의 실험 설계를 논의하겠습니다. 요인 설계에서는 하나 이상의 집단 변수를 포함하게 됩니다. 앞서 이와 같은 설계가 발생할 수 있는 한 가지 예를 들었습니다. 또 다른 예는 Chapter 13 에서 살펴본 것으로, 서로 다른 약물(drug)이 개인이 경험하는 기분 향상(mood.gain)에 미치는 영향을 연구한 경우입니다. 그 장에서 우리는 약물의 유의한 효과를 발견하였지만, 장의 마지막에서는 치료(therapy)의 효과가 있는지도 분석하였습니다. 치료의 효과는 발견되지 않았지만, 동일한 결과변수를 예측하기 위해 두 개의 별도 분석을 수행하는 것은 다소 걱정스러운 부분이 있습니다. 어쩌면 실제로 치료가 기분 향상에 영향을 미치지만, 약물의 효과에 의해 “숨겨져” 있어서 발견하지 못했을 수도 있습니다. 즉, 약물과 치료를 모두 예측변수로 포함하는 단일 분석을 수행하는 것이 필요합니다.\n이 분석에서 각 개인은 제공받은 약물(3가지 수준을 가지는 요인)과 받은 치료(2가지 수준을 가지는 요인)에 의해 교차 분류됩니다. 이를 \\(3 \\times 2\\) 요인 설계라고 합니다.\njamovi에서 ‘빈도분석’-‘분할표’ 분석을 사용하여 약물과 치료를 교차 집계하면, Figure 14.1 에 나타난 표를 얻을 수 있습니다 (자세한 내용은 Section 6.1 참조).\nFigure 14.1. jamovi에서 생성한 약물과 치료의 교차표\n보시다시피, 두 요인의 가능한 모든 조합에 해당하는 참가자가 존재하므로 완전 교차된(completely crossed) 설계입니다. 또한, 각 집단의 참가자 수가 동일하므로 균형 설계(balanced design)입니다. 이번 절에서는 균형 설계에서 데이터를 분석하는 방법을 다룰 것입니다. 이는 가장 단순한 경우이기 때문입니다. 반면, 불균형 설계(unbalanced design)의 경우 분석 과정이 다소 지루하고 복잡해지므로, 이에 대한 논의는 잠시 미뤄두겠습니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>요인분산분석</span>"
    ]
  },
  {
    "objectID": "14-Factorial-ANOVA.html#요인분산분석-1-균형-설계-주효과-분석",
    "href": "14-Factorial-ANOVA.html#요인분산분석-1-균형-설계-주효과-분석",
    "title": "14  요인분산분석",
    "section": "",
    "text": "Tip 14.1. 실습: Clinical Trial 데이터의 분할표\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Clinical Trial’을 선택합니다.\n스프레드시트 창에서 각 변수의 이름을 더블클릭하여 각 변수의 척도유형과 데이터 유형이 제대로 설정되어 있는지 확인하고 필요하면 이를 정정합니다.\n\n\nID: 아이디, 정수\ndrug, therapy: 명명척도, 문자\nmood.gain: 연속변수, 소수\n\n\n다음 단계를 거쳐 Figure 14.1 같은 drug을 행, therapy를 열로 하는 분할표를 구해봅니다.\n\n\n‘분석’-‘빈도’-‘분할표’-‘독립표본’ 메뉴를 선택합니다.\ndrug을 ‘행’ 상자로, therapy를 열 상자로 이동합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.1.1 가설\n일원분산분석과 마찬가지로, 요인분산분석은 모집단의 평균에 대한 특정 유형의 가설을 검정하는 도구입니다. 따라서 가장 먼저 해야 할 일은 우리가 실제로 어떤 가설을 검정하는지 명확히 하는 것입니다. 하지만 그 전에, 모집단 평균을 표현하는 간결하고 체계적인 표기법을 정하는 것이 유용합니다. 관측값이 두 개의 서로 다른 요인에 의해 교차 분류되기 때문에, 관심을 가질 수 있는 평균이 상당히 많습니다. 이를 이해하기 위해, 먼저 이러한 설계에서 계산할 수 있는 다양한 표본 평균을 생각해 보겠습니다. 가장 먼저 떠오르는 것은 각 집단 평균의 목록(Table 14.1)입니다.\n\n\n\n\nTable 14.1. clinicaltrial.csv 데이터에서 약물 및 치료 집단의 평균값\n\n\n\n\n\ndrugtherapymood.gain\n\nplacebono.therapy0.30\n\nanxifreeno.therapy0.40\n\njoyzepamno.therapy1.47\n\nplaceboCBT0.60\n\nanxifreeCBT1.03\n\njoyzepamCBT1.50\n\n\n\n\n\n\n\n다음으로, Table 14.2 도 두 요인의 가능한 모든 조합에 대한 집단 평균 목록을 보여줍니다(예: 위약을 받고 치료를 받지 않은 사람, 위약을 받고 CBT를 받은 사람 등). 이러한 모든 값과 주변 평균(marginal means), 전체 평균(grand mean)을 하나의 표로 정리하는 것이 도움이 됩니다.\n\n\n\n\nTable 14.2. clinicaltrial.csv 데이터에서 약물 및 치료 집단의 평균과 총 평균\n\n\n\n\n\nno therapyCBTtotal\n\nplacebo0.300.600.45\n\nanxifree0.401.030.72\n\njoyzepam1.471.501.48\n\ntotal0.721.040.88\n\n\n\n\n\n\n\n이러한 평균들은 모두 표본 통계량이며, 연구에서 수집한 특정 관측값을 기반으로 한 수치입니다. 하지만 우리가 관심을 가지는 것은 이와 대응되는 모집단의 모수, 즉 보다 넓은 모집단 내에서 존재하는 참된 평균입니다. 이러한 모집단 평균 또한 유사한 표로 정리할 수 있지만, 이를 위해서는 약간의 수학적 표기법이 필요합니다(Table 14.3). 보통 모집단 평균을 나타낼 때 기호 \\(\\mu\\)를 사용합니다. 하지만 평균이 여러 개 있기 때문에, 이를 구별하기 위해 첨자를 사용해야 합니다.\n\n\n\n\nTable 14.3. 요인표에서 모집단 평균을 나타내는 표기법\n\n\n\n\n\nno therapyCBTtotal\n\nplacebo\\( \\mu_{11} \\)\\( \\mu_{12} \\)\n\nanxifree\\( \\mu_{21} \\)\\( \\mu_{22} \\)\n\njoyzepam\\( \\mu_{31} \\)\\( \\mu_{32} \\)\n\ntotal\n\n\n\n\n\n\n\n표기법에 대하여 설명하자면, 이 표는 두 개의 요인을 기준으로 정의됩니다. 각 행은 요인 A(이 경우 약물)의 서로 다른 수준을 나타내며, 각 열(column)은 요인 B(이 경우 치료)의 서로 다른 수준을 나타냅니다. 만약 \\(R\\)이 표의 행 개수이고, \\(C\\)가 열 개수라면, 이를 \\(R \\times C\\) 요인분산분석이라고 합니다. 이번 경우에는 \\(R = 3\\), \\(C = 2\\)입니다. 특정 행과 열을 나타내기 위해 소문자 첨자를 사용하며, 예를 들어 \\(\\mu_{rc}\\)는 요인 A의 \\(r\\)번째 수준(즉, \\(r\\)번째 행)과 요인 B의 \\(c\\)번째 수준(즉, \\(c\\)번째 열)에 해당하는 모집단 평균을 의미합니다.1\n그렇다면 나머지 항목들은 어떻게 표현할까요? 예를 들어, CBT를 받았는지와 관계없이 Joyzepam을 투여받은 전체 (가상의) 모집단에서 기분 향상의 평균은 어떻게 표현할 수 있을까요? 이를 나타내기 위해 “점(dot) 표기법”을 사용합니다. Joyzepam의 경우, 표의 세 번째 행에 해당하는 평균을 의미하며, 두 개의 셀 평균(\\(\\mu_{31}\\)과 \\(\\mu_{32}\\))을 평균 내어 계산합니다. 이 평균을 주변 평균(marginal mean)이라고 하며, 이를 \\(\\mu_{3.}\\)로 나타냅니다. 마찬가지로, CBT에 대한 주변 평균은 표의 두 번째 열과 관련된 모집단 평균을 의미하며, 모든 행에 대해 평균을 구한 것입니다(즉, 주변화(marginalisation)된 값).2 따라서 모집단 평균을 정리한 전체 표는 Table 14.4 같이 나타낼 수 있습니다.\n\n\n\n\nTable 14.4. 요인표에서 모집단 평균과 총 평균을 나타내는 표기법\n\n\n\n\n\nno therapyCBTtotal\n\nplacebo\\( \\mu_{11} \\)\\( \\mu_{12} \\)\\( \\mu_{1.} \\)\n\nanxifree\\( \\mu_{21} \\)\\( \\mu_{22} \\)\\( \\mu_{2.} \\)\n\njoyzepam\\( \\mu_{31} \\)\\( \\mu_{32} \\)\\( \\mu_{3.} \\)\n\ntotal\\( \\mu_{.1} \\)\\( \\mu_{.2} \\)\\( \\mu_{..} \\)\n\n\n\n\n\n\n\n이제 이러한 표기법을 정의했으므로, 가설을 공식적으로 표현하는 것이 훨씬 쉬워졌습니다. 이번 분석의 목표가 두 가지라고 가정해 보겠습니다. 첫째, 약물 선택이 기분 향상에 영향을 미치는지 확인하는 것입니다. 둘째, CBT가 기분 향상에 영향을 미치는지 확인하는 것입니다. 물론 이 외에도 설정할 수 있는 가설이 많지만, 이후 [요인분산분석 2: 균형 설계, 상호작용 해석]에서 또 다른 중요한 가설의 예를 살펴볼 것입니다. 하지만 지금은 가장 단순한 두 가지 가설부터 시작하겠습니다.\n먼저 약물 효과에 대한 검정을 고려해 보겠습니다. 만약 약물이 영향을 미치지 않는다면, 모든 행 평균이 동일해야 합니다. 따라서 귀무가설은 행 평균이 동일하다는 것입니다. 반면, 약물이 영향을 미친다면 행 평균이 서로 다를 것입니다. 이를 공식적으로 표현하면 다음과 같습니다.\n\\[\\text{귀무가설 } H_0: \\text{ 행 평균이 동일하다, 즉 } \\mu_{1. } = \\mu_{2. } = \\mu_{3. }\\]\n\\[\\text{대립가설 } H_1: \\text{ 적어도 하나의 행 평균이 다르다}\\]\n이 가설들은 사실 Chapter 13 에서 일원분산분석을 수행할 때 설정한 것과 동일합니다. 그때는 \\(\\mu_{P}\\)를 위약 집단의 평균 기분 향상을 나타내는 기호로 사용했으며, \\(\\mu_{A}\\)와 \\(\\mu_{J}\\)는 두 약물 집단의 평균을 의미했습니다. 그때의 귀무가설은 \\(\\mu_{P} = \\mu_{A} = \\mu_{J}\\)이었습니다. 이번에도 동일한 가설을 다루지만, 다중 집단 변수를 고려해야 하므로 더 정교한 표기법이 필요했습니다.\n이제 두 번째 가설 검정을 살펴보겠습니다. 약물과 마찬가지로, 심리 치료가 기분 향상에 영향을 미치지 않는다면 모든 열 평균이 동일해야 합니다. 따라서 귀무가설과 대립가설은 다음과 같이 설정됩니다.\n\\[\\text{귀무가설 } H_0: \\text{ 열 평균이 동일하다, 즉 } \\mu_{ .1} = \\mu_{ .2} \\]\n\\[\\text{대립가설 } H_1: \\text{ 열 평균이 다르다, 즉 } \\mu_{ .1} \\neq \\mu_{ .2}\\]\n\n\n14.1.2 jamovi에서 분석 실행하기\n이전 절에서 설명한 귀무가설과 대립가설이 매우 익숙하게 느껴지실 것입니다. 이는 기본적으로 Chapter 13 에서 일원분산분석을 수행할 때 검정했던 가설과 동일합니다. 따라서 요인분산분석에서 사용하는 가설 검정이 Chapter 13 에서 사용한 \\(F\\)-검정과 본질적으로 동일할 것이라고 예상하실 것입니다. 즉, 제곱합(\\(SS\\)), 평균제곱(\\(MS\\)), 자유도(\\(df\\)), 그리고 최종적으로 \\(p\\)-값으로 변환할 수 있는 \\(F\\)-통계를 확인할 것으로 예상하셨을 것입니다. 네, 정확히 맞습니다. 그래서 이번에는 평소의 접근방식을 바꿔보려 합니다. 이 책에서는 일반적으로 특정 분석을 뒷받침하는 논리(그리고 어느 정도의 수학)를 먼저 설명한 후, jamovi에서 해당 분석을 수행하는 방법을 소개하는 방식으로 설명해 왔습니다. 하지만 이번에는 반대로 jamovi에서 먼저 분석을 수행하는 방법을 보여드리고, 이후에 논의를 진행하려고 합니다. 이렇게 하는 이유는 Chapter 13 에서 논의한 단순한 일원분산분석 도구와 이번 장에서 다룰 보다 복잡한 접근방식 사이의 유사성을 강조하기 위함입니다.\n분석하려는 데이터가 균형 잡힌 요인설계에 해당한다면, 분산분석을 실행하는 것은 매우 간단합니다. 얼마나 쉬운지 확인하기 위해 Chapter 13 에서 수행한 원래 분석을 재현하는 것부터 시작해 보겠습니다. 혹시 잊으셨다면, 해당 분석에서는 단일 요인(즉, drug)을 사용하여 결과변수(즉, mood.gain)를 예측하였으며, Figure 14.2 의 결과를 얻었습니다.\n\n\n\n\n\n\n\n\nFigure 14.2. 약물에 따른 mood.gain의 jamovi 일원분산분석\n\n\n\n\n\n이제 치료가 mood.gain과 관계가 있는지 궁금하다고 가정해 보겠습니다. Chapter 12 에서 다중회귀분석을 논의했을 때 보았던 내용을 고려하면, 분석에서 치료 변수를 두 번째 ’고정 요인’으로 추가하기만 하면 된다는 사실에 놀라지 않으실 것입니다. Figure 14.3 을 참고하십시오.\n\n\n\n\n\n\n\n\nFigure 14.3. 약물과 치료에 따른 mood.gain의 jamovi 이원분산분석\n\n\n\n\n\n이 출력 결과는 읽기 쉽습니다. 표의 첫 번째 행은 약물 요인과 관련된 집단 간 제곱합(\\(SS\\)) 값을 보고하며, 이에 대응하는 집단 간 자유도(\\(df\\)) 값도 포함됩니다. 또한 평균제곱(\\(MS\\)), \\(F\\)-통계량 및 \\(p\\)-값도 계산됩니다. 또한 치료 요인과 관련된 행, 약물 요인과 치료 요인의 상호작용과 관련된 행(이는 아직 다루지 않을 것이며, 나중에 논의할 예정입니다), 그리고 잔차(즉, 집단 내 변동)와 관련된 행도 포함되어 있습니다.\n각 개별 수치는 이미 익숙한 값들이며, 서로 간의 관계도 원래의 일원분산분석에서와 동일합니다. 평균제곱 값은 여전히 제곱합을 해당 자유도로 나눈 값입니다. 즉, 다음 식이 성립합니다.\n\\[MS=\\frac{SS}{df}\\]\n이는 약물, 치료, 혹은 잔차를 다룰 때도 변함이 없습니다. 이를 확인하기 위해 제곱합 값이 어떻게 계산되었는지는 신경 쓰지 말고, jamovi가 \\(SS\\) 값을 올바르게 계산했다고 가정한 후 다른 값들이 논리적으로 맞는지 검증해 보겠습니다. 우선 약물 요인의 경우, \\(3.45\\)를 \\(2\\)로 나누면 평균제곱 값 \\(1.73\\)이 나옵니다. 치료 요인의 경우 자유도가 1이므로 계산이 더욱 간단합니다. \\(0.47\\) (제곱합 값)을 1로 나누면 평균제곱 값 \\(0.47\\)이 됩니다.\n\\(F\\)-통계량과 \\(p\\)-값을 보면, 약물 요인과 치료 요인 각각에 해당하는 값이 존재합니다. 어떤 요인을 다루든지 간에 \\(F\\)-통계량은 해당 요인의 평균제곱 값을 잔차의 평균제곱 값으로 나누어 계산합니다. 약물 요인(Factor A)과 잔차(Factor R)에 대해 다음과 같이 표현할 수 있습니다.\n\\[F_A=\\frac{MS_A}{MS_R}\\]\n치료 요인(Factor B)에도 동일한 공식을 적용할 수 있습니다. 약물 요인에 대해 평균제곱 값 \\(1.73\\)을 잔차의 평균제곱 값 \\(0.05\\)로 나누면, \\(F\\)-통계량이 \\(31.71\\)이 됩니다.3 치료 요인의 경우 \\(0.47\\)을 \\(0.05\\)로 나누면 \\(F\\)-통계량은 \\(8.58\\)이 됩니다. jamovi에서 보고된 값과 동일합니다.\n또한 ANOVA 표에는 \\(p\\)-값 계산이 포함되어 있습니다. 다시 말하지만, 여기에는 새로운 내용이 없습니다. 두 요인 각각에 대해, 우리가 수행하려는 것은 요인과 결과변수 사이에 관계가 없다는 귀무가설을 검정하는 것입니다(이 부분에 대해서는 나중에 좀 더 정확하게 설명하겠습니다). 이를 위해, 우리는 일원배치 분산분석에서 사용했던 것과 유사한 전략을 따라 각 가설에 대한 \\(F\\)-통계량을 계산하였습니다. 이를 \\(p\\)-값으로 변환하려면, 귀무가설 하에서 \\(F\\)-통계량의 표본분포가 \\(F\\)-분포를 따른다는 점을 이용해야 합니다. 또한, 두 개의 자유도는 요인의 자유도와 잔차의 자유도입니다. 약물 요인의 경우, 자유도가 2와 12인 \\(F\\)-분포를 따르며(자유도에 대해서는 나중에 더 자세히 설명하겠습니다), 반면 치료 요인의 경우, 자유도가 1과 12인 \\(F\\)-분포를 따릅니다.\n복잡한 요인분산분석의 ANOVA 표를 해석하는 방식이 단순한 일원분산분석의 ANOVA 표를 해석하는 방식과 크게 다르지 않다는 점을 이해할 수 있었기를 바랍니다. 요약하자면, 우리의 \\(3 \\times 2\\) 설계에 대한 요인분산분석에서 약물 요인(\\(F_{2,12} = 31.71, p &lt; .001\\))과 치료 요인(\\(F_{1,12} = 8.58, p = .013\\)) 모두에서 유의한 효과가 발견되었다는 것을 의미합니다. 보다 기술적으로 정확한 용어를 사용하면, 약물과 치료라는 두 가지의 주효과(main effects)가 있다 라고 말할 수 있습니다. 현재로서는 이러한 효과를 “주효과”라고 부르는 것이 다소 중복적으로 보일 수 있겠지만, 사실 이렇게 부르는 이유가 있습니다. 이후에 두 요인 사이의 “상호작용”을 다룰 것이며, 일반적으로 주효과와 상호작용 효과를 구분하여 설명하기 때문입니다.\n\n\n\n\n\n\nTip 14.2. 실습: 이원분산분석 - 균형 설계\n\n\n\nTip 14.1 에 이어서 균형 설계된 데이터에 대한 이원분산분석을 수행해 봅니다.\n\n‘분석’-‘분산분석’-‘분산분석’ 메뉴를 선택합니다.\n왼쪽의 ‘분산분석’ 설정 창에서 다음을 수행합니다.\n\n\nmood.gain을 ‘종속변수’ 상자로 이동합니다.\ndrug와 therapy를 ‘고정요인’ 상자로 이동합니다.\n‘효과 크기’ 아래의 모든 옵션을 체크합니다.\n‘가설검증’ 옵션을 확장하여 그 아래에 있는 모든 옵션을 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n앞의 결과를 사용하여 다음 질문에 답해 봅시다.\n\n\ndrug는 ’mood.gain`에 영향을 미지치 않는다는 귀무가설은 유의수준 5%에서 채택되는가, 또는 기각되는가? 이 가설검정의 \\(p\\)-값은 얼마인가?\ntherapy는 ’mood.gain`에 영향을 미지치 않는다는 귀무가설은 유의수준 5%에서 채택되는가, 또는 기각되는가? 이 가설검정의 \\(p\\)-값은 얼마인가?\ndrug는 mood.gain의 변동성의 몇 %를 설명하고 있는가?\n이원분산분석은 등분산성 가정을 만족하는 것으로 보이는가?\n이원분산분석은 정규성 가정을 만족하는 것으로 보이는가?\n\n\n\n\n\n14.1.3 제곱합은 어떻게 계산되는가?\n이전 절에서 저는 두 가지 목표를 가지고 있었습니다. 첫째, 요인분산분석을 수행하는 jamovi 방법이 일원분산분석에서 사용했던 방법과 거의 동일하다는 것을 보여주는 것이었습니다. 유일한 차이점은 두 번째 요인이 추가된다는 점입니다. 둘째, 이 경우 ANOVA 표가 어떻게 생겼는지를 보여주어, 요인분산분석의 기본 논리와 구조가 일원분산분석과 동일하다는 것을 처음부터 이해할 수 있도록 하는 것이었습니다. 이러한 감각을 유지하려고 노력해 보십시오. 요인분산분석은 본질적으로 단순한 일원분산분석 모형과 거의 같은 방식으로 구축되므로, 이는 사실입니다. 다만, 세부 사항을 깊이 파고들기 시작하면 이러한 친숙한 느낌이 점차 사라지기 시작합니다. 전통적으로, 이러한 편안한 감각은 통계학 교과서 저자들에게 불만을 표출하고 싶은 충동으로 변화합니다.\n좋습니다. 이제 몇 가지 세부 사항을 살펴보겠습니다. 이전 절에서 설명한 내용은 약물과 치료 요인의 주효과에 대한 가설 검정이 \\(F\\)-검정이라는 사실을 보여주지만, 제곱합(\\(SS\\)) 값이 어떻게 계산되는지는 설명하지 않았습니다. 또한 자유도(\\(df\\)) 값을 구하는 방법을 명확히 설명하지 않았는데, 이는 상대적으로 간단한 과정입니다. 지금은 예측변수로 두 개의 요인, 즉 요인 A와 요인 B만 있는 경우를 가정하겠습니다. 결과변수를 \\(Y\\)라고 하면, \\(Y_{rci}\\)는 집단 \\(rc\\)의 \\(i\\)번째 구성원과 관련된 결과를 나타냅니다(즉, 요인 A의 \\(r\\)번째 수준/행과 요인 B의 \\(c\\)번째 수준/열). 따라서 표본 평균을 \\(\\bar{Y}\\)라고 하면, 이전과 동일한 표기법을 사용하여 집단 평균, 주변 평균(marginal means), 전체 평균(grand mean)을 나타낼 수 있습니다. 즉, \\(\\bar{Y}_{rc}\\)는 요인 A의 \\(r\\)번째 수준과 요인 B의 \\(c\\)번째 수준에 대한 표본 평균이고, \\(\\bar{Y}_{r.}\\)은 요인 A의 \\(r\\)번째 수준에 대한 주변 평균, \\(\\bar{Y}_{.c}\\)는 요인 B의 \\(c\\)번째 수준에 대한 주변 평균, \\(\\bar{Y}_{..}\\)은 전체 평균입니다. 다시 말해, 표본 평균을 모집단 평균과 동일한 표에 정리할 수 있습니다. 임상 시험 데이터의 경우의 평균 표는 Table 14.5 에 제시되어 있습니다.\n\n\n\n\nTable 14.5. 임상 시험 데이터의 표본 평균 표기법\n\n\n\n\n\nno therapyCBTtotal\n\nplacebo\\( \\bar{Y}_{11} \\)\\( \\bar{Y}_{12} \\)\\( \\bar{Y}_{1.} \\)\n\nanxifree\\( \\bar{Y}_{21} \\)\\( \\bar{Y}_{22} \\)\\( \\bar{Y}_{2.} \\)\n\njoyzepam\\( \\bar{Y}_{31} \\)\\( \\bar{Y}_{32} \\)\\( \\bar{Y}_{3.} \\)\n\ntotal\\( \\bar{Y}_{.1} \\)\\( \\bar{Y}_{.2} \\)\\( \\bar{Y}_{..} \\)\n\n\n\n\n\n\n\n이전에 제시한 표본 평균을 보면, \\(\\bar{Y}_{11} = 0.30\\), \\(\\bar{Y}_{12} = 0.60\\) 등입니다. 우리의 임상 시험 예제에서 약물 요인은 3개 수준, 치료 요인은 2개 수준을 가지므로, 실행하려는 분석은 \\(3 \\times 2\\) 요인분산분석입니다. 그러나 우리는 보다 일반적인 형태로, 요인 A(행 요인)가 \\(r\\)개 수준을 가지고, 요인 B(열 요인)가 \\(c\\)개 수준을 가지는 \\(r \\times c\\) 요인분산분석을 수행한다고 표현할 수 있습니다.\n\n추가 기술적 설명\n이제 표기법을 정리했으므로, 두 요인 각각의 제곱합 값을 비교적 익숙한 방식으로 계산할 수 있습니다. 요인 A의 경우, 집단 간 제곱합은 (행) 주변 평균 \\(\\bar{Y}_{1.}, \\bar{Y}_{2.}\\) 등이 전체 평균 \\(\\bar{Y}_{..}\\)과 얼마나 다른지를 평가하여 계산됩니다. 이는 일원분산분석에서 했던 방식과 동일하게, \\(\\bar{Y}_{i.}\\) 값과 \\(\\bar{Y}_{..}\\) 값 간의 제곱 차이를 합산하여 계산됩니다. 구체적으로, 각 집단에 \\(K\\)명의 사람이 있다고 가정하면, 다음과 같이 계산됩니다.\n\\[SS_A=(K \\times C)\\sum_{r=1}^R (\\bar{Y}_{r.}-\\bar{Y}_{..})^2\\]\n일원분산분석과 마찬가지로, 이 공식에서 가장 흥미로운 부분은 수준 \\(r\\)과 관련된 제곱 편차입니다. 이 공식은 요인의 모든 \\(R\\) 수준에 대해 이러한 제곱 편차를 계산하고, 이를 합산한 후 \\(K \\times C\\)를 곱하는 역할을 합니다. 이렇게 하는 이유는 설계 내에서 요인 A의 수준 \\(r\\)에 해당하는 여러 개의 셀이 존재하기 때문입니다. 실제로 요인 B의 가능한 각 수준마다 하나씩 총 \\(C\\)개의 셀이 존재합니다. 예를 들어, 우리의 예제에서는 “anxifree” 약물에 해당하는 두 개의 서로 다른 셀(무치료 집단과 CBT 집단)이 존재합니다. 뿐만 아니라, 각 셀에는 \\(K\\)개의 관측값이 존재합니다. 따라서 \\(SS\\) 값을 “관측값당” 집단 간 제곱합을 계산하는 양으로 변환하려면, \\(K \\times C\\)를 곱해야 합니다. 요인 B의 경우 공식이 동일하지만, 일부 첨자가 바뀝니다.\n\\[SS_B=(K \\times R)\\sum_{c=1}^C (\\bar{Y}_{.c}-\\bar{Y}_{..})^2\\]\n이제 이 공식을 사용하여 이전 절의 jamovi 출력과 비교할 수 있습니다. 이러한 계산을 수행하는 데에는 스프레드시트 프로그램이 유용하므로 직접 시도해 보시기 바랍니다. 또한, Excel에서 수행한 예제는 clinicaltrial_factorialanova.xls 파일에서 확인할 수 있습니다.\n먼저, 약물의 주효과에 대한 제곱합을 계산하겠습니다. 각 집단에는 총 \\(K = 3\\)명의 사람이 있고, 치료법의 종류는 \\(C = 2\\)가지입니다. 즉, 특정 약물을 받은 사람의 수는 \\(3 \\times 2 = 6\\)명입니다. 이 계산을 스프레드시트 프로그램에서 수행하면, 약물의 주요 효과에 대한 제곱합 값이 3.45로 나옵니다. 이는 이전에 제시한 ANOVA 표(Figure 14.3)에서 약물 요인의 \\(SS\\) 값을 확인했을 때 얻는 값과 동일합니다.\n같은 방법으로 치료법의 효과도 계산할 수 있습니다. 이번에도 각 집단에는 \\(K = 3\\)명의 사람이 있지만, 약물의 종류는 \\(R = 3\\)가지이므로, 인지행동치료(CBT)를 받은 사람은 \\(3 \\times 3 = 9\\)명이며, 치료를 받지 않은 사람도 9명입니다. 따라서 이 경우 치료법의 주요 효과에 대한 제곱합 값은 0.47로 계산됩니다. 마찬가지로, 이 값도 ANOVA 표(Figure 14.3)에서 확인한 값과 동일합니다.\n이제 두 주효과에 대한 \\(SS\\) 값을 계산하는 방법을 알게 되었습니다. 이러한 \\(SS\\) 값은 일원분산분석에서 계산한 집단 간 제곱합과 유사합니다(Chapter 13 참고). 그러나 이제는 두 개의 독립적인 집단 변수가 있으므로, 이를 단순히 집단 간 \\(SS\\) 값이라고 생각하는 것은 혼동을 일으킬 수 있습니다.\n\\(F\\) 검정을 수행하려면 집단 내 제곱합도 계산해야 합니다. 회귀 분석(Chapter 12) 장에서 사용했던 용어와 jamovi의 ANOVA 표 출력 방식과 일관성을 유지하기 위해, 이제부터 집단 내 \\(SS\\) 값을 잔차 제곱합(residual sum of squares, \\(SS_R\\))이라고 부르겠습니다. 이 문맥에서 잔차 \\(SS\\) 값을 이해하는 가장 쉬운 방법은, 결과변수의 변동 중 주변 평균의 차이를 고려한 후 남는 변동으로 생각하는 것입니다(즉, \\(SS_A\\)와 \\(SS_B\\)를 제거한 후 남는 변동). 이를 설명하기 위해 먼저 총제곱합을 계산하겠습니다. 이를 \\(SS_T\\)로 표기하며, 그 공식은 일원분산분석에서 사용한 것과 거의 동일합니다. 각 관측값 \\(Y_{rci}\\)와 전체 평균 \\(\\bar{Y}_{..}\\)의 차이를 구한 후 제곱하고, 이를 모두 합산합니다.\n\\[SS_T=\\sum_{r=1}^R \\sum_{c=1}^C \\sum_{i=1}^K (Y_{rci}-\\bar{Y}_{..})^2\\]\n위의 삼중 합 기호는 복잡해 보일 수 있지만, 실제로는 그렇지 않습니다. 첫 번째와 두 번째 합에서는 요인 A의 모든 수준(즉, 표에서 모든 행 \\(r\\))과 요인 B의 모든 수준(즉, 모든 열 \\(c\\))을 합산합니다. 각 \\((r,c)\\) 조합은 하나의 집단을 나타내며, 각 집단에는 \\(K\\)명의 사람이 포함됩니다. 따라서 해당 집단 내 모든 관측값(즉, 모든 \\(i\\) 값)에 대해 합산해야 합니다. 다시 말해, 데이터셋에 포함된 모든 관측값(즉, 모든 가능한 \\(rci\\) 조합)을 합산하는 것입니다.\n이제 결과변수의 전체 변동량(\\(SS_T\\))을 알게 되었고, 그중 요인 A(\\(SS_A\\))와 요인 B(\\(SS_B\\))에 기인하는 변동량도 알게 되었습니다. 따라서 잔차 제곱합은 두 요인(또는 상호작용 효과도 계산하는 경우에는 그 상호작용 효과)으로 설명할 수 없는 \\(Y\\)의 변동량으로 정의됩니다. 즉, 다음과 같습니다.\n\\[SS_R=SS_T-(SS_A+SS_B)\\]\n물론 잔차 제곱합을 직접 계산할 수 있는 공식이 있지만, 개념적으로 위와 같은 방식으로 생각하는 것이 더 이해하기 쉽습니다. “잔차”라고 부르는 이유 자체가 제거하고 남은 변동량이기 때문이며, 위의 공식이 이를 명확히 보여줍니다.\n또한 회귀분석 장에서 사용한 용어와 일관성을 유지하기 위해, \\(SS_A + SS_B\\)를 “ANOVA 모형”에 기인하는 분산으로 간주하는 것이 일반적이며, 이를 \\(SSM\\)으로 표기합니다. 따라서 전체 제곱합은 모형 제곱합과 잔차 제곱합의 합과 같다고 종종 표현합니다.\n이 장에서 이후에 설명하겠지만, 이러한 개념적 유사성은 단순한 표면적인 것이 아닙니다. 사실, 분산분석과 회귀분석은 내부적으로 동일한 원리에 기반을 두고 있습니다. 어쨌든, 위의 공식을 사용하여 \\(SS_R\\)을 계산하고, 우리가 jamovi의 ANOVA 표에서 얻은 값과 동일한 결과가 나오는지 확인해 보는 것이 좋습니다. 이러한 계산은 스프레드시트를 사용하면 비교적 간단하게 수행할 수 있습니다(관련 파일: clinicaltrial_factorialanova.xls).\n\n\n\n14.1.4 자유도\n자유도는 일원분산분석에서 계산하는 방식과 거의 동일합니다. 특정 요인에 대한 자유도는 해당 요인의 수준 개수에서 1을 뺀 값과 같습니다(즉, 행 변수 요인 A의 경우 \\(R - 1\\), 열 변수 요인 B의 경우 \\(C - 1\\)). 따라서, 약물 요인의 자유도는 \\(df = 2\\), 치료법 요인의 자유도는 \\(df = 1\\)입니다.\n이후에 ANOVA를 회귀 모형으로 해석하는 방법(Section 14.6)을 다룰 때, 이러한 자유도 값이 도출되는 과정에 대해 더 명확하게 설명하겠습니다. 하지만 지금은 자유도를 단순히 “관측된 수량의 개수에서 제약 조건의 개수를 뺀 값”으로 정의하여 사용할 수 있습니다. 즉, 약물 요인의 경우 3개의 집단 평균을 관측하지만, 이 값들은 하나의 전체 평균에 의해 제약을 받으므로 자유도는 2가 됩니다.\n\n\n14.1.5 요인분산분석과 일원분산분석 비교\n이제 요인분산분석이 어떻게 작동하는지 살펴보았으므로, 잠시 시간을 내어 이를 일원분산분석 결과와 비교해 보겠습니다. 이렇게 하면 요인분산분석을 수행하는 것이 왜 좋은지 명확하게 이해할 수 있습니다.\nChapter 13 에서 저는 약물 간 차이가 있는지 확인하기 위한 일원분산분석을 수행했고, 치료법 간 차이가 있는지 확인하기 위한 또 다른 일원분산분석을 수행했습니다. Section 14.1.1 에서 살펴본 바와 같이, 일원분산분석에서 검정하는 귀무가설과 대립가설은 요인분산분석에서 검정하는 가설과 사실상 동일합니다.\nANOVA 표를 더 면밀히 살펴보면, 두 분석에서 각 요인에 대한 제곱합은 동일함을 알 수 있습니다(약물 요인의 경우 3.45, 치료법 요인의 경우 0.92). 자유도 역시 동일합니다(약물 요인은 2, 치료법 요인은 1). 하지만 분석 결과는 다릅니다! 특히, Section 13.9 에서 치료법에 대한 일원분산분석을 수행했을 때는 유의한 효과를 발견하지 못했습니다(\\(p\\)-값이 .21이었습니다). 그러나 동일한 데이터를 사용하여 이원분산분석에서 치료법의 주요 효과를 살펴보면 유의한 효과를 발견할 수 있습니다(\\(p = .019\\)). 두 분석이 분명히 동일하지 않다는 것을 알 수 있습니다.\n이러한 차이가 발생하는 이유는 무엇일까요? 그 해답은 잔차가 어떻게 계산되는지 이해하는 데 있습니다. \\(F\\)-검정의 핵심 개념은 특정 요인에 기인하는 변동성과 설명되지 않는 변동성(잔차)을 비교하는 것입니다. 치료법에 대한 일원분산분석을 수행할 때 약물 요인의 영향을 무시하면, ANOVA는 약물로 인해 발생한 변동성을 모두 잔차에 포함시킵니다. 이렇게 되면 실제보다 데이터가 더 노이즈가 많은 것처럼 보이며, 이원분산분석에서는 유의한 것으로 나타나는 치료법의 효과가 일원분산분석에서는 유의하지 않게 됩니다. 즉, 특정 요인(예: 약물 요인)의 영향을 고려하지 않고 다른 요인(예: 치료법 요인)의 기여도를 평가하면, 분석 결과가 왜곡될 수 있습니다.\n물론 연구 대상과 무관한 변수를 무시하는 것은 전혀 문제가 되지 않습니다. 예를 들어, 실험실 벽의 색깔을 기록했는데, 이를 포함한 삼원분산분석(three-way ANOVA)에서 유의한 요인이 아니라고 판명되었다면, 이를 무시하고 더 단순한 이원분산분석을 보고하는 것이 합리적입니다. 하지만 실제로 결과에 영향을 미치는 변수를 제거해서는 안 됩니다!\n\n\n14.1.6 이 분석이 포착하는 결과 유형\n지금까지 논의한 ANOVA 모형은 데이터에서 관찰될 수 있는 다양한 패턴을 설명할 수 있습니다. 예를 들어, 이원분산분석 설계에서는 네 가지 가능한 결과가 있습니다.\n(a) 요인 A만 영향을 미치는 경우, (b) 요인 B만 영향을 미치는 경우, (c) 요인 A와 B 모두 영향을 미치는 경우, (d) 요인 A와 B 모두 영향을 미치지 않는 경우.\n이 네 가지 경우 각각의 예시는 Figure 14.4 그래프로 나타나 있습니다.\n\n\n\n\n\n\n\n\nFigure 14.4. 상호작용이 없는 \\(2 \\times 2\\) ANOVA의 네 가지 가능한 결과. 패널 (a)에서는 요인 A의 주 효과가 나타나며, 요인 B의 효과는 없습니다. 패널 (b)에서는 요인 B의 주 효과가 나타나고, 요인 A의 효과는 없습니다. 패널 (c)에서는 요인 A와 요인 B 모두 주 효과를 가지고 있습니다. 마지막으로, 패널 (d)에서는 어느 요인도 효과가 없습니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>요인분산분석</span>"
    ]
  },
  {
    "objectID": "14-Factorial-ANOVA.html#요인분산분석-2-균형-설계와-상호작용의-해석",
    "href": "14-Factorial-ANOVA.html#요인분산분석-2-균형-설계와-상호작용의-해석",
    "title": "14  요인분산분석",
    "section": "14.2 요인분산분석 2: 균형 설계와 상호작용의 해석",
    "text": "14.2 요인분산분석 2: 균형 설계와 상호작용의 해석\nFigure 14.4 에서 보여주는 네 가지 데이터 패턴은 매우 현실적인 경우입니다. 실제로 이러한 패턴을 정확히 따르는 데이터가 많이 존재합니다. 하지만 이것이 전부는 아니며, 지금까지 논의한 ANOVA 모형만으로는 집단 평균을 완전히 설명할 수 없습니다. 그 이유는 무엇일까요?\n지금까지는 약물이 기분 향상에 영향을 미칠 수 있고, 치료법이 기분 향상에 영향을 미칠 수 있다는 개념을 다룰 수 있었습니다. 하지만 두 요인의 상호작용(교호작용, interaction) 가능성에 대해 이야기할 방법이 없었습니다.\nA와 B 간의 상호작용이 발생한다고 말하는 것은, 요인 \\(A\\)의 효과가 요인 \\(B\\)의 수준에 따라 다르게 나타난다는 의미입니다. \\(2 \\times 2\\) ANOVA에서 상호작용 효과가 발생하는 몇 가지 예시는 Figure 14.5 에 표현되어 있습니다.\n\n\n\n\n\n\n\n\nFigure 14.5. \\(2 \\times 2\\) 분산분석(ANOVA)에 대한 질적으로 다른 상호작용\n\n\n\n\n\n보다 구체적인 예를 들어 설명하겠습니다. Anxifree와 Joyzepam의 작용이 매우 다른 생리학적 기전에 의해 조절된다고 가정해 보겠습니다. 이로 인해 나타나는 한 가지 결과는, Joyzepam은 치료를 받고 있는지 여부와 관계없이 기분에 거의 동일한 영향을 미치는 반면, Anxifree는 CBT와 함께 투여될 때 훨씬 더 효과적이라는 것입니다. 앞 절에서 설명한 분산분석 모형은 이러한 개념을 반영하지 못합니다. 상호작용이 실제로 발생하는지 여부를 파악하기 위해서는 여러 집단의 평균을 그래프로 나타내는 것이 도움이 됩니다. jamovi에서는 ANOVA의 ‘추정된 주변 평균(Estimated Marginal Means)’ 옵션을 통해 이를 수행할 수 있습니다. ‘Term 1’ 아래의 ‘주변 평균(Marginal Means)’ 상자에 약물과 치료 변수를 이동하면 됩니다. 이렇게 하면 Figure 14.6 같은 화면이 나타납니다.\n\n\n\n\n\n\n\n\nFigure 14.6. 임상 시험 데이터를 사용하여 분산분석에서 기술적 상호작용 그래프를 생성하는 방법을 보여주는 jamovi 화면\n\n\n\n\n\n우리의 주요 관심사는 두 개의 선이 평행하지 않다는 사실입니다. 약물이 Joyzepam일 때(오른쪽), CBT의 효과(실선과 점선 사이의 차이)는 거의 0에 가까우며, 심지어 위약을 사용했을 때(왼쪽)보다도 작아 보입니다. 그러나 Anxifree가 투여될 때, CBT의 효과는 위약보다 더 크게 나타납니다(가운데). 이 효과가 실제로 존재하는 것일까요, 아니면 단순한 우연에 의한 무작위 변동일까요? 기존의 ANOVA 모형으로는 이 질문에 답할 수 없습니다. 왜냐하면, 기존 모형에서는 상호작용이 존재할 가능성을 고려하지 않았기 때문입니다! 이번 절에서는 이 문제를 해결해 보겠습니다.\n\n\n\n\n\n\nTip 14.3. 실습: 이원분산분석 - 추정된 주변 평균 검토\n\n\n\nTip 14.2 에 이어서 추정된 주변 평균을 분석해 봅니다.\n\n오른쪽 결과 창에서 ‘분산분석’을 클릭하면 왼쪽에 ’분산분석’ 설정 창이 나타납니다.\n왼쪽의 ‘분산분석’ 설정 창에서 ‘Expected Marginal Means’ 옵션을 확장하여 다음을 수행하면 Figure 14.6 같은 결과를 얻습니다.\n\n\ndrug와 therapy를 ‘Marginal Means’ 상자의 ’Term 1’로 이동합니다.\n‘결과’ 아래의 모든 옵션을 체크합니다.\n\n\n\n\n14.2.1 상호작용 효과란 정확히 무엇인가?\n이번 절에서 소개할 핵심 개념은 상호작용 효과입니다. 지금까지 살펴본 분산분석 모형에는 두 개의 요인(예: 약물과 치료)만 포함되었습니다. 그러나 상호작용을 추가하면 모형에 새로운 요소가 포함됩니다. 즉, 약물과 치료의 조합이 추가되는 것입니다.\n직관적으로 보면, 상호작용 효과의 개념은 비교적 간단합니다. 즉, 요인 A의 효과가 요인 B의 수준에 따라 달라지는 경우를 의미합니다. 그러나 이러한 개념이 실제 데이터에서 어떤 의미를 가지는지 이해하는 것은 조금 더 어렵습니다.\nFigure 14.5 그래프는 여러 가지 유형의 상호작용 패턴을 보여줍니다. 이들은 서로 다르게 보이지만 모두 상호작용 효과에 해당합니다. 따라서 이 개념을 통계적으로 수학적 표현으로 변환하는 것은 다소 복잡합니다.\n\n추가 기술적 설명\n이러한 이유로, 상호작용 효과를 귀무가설과 대립가설의 형태로 공식화하는 과정은 약간 까다롭습니다. 아마도 이 책의 많은 독자들이 이 부분에 큰 관심을 가지지 않을 수도 있습니다. 하지만 기본적인 개념은 간략히 설명해 보겠습니다.\n우선, 주효과에 대해 좀 더 명확히 정의해야 합니다. 예를 들어, 요인 A(이 예제에서는 약물)의 주효과를 고려해 보겠습니다. 우리는 처음에 귀무가설을 세 개의 주변 평균 \\(\\mu_r\\)이 서로 동일하다는 방식으로 정의했습니다. 만약 모든 주변 평균이 동일하다면, 이 값들은 전체 평균 \\(\\mu_{..}\\)과도 같아야 합니다. 따라서, 요인 A의 특정 수준 \\(r\\)에서의 효과를 주변 평균 \\(\\mu_{r.}\\)과 전체 평균 \\(\\mu_{..}\\)의 차이로 정의할 수 있습니다. 이를 수식으로 나타내면 다음과 같습니다.\n\\[\n\\alpha_r=\\mu_{r.}-\\mu_{..}\n\\] 정의에 따라 모든 \\(\\alpha_r\\) 값의 합은 0이 되어야 합니다. 이는 주변 평균들의 평균이 전체 평균과 같아야 하기 때문입니다.\n마찬가지로, 요인 B의 수준 \\(c\\)에서의 효과는 열의 주변 평균 \\(\\mu_{.c}\\)와 전체 평균 \\(\\mu_{..}\\)의 차이로 정의할 수 있습니다.\n\\[\n\\beta_c=\\mu_{.c}-\\mu_{..}\n\\] 모든 \\(\\beta_c\\) 값의 합 역시 0이 됩니다.\n이제, 상호작용 효과가 없는 경우를 정밀하게 정의할 수 있습니다. 만약 상호작용이 없다면, \\(\\alpha_r\\)와 \\(\\beta_c\\) 값만으로 모든 집단 평균 \\(\\mu_{rc}\\)을 완벽하게 설명할 수 있어야 합니다. 즉, 다음과 같은 관계가 성립합니다.\n\\[\n\\mu_{rc}=\\mu_{..}+\\alpha_{r}+\\beta_{c}\n\\] 즉, 주변 평균만 알고 있다면 집단 평균을 정확히 예측할 수 있다는 것입니다. 이것이 바로 귀무가설입니다. 반대로, 대립가설(alternative hypothesis)은 다음과 같습니다.\n\\[\n\\mu_{rc} \\neq \\mu_{..}+\\alpha_{r}+\\beta_{c}\n\\] 즉, 적어도 하나의 집단 \\(rc\\)에서 위 식이 성립하지 않는 경우를 의미합니다.\n통계학자들은 이 표현을 조금 다르게 쓰는 경우가 많습니다. 특정 집단 \\(rc\\)에 대한 상호작용 효과를 \\((\\alpha \\beta)_{rc}\\)로 정의하고, 대립가설을 다음과 같이 표현합니다.\n\\[\n\\mu_{rc}=\\mu_{..} +\\alpha_{r} +\\beta_{c} + (\\alpha \\beta )_{rc}\n\\] 여기서 \\((\\alpha \\beta)_{rc}\\)는 적어도 하나의 집단에서 0이 아닙니다.\n이 표현은 보기에는 다소 복잡하지만, 후에 제곱합을 계산할 때 유용합니다.\n이제, 상호작용 효과의 제곱합 \\(SS_{A:B}\\)을 계산하는 방법을 알아보겠습니다. 우선, 실제 집단 평균이 주변 평균으로부터 얼마나 벗어나 있는지를 통해 상호작용 효과를 정의할 수 있습니다. 앞서 살펴본 수식들은 모집단의 모수를 기반으로 했지만, 우리는 실제 데이터를 다루므로 표본 평균을 사용하여 추정해야 합니다. 따라서 요인 A의 수준 \\(r\\)에서의 주효과는 다음과 같이 추정할 수 있습니다.\n\\[\n\\hat{\\alpha}_r = \\bar{Y}_{r.}-\\bar{Y}_{..}\n\\] 요인 B의 수준 \\(c\\)에서의 주효과는 다음과 같이 정의됩니다.\n\\[\n\\hat{\\beta}_{c}=\\bar{Y}_{.c}-\\bar{Y}_{..}\n\\] 이제, 두 개의 주효과에 대한 \\(SS\\) 값을 설명할 때 사용한 공식을 다시 살펴보면, 해당 효과 항들이 우리가 제곱하여 합산한 값과 정확히 일치한다는 것을 알 수 있습니다. 그렇다면, 상호작용 항의 경우에는 어떻게 표현할 수 있을까요? 이 질문에 대한 답을 찾기 위해, 먼저 대립가설 하에서 집단 평균 \\(\\mu_{rc}\\)에 대한 공식을 다시 정리해 보겠습니다. 그러면 다음과 같은 식을 얻을 수 있습니다.\n\\[\n\\begin{aligned}\n(\\alpha \\beta)_{rc} & = \\mu_{rc} - \\mu_{..} - \\alpha_r - \\beta_c \\\\  \n& = \\mu_{rc} - \\mu_{..} - (\\mu_{r.}-\\mu_{..})-(\\mu_{.c}-\\mu_{..}) \\\\  \n& = \\mu_{rc} - \\mu_{r.} - \\mu_{.c} +\\mu_{..}  \n\\end{aligned}\n\\]\n다시 한번, 모집단의 평균을 표본 평균으로 대체하면, 집단 \\(rc\\)의 상호작용 효과에 대한 추정치로 다음 식을 얻습니다. \\[\n(\\hat{\\alpha \\beta})_{rc}=\\bar{Y}_{rc}-\\bar{Y}_{r.}-\\bar{Y}_{.c}+\\bar{Y}_{..}\n\\]\n이 값을 모든 \\(R\\)개의 요인 A 수준과 \\(C\\)개의 요인 B 수준에 대해 합산하면, 상호작용 항의 제곱합(SS)은 다음과 같이 표현됩니다.\n\\[\nSS_{A:B}=K \\sum_{r=1}^R \\sum_{c=1}^C (\\bar{Y}_{rc}-\\bar{Y}_{r.}-\\bar{Y}_{.c}+\\bar{Y}_{..})^2\n\\] 여기서 \\(K\\)은 각 집단의 표본 크기입니다. 이제, 모형과 잔차의 총 제곱합을 정의할 수 있습니다. 상호작용 항을 포함하면 모형의 총 제곱합(\\(SS_M\\))은 다음과 같이 계산됩니다.\n\\[\nSS_M = SS_A + SS_B + SS_{A:B}\n\\]\n잔차의 제곱합(SSR)은 여전히 남은 변동을 나타내므로 다음과 같이 정의됩니다.\n\\[\nSS_R=SS_T - SS_M = SS_T-(SS_A+SS_B+SS_{A:B})\n\\]\n즉, 상호작용을 포함한 새로운 분산분석에서는 잔차 제곱합 \\(SS_R\\)이 원래의 ANOVA보다 작아집니다.\n\n\n\n14.2.2 상호작용의 자유도\n상호작용의 자유도를 계산하는 것은 주효과의 자유도를 계산하는 것보다 약간 까다롭습니다. 우선, 분산분석 모형 전체를 생각해 보겠습니다. 모형에 상호작용 효과를 포함하면 모든 집단이 고유한 평균 \\(mu_{rc}\\)를 갖도록 허용하는 것입니다. \\(R \\times C\\) 요인 분산 분석에서는 모형에서 고려해야 할 관심 대상이 \\(R \\times C\\)개 존재하며, 단 하나의 제약 조건이 있습니다. 즉, 모든 집단 평균이 전체 평균으로 평균화되어야 한다는 점입니다. 따라서 모형 전체의 자유도는 \\((R \\times C)-1\\)이 됩니다.\n하지만 요인 A의 주효과는 \\(R-1\\)의 자유도를 갖고, 요인 B의 주효과는 \\(C-1\\)의 자유도를 갖습니다. 따라서 상호작용의 자유도는 다음과 같습니다.\n\\[\n\\begin{aligned}\ndf_{A:B} & = (R \\times C - 1) - (R - 1) - (C - 1) \\\\\n& = RC - R - C + 1 \\\\\n& = (R-1)(C-1)\n\\end{aligned}\n\\]\n이는 단순히 행 요인과 열 요인의 자유도의 곱과 같습니다.\n그렇다면 잔차 자유도는 어떻게 될까요? 상호작용 항을 추가하면 일부 자유도가 흡수되므로 남아 있는 잔차 자유도가 줄어듭니다. 구체적으로, 상호작용을 포함한 모형의 총 자유도는 \\((R \\times C) - 1\\)이며, 데이터 집합에 있는 \\(N\\)개의 관측값은 하나의 전체 평균을 만족하도록 제한됩니다. 따라서 잔차 자유도는 \\(N - (R \\times C) - 1 + 1\\)이 되어 결국 \\(N - (R \\times C)\\)가 됩니다.\n\n\n14.2.3 jamovi에서 ANOVA 실행하기\njamovi에서 ANOVA 모형에 상호작용 항을 추가하는 것은 매우 간단합니다. 사실, ANOVA의 기본 옵션이므로 더욱 쉽습니다. 즉, 예를 들어 약물(drug)과 치료(therapy)라는 두 개의 요인을 포함하는 ANOVA를 지정하면, 상호작용 항인 drug \\(\\times\\) therapy가 자동으로 모형에 추가됩니다.4 상호작용 항을 포함한 ANOVA를 실행하면 Figure 14.7 같은 결과를 얻을 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 14.7. 상호작용 항 drug \\(\\times\\) therapy를 포함한 전체 요인 모형의 결과\n\n\n\n\n\n결과를 보면, 약물의 주효과는 유의하게 나타났으며 \\(F_{2,12} = 31.7, p &lt; .001\\)), 치료의 주효과도 유의하게 나타났습니다(\\(F_{1,12} = 8.6, p = .013\\)). 그러나 두 요인의 상호작용 효과는 유의하지 않았습니다(\\(F_{2,12} = 2.5, p = 0.125\\)).\n\n\n14.2.4 결과 해석하기\n요인분산분석 결과를 해석할 때 고려해야 할 몇 가지 중요한 사항이 있습니다.\n첫째, 일원분산분석에서와 마찬가지로, 특정 요인의 주효과(예: 약물 효과)가 유의하다고 해서 어떤 약물의 효과가 서로 다른지를 알 수 있는 것은 아닙니다. 이를 알아내기 위해서는 추가적인 분석을 수행해야 합니다. 이후 대비를 지정하는 다양한 방법 및 사후 검정 절에서 실행할 수 있는 몇 가지 분석 방법을 다룰 것입니다. 이는 상호작용 효과에도 동일하게 적용됩니다. 상호작용 효과가 유의하다고 해서 어떤 종류의 상호작용이 존재하는지를 알 수 있는 것은 아닙니다. 마찬가지로, 추가적인 분석이 필요합니다.\n둘째, 유의한 상호작용 효과는 나타났지만 해당 요인들의 주효과는 유의하지 않은 경우에 대한 해석 문제가 있습니다. 이러한 상황은 가끔 발생합니다. 예를 들어, Figure 14.5(a)에 나타난 교차 상호작용(crossover interaction)에서는 바로 이러한 결과가 나타납니다. 즉, 두 요인의 주효과는 유의하지 않지만, 상호작용 효과는 유의하게 나타납니다. 이는 해석하기 어려운 상황이며, 많은 사람들이 혼란스러워하는 경우가 많습니다. 통계학자들이 일반적으로 제공하는 조언은, 상호작용 효과가 존재하는 경우 주효과에 너무 많은 의미를 부여하지 않는 것이 좋다는 것입니다. 수학적으로 보면 주효과 검정은 완전히 타당하지만, 상호작용 효과가 유의할 때 주효과는 흥미로운 가설을 검정하는 경우가 드뭅니다. Section 14.1.1 에서 논의했듯이, 주효과의 귀무가설은 변인의 주변 평균이 서로 같다는 것입니다. 주변 평균은 여러 다른 집단의 평균을 내어 계산됩니다. 그러나 상호작용 효과가 유의하다는 것은 주변 평균을 구성하는 집단들이 동질적이지 않다는 것을 의미하므로, 동질적이지 않은 집단을 평균하여 만들어지는 주변 평균에 관심을 가질 이유가 분명하지 않을 수도 있습니다.\n이를 임상 연구 예제를 통해 설명해 보겠습니다. 공포증 치료법(예: 체계적 둔감법(systematic desensitisation)과 홍수법(flooding)) 두 가지와 불안 감소 약물(예: Anxifree와 Joyzepam) 두 가지를 비교하는 \\(2 \\times 2\\) 실험 설계를 가정해 보겠습니다. 실험 결과, Anxifree는 둔감법 치료를 받을 때 효과가 없었고, Joyzepam은 홍수법 치료를 받을 때 효과가 없었다고 가정합시다. 하지만 두 약물 모두 다른 치료법에서는 효과가 있었습니다. 이는 전형적인 교차 상호작용이며, ANOVA를 수행하면 약물의 주효과는 유의하지 않지만, 상호작용 효과는 유의하게 나타납니다. 그렇다면, “주효과가 유의하지 않다”는 것이 실제로 의미하는 바는 무엇일까요? 이는 두 가지 심리 치료법을 평균했을 때 Anxifree와 Joyzepam의 평균 효과가 동일하다는 것을 의미합니다. 하지만 이는 실질적으로 중요하지 않습니다. 공포증 치료를 할 때, 환자가 “홍수법과 둔감법의 평균적인 치료”를 받을 수는 없습니다. 즉, 환자는 두 치료법 중 하나만을 받게 됩니다. 한 치료법에서는 한 약물이 효과적이고, 다른 치료법에서는 다른 약물이 효과적입니다. 이 경우 중요한 것은 상호작용 효과이며, 주효과는 별로 의미가 없습니다.\n이러한 상황은 자주 발생합니다. 주효과 검정은 주변 평균을 기준으로 수행되며, 상호작용 효과가 존재하는 경우에는 이러한 주변 평균이 의미를 갖지 않는 경우가 많습니다. 이는 상호작용 효과가 집단 간 차이를 나타내므로, 서로 평균을 내는 것이 적절하지 않기 때문입니다. 물론, 항상 주효과가 무의미한 것은 아닙니다. 때로는 주효과가 크고 상호작용 효과가 작게 나타날 수도 있습니다. 이 경우, “약물 A가 전반적으로 약물 B보다 효과적이다”라고 말할 수 있습니다(즉, 약물의 주효과가 상호작용 효과보다 상대적으로 크기 때문입니다). 다만, “그 효과의 크기는 심리 치료법에 따라 다르다”라는 설명을 추가해야 합니다.\n어떤 경우든, 중요한 점은 상호작용 효과가 유의할 때 주효과가 실제로 어떤 의미를 가지는지를 신중하게 생각해야 한다는 것입니다. 주효과가 자동적으로 중요한 것이라고 가정하지 마십시오.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>요인분산분석</span>"
    ]
  },
  {
    "objectID": "14-Factorial-ANOVA.html#효과-크기",
    "href": "14-Factorial-ANOVA.html#효과-크기",
    "title": "14  요인분산분석",
    "section": "14.3 효과 크기",
    "text": "14.3 효과 크기\n요인분산분석의 효과 크기 계산은 일원분산분석에서 사용한 방법과 상당히 유사합니다(자세한 내용은 효과 크기 절 참조). 특히, \\(\\eta^2\\) (에타 제곱)는 특정 요인의 전체적인 효과 크기를 측정하는 간단한 방법으로 사용할 수 있습니다. 이전과 마찬가지로, \\(\\eta^2\\)는 해당 요인과 관련된 제곱합을 총제곱합으로 나누어 정의됩니다. 예를 들어, 요인 A의 주효과 크기를 결정하려면 다음 공식을 사용합니다.\n\\[\\eta_A^2=\\frac{SS_A}{SS_T}\\]\n이 값은 회귀 분석에서의 \\(R^2\\)과 유사한 방식으로 해석될 수 있습니다.5 즉, 결과변수의 분산 중에서 요인 A의 주효과가 설명하는 비율을 나타냅니다. 따라서 이 값은 0(전혀 효과 없음)에서 1(결과변수의 모든 변동을 설명함) 사이의 숫자가 됩니다. 또한, 모형의 모든 항목에 대한 \\(\\eta^2\\) 값을 합하면, ANOVA 모형의 총 \\(R^2\\) 값이 됩니다. 만약 ANOVA 모형이 완벽하게 맞아떨어진다면(즉, 집단 내 변동이 전혀 없다면!), \\(\\eta^2\\) 값의 합은 1이 됩니다. 물론, 실제 연구에서 이러한 경우는 거의 발생하지 않습니다.\n그러나 요인분산분석을 수행할 때 연구자들이 자주 보고하는 또 다른 효과 크기 지표가 있는데, 이를 부분 에타 제곱(partial \\(\\eta^2\\))이라고 합니다. 부분 \\(\\eta^2\\) (때때로 \\(p^{\\eta^2}\\) 또는 \\(\\eta_p^2\\)로 표기됨)의 개념은 특정 항목(예: 요인 A의 주효과)의 효과 크기를 측정할 때, 모형 내의 다른 효과(예: 요인 B의 주효과)를 의도적으로 무시한다는 것입니다. 즉, 다른 요인들의 효과가 0이라고 가정한 후 \\(\\eta^2\\) 값을 계산하는 것입니다.6\n이 값은 비교적 간단하게 계산할 수 있습니다. 다른 항목과 관련된 제곱합을 분모에서 제거하면 됩니다. 즉, 요인 A의 부분 \\(\\eta^2\\) 값을 구하려면, 분모를 요인 A의 제곱합과 잔차 제곱합의 합으로 설정하면 됩니다.\n\\[\\text{partial }\\eta_A^2= \\frac{SS_A}{SS_A+SS_R}\\]\n이 값은 항상 \\(\\eta^2\\)보다 크게 나오는데, 저의 회의적인 관점에서는 이 때문에 부분 \\(\\eta^2\\)가 널리 사용되는 것 같습니다. 부분 \\(\\eta^2\\)도 0(효과 없음)에서 1(완전한 효과) 사이의 값을 가집니다. 하지만 부분 \\(\\eta^2\\) 값이 클 때 이를 해석하는 것이 다소 까다로울 수 있습니다. 특히, 부분 \\(\\eta^2\\) 값들은 서로 비교할 수 없다는 점을 유의해야 합니다.\n예를 들어, 집단 내 변동이 전혀 없다고 가정해 봅시다(\\(SS_R = 0\\)인 경우). 이 경우, 모든 항목의 부분 \\(\\eta^2\\) 값이 1이 됩니다. 하지만 이것이 모든 항목이 동일하게 중요하거나 크다는 의미는 아닙니다. 단지 모든 항목이 잔차 변동과 비교했을 때 상대적으로 큰 효과 크기를 가진다는 것일 뿐입니다. 즉, 부분 \\(\\eta^2\\) 값들은 서로 비교할 수 없습니다.\n이를 좀 더 명확하게 이해하기 위해 구체적인 예를 살펴보겠습니다. 먼저, Figure 14.3 의 상호작용 요인이 포함되지 않은 ANOVA 결과에서 효과 크기를 살펴보겠습니다(Table 14.6).\n\n\n\n\nTable 14.6. ANOVA 모형에서 상호작용 항이 포함되지 않은 경우의 효과 크기\n\n\n\n\n\neta.sqpartial.eta.sq\n\ndrug0.710.79\n\ntherapy0.100.34\n\n\n\n\n\n\n\n먼저 \\(\\eta^2\\) 값을 살펴보면, 약물(drug)이 기분 향상(mood.gain) 변동의 71%를 설명하는 반면(즉, \\(\\eta^2 = 0.71\\)), 치료법(therapy)는 10%만을 설명합니다. 따라서 19%의 변동은 설명되지 않은 상태로 남아 있습니다(즉, 잔차 변동이 전체 변동의 19%를 차지함). 이는 약물의 효과가 매우 크고7, 치료법의 효과는 상대적으로 작음을 의미합니다.\n이제 부분 \\(\\eta^2\\) 값을 살펴보겠습니다(Figure 14.3). 치료법의 효과가 크지 않기 때문에 이를 통제한다고 해도 큰 차이가 발생하지 않습니다. 따라서 약물의 부분 \\(\\eta^2\\) 값은 크게 증가하지 않으며, \\(p^{\\eta^2} = 0.79\\)가 됩니다. 반면, 약물의 효과가 매우 컸기 때문에 이를 통제하면 치료법의 부분 \\(\\eta^2\\) 값이 크게 증가하여 \\(p^{\\eta^2} = 0.34\\)가 됩니다.\n그렇다면, 이 부분 \\(\\eta^2\\) 값들은 실제로 무엇을 의미할까요? 일반적으로 저는 요인 A의 부분 \\(\\eta^2\\) 값을 해석할 때, 요인 A만을 조작하는 가상의 실험에서 기대할 수 있는 효과 크기를 나타내는 것으로 해석합니다. 즉, 이 실험에서는 요인 A와 B를 모두 조작했지만, 만약 요인 A만 조작한 실험을 상상해 본다면, 해당 실험에서 결과변수의 변동을 얼마나 설명할 수 있는지를 알려주는 값이 됩니다. 그러나 주효과와 관련된 많은 개념들과 마찬가지로, 상호작용 효과가 크고 유의할 경우 이 해석이 적절하지 않을 수도 있습니다.\n이제 상호작용 효과를 포함했을 때의 효과 크기를 살펴보겠습니다(Table 14.7). Figure 14.7 의 모형과 같이 상호작용 항이 포함된 경우의 효과 크기 값은 다음과 같습니다. \\(\\eta^2\\) 값 자체는 변하지 않지만, 부분 \\(\\eta^2\\) 값들은 변합니다.\n\n\n\n\nTable 14.7. ANOVA 모형에서 상호작용 항이 포함된 경우의 효과 크기\n\n\n\n\n\n\\( \\eta^2 \\)부분 \\( \\eta^2 \\)\n\ndrug0.710.84\n\ntherapy0.100.42\n\ndrug*therapy0.060.29\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip 14.4. 실습: 이원분산분석 - 상호작용 요인 제거하기\n\n\n\nTip 14.2 에서 수행한 균형 설계된 데이터에 대한 이원분산분석에서 상호작용 요인을 제거하여 분석해 봅니다.\n\n오른편 결과 창에서 ‘분산분석’을 클릭하면 왼편에 ’분산분석’ 설정 창이 나타납니다.\n상호작용 요인을 제거하기 위하여 왼쪽의 ‘분산분석’ 설정 창에서 다음을 수행합니다.\n\n\n‘모형’ 옵션을 확장하여 ’모형 항’에 있는 drug * therapy 상호작용 항을 왼편으로 이동합니다.\n\n\n\n\n\n\n\n\n\n\n\n상호작용 요인을 다시 넣기 위하여 왼쪽의 ‘분산분석’ 설정 창에서 다음을 수행합니다.\n\n\n‘모형’ 옵션을 확장하여 ’모형 항’에 있는 주성분의 drug와 therapy를 선택한 후, 가운데 두 개의 화상표 중 아래 화살표에서 ’상호작용’을 선택합니다(아래 그림 참조).\n그러면 drug * therapy 교차항이 ’모형 항’에 다시 들어와서 Figure 14.7 결과가 다시 나타납니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.3.1 추정된 집단 평균\n많은 경우 ANOVA 결과에서 모든 집단 평균의 추정값과 신뢰 구간을 보고하고 싶을 것입니다. 이를 위해 jamovi 분산분석에서 ‘추정 주변 평균(Estimated Marginal Means)’ 옵션을 사용할 수 있습니다. Figure 14.8 같이 이를 수행할 수 있습니다.\n만약 실행한 ANOVA가 포화 모형(saturated model)이라면(즉, 가능한 모든 주효과와 모든 상호작용 효과를 포함하는 경우), 집단 평균의 추정값은 실제로 표본 평균과 동일합니다. 다만, 신뢰 구간은 각 집단별로 개별 표준 오차를 사용하는 것이 아니라, 공통으로 추정된 표준 오차를 사용하여 계산됩니다.\n\n\n\n\n\n\n\n\nFigure 14.8. jamovi에서 포화 모형(즉, 상호작용 항 포함)으로 추정된 주변 평균을 보여주는 스크린샷 (임상 시험 데이터셋)\n\n\n\n\n\n출력 결과를 보면, 치료를 받지 않은 위약 집단의 추정된 기분 향상(mood.gain) 평균은 \\(0.300\\)이며, \\(95\\%\\) 신뢰구간은 \\(0.006\\)에서 \\(0.594\\)입니다. 이 신뢰구간은 각 집단에 대해 개별적으로 계산했을 때와 동일하지 않습니다. 이는 ANOVA 모형이 분산의 동질성을 가정하고 있으며, 따라서 공통으로 추정된 표준 편차를 사용하기 때문입니다.\n모형에 상호작용 항이 포함되지 않은 경우, 추정된 집단 평균은 표본 평균과 다르게 나타납니다. jamovi는 표본 평균을 직접 보고하는 대신, 주변 평균을 기반으로 집단 평균 값을 계산합니다(즉, 상호작용이 없다고 가정함).\n이전에 사용한 표기법을 활용하면, 행(row) 요인 A의 수준 \\(r\\)과 열(column) 요인 B의 수준 \\(c\\)에 대한 평균 \\(\\mu_{rc}\\)의 추정값은 다음과 같이 계산됩니다.\n\\[\\mu_{rc} = \\mu_{..} + \\alpha_r + \\beta_c\\]\n만약 두 요인 간의 실제 상호작용이 없다면, 이는 원래 표본 평균보다 모집단 평균을 더 잘 추정하는 방법이 됩니다. jamovi ANOVA 분석의 ‘모형’ 옵션에서 상호작용 항을 제거하면, Figure 14.9 에서 볼 수 있는 분석 결과처럼 주변 평균이 제공됩니다.\n\n\n\n\n\n\n\n\nFigure 14.9. jamovi에서 비포화 모형(즉, 상호작용 항이 없는 경우)의 추정 주변 평균을 보여주는 스크린샷 (임상 시험 데이터셋)\n\n\n\n\n\n\n\n\n\n\n\nTip 14.5. 실습: 이원분산분석 - 추정된 주변 평균 비교\n\n\n\nTip 14.2 에서 수행한 균형 설계된 데이터에 대한 이원분산분석에서 상호작용 요인이 있을 때와 없을 때의 추정된 주변 평균을 비교해 봅니다.\n\n오른편 결과 창에서 ‘분산분석’을 클릭하면 왼편에 ’분산분석’ 설정 창이 나타납니다.\n\n\n추정된 주변 평균에 주목하기 위해서 왼편의 ‘분산분석’ 창에서 ’가정검정’의 모든 옵션의 체크를 해제합니다.\n\n\n왼쪽의 ‘분산분석’ 창에서 ’Estimated Marginal Means` 옵션을 확장하여 집단의 주변 평균을 구해봅니다.\n\n\ndrug와 therapy를 ’Marginal Means’의 ’Term 1’으로 이동합니다.\n‘결과’ 아래의 모든 옵션을 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n상호작용 요인을 제거했을 때의 주변 평균의 추정치를 보기 위하여 왼쪽의 ‘분산분석’ 설정 창에서 다음을 수행합니다.\n\n\n‘모형’ 옵션을 확장하여 ’모형 항’에 있는 drug * therapy 상호작용 항을 왼편으로 이동합니다.\n\n\n\n\n\n\n\n\n\n\n\n상호작용 효과가 있을 때와 없을 때의 집단 평균의 추정치를 비교해 봅니다. 특히 주변 평균 도표에서 상호작용 효과가 없을 때 각 요인의 모든 수준에 대하여 다른 요인의 효과가 동일한 것을 관찰해 봅니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>요인분산분석</span>"
    ]
  },
  {
    "objectID": "14-Factorial-ANOVA.html#가정-검토",
    "href": "14-Factorial-ANOVA.html#가정-검토",
    "title": "14  요인분산분석",
    "section": "14.4 가정 검토",
    "text": "14.4 가정 검토\n일원분산분석과 마찬가지로, 요인분산분석의 주요 가정은 분산의 동질성(모든 집단이 동일한 표준 편차를 가짐), 잔차의 정규성, 관측치의 독립성입니다.\n첫 번째와 두 번째 가정은 검토할 수 있는 항목입니다. 세 번째 가정은 연구자가 직접 평가해야 하며, 예를 들어 독립변수가 시간인 반복측정 실험에서는 시간 1과 시간 2의 관측값이 같은 사람으로부터 나온 것이므로 독립이 아닙니다.\n또한, 포화 모형을 사용하지 않는 경우(예: 상호작용 항을 생략한 경우)에는 여러분은 생략된 항이 중요하지 않다고 가정하는 것입니다. 그러므로 이러한 가정이 적절한 것인지 검토해 보아야 합니다. 생략된 항을 포함한 ANOVA를 실행하여 유의한지 확인할 수 있으므로, 이를 검토하는 것은 비교적 간단합니다.\n그렇다면, 앞에서 언급한 분산의 동질성과 잔차의 정규성은 어떻게 확인할 수 있을까요? 다행히도 이는 일원분산분석에서 수행했던 검토 방법과 다르지 않고 비교적 쉽게 확인할 수 있습니다.\n\n14.4.1 분산의 동질성\n이전 장의 Section 13.6.1 에서 설명한 것처럼, 서로 다른 집단/범주 간의 표준 편차를 시각적으로 비교하는 것이 좋은 방법입니다. 또한, Levene 검정을 수행하여 시각적 검토 결과와 일치하는지 확인하는 것이 좋습니다.\nLevene 검정의 이론적 배경은 Section 13.6.1 에서 다루었으므로, 여기서 다시 설명하지 않겠습니다. 이 검정은 포화 모형(즉, 모든 관련 항을 포함하는 모형)을 가정합니다. 왜냐하면 이 검정은 주로 집단 내 분산과 관련이 있으며, 완전 모형을 기준으로 계산하는 것이 가장 타당하기 때문입니다.\njamovi의 ANOVA 분석에서 ‘가설검증’-‘등분산 검정’ 옵션을 통해 Levene 검정을 수행할 수 있으며, 결과는 Figure 14.10 같이 나타납니다. Levene 검정이 유의하지 않고(즉, 통계적으로 유의한 차이가 없다면), 표준 편차 그래프의 시각적 검토 결과와도 일치하는 경우, 분산의 동질성 가정이 위배되지 않았다고 안전하게 가정할 수 있습니다.\n\n\n14.4.2 잔차의 정규성\n일원분산분석과 마찬가지로, 잔차의 정규성을 확인하는 것은 간단합니다(Section 13.6.4 참고). 우선, QQ 플롯을 사용하여 잔차를 그래픽적으로 검사하는 것이 좋습니다. 자세한 내용은 Figure 14.10 을 참조하십시오.\n\n\n\n\n\n\n\n\nFigure 14.10. ANOVA 모형에서 가정 검토",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>요인분산분석</span>"
    ]
  },
  {
    "objectID": "14-Factorial-ANOVA.html#sec-analysis-of-covariance-ancova",
    "href": "14-Factorial-ANOVA.html#sec-analysis-of-covariance-ancova",
    "title": "14  요인분산분석",
    "section": "14.5 공분산분석 (ANCOVA)",
    "text": "14.5 공분산분석 (ANCOVA)\n분산분석의 변형 중 하나는 종속변수와 관련이 있을 것으로 생각되는 추가적인 연속변수를 포함하는 경우입니다. 이 추가 변수를 공변량(covariate)이라하며 이를 포함한 분석을 공분산분석(ANCOVA, Analysis of Covariance)이라고 합니다.\nANCOVA에서는 종속변수의 값이 공변량의 영향을 고려하여 “조정”되며, 이후 조정된 평균을 사용하여 집단 간 차이를 일반적인 분산분석 방법으로 검정합니다. 이 기법은 실험의 정밀도를 높이고, 종속변수의 집단 평균이 동일한지에 대한 “강한 검정력”으로 수행할 수 있도록 합니다.\nANCOVA가 이를 수행하는 방식은 무엇일까요? 공변량 자체는 일반적으로 실험에서 관심 있는 변수가 아니지만, 공변량을 조정함으로써 실험 오차의 추정값을 줄일 수 있습니다. 오차 분산을 감소시키면 정밀도가 향상되며, 이는 대립가설의 잘못된 기각(2종 오류)이 발생할 가능성을 낮춥니다.\n이러한 장점에도 불구하고, ANCOVA는 집단 간의 실제 차이를 무효화할 위험이 있으며, 이는 피해야 합니다. 예를 들어, Figure 14.11 을 보면 연령에 따른 통계학 불안(statistics anxiety)을 나타내는 그래프가 있으며, 두 개의 뚜렷한 집단(예술(Arts) 또는 과학(Science) 배경을 가진 학생들)을 보여주고 있습니다. 이때, 연령을 공변량으로 설정하여 ANCOVA를 수행하면, 두 집단 간에 통계학 불안 차이가 없다는 결론이 도출될 수 있습니다. 이러한 결론이 합리적일까요? 아마도 그렇지 않을 것입니다. 왜냐하면 두 집단의 연령이 겹치지 않으며, 분산분석이 사실상 “데이터가 없는 영역으로 외삽(extrapolation)한 것”이기 때문입니다 (Everitt (1996), p. 68). 따라서 뚜렷히 구별되는 집단이 존재하는 경우, 공분산분석을 신중하게 수행해야 합니다. 이 점은 일원설계(one-way design)와 요인설계(factorial design) 모두에 적용됩니다. ANCOVA는 두 설계에서 모두 사용할 수 있기 때문입니다.\n\n\n\n\n\n\n\n\nFigure 14.11. 두 개의 뚜렷한 집단에 대한 연령과 통계 불안의 산점도\n\n\n\n\n\n\n14.5.1 jamovi에서 ANCOVA 실행하기\n한 건강 심리학자는 일상적인 자전거 이용과 스트레스가 행복 수준에 미치는 영향을 연구하고자 했으며, 연령을 공변량으로 포함하였습니다. 데이터 파일 ancova.csv에서 해당 데이터를 찾을 수 있습니다. 이 파일을 jamovi에서 열고, ANCOVA를 수행하려면 ‘분석’-‘분산분석’-‘공분산 분석’ 메뉴를 선택하여 ANCOVA 분석 창을 엽니다(Figure 14.12).\n종속변수인 happiness를 선택하여 ‘종속변수’ 입력란으로 이동합니다. 독립 변수인 stress와 commute를 선택하여 ‘고정요인’ 입력란으로 이동합니다. 공변량인 age를 선택하여 ‘독립변수(Covariates의 한글 jamovi의 번역 용어)’8 입력란으로 이동합니다. 그런 다음 ’Estimated Marginal Means’를 클릭하여 그래프 및 표 옵션을 확인합니다.\n\n\n\n\n\n\n\n\nFigure 14.12. jamovi ANCOVA 분석 창\n\n\n\n\n\njamovi 결과 창에서 ’참가자 간 효과의 검정’을 포함한 ANCOVA 표가 생성됩니다 (Figure 14.13). 공변량 age의 \\(F\\)-값이 \\(p = .023\\)에서 유의미하며, 이는 연령이 종속변수인 행복(happiness)의 중요한 예측변수임을 시사합니다.\n추정된 주변 평균을 보면 (Figure 14.14), ANCOVA에 공변량 age가 포함됨에 따라 (공변량이 없는 분석과 비교했을 때) 조정이 이루어졌습니다. 그래프(Figure 14.15)를 활용하면 유의미한 효과를 보다 쉽게 시각화하고 해석할 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 14.13. 연령을 공변량으로 포함한 스트레스와 출퇴근 방식에 따른 행복도의 jamovi ANCOVA 결과\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 14.14. 공변량 연령을 조정한 스트레스와 출퇴근 방식에 따른 평균 행복도 (95% 신뢰구간 포함)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 14.15. 스트레스와 출퇴근 방식에 따른 평균 행복도 그래프\n\n\n\n\n\nstress의 주효과에 대한 \\(F\\)-값은 52.61이며, 관련된 확률 값은 \\(p &lt; .001\\)입니다. 독립 변수 commute의 주효과에 대한 \\(F\\)-값은 42.33이며, 관련된 확률 값은 \\(p &lt; .001\\)입니다.\n이 두 값이 통계적으로 유의한 결과를 판별하는 일반적인 기준인 \\(p &lt; .05\\)보다 작으므로, 스트레스의 주효과가 유의함(\\(F(1, 15) = 52.61, p &lt; .001\\))과 출퇴근 방식의 주효과가 유의함(\\(F(1, 15) = 42.33, p &lt; .001\\))을 결론지을 수 있습니다. 또한 스트레스와 출퇴근 방식 사이의 상호작용 효과 역시 유의하게 나타났습니다 (\\(F(1, 15) = 14.15, p = .002\\)).\nFigure 14.15 에서 ANCOVA에서 연령을 공변량으로 포함했을 때 조정된 주변 평균 행복 점수를 볼 수 있습니다. 이 분석에서는 유의한 상호작용 효과가 나타났으며, 스트레스가 낮고 자전거를 이용하여 출퇴근하는 사람이 스트레스가 낮고 운전하는 사람 및 스트레스가 높은 사람(출퇴근 방식과 관계없이)보다 더 행복하다는 결과를 보여줍니다. 또한, 스트레스의 주효과가 유의하여 스트레스가 낮은 사람이 스트레스가 높은 사람보다 더 행복하다는 결론을 내릴 수 있습니다. 출퇴근 방식의 주효과 또한 유의하여, 자전거를 이용하는 사람이 평균적으로 운전하는 사람보다 더 행복하다는 결과가 도출되었습니다.\n마지막으로, ANOVA에 공변량을 포함하려는 경우 추가적인 가정을 고려해야 합니다. 즉, 공변량과 종속변수의 관계가 모든 요인의 수준에서 유사해야 합니다. 이를 확인하려면 jamovi의 ‘모형’-‘모형 항’ 옵션에서 공변량과 각 요인의 상호작용 항을 추가하여 확인할 수 있습니다. 만약 공변량과 요인의 상호작용 효과가 유의하지 않다면 이를 제거할 수 있습니다. 그러나 상호작용 효과가 유의하다면, 보다 고급 통계 기법을 적용하는 것이 적절할 수 있으며, 이는 본 책의 범위를 벗어나므로 통계 전문가와 상담하는 것이 좋습니다.\n\n\n\n\n\n\nTip 14.6. 실습: 공분산 분석\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’ANCOVA’를 선택합니다.\n스프레드시트 창에서 각 변수의 이름을 더블클릭하여 각 변수의 척도유형과 데이터 유형이 제대로 설정되어 있는지 확인하고 필요하면 이를 정정합니다.\n\n\nhappiness: 연속변수, 소수\nstress, commute: 명명척도, 정수\nage: 연속변수, 정수\n\n\n‘분석’-‘분산분석’-‘공분산 분석’ 메뉴를 선택합니다.\n왼편의 ‘공분산 분석’ 창에서 다음을 수행합니다.\n\n\nhappyness를 ‘종속변수’ 상자로 이동\nstress와 commute를 ‘고정요인’ 상자로 이동\nage를 ‘독립변수’ 상자로 이동\n’효과 크기’의 모든 옵션 체크\n’Estimated Marginal Means옵션을 확장하여stress와commute`를 ’Marginal Means’의 ’Term 1’으로 이동하고 ’결과’의 모든 옵션 체크\n\n\n\n\n\n\n\n\n\n\n6.’가정검증’ 옵션을 확장하여 모든 옵션을 선택한다.\n\n\n\n\n\n\n\n\n\n\n공분산분석의 결과를 보고 다음 물음에 대한 답을 생각해 봅시다.\n\n\nstress와 commute 요인의 happiness에 대한 주효과는 유효수준 5%에서 유의한가?\nage 공변량의 happiness에 대한 효과는 유효수준 5%에서 유의한가?\nhappiness에 대한 stress와 commute의 상호작용 효과는 유효수준 5%에서 유의한가?\n모형의 등분산성과 정규성은 만족되는가?",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>요인분산분석</span>"
    ]
  },
  {
    "objectID": "14-Factorial-ANOVA.html#sec-ANOVA-as-a-linear-model",
    "href": "14-Factorial-ANOVA.html#sec-ANOVA-as-a-linear-model",
    "title": "14  요인분산분석",
    "section": "14.6 선형 모형으로서의 ANOVA",
    "text": "14.6 선형 모형으로서의 ANOVA\nANOVA와 회귀분석에 대해 가장 중요한 점 중 하나는 이 둘이 본질적으로 동일하다는 것입니다. 표면적으로 보면, 이는 사실이 아니라고 생각할 수도 있습니다. 지금까지 설명한 방식에 따르면, ANOVA는 주로 집단 간 차이를 검정하는 데 중점을 두고 있고, 회귀분석은 주로 변수 간의 상관 관계를 이해하는 데 중점을 두고 있기 때문입니다. 그리고 이런 설명 자체는 전적으로 맞는 말입니다. 하지만 이를 더 깊이 들여다보면, 즉 “보닛을 열어 보면” ANOVA와 회귀분석의 기본적인 메커니즘이 상당히 유사하다는 것을 알 수 있습니다. 사실, 이를 곰곰이 생각해 보면, 이미 그러한 증거를 본 적이 있을 것입니다. ANOVA와 회귀 분석 모두 제곱합 (\\(SS\\))을 많이 활용하며, \\(F\\)-검정을 사용하고 있습니다. 되돌아보면, Chapter 12 및 Chapter 13 에서 다룬 내용이 다소 반복적이었다는 느낌을 지울 수 없습니다.\n이러한 이유는 ANOVA와 회귀 분석이 모두 선형 모형의 한 종류이기 때문입니다. 회귀분석의 경우, 이는 비교적 명확합니다. 예측변수와 결과변수의 관계를 정의하는 회귀 방정식은 직선의 방정식이므로, 이는 명백한 선형 모형이며, 그 식은 다음과 같습니다.\n\\[Y_p=b_0+b_1 X_{1p} +b_2 X_{2p} + \\epsilon_p\\]\n여기서 \\(Y_p\\)는 \\(p\\)번째 관찰값(예: \\(p\\)번째 사람)의 결과 값이며, \\(X_{1p}\\)는 \\(p\\)번째 관찰값의 첫 번째 예측변수 값, \\(X_{2p}\\)는 두 번째 예측변수 값, \\(b_0\\), \\(b_1\\), \\(b_2\\)는 회귀 계수, 그리고 \\(\\epsilon_p\\)는 \\(p\\)번째 잔차입니다. 잔차 \\(\\epsilon_p\\)을 무시하고 회귀선 자체에만 집중하면, 다음과 같은 식이 됩니다.\n\\[\\hat{Y}_p=b_0+b_1 X_{1p} +b_2 X_{2p}\\]\n여기서 \\(\\hat{Y}_p\\)는 \\(p\\)번째 사람에 대해 회귀선이 예측하는 \\(Y\\) 값이며, 실제로 관찰된 값 \\(Y_p\\)와는 구별됩니다. 즉시 알아차리기는 어렵지만, 사실 ANOVA 역시 선형 모형으로 표현할 수 있습니다. 그러나 이를 수행하는 것은 비교적 간단합니다. 아주 간단한 예시로, \\(2 \\times 2\\) 요인 ANOVA를 선형 모형으로 다시 작성하는 것부터 시작해 보겠습니다.\n\n14.6.1 데이터\n좀 더 구체적으로 설명하기 위해, 제 강의의 학생의 성적이 결과변수라고 가정해 보겠습니다. 이 변수는 \\(0\\)에서 \\(100\\)까지의 점수로 표현되는 비율척도 변수입니다. 우리가 관심을 두는 두 가지 예측변수는 학생이 강의에 출석했는지 여부(출석 변수)와 교재를 실제로 읽었는지 여부(독서 변수)입니다. 출석 변수(attend)의 경우, 학생이 출석했다면 attend = 1, 출석하지 않았다면 attend = 0이라고 하겠습니다. 마찬가지로, 독서 변수(reading)의 경우, 학생이 교재를 읽었다면 reading = 1, 읽지 않았다면 reading = 0이라고 하겠습니다.\n지금까지는 비교적 단순한 개념입니다. 이제 여기에 수학적 표현을 추가해야 합니다(죄송합니다!). 이 예제에서는 \\(p\\)번째 학생의 성적을 \\(Y_p\\)로 나타내겠습니다. 이는 이 장의 앞에서 사용한 표기법과는 다소 다릅니다. 이전에는 \\(Y_{rci}\\)라는 표기법을 사용하여, 예측변수 1(행 요인)의 \\(r\\)번째 집단과 예측변수 2(열 요인)의 \\(c\\)번째 집단에 속하는 \\(i\\)번째 사람을 나타냈습니다. 이 확장된 표기법은 제곱합(\\(SS\\)) 값을 계산하는 과정을 설명하는 데 유용했지만, 현재 문맥에서는 다소 불편하기 때문에 여기서는 표기법을 변경하겠습니다.\n새로운 표기법인 \\(Y_p\\)는 \\(Y_{rci}\\)보다 시각적으로 단순하지만, 단점은 집단 소속 정보를 유지하지 않는다는 점입니다. 예를 들어, 만약 \\(Y_{0,0,3} = 35\\)라고 하면, 이는 강의에 출석하지 않았고(attend = 0) 교재도 읽지 않은(reading = 0) 한 학생(동일한 조건의 학생 중 3 번째 학생)이 결과적으로 성적이 35점으로 낙제하였다는 것을 즉시 알 수 있습니다. 하지만 \\(Y_p = 35\\)라고 하면, 단순히 \\(p\\)번째 학생의 성적이 좋지 않다는 것만 알 수 있을 뿐입니다. 즉, 중요한 정보를 일부 잃어버리게 됩니다.\n물론, 이러한 문제를 해결하는 것은 어렵지 않습니다. 대신, 이러한 정보를 추적할 수 있도록 두 개의 새로운 변수를 도입하겠습니다. 즉, 출석 여부를 추적하는 변수 \\(X_{1p}\\)와 독서 여부를 추적하는 변수 \\(X_{2p}\\)입니다. 좀 전의 가상의 학생을 예로 들면, 우리는 \\(X_{1p} = 0\\)(즉, attend = 0)이고 \\(X_{2p} = 0\\)(즉, reading = 0)이라는 것을 알고 있습니다. 따라서 데이터는 Table 14.8 같은 형식이 될 것입니다.\n\n\n\n\nTable 14.8. 성적, 출석, 교재 읽기에 대한 데이터\n\n\n\n\n\nperson, \\(p\\)grade, \\(Y_p\\)attendance, \\(X_{1p}\\)reading, \\(X_{2p}\\)\n\n19011\n\n28711\n\n37501\n\n46010\n\n53500\n\n65000\n\n76510\n\n87001\n\n\n\n\n\n\n\n이것은 특별한 것이 아닙니다. 우리가 데이터를 기대하는 바로 그 형식입니다! 데이터 파일 rtfm.csv를 확인해 보십시오. jamovi의 ‘기술 통계’ 분석을 사용하면, 이 데이터셋이 출석과 독서의 모든 조합에 대해 각각 2개의 관찰값을 갖는 균형 설계를 따르고 있음을 확인할 수 있습니다. 같은 방식으로, 각 조합에 대한 평균 성적도 계산할 수 있습니다. 이는 Figure 14.16 에 나타나 있습니다. 평균 점수를 살펴보면, 교재를 읽는 것과 강의에 출석하는 것이 성적에 상당한 영향을 미친다는 강한 인상을 받을 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 14.16. rtfm.csv 데이터셋에 대한 jamovi 기술 통계 분석\n\n\n\n\n\n\n\n\n\n\n\nTip 14.7. 실습: RTFM 데이터\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’RTFM’을 선택합니다.\n스프레드시트 창에서 각 변수의 이름을 더블클릭하여 각 변수의 척도유형과 데이터 유형이 제대로 설정되어 있는지 확인하고 필요하면 이를 정정합니다.\n\n\nA 열의 이름을 persion으로 바꾸고 척도유형과 데이터 유형을 아이디, 정수로 변경\ngrade: 연속변수, 정수\nattend, `reading``: 명명척도, 정수\n\n\n다음 단계를 거쳐 Figure 14.1 같은 기술통계 표를 구해봅니다.\n\n\n‘분석’-‘기술통계’-‘기술통계’ 메뉴를 선택합니다.\ngrade를 ‘변수’ 상자로 옮깁니다.\nattend와 reading을 ‘Split by’ 상자로 이동합니다.\n‘통계’ 옵션을 확장한 후, ’사례수’와 ’평균’만 체크합니다.\n\n\n\n\n\n14.6.2 이항 요인 ANOVA를 회귀 모형으로 표현하기\n이제 다시 수학적인 내용으로 돌아가 보겠습니다. 현재 데이터는 연속 변수 \\(Y\\)와 두 개의 이항 변수 \\(X_1\\) 및 \\(X_2\\)로 표현되어 있습니다. 여기서 중요한 점은, 우리가 다루는 \\(2 \\times 2\\) 요인 ANOVA가 아래의 회귀 모형과 정확히 동일하다는 것입니다.\n\\[Y_p=b_0+b_1 X_{1p} + b_2 X_{2p} + \\epsilon_p\\]\n이는 앞서 설명했던 두 개의 예측변수를 포함하는 회귀 모형과 정확히 같은 식입니다! 단 한 가지 차이점은, 회귀 분석에서는 \\(X_1\\)과 \\(X_2\\)가 일반적으로 연속 변수인 반면, 여기에서는 이항 변수(즉, 값이 0 또는 1만 가능)라는 점입니다. 이를 이해할 수 있도록 여러 가지 방법으로 설명할 수 있습니다. 수학적으로 두 개념이 동일함을 길게 증명할 수도 있지만, 이 책의 대부분의 독자들에게는 오히려 도움이 되기보다는 지루할 것이라 생각됩니다. 대신, 기본적인 개념을 설명한 후, jamovi를 이용해 ANOVA 분석과 회귀 분석이 단순히 유사한 것이 아니라, 사실상 동일하다는 것을 보여드리겠습니다. 우선, ANOVA 분석을 실행해 보겠습니다. 이를 위해 rtfm.csv 데이터셋을 사용하고, jamovi에서 실행한 결과가 Figure 14.17 에 나와 있습니다.\n\n\n\n\n\n\n\n\nFigure 14.17. jamovi에서 상호작용 항을 제외한 rtfm.csv 데이터셋의 ANOVA 분석\n\n\n\n\n\nANOVA 테이블과 앞서 제시한 평균 점수를 참고하면, 강의에 출석한 학생들이 더 높은 성적을 받았으며 (\\(F_{1,5} = 21.6, p = .0056\\)), 교재를 읽은 학생들도 더 높은 성적을 받았다는 것을 확인할 수 있습니다 (\\(F_{1,5} = 52.3, p = .0008\\)). 이러한 \\(p\\)-값과 \\(F\\)-통계를 기록해 두겠습니다.\n이제 동일한 분석을 선형회귀 관점에서 생각해 보겠습니다. rtfm.csv 데이터셋에서 attend와 reading 변수는 숫자로 인코딩되어 있습니다. 여기에서는 이러한 표현이 완전히 적절합니다. 예를 들어, 출석한 학생(attend = 1)은 출석하지 않은 학생(attend = 0)보다 “더 많은 출석”을 했다고 볼 수 있습니다. 따라서 이를 회귀 모형의 예측변수로 포함하는 것은 전혀 무리가 없습니다. 물론 예측변수가 두 개의 값(0 또는 1)만 가질 수 있다는 점에서 다소 특이하지만, 이는 선형 회귀의 가정을 위배하는 것은 아닙니다. 또한, 해석하기도 쉽습니다. 만약 attend 변수의 회귀 계수가 0보다 크다면, 강의에 출석한 학생들의 성적이 더 높다는 것을 의미합니다. 반대로, 0보다 작다면 강의에 출석한 학생들이 더 낮은 성적을 받았다는 뜻이 됩니다. 독서 변수(reading)도 동일한 방식으로 해석할 수 있습니다.\n그런데 왜 이런 결과가 나오는 것일까요? 통계 수업을 몇 번 들은 사람들에게는 직관적으로 명확한 내용일 수 있지만, 처음 접하는 사람들에게는 바로 이해되지 않을 수도 있습니다. 이를 이해하기 위해, 특정 학생 몇 명을 자세히 살펴보겠습니다. 예를 들어, 데이터셋에서 6번째와 7번째 학생(\\(p = 6\\)과 \\(p = 7\\))을 고려해 보겠습니다. 이 두 학생은 모두 교재를 읽지 않았으므로 reading = 0입니다. 수학적 표기법으로 표현하면, \\(X_{2,6} = 0\\)이고 \\(X_{2,7} = 0\\)입니다. 하지만 7번째 학생은 강의에 출석했으며 (\\(X_{1,7} = 1\\)), 6번째 학생은 출석하지 않았습니다 (\\(X_{1,6} = 0\\)).\n이제 이 숫자들을 회귀 직선의 일반 식에 대입해 보겠습니다. 우선, 6번째 학생의 경우 회귀식은 다음과 같이 계산됩니다.\n\\[\n\\begin{split}\n\\hat{Y}_6 & = b_0 + b_1 X_{1,6} + b_2 X_{2,6} \\\\\n& = b_0 + (b_1 \\times 0) + (b_2 \\times 0) \\\\\n& = b_0\n\\end{split}\n\\]\n즉, 이 학생의 예측 성적은 절편 항 \\(b_0\\)의 값과 같습니다. 그렇다면 7번째 학생의 경우는 어떻게 될까요? 이번에는 회귀식에 해당 값을 대입하면 다음과 같은 결과가 나옵니다.\n\\[\n\\begin{split}\n\\hat{Y}_7 & = b_0 + b_1 X_{1,7} + b_2 X_{2,7} \\\\\n& = b_0 + (b_1 \\times 1) + (b_2 \\times 0) \\\\\n& = b_0 + b_1\n\\end{split}\n\\]\n이 학생은 강의에 출석했기 때문에, 예측된 성적은 절편 항 \\(b_0\\)에 출석 변수와 관련된 계수 \\(b_1\\)을 더한 값과 같습니다. 따라서, 만약 \\(b_1\\)이 0보다 크다면, 강의에 출석한 학생들이 출석하지 않은 학생들보다 더 높은 성적을 받을 것으로 예상됩니다. 반대로, 이 계수가 음수라면, 강의에 출석한 학생들이 오히려 더 낮은 성적을 받을 것으로 예상됩니다.\n사실, 이를 조금 더 확장해 볼 수 있습니다. 예를 들어, 강의에 출석하고(\\(X_{1,1} = 1\\)) 교재를 읽은(\\(X_{2,1} = 1\\)) 1번 학생의 경우를 생각해 보겠습니다. 이 값을 회귀식에 대입하면 다음과 같습니다.\n\\[\n\\begin{split}\n\\hat{Y}_1 & = b_0 + b_1 X_{1,1} + b_2 X_{2,1} \\\\\n& = b_0 + (b_1 \\times 1) + (b_2 \\times 1) \\\\\n& = b_0 + b_1 + b_2\n\\end{split}\n\\]\n따라서, 만약 강의에 출석하는 것이 성적을 높이는 데 도움이 된다고 가정하면 (\\(b_1 &gt; 0\\)), 그리고 교재를 읽는 것이 또한 성적을 높이는 데 도움이 된다고 가정하면 (\\(b_2 &gt; 0\\)), 1번 학생의 성적은 6번 학생과 7번 학생보다 높을 것으로 예상됩니다.\n이제 회귀 모형이 강의에 출석하지 않았지만 교재를 읽은 3번 학생에 대해 \\(b_2 + b_0\\)의 성적을 예측한다고 해도 전혀 놀랍지 않을 것입니다. 더 이상의 회귀식을 나열하는 대신, 예상 성적을 보여주는 Table 14.9 을 확인해 보겠습니다.\n\n\n\n\nTable 14.9. 회귀 모형에서 예측된 성적\n\n\n\n\n\n교재 읽기 여부\n\nnoyes\n\n출석 여부no\\( \\beta_0 \\)\\( \\beta_0 + \\beta_2 \\)\n\nyes\\( \\beta_0 + \\beta_1 \\)\\( \\beta_0 + \\beta_1 + \\beta_2 \\)\n\n\n\n\n\n\n\n위에서 볼 수 있듯이, 절편 항 \\(b_0\\)은 강의에 출석하지 않고 교재도 읽지 않은 학생들에게 기대되는 “기준” 성적 역할을 합니다. 마찬가지로, \\(b_1\\)은 강의에 출석함으로써 기대할 수 있는 성적 증가분을 나타내고, \\(b_2\\)는 교재를 읽음으로써 기대할 수 있는 성적 증가분을 나타냅니다. 사실, 이것이 ANOVA 분석이었다면, \\(b_1\\)을 출석의 주 효과로, \\(b_2\\)를 독서의 주 효과로 간주할 수도 있을 것입니다. 실제로, 간단한 \\(2 \\times 2\\) ANOVA에서는 정확히 이러한 방식으로 해석됩니다.\n이제 ANOVA와 회귀 분석이 기본적으로 동일한 개념이라는 것이 점점 더 분명해지고 있으므로, 실제로 rtfm 데이터를 사용하여 회귀 분석을 실행하고, jamovi 회귀 분석을 통해 이것이 정말로 사실인지 확인해 보겠습니다. 일반적인 방법으로 회귀 분석을 실행한 결과는 Figure 14.18 에서 확인할 수 있습니다.\n여기서 주목할 몇 가지 흥미로운 점이 있습니다. 첫째, 절편 항이 43.5로 나타났으며, 이는 교재를 읽지 않고 강의에도 출석하지 않은 두 학생의 평균 성적인 42.5에 근접한 값입니다. 둘째, 출석 변수의 회귀 계수 \\(b_1 = 18.0\\)이며, 이는 강의에 출석한 학생들이 출석하지 않은 학생들보다 18점 높은 성적을 받았음을 시사합니다. 따라서, 강의에 출석했지만 교재를 읽지 않은 학생들의 예상 성적은 \\(b_0 + b_1\\)이며, 이는 \\(43.5 + 18.0 = 61.5\\)가 됩니다. 같은 방식으로 교재를 읽은 학생들의 성적도 검토해 볼 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 14.18. jamovi에서 rtfm.csv 데이터셋의 회귀 분석 (상호작용 항 제외)\n\n\n\n\n\n사실, ANOVA와 회귀분석의 동등성을 좀 더 깊이 살펴볼 수도 있습니다. 회귀분석 결과에서 출석 변수와 독서 변수의 \\(p\\)-값을 확인해 보면, 이는 이전에 ANOVA를 실행했을 때 얻은 값과 동일합니다. 이는 다소 놀라울 수도 있지만, 회귀 분석에서는 \\(t\\)-통계를 사용하고 ANOVA에서는 \\(F\\)-통계를 사용함에도 불구하고, 두 분포 간의 관계를 고려하면 그리 놀라운 일이 아닙니다. Chapter 7 에서 설명한 바와 같이, 자유도가 \\(k\\)인 \\(t\\)-분포를 따르는 어떤 값의 제곱은 자유도가 1과 \\(k\\)인 \\(F\\)-분포를 따릅니다. 우리 회귀 모형에서 출석 변수의 \\(t\\)-값이 4.65인데, 이를 제곱하면 21.6이 됩니다. 이는 ANOVA 분석에서 얻은 해당 변수의 \\(F\\)-통계량과 일치합니다.\n마지막으로 한 가지 더 알아두어야 할 점이 있습니다. jamovi는 ANOVA와 회귀 분석이 모두 선형 모형의 예제임을 이해하고 있기 때문에, ‘선형 회귀분석’-‘모형 계수’-‘모형 검정’-’분산분석 검정’를 사용하여 회귀분석 모형에서 전형적인 ANOVA 테이블을 추출할 수 있습니다. 이를 실행하면 Figure 14.19 를 얻을 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 14.19. jamovi 회귀 분석에서의 Omnibus ANOVA Test 결과\n\n\n\n\n\n\n\n\n\n\n\nTip 14.8. 실습: 이항 요인 ANOVA와 선형회귀 모형 비교\n\n\n\nTip 14.7 실습에 이어서 RTFM 데이터를 사용하여 요인분산분석과 이와 동등한 선형회귀 모형을 만들어 봅니다.\n\n다음 단계를 거쳐 grade의 변동성을 두 요인 attend와 reading으로 요인분산분석을 수행합니다.\n\n\n‘분석’-‘분산분석’-‘분산분석’ 메뉴를 선택\n왼편 ‘분산분석’ 설정 창에서 grade를 ‘종속변수’ 상자로 이동\nattend와 reading을 ‘고정요인’ 상자로 이동\n’효과 크기’의 모든 옵션 선택\n‘모형’ 옵션을 확장한 후, ’모형 항’의 attend * reading 상호작용 항을 왼편으로 이용하여 모형에서 상호작용 효과 제거\n\n\n\n\n\n\n\n\n\n\n\n다음 단계를 거쳐 grade를 attend와 reading으로 선형회귀 분석을 수행합니다.\n\n\n‘분석’-‘회귀분석’-‘선형 회귀분석’ 메뉴를 선택\n왼편 ‘선형 회귀분석’ 설정 창에서 grade를 ‘종속변수’ 상자로 이동\nattend와 reading을 ‘독립변수’ 상자로 이동\n‘모형 계수’ 옵션을 확장하여 다음을 수행\n\n’분산분석 검증’을 선택하여 회귀계수에 대한 분산분석을 수행\n’신뢰구간’을 선택하여 회귀계수의 신뢰구간을 표시\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.6.3 비이항 요인을 대비로서 인코딩하는 방법\n지금까지 \\(2 \\times 2\\) ANOVA를 선형 모형으로 볼 수 있다는 것을 설명하였습니다. 그리고 이것이 \\(2 \\times 2 \\times 2\\) ANOVA 또는 \\(2 \\times 2 \\times 2 \\times 2\\) ANOVA로 일반화되는 방식도 쉽게 이해할 수 있을 것입니다. 사실 같은 개념입니다. 각 요인에 대해 새로운 이항 변수를 추가하면 됩니다. 하지만 두 개 이상의 수준을 가진 요인을 고려할 때는 다소 복잡해집니다. 예를 들어, 이번 장에서 clinicaltrial.csv 데이터를 사용하여 수행한 \\(3 \\times 2\\) ANOVA를 고려해 보겠습니다. 이 세 수준을 가진 약물 요인을 회귀분석에 적합한 수치 형태로 변환하려면 어떻게 해야 할까요?\n이 질문에 대한 답은 사실 간단합니다. 세 수준을 가진 요인은 두 개의 이항 변수로 다시 표현될 수 있다는 점만 깨달으면 됩니다. 예를 들어, 새로운 이항 변수 druganxifree를 생성한다고 가정해 보겠습니다. 이 변수는 “anxifree”일 경우 druganxifree = 1로 설정하고, 그렇지 않으면 0으로 설정합니다. 이 변수는는 anxifree와 나머지 두 약물 사이의 대비(contrast)를 설정합니다. 물론, druganxifree 대비 변수(contrast variable)만으로 약물 변수의 모든 정보를 완벽하게 표현할 수는 없습니다. Joyzepam과 위약을 구별할 수 있도록 두 번째 대비 변수가 필요합니다. 이를 위해, 두 번째 이항 대비 변수 drugjoyzepam을 생성할 수 있습니다. 이 변수는 약물이 joyzepam일 경우 1, 그렇지 않으면 0이 됩니다. 이렇게 두 개의 대비 변수를 함께 사용하면 세 가지 약물을 완벽하게 구별할 수 있습니다. 이에 대한 예시는 Table 14.10 에 나와 있습니다.\n\n\n\n\nTable 14.10. 세 가지 약물을 구별하기 위한 이항 대비 변수\n\n\n\n\n\ndrugdruganxifreedrugjoyzepam\n\n\\(placebo\\)00\n\n\\(anxifree\\)10\n\n\\(joyzepam\\)01\n\n\n\n\n\n\n\n환자에게 투여된 약물이 위약인 경우, 두 개의 대비 변수는 모두 0이 됩니다. 약물이 Anxifree인 경우, druganxifree 변수는 1이 되고, drugjoyzepam 변수는 0이 됩니다. 반대로, Joyzepam의 경우 drugjoyzepam 변수는 1이 되고, druganxifree 변수는 0이 됩니다.\njamovi의 “새 변수 계산” 명령을 사용하면 대비 변수를 쉽게 생성할 수 있습니다. 예를 들어, druganxifree 변수를 생성하려면 “새 변수 계산” 수식 상자에 다음 논리식을 입력하면 됩니다.\n\nIF(drug == ‘anxifree’, 1, 0)\n\n마찬가지로, drugjoyzepam 변수를 생성하려면 다음 논리식을 사용합니다.\n\nIF(drug == ‘joyzepam’, 1, 0)\n\nCBT 치료 변수 CBTtherapy에 대해서도 동일한 방식으로 생성할 수 있습니다.\n\nIF(therapy == ‘CBT’, 1, 0)\n\n이 새로운 변수들과 해당 논리식은 jamovi 데이터 파일 clinicaltrial2.omv에서 확인할 수 있습니다.\n이제 세 수준을 가진 요인을 두 개의 이항 변수로 다시 코딩하였습니다. 그리고 이미 ANOVA와 회귀 분석이 이항 변수에 대해 동일한 방식으로 동작한다는 것을 살펴보았습니다. 그러나 이 경우에는 추가적인 복잡성이 존재하며, 이에 대해서는 다음 절에서 논의하겠습니다.\n\n\n\n\n\n\nTip 14.9. 실습: 대비 변수 생성하기\n\n\n\nClinical Trial 데이터에 대비 변수를 생성해 둔 Clinical Trial 2 데이터가 jamovi 데이터 라이브러리에 있지만, 이 실습에서는 Clinical Trial에서 직접 대비 변수를 설정해 보겠습니다. Tip 14.1 실습에 이어서 두 요인에 대한 대비 변수를 추가해 봅니다.\n\n다음을 수행하여 drug 변수가 anxifree인 경우와 아닌 경우를 대비하는 druganxifree 변수를 추가합니다.\n\n\n‘데이터’-‘추가’-‘다중 계산 변수’-’추가’를 선택하여 계산 변수를 추가합니다.\n생성된 변수의 열이름을 더블클릭하면 ‘다중 계산 변수’ 설정 창이 상단에 나타납니다.\n이름을 druganxifree로 설정합니다.\n\\(f_x\\) 오른편의 수식 상장에 IF(drug == \"anxifree\", 1, 0)을 입력합니다.\n\n\n\n\n\n\n\n\n\n\n\n다음을 수행하여 drug 변수가 joyzepam인 경우와 아닌 경우를 대비하는 drugjoyzepam 변수를 추가합니다.\n\n\n‘데이터’-‘추가’-‘다중 계산 변수’-’추가’를 선택하여 계산 변수를 추가합니다.\n생성된 변수의 열이름을 더블클릭하면 ‘다중 계산 변수’ 설정 창이 상단에 나타납니다.\n이름을 drugjoyzepam로 설정합니다.\n\\(f_x\\) 오른편의 수식 상장에 IF(drug == \"joyzepam\", 1, 0)을 입력합니다.\n\n\n다음을 수행하여 therapy 변수가 CBT인 경우와 아닌 경우를 대비하는 CBTtherapy 변수를 추가합니다.\n\n\n‘데이터’-‘추가’-‘다중 계산 변수’-’추가’를 선택하여 계산 변수를 추가합니다.\n생성된 변수의 열이름을 더블클릭하면 ‘다중 계산 변수’ 설정 창이 상단에 나타납니다.\n이름을 CBTtherapy로 설정합니다.\n\\(f_x\\) 오른편의 수식 상장에 IF(therapy == \"CBT\", 1, 0)을 입력합니다.\n\n\n\n\n\n14.6.4 비이항 요인에 대한 ANOVA와 회귀 분석의 동등성\n이제 동일한 데이터 집합에 대해 두 가지 다른 버전이 있습니다. 하나는 clinicaltrial.csv 파일에서 약물 변수가 단일한 세 수준 요인으로 표현된 원본 데이터이고, 다른 하나는 clinicaltrial2.omv 파일에서 이를 두 개의 이항 대비 변수로 확장한 데이터입니다. 다시 한번 우리가 증명하고자 하는 것은, 원래의 \\(3 \\times 2\\) 요인 ANOVA가 이 대비 변수들을 사용한 회귀 모형과 동등하다는 점입니다. 먼저 ANOVA를 다시 실행해 보겠습니다. 결과는 Figure 14.20 에 나타나 있습니다.\n\n\n\n\n\n\n\n\nFigure 14.20. 상호작용 항목을 포함하지 않은 jamovi ANOVA 결과\n\n\n\n\n\n당연히 여기에는 새로운 내용이 없습니다. 이것은 우리가 앞서 수행한 ANOVA와 동일합니다. 이제 회귀 분석을 실행하되, 예측변수로 druganxifree, drugjoyzepam, CBTtherapy를 사용하겠습니다. 결과는 Figure 14.21 에 나타나 있습니다.\n\n\n\n\n\n\n\n\nFigure 14.21. 대비 변수 druganxifree 및 drugjoyzepam을 포함한 jamovi 회귀 분석 결과\n\n\n\n\n\n이번 출력 결과는 앞서 얻었던 것과 다릅니다. 예상할 수 있듯이, 회귀 분석의 출력은 세 개의 예측변수 각각에 대한 결과를 개별적으로 제시합니다. 기존 ANOVA에서 치료 요인(therapy)에 대한 \\(p\\)-값과 CBTtherapy 변수의 \\(p\\)-값이 동일하다는 점에서, 회귀 모형이 ANOVA와 동일한 작업을 수행하고 있음을 확인할 수 있습니다. 그러나 이 회귀 모형에서는 druganxifree 대비 변수와 drugjoyzepam 대비 변수를 개별적으로 검정하고 있으며, 마치 서로 완전히 독립적인 변수인 것처럼 다루고 있습니다. 이는 당연한 결과입니다. 회귀 분석 자체로는 druganxifree와 drugjoyzepam이 세 수준의 약물 요인을 인코딩하기 위해 사용된 두 개의 대비 변수라는 사실을 알 방법이 없기 때문입니다. 회귀 모형의 입장에서 보면, druganxifree와 drugjoyzepam의 관계는 drugjoyzepam과 CBTtherapy의 관계와 다를 바가 없습니다. 그러나 우리는 이를 알고 있습니다.\n현재 우리의 관심은 두 대비 변수가 개별적으로 유의한지를 평가하는 것이 아닙니다. 우리가 알고 싶은 것은 약물(drug) 요인이 “전반적으로” 효과가 있는지 여부입니다. 즉, jamovi가 두 개의 “약물 관련” 대비 변수를 하나의 묶음으로 처리하여 모형 비교 검정을 수행하도록 설정해야 합니다. 이 방식이 익숙하게 들리시나요? 우리가 해야 할 일은 귀무 모형을 지정하는 것입니다. 이 경우, 귀무 모형에는 CBTtherapy 예측변수를 포함하고, 두 개의 약물 관련 변수를 생략하면 됩니다. 결과는 Figure 14.22 에 나타나 있습니다.\n\n\n\n\n\n\n\n\nFigure 14.22. jamovi 회귀 분석에서의 모형 비교 - 귀무 모형 1과 대립 모형 2 비교\n\n\n\n\n\n이제 제대로 나왔습니다. \\(F\\)-통계량은 26.15이고, 자유도는 2와 14이며, \\(p\\)-값은 0.00002입니다. 이 값들은 원래 ANOVA에서 약물 주효과에 대해 얻었던 값과 동일합니다. 다시 한번 ANOVA와 회귀 분석이 본질적으로 동일하다는 점을 확인할 수 있습니다. 두 분석 모두 선형 모형에 속하며, ANOVA와 회귀 분석의 기저에 있는 통계적 원리는 완전히 동일합니다. 이 사실은 매우 중요하며, 이번 장의 나머지 부분에서도 이를 기반으로 논의를 진행할 것입니다.\n우리는 대비 변수 druganxifree와 drugjoyzepam을 만들기 위해 jamovi에서 새로운 변수를 계산하는 번거로운 작업을 수행했습니다. 이는 ANOVA와 회귀 분석이 본질적으로 동일함을 보여주기 위한 과정이었습니다. 그러나 jamovi의 선형 회귀 분석에서는 이러한 대비 변수를 자동으로 생성하는 편리한 방법이 있습니다. 이를 Figure 14.23 에서 확인할 수 있습니다. jamovi는 예측변수를 요인 그대로 입력할 수 있도록 허용합니다. 매우 스마트한 기능입니다. 또한 ‘준거 수준(Reference Levels)’ 옵션을 통해 기준 수준을 지정할 수도 있습니다. 여기서는 ’placebo’와 ’no.therapy’를 기준 수준으로 설정하였습니다. 이는 가장 논리적인 선택입니다.\n\n\n\n\n\n\n\n\nFigure 14.23. jamovi에서 요인 및 대비 변수를 포함한 회귀 분석 (포괄적 ANOVA 검정 포함)\n\n\n\n\n\n또한 ‘모형 계수’의 ’모형 검정’ 옵션 아래에 있는 ‘분산분석 검정’ 테스트 체크박스를 클릭하면, \\(F\\)-통계량이 26.15, 자유도가 2와 14, \\(p\\)-값이 0.00002로 나타납니다 (Figure 14.23). 이 값들은 원래 ANOVA에서 약물 주효과에 대해 얻었던 값과 정확히 일치합니다. 다시 한번 ANOVA와 회귀 분석이 본질적으로 동일하다는 점을 확인할 수 있습니다. 두 분석 모두 선형 모형이며, ANOVA와 회귀 분석의 기저에 있는 통계적 원리는 완전히 동일합니다.\n\n\n\n\n\n\nTip 14.10. 실습: 비이항 요인 ANOVA와 선형회귀 모형 비교\n\n\n\n요인에 대한 이항 대비 변수를 생성한 Tip 14.9 실습에 이어서 비이항 요인으로 구성된 요인분산분석과 이와 동등한 선형회귀 모형을 만들어 봅니다.\n\n다음 단계를 거쳐 mood.gain의 변동성을 두 요인 drug와 therapy으로 요인분산분석을 수행합니다.\n\n\n‘분석’-‘분산분석’-‘분산분석’ 메뉴를 선택\n왼편 ‘분산분석’ 설정 창에서 mood.gain를 ‘종속변수’ 상자로 이동\ndrug와 therapy를 ‘고정요인’ 상자로 이동\n’효과 크기’의 모든 옵션 선택\n‘모형’ 옵션을 확장한 후, ’모형 항’의 drug * therapy 상호작용 항을 왼편으로 이용하여 모형에서 상호작용 효과 제거\n\n\n\n\n\n\n\n\n\n\n\n\n다음 단계를 거쳐 mood.gain을 대비 변수인 druganxifree, drugjoyzepam, CBTtherapy로 선형회귀 분석을 수행합니다. 그러면 Figure 14.23 같은 결과를 얻습니다.\n\n\n‘분석’-‘회귀분석’-‘선형 회귀분석’ 메뉴를 선택\n왼편 ‘선형 회귀분석’ 설정 창에서 mood.gain을 ‘종속변수’ 상자로 이동\ndrug와 therapy를 ‘요인’ 상자로 이동\n‘준거 수준’ 옵션을 확장하여 각 요인별로 기준이 되는 수준 설정\n\ndrug은 ’placebo’가 기준 수준이 되도록 설정\ntherapy는 ’no.therapy’가 기준 수준이 되도록 설정\n\n‘모형 계수’ 옵션을 확장하여 다음을 수행\n\n’분산분석 검증’을 선택하여 회귀계수에 대한 분산분석을 수행\n’신뢰구간’을 선택하여 회귀계수의 신뢰구간을 표시\n\n\n\n\n\n\n14.6.5 자유도는 모수의 개수\n마침내 자유도에 대한 만족스러운 정의를 내릴 수 있게 되었습니다. 자유도는 모형에서 추정해야 하는 모수의 개수로 정의됩니다. 회귀 모형이나 ANOVA에서는 모수의 개수가 회귀계수(즉 \\(b\\) 값)에 절편을 포함한 개수와 동일합니다. 모든 \\(F\\)-검정은 항상 두 개의 모형을 비교하는 것이므로, 첫 번째 자유도(df)는 모수 개수의 차이입니다. 예를 들어, 앞서 살펴본 모형 비교에서, 귀무 모형 (mood.gain ~ CBTtherapy)에는 두 개의 모수가 있습니다. 하나는 CBTtherapy 변수에 대한 회귀 계수이고, 다른 하나는 절편입니다. 반면 대립 모형 (mood.gain ~ druganxifree + drugjoyzepam + CBTtherapy)에는 네 개의 모수가 있습니다. 세 개의 대비 변수에 대한 회귀 계수가 각각 하나씩 있으며, 절편을 위한 모수가 하나 추가됩니다. 따라서 이 두 모형 사이의 차이에 해당하는 자유도는 \\(df_1 = 4 - 2 = 2\\)입니다.\n그렇다면 귀무 모형이 명확하지 않은 경우는 어떻게 될까요? 예를 들어, ‘선형 회귀분석’-‘모형 적합도’ 옵션에서 ’F 검정(F Test)’을 선택할 때 나타나는 \\(F\\)-검정을 생각해 볼 수 있습니다. 처음에는 이를 전체 회귀 모형에 대한 검정이라고 설명했지만, 사실 이것도 두 개의 모형을 비교하는 것입니다. 귀무 모형은 절편 항만 포함하는 단순한 모형입니다. 반면 대립 모형에는 \\(K + 1\\)개의 회귀 계수가 포함되는데, 여기서 \\(K\\)는 예측변수의 개수이고, 절편을 위한 추가적인 계수가 하나 더 있습니다. 따라서 이 \\(F\\)-검정에서 나타나는 자유도는 \\(df_1 = K + 1 - 1 = K\\)입니다.\n그렇다면 \\(F\\)-검정에서 나타나는 두 번째 자유도 값은 무엇일까요? 이것은 항상 잔차에 해당하는 자유도를 의미합니다. 이 개념을 모수 관점에서 생각하는 것도 가능하지만, 다소 직관에 반하는 방식이 될 수 있습니다. 다음과 같이 생각해 봅시다. 연구 전체에서 총 관측값의 개수가 \\(N\\)이라고 가정합시다. 이 \\(N\\)개의 수치를 완벽하게 기술하려면, 당연히 \\(N\\)개의 수치가 필요할 것입니다. 회귀 모형을 구축한다는 것은 일부 수치만으로 데이터를 설명해야 한다고 지정하는 것과 같습니다. 만약 모형에 \\(K\\)개의 예측변수와 절편이 포함되어 있다면, 총 \\(K + 1\\)개의 수치가 지정된 것입니다. 그러면 정확히 어떤 방식으로 이를 수행할지는 차치하고, \\(K + 1\\)개의 모수를 사용하는 회귀 모형으로 원래 데이터의 완벽한 재기술하도록 변환하려면 얼마나 많은 추가적 수치가 필요할까요? 만약 당신이 \\((K + 1) + (N - K - 1) = N\\)을 떠올렸고, 따라서 그 답이 \\(N - K - 1\\)이라고 생각했다면, 정확합니다!\n이론적으로는 모든 데이터 포인트마다 하나의 모수를 포함하는 극도로 복잡한 회귀 모형을 상상할 수 있으며, 이 모형은 당연히 데이터를 완벽하게 설명할 것입니다. 이 모형은 총 \\(N\\)개의 모수를 포함하지만, 우리가 관심 있는 것은 이러한 완전 모형을 설명하는 데 필요한 모수의 개수(\\(N\\))와 우리가 실제로 관심 있는 단순한 회귀 모형에서 사용된 모수의 개수(\\(K + 1\\))의 차이입니다. 따라서 \\(F\\)-검정에서 두 번째 자유도는 \\(df_2 = N - K - 1\\)이며, 여기서 \\(K\\)는 회귀 모형에서 사용한 예측변수의 개수(또는 ANOVA에서 대비의 개수)입니다. 앞서 제시한 예제에서는 \\(N = 18\\)개의 관측값이 있고, ANOVA 모형과 관련된 회귀 계수의 개수가 \\(K + 1 = 4\\)개이므로, 잔차에 대한 자유도는 \\(df_2 = 18 - 4 = 14\\)입니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>요인분산분석</span>"
    ]
  },
  {
    "objectID": "14-Factorial-ANOVA.html#대비를-지정하는-다양한-방법",
    "href": "14-Factorial-ANOVA.html#대비를-지정하는-다양한-방법",
    "title": "14  요인분산분석",
    "section": "14.7 대비를 지정하는 다양한 방법",
    "text": "14.7 대비를 지정하는 다양한 방법\n이전 절에서는 요인을 여러 개의 대비(contrast)로 변환하는 방법을 설명하였습니다. 앞에서 소개한 방법에서는 이항 변수 집합을 지정하여 Table 14.11 같은 표를 정의하였습니다.\n\n\n\n\nTable 14.11. 세 가지 가능한 약물을 구별하기 위한 이항 대비\n\n\n\n\n\ndrugdruganxifreedrugjoyzepam\n\n\\(placebo\\)00\n\n\\(anxifree\\)10\n\n\\(joyzepam\\)01\n\n\n\n\n\n\n\n이 표에서 각 행은 요인의 한 수준(level)에 해당하며, 각 열은 하나의 대비를 나타냅니다. 이 표는 항상 열보다 행이 하나 더 많으며, 대비 행렬(contrast matrix)이라고 합니다. 하지만 대비 행렬을 지정하는 방법에는 여러 가지가 있습니다. 이번 절에서는 통계학자들이 흔히 사용하는 표준적인 대비 행렬 몇 가지와 jamovi에서 이를 활용하는 방법을 설명하겠습니다. 이후 [요인 ANOVA 3: 불균형 설계(Factorial ANOVA 3: unbalanced designs)] 절을 읽을 계획이라면, 이번 절을 꼼꼼히 읽어 두는 것이 좋습니다. 그렇지 않다면, 대비의 선택이 균형 설계에서는 크게 중요하지 않으므로 대략 훑어봐도 무방합니다.\n\n14.7.1 처리 대비\n앞서 설명한 대비에서는 요인의 한 수준이 특별한 역할을 하며, 일종의 기준(baseline) 범주(예제에서는 위약)가 되어 다른 두 수준을 이와 비교하여 정의합니다. 이러한 유형의 대비를 처리 대비(treatment contrasts) 또는 더미 코딩(dummy coding)이라고 합니다. 이 대비에서 각 수준은 기준 준거 수준(base reference level)과 비교되며, 기준 준거 수준의 값은 모형의 절편의 값이 됩니다.\n이러한 명칭은 요인의 한 범주가 실제로 특별한 의미를 가지며 기준선을 나타내는 경우에 자연스럽고 합리적인 선택이라는 점을 반영합니다. 예를 들어, 임상 시험에서 위약 조건(placebo condition)은 참가자에게 실제 약물을 투여하지 않는 경우이므로 특별한 의미를 가집니다. 따라서 다른 두 조건은 위약과 비교하여 정의됩니다. 한 경우에는 위약을 Anxifree로 대체하고, 다른 경우에는 Joyzepam으로 대체하는 방식입니다.\n위에서 제시한 표는 3 수준 요인에 대한 처리 대비 행렬입니다. 그렇다면, 5 수준 요인에 대한 처리 대비 행렬을 만들고 싶다면 어떻게 해야 할까요? 이에 대한 예시는 Table 14.12 에서 확인할 수 있습니다.\n\n\n\n\nTable 14.12. 5수준 처리 대비 행렬\n\n\n\n\n\n수준2345\n\n10000\n\n21000\n\n30100\n\n40010\n\n50001\n\n\n\n\n\n\n\n이 예제에서 첫 번째 대비는 수준 2와 수준 1을 비교하며, 두 번째 대비는 수준 3과 수준 1을 비교하는 방식으로 계속됩니다. 기본적으로 요인의 첫 번째 수준이 기준 범주로 처리됩니다(즉, 모든 값이 0이며 명시적인 대비로 설정되지 않은 수준). jamovi에서는 ‘데이터 변수’ 창에서 변수의 수준 순서를 조정하여 요인의 첫 번째 수준을 변경할 수 있습니다(스프레드시트 열에서 변수 이름을 두 번 클릭하면 ‘데이터 변수’ 창이 나타납니다).\n\n\n\n\n\n\nTip 14.11. 실습: 처리 대비와 ANOVA\n\n\n\nTip 14.10 실습에 이어서 요인의 기준 수준을 조정하여 처리 대비의 결과를 분산분석에서 확인해 봅니다.\n\n‘데이터’ 창의 스프레드시트에서 drug 열의 수준의 순서를 조정합니다.\n\n\ndrug 열 이름을 더블클릭하면 상단에 ‘데이터 변수’ 설정 창이 나타납니다.\n수준을 나타내는 ’레베’에서 “placebo”를 맨 위로 이동하여 기준 수준이 되도록 합니다.\n\n\n\n\n\n\n\n\n\n\n\n‘데이터’ 창의 스프레드시트에서 therapy 열의 수준의 순서를 조정합니다.\n\n\ntherapy 열 이름을 더블클릭하면 상단에 ‘데이터 변수’ 설정 창이 나타납니다.\n수준을 나타내는 ’레베’에서 “no.therapy”를 맨 위로 이동하여 기준 수준이 되도록 합니다.\n\n\n\n\n\n\n\n\n\n\n\n오른편 ‘결과’ 창에서 ‘분산분석’ 결과를 클릭하면 왼편에 ‘분산분석’ 설정창이 나타납니다.\n\n\n‘대비’ 옵션을 확장하여 drug와 therapy의 대비를 모두 ’Simple’로 설정합니다.\n그러면 오른편 ‘분산분석’ 결과에 ’대비’가 나타나고 기준 수준 대비 다른 수준과의 평균 차이에 대한 분석 결과가 나타납니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.7.2 Helmert 대비\n처리 대비는 다양한 상황에서 유용합니다. 그러나 이러한 대비는 기준이 되는 범주가 명확하게 존재하고, 다른 모든 집단을 그 기준과 비교하려는 경우에 가장 적절합니다. 하지만 어떤 경우에는 이러한 기준 범주가 존재하지 않으며, 각 집단을 다른 집단들의 평균과 비교하는 것이 더 의미가 있을 수 있습니다. 이러한 상황에서 사용되는 것이 Helmert 대비이며, 이는 jamovi의 ‘분산분석’-‘대비’ 옵션에서 ’Helmert’을 선택하여 생성할 수 있습니다.\nHelmert 대비의 기본 개념은 각 집단을 이전 집단들의 평균과 비교하는 것입니다. 즉, 첫 번째 대비는 집단 2와 집단 1의 차이를 나타내며, 두 번째 대비는 집단 3과 집단 1과 2의 평균 사이의 차이를 나타냅니다. 이러한 방식으로 진행되며, 다섯 개의 수준을 가진 요인의 경우 Table 14.13 에 제시된 대비 행렬로 변환됩니다.\n\n\n\n\nTable 14.13. 5개 수준을 가진 Helmert 대비 행렬\n\n\n\n\n\n1-1-1-1-1\n\n21-1-1-1\n\n302-1-1\n\n4003-1\n\n50004\n\n\n\n\n\n\n\nHelmert 대비에서는 모든 대비의 합이 0이 됩니다(즉, 모든 열의 합이 0이 됩니다.). 따라서 ANOVA를 회귀분석의 관점에서 해석할 때, Helmert 대비를 사용하면 절편 항이 전체 평균 \\(\\mu_{..}\\) 에 해당합니다. 반면, 처리 대비를 사용할 경우 절편 항은 기준 범주의 집단 평균에 해당합니다. 지금까지는 균형 설계를 가정했기 때문에 이러한 차이가 크게 중요하지 않지만, 이후 [요인형 ANOVA 3: 불균형 설계]를 다룰 때는 중요한 요소로 작용할 것입니다. 사실, 이 절을 포함한 주요 이유는 불균형 ANOVA를 이해하는 데 있어서 대비가 중요한 역할을 하기 때문입니다.\n\n\n14.7.3 합이 0이 되는 대비 (Sum to zero contrasts)\n세 번째로 간략히 언급해야 할 옵션은 “합이 0이 되는” 대비(sum to zero contrasts)이며, jamovi에서는 “단순(Simple)” 대비라고 불립니다. 이 대비는 집단 간의 쌍별(pairwise) 비교를 수행하는 데 사용됩니다. 구체적으로, 각 대비는 특정 집단과 기준 범주의 차이를 나타냅니다. 다음은 기준 범주가 첫 번째 집단일 때의 단순 대비에 해당합니다 (Table 14.14).\n\n\n\n\nTable 14.14. 5개 수준을 가진 “합이 0이 되는” 대비 행렬\n\n\n\n\n\n1-1-1-1-1\n\n21000\n\n30100\n\n40010\n\n50001\n\n\n\n\n\n\n\nHelmert 대비와 마찬가지로, 각 열의 합이 0이 됩니다. 이는 ANOVA를 회귀 모형으로 해석할 때, 절편이 전체 평균에 해당함을 의미합니다. 이러한 대비를 해석할 때 중요한 점은 각 대비가 집단 1과 다른 네 개 집단 간의 쌍별 비교를 나타낸다는 것입니다.\n\n대비 1: “집단 2 - 집단 1” 비교\n\n대비 2: “집단 3 - 집단 1” 비교\n\n대비 3: “집단 4 - 집단 1” 비교\n\n대비 4: “집단 5 - 집단 1” 비교\n\n처리 대비와 단순 대비의 차이점은 무엇일까요? 예를 들어, 성별 주효과를 고려해 보겠습니다. 남성(\\(m\\))을 0, 여성(\\(f\\))을 1로 설정하면, 처리 대비에서는 계수가 남성과 여성의 평균 차이를 측정하며, 절편은 남성의 평균이 됩니다. 단순 대비에서는 남성을 -1, 여성을 1로 설정하며, 절편은 전체 평균이 되고, 주효과는 각 집단 평균이 절편에서 얼마나 벗어나는지를 나타냅니다.\n\n\n14.7.4 jamovi에서의 대비 옵션\njamovi에서는 ANOVA에서 다양한 유형의 대비를 생성할 수 있는 옵션이 제공됩니다. 이러한 대비 옵션은 ‘분산분석’ 창의 ‘대비’ 옵션에서 확인할 수 있으며, Table 14.15 에 나열되어 있습니다.\n\n\n\n\nTable 14.15. jamovi ANOVA 분석에서 사용 가능한 대비 옵션\n\n\n\n\n\n대비 유형\n\n편차각 수준(참조 범주 제외)의 평균을 전체 수준의 평균(전체 평균)과 비교합니다.\n\n단순처리 대비와 유사하게, 단순 대비는 각 수준의 평균을 지정된 수준의 평균과 비교합니다. 이 대비 유형은 대조군이 있을 때 유용합니다. 기본적으로 첫 번째 범주가 참조입니다. 그러나 단순 대비에서는 절편이 요인의 모든 수준에 대한 전체 평균입니다.\n\n차이첫 번째 수준을 제외한 각 수준의 평균을 이전 수준의 평균과 비교합니다. (때때로 역 헬머트 대비라고도 합니다.)\n\n헬머트마지막 수준을 제외한 각 수준의 평균을 이후 수준의 평균과 비교합니다.\n\n반복마지막 수준을 제외한 각 수준의 평균을 다음 수준의 평균과 비교합니다.\n\n다항식선형 효과와 이차 효과를 비교합니다. 첫 번째 자유도는 모든 범주에 걸친 선형 효과를 포함하고, 두 번째 자유도는 이차 효과를 포함합니다. 이러한 대비는 종종 다항식 경향을 추정하는 데 사용됩니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip 14.12. 실습: 단순 대비와 ANOVA\n\n\n\nTip 14.10 실습에 이어서 요인의 기준 수준을 조정하여 단순 대비의 결과를 분산분석에서 확인해 봅니다.\n\n‘데이터’ 창의 스프레드시트에서 drug 열의 수준의 순서를 조정합니다.\n\n\ndrug 열 이름을 더블클릭하면 상단에 ‘데이터 변수’ 설정 창이 나타납니다.\n수준을 나타내는 ’레베’에서 “placebo”를 맨 위로 이동하여 기준 수준이 되도록 합니다.\n\n\n\n\n\n\n\n\n\n\n\n‘데이터’ 창의 스프레드시트에서 therapy 열의 수준의 순서를 조정합니다.\n\n\ntherapy 열 이름을 더블클릭하면 상단에 ‘데이터 변수’ 설정 창이 나타납니다.\n수준을 나타내는 ’레베’에서 “no.therapy”를 맨 위로 이동하여 기준 수준이 되도록 합니다.\n\n\n\n\n\n\n\n\n\n\n\n오른편 ‘결과’ 창에서 ‘분산분석’ 결과를 클릭하면 왼편에 ‘분산분석’ 설정창이 나타납니다.\n\n\n‘대비’ 옵션을 확장하여 drug와 therapy의 대비를 모두 ’Simple’로 설정합니다.\n그러면 오른편 ‘분산분석’ 결과에 ’대비’가 나타나고 기준 수준 대비 다른 수준과의 평균 차이에 대한 분석 결과가 나타납니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>요인분산분석</span>"
    ]
  },
  {
    "objectID": "14-Factorial-ANOVA.html#sec-Post-hoc-tests",
    "href": "14-Factorial-ANOVA.html#sec-Post-hoc-tests",
    "title": "14  요인분산분석",
    "section": "14.8 사후 검정",
    "text": "14.8 사후 검정\n이제 다른 주제로 넘어가 보겠습니다. 대비를 사용하여 사전에 계획된 비교를 수행하는 대신, ANOVA를 수행하여 유의한 효과를 발견했다고 가정해 보겠습니다. \\(F\\)-검정은 “일괄(omnibus)” 검정으로서 여러 집단 사이의 차이가 없다는 귀무가설을 검정합니다. 따라서 유의한 효과가 나타났다고 해서 어떤 집단 사이에 차이가 있는지를 즉시 알 수 있는 것은 아닙니다.\n이 문제는 Chapter 13 에서 이미 논의한 바 있습니다. 그 장에서의 해결 방법은 가능한 모든 집단 쌍들에 대해 \\(t\\)-검정을 수행하고, 다중 비교 전체의 일종 오류를 통제하기 위해 본페로니 또는 Holm 방법을 사용하여 \\(p\\)-값을 보정하였습니다. 이러한 방법들은 상대적으로 단순하며, 여러 가설을 검정하는 다양한 상황에서 사용할 수 있는 일반적인 도구라는 장점이 있습니다. 그러나 ANOVA의 사후 검정을 보다 효율적으로 수행하려는 경우, 최적의 선택은 아닐 수 있습니다. 실제로 다중 비교를 수행하는 다양한 방법이 통계학 문헌에서 논의되어 왔으며(Hsu, 1996), 이 입문서에서 모든 방법을 상세히 설명하는 것은 범위를 벗어나는 일입니다.\n그럼에도 불구하고, 주목할 만한 중요한 도구가 하나 있습니다. 바로 Tukey의 “정직한 유의 차이”(Honestly Significant Difference) 또는 Tukey의 HSD라고 불리는 방법입니다. 이번에는 수식을 생략하고 개념적인 내용만 설명하겠습니다. Tukey의 HSD는 모든 집단 쌍 사이의 비교를 수행하는 방법입니다. 따라서 모든 두 집단 사이의 차이가 관심일 경우에만 Tukey의 HSD를 사용하는 것이 적절합니다.9 예를 들어, 앞에서 clinicaltrial.csv 데이터 세트를 사용하여 요인분산분석을 수행했습니다. 약물과 치료법의 주효과를 검정하는 경우, 다음 네 가지 비교에 관심을 가질 수 있습니다.\n\nAnxifree를 투여받은 사람과 위약을 투여받은 사람의 기분 향상 차이\n\nJoyzepam을 투여받은 사람과 위약을 투여받은 사람의 기분 향상 차이\n\nAnxifree를 투여받은 사람과 Joyzepam을 투여받은 사람의 기분 향상 차이\n\n인지행동치료(CBT)를 받은 사람과 아무 치료도 받지 않은 사람의 기분 향상 차이\n\n이러한 비교에서 관심을 가지는 것은 각 집단의 (모집단) 평균의 차이입니다. Tukey의 HSD는 이 모든 비교에 대해 동시신뢰구간(simultaneous confidence intervals)을 제공합니다. 여기서 “95% 동시신뢰구간”이란, 만약 이 연구를 여러 번 반복할 경우 95%의 경우에 해당 신뢰구간이 참값을 포함한다**는 의미입니다. 또한, 이 신뢰구간을 사용하여 특정 비교에 대한 조정된 \\(p\\)-값을 계산할 수 있습니다.\njamovi에서 Tukey의 HSD를 수행하는 것은 매우 쉽습니다. ‘분산분석’ 모형에서 ‘사후 검정’을 수행하려는 항을 지정하기만 하면 됩니다. 예를 들어, 주효과에 대한 사후 검정을 수행하고 상호작용 효과는 고려하지 않는 경우, ’분산분석’ 창의 ‘사후 검정’ 옵션을 열어 drug 및 therapy 변수를 선택한 후 ‘Tukey’ 옵션을 체크하면 됩니다. 이와 관련된 결과 표는 Figure 14.24 에 제시되어 있습니다.\n\n\n\n\n\n\n\n\nFigure 14.24. jamovi 요인배치 ANOVA에서 상호작용 효과 없이 수행한 Tukey HSD 사후 검정\n\n\n\n\n\n‘사후 검정’ 결과 표는 비교적 직관적입니다. 예를 들어, Anxifree 대 위약의 비교 결과를 보면, 관측된 집단 간 평균 차이는 \\(0.27\\)입니다. 그다음 값은 표준오차로, 이를 사용하여 95% 신뢰구간을 계산할 수 있지만, jamovi에서는 제공하지 않습니다. 이후 자유도, \\(t\\)-값, \\(p\\)-값이 제시됩니다. 이 비교에서 조정된 \\(p\\)-값은 \\(0.21\\)입니다. 반면, Joyzepam 대 위약의 비교에서는 관측된 평균 차이는 \\(1.03\\)이며, \\(p\\)-값이 \\(0.001\\)보다 작아서 유의한 차이가 있음이 확인됩니다.\n지금까지는 상호작용 효과 없이 사후 검정을 수행했습니다. 그러나 jamovi의 기본 옵션은 약물과 치료법의 상호작용 항을 포함하는 것입니다. 이 경우, 고려해야 할 쌍별 비교의 수가 증가합니다. 앞에서는 약물 주효과에 대한 3개의 비교와 치료법 주효과에 대한 1개의 비교가 있었습니다.\n상호작용 효과를 분석하고 상호작용 집단 사이의 차이를 분석하려면 다음과 같은 비교도 추가해야 합니다.\n\nAnxifree + CBT 치료를 받은 집단과 위약 + CBT 치료를 받은 집단의 기분 향상 차이\n\nAnxifree + 치료 없음 집단과 위약 + 치료 없음 집단의 기분 향상 차이\n\n등등…\n\n이처럼 고려해야 할 비교가 많아집니다.\n실제로, Tukey 사후 검정을 수행하면 총 19개의 쌍별 비교가 이루어지며, 결과는 Figure 14.25 에 나타나 있습니다.\n\n\n\n\n\n\n\n\nFigure 14.25. jamovi 요인배치 ANOVA에서 상호작용 효과를 포함한 Tukey HSD 사후 검정\n\n\n\n\n\n\n\n\n\n\n\nTip 14.13. 실습: 요인분산분석에서 사후 검정\n\n\n\nTip 14.10 실습에 이어서 요인분산분석에서 사후 검정을 수행해 봅니다.\n\n오른편 ‘결과’ 창에서 ‘분산분석’ 결과를 클릭하면 왼편에 ‘분산분석’ 설정창이 나타납니다.\n‘사후 검정’ 옵션을 확장하여 주요인에 대한 Tukey의 HSD를 수행합니다.\n\n\ndrug와 therapy를 오른편 상자로 이동시킵니다.\n‘교정’ 옵션에서 ’Tukey’를 선택합니다.\n그러면 Figure 14.24 의 결과를 얻습니다.\n\n\n상호작용 효과를 포함하여 ’사후 검정’하기 위하여 다음을 수행합니다.\n\n\n‘모형’ 옵션을 확장하여 왼편의 drug와 therapy를 선택한 후 아래 화살표의 ‘상호작용’을 선택하여 ’모형 항’ 상자에 ’drug * therapy`를 넣습니다.\ndrug와 therapy를 오른편 상자로 이동시킵니다.\n그러면 ‘사후 검정’ 옵션에서 왼편 상장에 drug * therapy 항이 나타납니다. 이를 오픈편 상자로 옮깁니다.\n그러면 Figure 14.25 의 결과를 얻습니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>요인분산분석</span>"
    ]
  },
  {
    "objectID": "14-Factorial-ANOVA.html#sec-The-method-of-planned-comparisons",
    "href": "14-Factorial-ANOVA.html#sec-The-method-of-planned-comparisons",
    "title": "14  요인분산분석",
    "section": "14.9 계획된 비교",
    "text": "14.9 계획된 비교\n앞서 ANOVA에서 대비와 사후 검정에 대해 논의하였는데, 계획된 비교(method of planned comparisons)는 별도로 다룰 가치가 있는 중요한 개념이라고 생각합니다.\nChapter 13 과 이전 절에서 다중 비교에 대해 논의할 때, 저는 여러분이 수행하려는 검정이 진정한 의미에서 사후 검정이라고 가정했습니다. 예를 들어, 앞의 약물 실험에서 약물이 기분 향상에 미치는 효과가 다를 것이라고 가정했을 수 있습니다(즉, 약물의 주효과를 가설로 설정한 경우). 하지만 약물이 어떻게 다를지에 대한 구체적인 가설이 없었고, 어떤 쌍별 비교가 중요한지도 알지 못했다고 가정해 보겠습니다. 이러한 경우라면, Tukey의 HSD 같은 방법을 사용하여 쌍별 비교를 수행하는 것이 적절합니다.\n그러나 관심 있는 비교가 명확하게 정해져 있는 경우에는 상황이 달라집니다. 즉, 어떤 비교를 수행할지에 대한 구체적인 가설이 있으며, 사전에 결정한 비교 이외의 다른 비교는 절대 수행할 의도가 없는 경우입니다.\n이 조건을 철저히 지킨다면(즉, 여러분의 가설에 없었던 것들 사이에 유의한 결과가 발결되었더라도 원래의 가설에 대한 검정으로 한정한다면), Tukey의 HSD를 수행하는 것은 비효율적일 수 있습니다. 왜냐하면, Tukey의 HSD는 여러 비교를 동시에 수행한다는 전제하에 오류율을 조정하는 방법인데, 여러분은 계획이 없던 집단 쌍들에 대해서는 애초에 검정할 생각이 없기 때문입니다.\n이러한 경우라면, 다중 검정에 대한 조정을 하지 않고도 제한된 수의 가설 검정을 안전하게 수행할 수 있습니다. 이러한 접근법을 계획된 비교라고 하며, 임상시험에서 때때로 사용됩니다. 본 입문서에서는 이에 대한 추가적인 논의를 다루지 않겠지만, 이러한 방법이 존재한다는 점만큼은 기억해 두시기 바랍니다!",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>요인분산분석</span>"
    ]
  },
  {
    "objectID": "14-Factorial-ANOVA.html#요인분산분석-3-불균형-설계",
    "href": "14-Factorial-ANOVA.html#요인분산분석-3-불균형-설계",
    "title": "14  요인분산분석",
    "section": "14.10 요인분산분석 3: 불균형 설계",
    "text": "14.10 요인분산분석 3: 불균형 설계\n요인분산분석은 매우 유용한 분석 방법입니다. 수십 년 동안 실험 데이터를 분석하는 표준 도구로 사용되어 왔으며, 심리학 논문을 두세 편만 읽어 보아도 ANOVA 분석을 접하게 될 가능성이 매우 높습니다. 하지만 실제 연구에서 수행하는 ANOVA와 지금까지 설명한 ANOVA 사이에는 큰 차이가 있습니다. 실제 연구에서는 완벽하게 균형 잡힌 설계를 적용하는 경우가 거의 없습니다. 어떤 이유에서든 일부 조건에서 더 많은 관찰값을 얻게 되는 것이 일반적이기에, 불균형 설계(unbalanced design)가 발생합니다.\n불균형 설계를 다룰 때는 균형 설계보다 훨씬 더 신중해야 합니다. 불균형 설계의 통계적 이론은 훨씬 복잡하며, 이를 적절히 처리하지 않으면 잘못된 분석 결과를 얻을 수 있습니다. 그러나 제 경험상, 심리학의 학부 연구방법론 수업에서는 이 문제를 완전히 무시하는 경향이 있습니다. 많은 통계 교재에서도 불균형 설계에 대한 설명을 대충 넘어가곤 합니다. 이로 인해 많은 연구자들이 불균형 요인분산분석에는 여러 가지 “유형”이 존재하며, 각각의 분석 방법이 서로 다른 결과를 초래할 수 있다는 사실을 모르는 경우가 많습니다. 실제로 심리학 논문을 읽어보면, 연구자들이 불균형 요인분산분석을 수행한 후에도 분석을 재현할 수 있을 만큼 충분한 정보를 제공하지 않는 경우가 많습니다. 심지어 저는 많은 연구자들이 자신이 사용하는 통계 소프트웨어가 데이터를 분석하는 과정에서 자동으로 많은 중요한 결정을 내리고 있다는 사실조차 모른다고 의심하고 있습니다. 이 문제를 생각하면 조금 섬뜩하기까지 합니다. 따라서 데이터 분석의 통제권을 “멍청한 소프트웨어”에 넘겨주지 않으려면, 계속해서 읽어 나가시기 바랍니다.\n\n14.10.1 coffee 데이터\n언제나 그렇듯이, 실제 데이터를 다루면서 이해를 돕도록 하겠습니다. coffee.csv 파일에는 불균형한 \\(3 \\times 2\\) 요인분산분석을 해야하는 가상의 데이터가 포함되어 있습니다.\n이번에는 사람들이 커피를 너무 많이 마시면 말을 많이 하게 되는 것이 순수하게 커피 자체의 영향인지, 아니면 커피에 첨가하는 우유나 설탕의 영향도 있는지 알아보려고 한다고 가정하겠습니다. 이를 위해 18명의 참가자에게 커피를 제공하였습니다. 이때 커피(카페인)의 양은 일정하게 유지하면서, 우유를 첨가하는지 여부를 다르게 하였습니다. 우유 변수는 이항 요인(binary factor)으로, “yes”(첨가) 또는 “no”(미첨가)의 두 수준을 가집니다. 사용한 설탕의 종류도 다르게 하였습니다. 설탕 변수는 세 가지 수준을 가지며, “real”(일반 설탕), “fake”(인공 감미료), “none”(설탕 없음) 중 하나로 설정됩니다. 결과변수는 연속형 변수이며, 참가자가 “말을 많이 하는 정도(babbling)”를 심리학적으로 적절한 방식으로 측정한 값이라고 가정하겠습니다. 세부적인 측정 방식은 여기서 중요하지 않으므로 넘어가겠습니다.\n데이터를 jamovi의 스프레드시트 보기에서 확인하면 Figure 14.26 같습니다.\n\n\n\n\n\n\n\n\nFigure 14.26. jamovi에서 본 coffee.csv 데이터셋. 요인 수준별로 집계된 기술적 정보 포함.\n\n\n\n\n\nFigure 14.26 의 평균값 표를 보면, 집단 간에 차이가 있다는 강한 인상을 받게 됩니다. 특히, babble 변수의 평균의 크기와을 표준편차의 크기를 비교해 보면 더욱 그렇습니다. 각 집단에서 babble 변수의 표준편차는 \\(0.14\\)에서 \\(0.71\\)까지 변하는데, 집단 사이의 평균 차이에 비하면 비교적 작은 값입니다.10\n처음에는 이것이 단순한 요인분산분석 문제처럼 보일 수 있지만, 데이터를 자세히 보면 각 집단별 관측 수가 다르다는 문제가 있습니다. Figure 14.26 에 표시된 각 집단별 사례수를 보면 이를 확인할 수 있습니다. 이는 각 집단의 표본 크기가 동일하다는 균형 설계 ANOVA의 가정이 위배되었음을 의미합니다. 이러한 상황을 어떻게 처리해야 하는지에 대해서는 아직 논의하지 않았습니다.\n\n\n\n\n\n\nTip 14.14. 실습: Coffee 데이터\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Coffee’을 선택합니다.\n스프레드시트 창에서 각 변수의 이름을 더블클릭하여 각 변수의 척도유형과 데이터 유형이 제대로 설정되어 있는지 확인하고 필요하면 이를 정정합니다.\n\n\nID: 아이디, 정수\nmilk, sugar: 명명척도, 문자\nbabble: 연속변수, 소수\n\n\n다음 단계를 거쳐 Figure 14.26 같은 기술통계량을 구해봅니다.\n\n\n‘분석’-‘기술분석’-‘기술분석’ 메뉴를 선택합니다.\nbabble을 ‘변수’ 상자로, milk와 sugar를 ’Split by` 상자로 이동합니다.\n‘기술통계’ 드롭다운 메뉴에서 ’Variable across rows’를 선택합니다.\n‘통계’ 옵션을 확장하여 ‘사례수’, ‘평균’, ’표준편차’만 체크합니다.\n\n\n\n\n\n14.10.2 불균형 설계에서는 “표준 ANOVA”가 존재하지 않는다\n불균형 설계를 다루다 보면 실제로 표준 ANOVA라고 부를 수 있는 단 하나의 방법이 존재하지 않는다는 다소 불편한 사실을 발견하게 됩니다. 실제로 불균형 설계에서 ANOVA를 수행하는 방법에는 근본적으로 세 가지 다른 방식이 있습니다**.11 만약 균형 설계를 사용한다면, 이 세 가지 방식 모두 동일한 결과를 제공하며, 제곱합, \\(F\\) 값 등의 계산이 이 장의 초반에 소개한 공식과 완벽하게 일치합니다. 그러나 설계가 불균형할 경우, 이 세 가지 방법은 서로 다른 결과를 제공합니다. 또한, 모든 방법이 모든 상황에 동일하게 적절한 것은 아닙니다. 일부 방법은 특정한 연구 상황에서 더 적절할 수 있습니다. 이러한 점을 고려하면, 세 가지 ANOVA 방식이 무엇이며, 서로 어떻게 다른지를 이해하는 것이 중요합니다.\n첫 번째 방식은 제곱합 유형 I(Type I sum of squares)라고 불립니다. 이름에서 유추할 수 있듯이, 다른 두 가지 방식도 존재합니다. 이러한 용어는 SAS 통계 소프트웨어 패키지에서 처음 도입되었으며, 이후 표준적인 명칭이 되었습니다. 그러나 이 명칭은 다소 오해의 소지가 있습니다. 이 방식들을 제곱합 \\(SS\\)의 유형의 차이로 구분하는 이유는, ANOVA 표를 살펴보았을 때 핵심적인 차이가 바로 제곱합(\\(SS\\)) 값에 있기 때문입니다. 자유도(\\(df\\))는 변하지 않으며, 평균제곱(\\(MS\\))도 \\(SS\\)를 \\(df\\)로 나눈 값으로 동일하게 정의됩니다.\n그러나, 단순히 제곱합 값이 다르다는 점만 강조하는 것은 중요한 본질을 숨기는 것입니다. 실제로 중요한 것은, 왜 \\(SS\\) 값이 서로 다르게 계산되는가 하는 이유입니다. 이 점을 이해하는 더 좋은 방법은, 이 세 가지 ANOVA 방식을 “서로 다른 가설 검정 전략”으로 생각하는 것입니다. 각각의 전략은 결과적으로 서로 다른 \\(SS\\) 값을 초래하지만, 정작 중요한 것은 “제곱합의 값” 자체가 아니라 “가설 검정의 전략”입니다.\n이전에 선형 모형으로서의 ANOVA 절에서 논의했듯이, 어떤 특정한 \\(F\\) 검정도 본질적으로 두 개의 선형 모형을 비교하는 과정입니다. 따라서 ANOVA 표를 해석할 때, 각 \\(F\\) 검정이 어떤 두 개의 모형을 비교하고 있는지를 이해하는 것이 중요합니다. 결국, 세 가지 ANOVA 방식(유형 I, 유형 II, 유형 III)의 근본적인 차이점은 바로 “어떤 모형 쌍을 비교”하느냐에 있습니다.\n\n\n14.10.3 제곱합 유형 I\n제곱합 유형 I 방식은 “순차형(sequential)” 제곱합이라고 불리기도 합니다. 이는 모형에 항을 하나씩 순차적으로 추가하는 과정을 포함하기 때문입니다.\n예를 들어, coffee 데이터를 고려해 보겠습니다. 우리가 상호작용 항을 포함한 전체 \\(3 \\times 2\\) 요인 ANOVA를 수행한다고 가정해 보겠습니다. 이 전체 모형에는 결과변인 babble, 예측변수인 sugar와 milk, 상호작용 항인 sugar \\times milk가 포함됩니다. 이를 수식으로 나타내면 다음과 같습니다.\n\\[\nbabble \\sim sugar + milk + sugar {\\times} milk\n\\]\n제곱합 유형 I 방식은 이 모형을 가장 단순한 형태에서 시작하여 점진적으로 항을 추가하는 방식으로 구성됩니다.\n데이터를 설명하는 가장 단순한 모형은 milk나 sugar가 babble에 아무런 영향을 미치지 않는다고 가정하는 것입니다. 즉, 절편만 포함하는 모형입니다. 이를 수식으로 나타내면 다음과 같습니다.\n\\[\nbabble \\sim 1\n\\]\n이것이 우리가 설정하는 초기 귀무가설입니다.\n이제, 가장 단순한 모형에서 주효과 하나만 추가한 새로운 모형을 고려합니다. coffee 데이터에서는 두 가지 선택이 가능합니다. milk를 먼저 추가할 수도 있고, sugar를 먼저 추가할 수도 있습니다. 사실, 어떤 요인을 먼저 추가하는지가 결과에 영향을 미친다는 점이 중요합니다. 하지만 지금은 임의로 하나를 선택하여 sugar를 먼저 추가해 보겠습니다. 이때의 새로운 모형은 다음과 같습니다.\n\\[\nbabble \\sim sugar\n\\]\n이 모형은 첫 번째 대립가설이 됩니다. 따라서 첫 번째 가설 검정은 다음 두 모형을 비교하는 것입니다(Table 14.16). 해당 비교를 통해 설탕의 주효과를 검정하게 됩니다.\n\n\n\n\nTable 14.16. 결과변수 “babble”에 대한 귀무가설과 대립가설\n\n\n\n\n\n귀무 모형:\\(babble \\sim 1\\)\n\n대립 모형:\\(babble \\sim  sugar\\)\n\n\n\n\n\n\n\n이제 두 번째 주효과인 milk를 추가하여 모형을 확장합니다. 새로운 모형은 다음과 같습니다.\n\\[\nbabble \\sim sugar + milk\n\\]\n이제 두 번째 가설 검정을 수행합니다. 이때의 비교 대상이 되는 모형 쌍은 Table 14.17 과 같습니다. 이 비교를 통해 우유의 주효과를 검정하게 됩니다.\n\n\n\n\nTable 14.17. 결과변수 “babble”에 대한 추가적인 귀무가설과 대립가설\n\n\n\n\n\n귀무 모형:\\(babble \\sim  sugar\\)\n\n대립 모형:\\(babble \\sim  sugar + milk\\)\n\n\n\n\n\n\n\n이러한 방식으로 모형을 확장하는 것은 일관된 순차적 방법이라는 점에서 매우 우아한 방식입니다. 즉, 첫 번째 검정의 대립가설이 두 번째 검정의 귀무가설이 됩니다. 그러나, 이 방법은 비대칭성 문제를 갖고 있습니다. sugar의 주효과를 검정할 때(babble \\sim sugar 모형)에는 milk를 완전히 무시합니다. 반면, milk의 주효과를 검정할 때(babble \\sim sugar + milk 모형)는 sugar를 고려하게 됩니다. 따라서 두 주효과에 대한 검정에는 강한 비대칭성이 있어서 요인을 추가하는 순서에 따라 결과가 달라질 수 있다는 점이 문제점으로 작용할 수 있습니다.\n마지막으로, 상호작용 항을 추가하여 전체 모형을 구성합니다.\n\\[\nbabble \\sim sugar + milk + sugar {\\times} milk\n\\]\n이제 세 번째 가설 검정을 수행합니다. 이때의 비교 대상이 되는 모형 쌍은 Table 14.18 과 같습니다. 해당 비교를 통해 설탕과 우유의 상호작용 효과를 검정합니다.\n\n\n\n\nTable 14.18. 결과변수 “babble”에 대한 추가적인 귀무가설과 대립가설\n\n\n\n\n\n귀무 모형:\\(babble \\sim  sugar + milk\\)\n\n대립 모형:\\(babble \\sim  sugar + milk + sugar * milk \\)\n\n\n\n\n\n\n\n제곱합 유형 III 방식이 jamovi의 ANOVA에서 기본적으로 사용되는 가설 검정 방법입니다. 따라서 제곱합 유형 I 방식으로 분석을 수행하려면 jamovi의 ‘분산분석’-‘모형’ 옵션에서 ‘제곱합’ 선택 상자를 ’Type 1’로 설정해야 합니다. 이렇게 설정하면 Figure 14.27 에 제시된 ANOVA 표가 생성됩니다.\n\n\n\n\n\n\n\n\nFigure 14.27. jamovi에서 제곱합 유형 I을 사용한 ANOVA 결과표\n\n\n\n\n\n제곱합 유형 I 방식의 가장 큰 문제점은 요인을 입력하는 순서에 따라 결과가 달라진다는 것입니다. 그러나 많은 경우 연구자는 특정한 요인 순서를 선호할 이유가 없습니다. 이는 우리 예제인 우유와 설탕 문제에서도 마찬가지입니다. milk를 먼저 추가해야 할까요? 아니면 sugar를 먼저 추가해야 할까요? 이 선택은 커피를 만들 때와 마찬가지로 임의적입니다. 일부 사람들은 특정 순서에 대한 강한 의견을 가질 수도 있겠지만, 이 문제에 대해 원칙적으로 옳은 답을 찾기는 어렵습니다. 그런데, 예측변수의 순서를 변경하면 결과가 어떻게 변하는지 살펴보겠습니다(Figure 14.28).\n\n\n\n\n\n\n\n\nFigure 14.28. jamovi에서 제곱합 유형 I을 사용한 ANOVA 결과표 (변수를 다른 순서로 입력한 경우, 우유 먼저)\n\n\n\n\n\n이제 두 개의 주효과에 대한 \\(p\\)-값이 크게 변경되었음을 알 수 있습니다. 특히, 우유의 효과가 통계적으로 유의하게 나왔습니다. 그러나 앞서 언급했듯이, 이 결과만 보고 섣불리 결론을 내리는 것은 위험합니다. 이제 어떤 ANOVA 결과를 보고해야 할까요? 명확한 답을 내리기는 어렵습니다. 제곱합 유형 I 방식에서는 “첫 번째” 주효과와 “두 번째” 주효과를 검정하는 방식이 근본적으로 다릅니다. 우리가 처음에 본 예제에서, 설탕의 주효과를 검정할 때는 우유를 완전히 무시했습니다. 반면, 우유의 주효과를 검정할 때는 설탕의 효과를 고려했습니다. 즉, 제곱합 유형 I 방식에서는 첫 번째 주효과를 두 번째 주효과보다 이론적으로 우선하는 것처럼 다룹니다. 그러나 실제 연구에서는\n이러한 이론적 우선성이 정당화될 경우는 거의 없습니다. 즉, 두 개의 주효과를 비대칭적으로 다뤄야 할 이유가 없는 경우가 대부분입니다.\n이러한 문제점 때문에 제곱합 유형 I 방식은 실무에서 잘 사용되지 않습니다. 따라서, 제곱합 유형 II 및 유형 III 방식에 대한 논의로 이동해야 할 것 같습니다.\n\n\n14.10.4 제곱합 유형 III\n앞서 제곱합 유형 I 방식에 대해 설명했으므로, 다음으로 유형 II 방식을 다루는 것이 자연스러울 것이라고 생각할 수 있습니다. 그러나 (간단하며 jamovi ANOVA의 기본 설정인) 유형 III 방식을 먼저 설명하는 것이 더 적절하다고 생각합니다. 이후에 (더 까다로운) 유형 II 방식을 설명하는 것이 이해하기 쉬울 것입니다.\n제곱합 유형 III 방식의 핵심 개념은 매우 단순합니다. 검정하려는 항에 관계없이, 다음과 같이 \\(F\\)-검정을 수행합니다.\n\n대립가설: 사용자가 지정한 완전한(full) ANOVA 모형\n귀무가설: 전체 모형에서 검정하려는 특정 항만 제거한 모형\n\n예를 들어, 커피 데이터에서 전체 모형이 babble ~ sugar + milk + sugar × milk라고 가정해 보겠습니다. 이때, 설탕(sugar)의 주효과에 대한 검정은 다음 두 개의 모형을 비교하는 것입니다 (Table 14.19).\n\n\n\n\nTable 14.19. 제곱합 유형 III을 사용한 ’babble’에 대한 귀무 가설과 대립 가설 (설탕 효과 검정)\n\n\n\n\n\n귀무 모형:\\(babble \\sim  milk + sugar * milk\\)\n\n대립 모형:\\(babble \\sim  sugar + milk +sugar * milk \\)\n\n\n\n\n\n\n\n우유(milk)의 주효과는 우유 항을 제거한 귀무 모형과 완전 모형을 비교하여 검정합니다(Table 14.20).\n\n\n\n\nTable 14.20. 제곱합 유형 III을 사용한 ’babble’에 대한 귀무 가설과 대립 가설 (우유 효과 검정)\n\n\n\n\n\n귀무 모형:\\(babble \\sim  sugar + sugar * milk\\)\n\n대립 모형:\\(babble \\sim  sugar + milk +sugar * milk \\)\n\n\n\n\n\n\n\n상호작용 항 sugar * milk 역시 같은 방식으로 검정합니다.\n즉, 완전 모형에서 sugar * milk 항을 제거한 귀무 모형과 완전 모형을 비교합니다(Table 14.21).\n\n\n\n\nTable 14.21. 제곱합 유형 III을 사용한 ’babble’에 대한 귀무 가설과 대립 가설 (상호작용 항 제거)\n\n\n\n\n\n귀무 모형:\\(babble \\sim  sugar + milk\\)\n\n대립 모형:\\(babble \\sim  sugar + milk +sugar * milk \\)\n\n\n\n\n\n\n\n이 개념은 더 높은 차원의 ANOVA에도 적용할 수 있습니다. 예를 들어, 요인 A, B, C가 있는 세 요인 ANOVA(Three-way ANOVA)를 수행한다고 가정해 보겠습니다. 이때, 모든 주효과와 상호작용 항을 포함하여 세 요인 간의 상호작용(A × B × C)까지 고려할 수 있습니다. 이러한 경우, 제곱합 유형 III 검정의 원리는 다음과 같습니다(Table 14.22).\n\n\n\n\nTable 14.22. 세 개의 요인이 포함된 경우의 제곱합 유형 III 검정\n\n\n\n\n\n검정하는 항귀무 모형: Y ~ ...대립 모형:  Y ~ ...\n\nA\\(B + C + A*B + A*C + B*C + A*B*C \\)\\(A + B + C + A*B + A*C + B*C + A*B*C \\)\n\nB\\(A + C + A*B + A*C + B*C + A*B*C \\)\\(A + B + C + A*B + A*C + B*C + A*B*C\\)\n\nC\\(A + B + A*B + A*C + B*C + A*B*C \\)\\(A + B + C + A*B + A*C + B*C + A*B*C \\)\n\nA*B\\(A + B + C + A*C + B*C + A*B*C \\)\\(A + B + C + A*B + A*C + B*C + A*B*C \\)\n\nA*C\\(A + B + C + A*B + B*C + A*B*C \\)\\(A + B + C + A*B + A*C + B*C + A*B*C \\)\n\nB*C\\(A + B + C + A*B + A*C + A*B*C \\)\\(A + B + C + A*B + A*C + B*C + A*B*C \\)\n\nA*B*C\\(A + B + C + A*B + A*C + B*C \\)\\(A + B + C + A*B + A*C + B*C + A*B*C \\)\n\n\n\n\n\n\n\n이 표는 복잡해 보일 수 있지만, 개념적으로는 단순합니다.\n\n대립 가설: 완전 모형 (A, B, C의 주효과 + 2차 상호작용(A×B 등) + 3차 상호작용(A×B×C))\n\n귀무 가설: 완전 모형에서 특정 항 1개만 제거한 모형\n\n즉, 검정하려는 특정 항(term)을 제외한 나머지 모든 항이 포함된 모형을 귀무 가설로 설정합니다.\n처음 보면, 제곱합 유형 III 방식은 매우 바람직한 방법처럼 보입니다. 유형 I 방식에서 문제가 되었던 비대칭성 문제가 사라졌습니다. 유형 I 방식에서는 변수 입력 순서에 따라 검정 결과가 달라졌습니다. 유형 III 방식에서는 모든 항이 동일한 방식으로 처리되므로, 변수 입력 순서의 영향을 받지 않습니다.\n이러한 성질은 매우 좋은 성질입니다. 그러나 유형 III에서는 주효과에 대한 해석의 어려움이라는 문제가 발생합니다. 예를 들어, 커피 데이터에서 우유의 주효과가 유의하지 않다고 가정해 보겠습니다. 이는 babble ~ sugar + sugar × milk 모형이 완전 모형보다 데이터를 더 잘 설명한다는 의미입니다. 하지만 이것이 실제로 어떤 의미를 가지는지 명확하지 않습니다. 특히, 상호작용 항이 유의한데 그것의 주효과가 유의하지 않은 경우에는 해석이 더욱 어렵습니다. sugar * milk 상호작용 항이 유의미한데, milk의 주효과는 유의하지 않다면? sugar의 효과는 존재하지만, milk의 효과는 존재하지 않는다”라고 해석해야 할까요? 하지만 milk와 sugar의 상호작용이 존재한다면, milk의 효과가 아예 없다고 보는 것은 말이 되지 않습니다. 일반적으로 많은 통계학자들은 상호작용 항이 유의할 때 개별 주효과를 논하는 것은 무의미하다고 조언합니다.12\n상호작용 항이 유의할 때 주효과를 논의하는 것이 무의미하다면, 유형 III에서 귀무 가설을 설정할 때 상호작용 항은 유지하면서 주효과 항을 제거하여 가설 검정하는 것도 전혀 타당한지 않습니다. 이에 대한 논란이 있으며, 이러한 이유로 제곱합 유형 III 방식의 귀무 가설 설정 방식은 논리적으로 문제가 있을 수 있습니다.\n뒤에서 유형 III 검정이 적절한 문맥을 볼 수 있을 것입니다. 이제 jamovi에서 제곱합 유형 III 방식을 사용한 ANOVA 결과표를 살펴보겠습니다(Figure 14.29).\n\n\n\n\n\n\n\n\nFigure 14.29. jamovi에서 제곱합 유형 III을 사용한 ANOVA 결과표\n\n\n\n\n\n유념해야 할 것이 있습니다. 제곱합 유형 III 방식의 중요한 문제점 중 하나는 대부분의 경우 검정 결과가 사용된 대비에 따라 달라진다는 점입니다.13 (대비의 유형에 대해 잊었다면 대비를 지정하는 다양한 방법을 참조하세요.)\n일반적으로 유형 III 검정에서는 \\(p\\)-값이 대비의 유형에 매우 민감하게 변화합니다. 즉, 사용자가 어떤 대비 방식을 선택하느냐에 따라 검정 결과가 달라질 수 있습니다. 이러한 임의성 때문에 유형 III 검정을 신뢰할 수 없다는 것일까요?\n어느 정도는 문제가 있기 때문에, 이 문제를 피하기 위해 유형 II 방식이 대안으로 제시됩니다. 유형 II 검정에서는 대비 방식에 의한 임의성을 완전히 제거할 수 있습니다.\n그러나 제곱합 유형 III 방식이 완전히 무의미한 것은 아닙니다. 특정 조건에서는 대비의 유형에 상관없이 일관된 결과를 제공할 수 있으며, jamovi에서는 대비 방식과 관계없이 동일한 결과를 산출합니다. 특히 대비 행렬의 열의 합이 0인 대비에서는 유형 III응 항상 동일한 결과를 제공합니다.\n\n\n14.10.5 제곱합 유형 II\n지금까지 유형 I과 유형 III형 검정을 살펴보았으며, 둘 다 비교적 간단하였습니다. 유형 I 검정은 항을 순차적으로 추가하여 수행하며, 유형 III 검정은 완전 모형에서 각 항을 제거했을 때 어떤 일이 발생하는지를 확인하는 방식입니다. 하지만 두 방법 모두 몇 가지 한계를 가질 수 있습니다. 유형 I 검정은 항을 입력하는 순서에 따라 결과가 달라지며, 유형 III 검정은 대비를 설정하는 방식에 따라 결과가 달라질 수 있습니다. 유형 II 검정은 설명하기가 조금 더 어렵지만, 이러한 두 가지 문제를 모두 회피하며 결과의 해석이 보다 용이한 방법입니다.\n유형 II 검정은 전체적인 방식이 유형 III 검정과 유사합니다. 즉, “완전” 모형을 시작점으로 삼고 특정 항을 제거하여 그 항을 검정하는 방식입니다. 하지만 유형 II 검정은 주변성 원칙(marginality principle)에 기반을 둡니다. 이는 어떤 모형에서 고차 항(higher-order term)이 포함되어 있다면, 해당 항이 의존하는 저차 항(lower-order term)을 모형에서 생략해서는 안 된다는 원칙입니다. 예를 들어, 모형에 이차(2차) 상호작용 항인 A \\(\\times\\) B가 포함되어 있다면, 주효과인 A와 B도 반드시 포함되어야 합니다. 마찬가지로, 삼차(3차) 상호작용 A \\(\\times\\) B \\(\\times\\) C가 포함된 경우, 주효과 A, B, C뿐만 아니라 이차 상호작용 A \\(\\times\\) B, A \\(\\times\\) C, B \\(\\times\\) C도 포함해야 합니다.\n유형 III 검정은 종종 주변성 원칙을 위반합니다. 예를 들어, 모든 가능한 상호작용 항이 포함된 삼원분산분석에서 A의 주효과를 검정한다고 가정해 보겠습니다. 유형 III 검정에서의 귀무가설과 대립가설은 Table 14.23 에 나와 있습니다.\n\n\n\n\nTable 14.23. 모든 가능한 상호작용 항이 포함된 삼원 분산분석에서 A의 주효과에 대한 유형 III 검정\n\n\n\n\n\n귀무 모형:\\(Y \\sim B + C + A*B + A*C + B*C + A*B*C\\)\n\n대립 모형:\\(Y \\sim A + B + C + A*B + A*C + B*C + A*B*C\\)\n\n\n\n\n\n\n\n여기서 귀무가설은 A를 제외하지만, A \\(\\times\\) B, A \\(\\times\\) C 및 A \\(\\times\\) B \\(\\times\\) C는 포함하고 있습니다. 유형 II 검정 관점에서 보면, 이는 적절한 귀무 가설이 아닙니다. 대신, A가 결과변수에 영향을 미치지 않는다는 귀무 가설을 검정하려면, A와 관련된 어떤 항도 포함하지 않는 가장 복잡한 모형을 귀무가설로 설정해야 합니다. 대립가설은 이 귀무 모형에 A의 주효과 항을 추가한 것입니다. 이는 대부분의 사람들이 직관적으로 “A의 주효과”라고 생각하는 것과 훨씬 더 가까운 개념이며, 유형 II 검정에서는 A의 주효과에 대한 검정을 Table 14.24 같이 수행합니다.14\n\n\n\n\nTable 14.24. 모든 가능한 상호작용 항이 포함된 삼원 분산분석에서 A의 주효과에 대한 유형 II 검정\n\n\n\n\n\n귀무 모형:\\(outcome \\sim B + C + B*C\\)\n\n대립 모형:\\(outcome \\sim A + B + C + B*C\\)\n\n\n\n\n\n\n\n어쨌든, 유형 II 검정이 어떻게 적용되는지를 보다 직관적으로 이해하기 위해, 삼원분산분석에서 적용되는 전체 검정표를 Table 14.25 에서 확인할 수 있습니다.\n\n\n\n\nTable 14.25. 삼원 요인 모형에 대한 유형 II 검정\n\n\n\n\n\n검정되는 항귀무 모형: Y ~ ...대립 모형: Y ~ ...\n\nA\\(B + C + B*C \\)\\(A + B + C + B*C \\)\n\nB\\(A + C + A*C \\)\\(A + B + C + A*C\\)\n\nC\\(A + B + A*B \\)\\(A + B + C + A*B\\)\n\nA*B\\(A + B + C + A*C + B*C  \\)\\(A + B + C + A*B + A*C + B*C \\)\n\nA*C\\(A + B + C + A*B + B*C  \\)\\(A + B + C + A*B + A*C + B*C \\)\n\nB*C\\(A + B + C + A*B + A*C \\)\\(A + B + C + A*B + A*C + B*C \\)\n\nA*B*C\\(A + B + C + A*B + A*C + B*C \\)\\(A + B + C + A*B + A*C + B*C + A*B*C \\)\n\n\n\n\n\n\n\n커피 데이터를 이용한 이원분산분석에서는 가설 검정이 더욱 단순해집니다. 설탕의 주효과는 Table 14.26 에 나타난 두 모형을 비교하는 \\(F\\)-검정에 해당합니다. 우유의 주효과 검정은 Table 14.27 에 나와 있습니다. 마지막으로, 설탕 \\(\\times\\) 우유의 상호작용 항 검정은 Table 14.28 에 제시되어 있습니다.\n\n\n\n\nTable 14.26. Coffee 데이터에서 설탕의 주효과에 대한 유형 II 검정\n\n\n\n\n\n귀무 모형:\\(babble \\sim milk \\)\n\n대립 모형:\\(babble \\sim sugar + milk\\)\n\n\n\n\n\n\n\n\n\n\n\nTable 14.27. Coffee 데이터에서 우유의 주효과에 대한 유형 II 검정\n\n\n\n\n\n귀무 모형:\\(babble \\sim  sugar \\)\n\n대립 모형:\\(babble \\sim sugar + milk\\)\n\n\n\n\n\n\n\n\n\n\n\nTable 14.28. 설탕 \\(\\times\\) 우유 상호작용 항에 대한 유형 II 검정\n\n\n\n\n\n귀무 모형:\\(babble \\sim  sugar + milk \\)\n\n대립 모형:\\(babble \\sim sugar + milk  + sugar*milk \\)\n\n\n\n\n\n\n\n검정을 실행하는 과정은 매우 간단합니다. jamovi에서 ‘분산부석’-‘모형’ 옵션에서 ‘제곱합’ 선택 상자에서 ’Type 2’를 선택하면, Figure 14.30 에 나타난 ANOVA 표를 얻을 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 14.30. jamovi에서 유형 II 제곱합을 사용한 ANOVA 결과 표\n\n\n\n\n\n유형 II 검정은 유형 I 및 유형 III 검정에 비해 몇 가지 명확한 장점을 가지고 있습니다. 유형 I 검정과 달리 요인을 지정하는 순서에 영향을 받지 않으며, 유형 III 검정과 달리 요인을 지정할 때 사용하는 대비에 영향을 받지 않습니다. 그리고 이 마지막 부분에 대해서는 의견이 다를 수 있으며, 사용자의 연구 목적에 따라 다를 수도 있지만, 유형 II 검정에서 설정하는 가설 검정이 실제로 관심을 가지는 내용과 더 잘 부합할 가능성이 높다고 생각합니다. 따라서 저는 유형 II 검정의 결과가 유형 I이나 유형 III 검정보다 해석하기 쉬운 경우가 많다고 느낍니다. 이러한 이유로, 만약 연구 질문에 직접적으로 대응하는 명확한 모형 비교를 떠올릴 수 없지만 불균형 설계에서 ANOVA를 수행하고 싶다면, 유형 II 검정이 유형 I이나 유형 III 검정보다 더 나은 선택일 가능성이 큽니다.15\n:::{.callout-tip title=“불균형 설계 ANOVA - 제곱합 유형}\nTip 14.14 에 이어 다양한 제곱합 유형 별로 ANOVA 분석을 수행해 봅니다.\n\n다음처럼 sugar를 첫 번째 주효과로 milk를 두 번째 주효과로 하여 제곱합 유형 I로 ANOVA 분석을 수행합니다.\n\n\n‘분석’-‘분산분석’-‘분산분석’ 메뉴를 선택합니다.\n왼편의 ‘분산분석’ 설정 창에서 다음을 수행합니다.\nbabble을 ‘종속변수’ 상자로 이동합니다.\nsugar를 ‘고정요인’ 상자로 이동한 다음에, milk를 ‘고정요인’ 상자로 이동합니다.\n‘모형’ 옵션을 확장한 후, ‘제곱합’ 선택 상자에서 ’Type 1’을 선택합니다.\n\n\n\n\n\n\n\n\n\n\n\n다음처럼 milk를 첫 번째 주효과로 sugar를 두 번째 주효과로 하여 제곱합 유형 I로 ANOVA 분석을 수행합니다.\n\n\n‘분석’-‘분산분석’-‘분산분석’ 메뉴를 선택합니다.\n왼편의 ‘분산분석’ 설정 창에서 다음을 수행합니다.\nbabble을 ‘종속변수’ 상자로 이동합니다.\nsugar를 ‘고정요인’ 상자로 이동한 다음에, milk를 ‘고정요인’ 상자로 이동합니다.\n‘모형’ 옵션을 확장한 후, ‘제곱합’ 선택 상자에서 ’Type 1’을 선택합니다.\n\n\n\n\n\n\n\n\n\n\n\n다음처럼 제곱합 유형 III로 ANOVA 분석을 수행합니다.\n\n\n‘분석’-‘분산분석’-‘분산분석’ 메뉴를 선택합니다.\n왼편의 ‘분산분석’ 설정 창에서 다음을 수행합니다.\nbabble을 ‘종속변수’ 상자로 이동합니다.\nsugar와 milk를 ‘고정요인’ 상자로 이동합니다.\n‘모형’ 옵션을 확장한 후, ‘제곱합’ 선택 상자에서 ’Type 3’을 선택합니다.\n\n\n\n\n\n\n\n\n\n\n\n다음처럼 제곱합 유형 II로 ANOVA 분석을 수행합니다.\n\n\n‘분석’-‘분산분석’-‘분산분석’ 메뉴를 선택합니다.\n왼편의 ‘분산분석’ 설정 창에서 다음을 수행합니다.\nbabble을 ‘종속변수’ 상자로 이동합니다.\nsugar와 milk를 ‘고정요인’ 상자로 이동합니다.\n’효과 크기’의 모든 옵션을 체크합니다.\n‘모형’ 옵션을 확장한 후, ‘제곱합’ 선택 상자에서 ’Type 2’를 선택합니다.\n\n\n\n\n\n\n\n\n\n\n:::\n\n\n14.10.6 효과 크기 (및 비가산적 제곱합)\njamovi에서는 Figure 14.30 같이 해당 옵션을 선택하면 효과 크기 \\(\\eta^2\\) 및 부분 \\(\\eta^2\\)도 제공합니다. 그러나 불균형 설계에서는 약간의 추가적인 복잡성이 존재합니다.\nANOVA에 대한 초기 논의에서 기억할 만한 핵심 개념 중 하나는 제곱합 계산의 기본 원리입니다. 모형에서 각 효과에 해당하는 \\(SS\\) 항들을 모두 더하고, 여기에 잔차 \\(SS\\)를 추가하면 전체 제곱합과 같아야 합니다. 또한, \\(\\eta^2\\)의 기본 개념은 특정 효과의 \\(SS\\) 값을 전체 \\(SS\\) 값으로 나누기 때문에, \\(\\eta^2\\) 값이 특정 효과가 설명하는 분산의 비율로 해석될 수 있다는 점입니다. 하지만 불균형 설계에서는 일부 분산이 “사라지기” 때문에 이러한 해석이 단순하지 않습니다.\n처음에는 이것이 다소 이상하게 보일 수 있지만, 이유는 다음과 같습니다. 불균형 설계에서는 요인 사이에 상관성이 생기며, 요인 A의 효과와 요인 B의 효과를 구별하는 것이 어려워집니다. 극단적인 경우를 생각해 보겠습니다. Table 14.29 같이 각 집단에 속한 참가자 수가 다음과 같은 \\(2 \\times 2\\) 설계를 실행했다고 가정해 보겠습니다.\n\n\n\n\nTable 14.29. \\(2 \\times 2\\) 극단적으로 불균형한 요인 설계에서 각 집단의 참가자 수\n\n\n\n\n\nsugarno sugar\n\nmilk1000\n\nno milk0100\n\n\n\n\n\n\n\n여기서는 극도로 불균형한 설계를 가지고 있습니다. 100명은 우유와 설탕을 모두 섭취했으며, 100명은 우유와 설탕을 모두 섭취하지 않았습니다. 하지만 우유는 있지만 설탕이 없는 경우, 설탕은 있지만 우유가 없는 경우에는 참가자가 없습니다. 이제 데이터를 수집했을 때, “우유와 설탕” 집단과 “우유 없음, 설탕 없음” 집단 간에 큰 (그리고 통계적으로 유의한) 차이가 나타났다고 가정해 보겠습니다. 그렇다면 이것이 설탕의 주효과일까요? 우유의 주효과일까요? 아니면 상호작용 효과일까요? 이를 구분하는 것은 불가능합니다. 왜냐하면 설탕의 사용 여부가 우유의 사용 여부가 완벽하게 연관되어 있기 때문입니다.\n이제 설계가 약간 더 균형을 이루었다고 가정해 보겠습니다(Table 14.30).\n\n\n\n\nTable 14.30. \\(2 \\times 2\\) 여전히 불균형한 요인 설계에서 각 집단의 참가자 수\n\n\n\n\n\nsugarno sugar\n\nmilk1005\n\nno milk5100\n\n\n\n\n\n\n\n이번에는 기술적으로 우유의 효과와 설탕의 효과를 구별하는 것이 가능하긴 합니다. 왜냐하면 한 요인은 있지만 다른 요인은 없는 참가자가 몇 명 있기 때문입니다. 그러나 여전히 이를 구분하는 것은 매우 어렵습니다. 설탕과 우유 사이의 연관성이 여전히 매우 강하며, 두 개의 집단에서 관측치 수가 너무 적기 때문입니다. 결국, 예측변수(우유와 설탕)가 결과변수에 영향을 미친다는 사실은 알고 있지만, 그 관계의 본질이 개별적인 주효과 때문인지, 상호작용 효과 때문인지는 알 수 없는 상황이 됩니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>요인분산분석</span>"
    ]
  },
  {
    "objectID": "14-Factorial-ANOVA.html#요약",
    "href": "14-Factorial-ANOVA.html#요약",
    "title": "14  요인분산분석",
    "section": "14.11 요약",
    "text": "14.11 요약\n\n요인분산분석 1: 균형 설계, 주효과 분석 및 요인분산분석 2: 균형 설계와 상호작용의 해석\n\n효과 크기, 요인분산분석에서 추정된 평균 및 신뢰 구간\n\nANOVA에서의 가정 검토\n\n공분산분석 (ANCOVA)\n\n선형 모형으로서의 ANOVA, 그리고 대비를 지정하는 다양한 방법\n\nTukey의 HSD를 활용한 사후 검정 및 계획된 비교에 대한 간략한 논의\n\n요인분산분석 3: 불균형 설계\n\n\n\n\n\nEveritt, B. S. (1996). Making sense of statistics in psychology. A second-level course. Oxford University Press.\n\n\nHsu, J. C. (1996). Multiple comparisons: Theory and methods. Chapman & Hall. https://doi.org/10.1201/b15074",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>요인분산분석</span>"
    ]
  },
  {
    "objectID": "14-Factorial-ANOVA.html#footnotes",
    "href": "14-Factorial-ANOVA.html#footnotes",
    "title": "14  요인분산분석",
    "section": "",
    "text": "첨자 표기법의 장점은 확장성이 뛰어나다는 것입니다. 만약 실험에서 세 번째 요인이 포함된다면, 단순히 세 번째 첨자를 추가하면 됩니다. 원칙적으로는 원하는 만큼 요인을 추가할 수 있지만, 이 책에서는 세 개 이상의 요인을 포함하는 분석을 드물게 다루며, 세 개를 초과하는 경우는 다루지 않습니다.↩︎\n기술적으로, 주변 평균은 단순 산술 평균과 완전히 동일하지 않습니다. 주변 평균을 구할 때 각 사건의 빈도를 고려한 가중 평균을 합니다. 그러나 균형 설계에서는 모든 셀의 빈도가 동일하므로 두 값이 동일합니다. 불균형 설계에 대해서는 이후에 다룰 예정이며, 그때 가중 평균을 계산하는 과정이 훨씬 복잡해진다는 점을 확인할 수 있을 것입니다. 하지만 지금은 이에 대해 논의하지 않겠습니다.↩︎\n참고로 여기에는 반올림 오차가 있습니다. 평균제곱 값은 소수점 다섯째 자리까지 \\(1.72667\\)이고, 잔차의 평균제곱 값은 \\(0.05444\\)입니다. jamovi는 계산에서 더 많은 소수점을 사용하지만, 결과 표에서는 가독성을 위해 반올림하여 표시합니다. jamovi에서 표시되는 소수점 자릿수를 변경할 수도 있습니다.↩︎\njamovi에서 주효과 분석을 살펴볼 때 이미 이를 발견했을 수도 있습니다. 본서의 설명을 위해 이전 모형에서는 상호작용 항을 제거하여 보다 명확하고 간단하게 만들었습니다.↩︎\n이 장에서는 R이라는 글자가 너무 많은 의미를 갖고 있는 것 같습니다. 지금까지 R은 통계 소프트웨어 패키지를 가리키기도 했고, 평균 표의 행(row) 개수를 의미하기도 했으며, 모형의 잔차(residual)를 나타내기도 했고, 회귀 분석에서 상관 계수를 의미하기도 했습니다. 죄송합니다. 알파벳이 부족한 것 같습니다. 하지만 각 경우에서 R이 무엇을 의미하는지 명확하게 설명하려고 노력했습니다.↩︎\n&lt;역주&gt; 부분 \\(\\eta^2\\)의 개념을 생각하는 또 다른 방법은 결과변수의 변동성을 다른 요인으로 설명하고도 남은 변동성을 해당 요인이 설명하는 비율로 생각할 수 있습니다. 즉, 다른 요인을 통제했을 때 해당 요인의 효과 크기라 할 수 있습니다.↩︎\n현실적으로는 과도하게 큰 효과 크기입니다. 이 데이터셋이 인위적으로 만들어졌다는 점이 드러나고 있습니다!↩︎\njamovi의 한글 버전에서 Covariates를 ’독립변수’라고 번역했는데 이는 옳은 번역이 아니다. 왜냐하면 고정요인들도 독립변수이기 때문이다.↩︎\n만약 집단 A가 집단 B와 C의 평균과 유의미한 차이가 있는지 알고 싶다면, 다른 방법(예: 보다 보수적인 Scheffé 방법)이 필요합니다. 그러나 대부분의 경우 관심이 있는 것은 가능한 모든 두 집단 쌍의 차이(pairwise group differences)이므로, Tukey의 HSD는 매우 유용한 방법입니다.↩︎\n표준편차의 차이가 크다는 점에서 등분산성 가정이 위배될 가능성이 있습니다. 이 점을 Levene 검정 옵션을 사용하여 직접 검토해 보는 것을 연습 문제로 남기겠습니다.↩︎\n사실, 이는 다소 단순화한 설명입니다. ANOVA는 이 책에서 다룬 내용 외에도 여러 방식으로 차이를 가질 수 있습니다. 예를 들어, 요인의 수준이 실험자가 직접 고정한 것인지, 아니면 더 큰 모집단에서 무작위로 추출된 것인지에 따라 고정효과 모형(fixed-effect model)과 랜덤효과 모형(random-effect model)으로 나눌 수 있습니다. 이 책에서는 고정효과 모형만을 다루고 있으며, 랜덤효과 모형에 대한 내용은 포함되지 않았습니다. 이 책, 혹은 다른 단일한 책 한 권이 통계학에 대해 “당신이 알아야 할 모든 것”을 알려줄 것이라고 착각하지 마십시오. 심리학, 물리학, 철학에 대해 단 한 권의 책으로 모든 것을 배울 수 없는 것과 마찬가지입니다. 세상은 그보다 훨씬 복잡합니다. 그러나 좌절할 필요는 없습니다. 대부분의 연구자는 이 책에서 다루는 수준 이상의 ANOVA 개념을 알지 못해도 연구를 수행하는 데 충분한 기초 지식을 갖추고 있다고 할 수 있습니다. 단지, 이 책이 “완전한 이야기”가 아니라 “매우 긴 이야기의 시작”일 뿐이라는 점을 기억해 두셨으면 합니다.↩︎\n적어도, 대부분의 경우 관심을 가질 필요가 없습니다.↩︎\n하지만 jamovi에서는 대비 방식과 상관없이 제곱합 유형 III 방식의 결과가 동일합니다. 즉, jamovi에서는 일반적인 방식과는 다른 접근법을 사용하고 있는 것으로 보입니다.↩︎\n물론, 이는 사용자가 지정한 모형에 따라 달라질 수 있습니다. 예를 들어, 원래의 분산분석 모형에 \\(B \\times C\\)에 대한 상호작용 항이 포함되지 않았다면, 이는 귀무가설과 대립가설 어디에도 나타나지 않을 것입니다. 하지만 이는 유형 I, II, III 모두에 해당하는 사항입니다. 이들은 사용자가 포함하지 않은 항을 추가하지는 않지만, 포함된 항을 검정하는 방식에서는 차이가 있습니다.↩︎\n재미있는 점은, \\(R\\)의 기본값은 유형 I 검정이고 SPSS와 jamovi의 기본값은 유형 III 검정이라는 것입니다. 개인적으로는 둘 다 썩 마음에 들지는 않습니다. 더 관련된 문제로, 심리학 논문에서 거의 아무도 어떤 유형의 검정을 사용했는지를 명시하지 않는다는 사실이 저를 우울하게 만듭니다. 사람들이 일반적으로 보고하는 내용을 이해하는 유일한 방법은, 그들이 사용한 소프트웨어를 보조적인 단서에서 추측하고, 기본 설정을 변경하지 않았다고 가정하는 것입니다. 제발 이렇게 하지 마십시오! 이제 이러한 문제를 알게 되었으니, 사용한 소프트웨어를 명확히 밝히고, 불균형 데이터를 대상으로 ANOVA 결과를 보고할 때는 어떤 유형의 검정을 수행했는지 명시하십시오. 유형 I 검정을 수행했다면 항목의 순서를, 유형 III 검정을 수행했다면 대비를 명확히 기술하십시오. 아니면 더 나은 방법으로, 실제로 관심을 가지는 가설 검정을 수행하고 그 결과를 보고하는 것이 좋습니다!↩︎",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>요인분산분석</span>"
    ]
  },
  {
    "objectID": "15-Factor-Analysis.html",
    "href": "15-Factor-Analysis.html",
    "title": "15  요인분석",
    "section": "",
    "text": "15.1 탐색적 요인분석\n탐색적 요인분석 (Exploratory Factor Analysis; EFA)은 관찰된 데이터에서 숨겨진 잠재 요인을 추론하는 통계적 기법입니다. 이 기법은 측정된 변수 집합, 예를 들어 \\(V_1, V_2, V_3, V_4\\), \\(V_5\\)가 기저의 잠재 요인의 측정값으로 얼마나 잘 표현될 수 있는지를 계산합니다. 이러한 잠재 요인은 하나의 관찰된 변수만으로 측정될 수 없으며, 대신 관찰된 변수 집합에서 나타나는 관계를 통해 드러납니다.\nFigure 15.1 에서 관찰된 변수 \\(V\\)들은 기저의 잠재요인(\\(F\\))에 의해 어느 정도 ’유발’되며, 이는 계수 \\(b_1\\)에서 \\(b_5\\)(요인 적재량(부하량)이라고도 함)으로 나타납니다. 관찰된 변수에는 또한 \\(e_1\\)에서 \\(e_5\\)까지의 오차 항이 있습니다. 각 오차 항은 관찰된 변수 \\(V_i\\)에서 기저의 잠재 요인으로 설명되지 않는 분산을 나타냅니다.\nFigure 15.1. 여러 관찰된 변수 간의 관계를 설명하는 기저의 잠재 요인\n심리학에서 잠재 요인은 직접 관찰하거나 측정하기 어려운 심리적 현상이나 구성 개념을 나타냅니다. 예를 들어, 성격, 지능, 사고 방식 등이 이에 해당합니다. Figure 15.1 은 사람들이 특정한 행동이나 태도에 대한 다섯 가지 질문에 응답하도록 했고, 이를 통해 “외향성”이라는 성격 구성 개념을 파악하는 예일 수도 있습니다. 또 다른 질문 집합을 통해 개인의 내향성이나 성실성을 측정할 수도 있습니다.\n또 다른 예로, 통계 불안을 직접 측정할 수는 없지만, 설문지의 일련의 질문을 통해 통계 불안이 높은지 낮은지를 평가할 수 있습니다. 예를 들어, “\\(Q1\\): 통계 과목의 과제를 수행하기”, “\\(Q2\\): 학술 논문에서 기술된 통계를 이해하려고 시도하기”, “\\(Q3\\): 강사에게 강의 내용에 대한 도움을 요청하기” 등을 수행할 때 불안의 정도를 낮은 불안에서 높은 불안까지 평가하게 질문할 수 있습니다. 통계 불안이 높은 사람들은 이러한 질문들에 대해 일관되게 높은 점수를 줄 가능성이 높으며, 반대로 통계 불안이 낮은 사람들은 일관되게 낮은 점수를 줄 가능성이 큽니다.\n탐색적 요인분석(EFA)에서는 본질적으로 관찰된 변수들 사이의 상관관계를 분석하여 흥미롭고 중요한 기저의 잠재 요인을 찾아냅니다. 통계 소프트웨어를 이용하여 잠재 요인을 추정하고, 어떤 변수가 특정 요인에 대해 높은 적재량1 (예: 적재량 &gt; 0.5)을 가지는지 식별할 수 있고, 이는 해당 변수가 잠재 요인의 유용한 측정 지표임을 의미합니다. 이 과정에서 “회전(rotation)”이라는 단계가 포함되는데, 이는 다소 이해하기 어려운 개념이지만, 다행히도 깊이 이해할 필요는 없습니다. 단지 회전이 서로 다른 요인에 대한 적재량 패턴을 보다 명확하게 만들어 주는 유용한 과정임을 알면 충분합니다. 즉, 회전은 각 요인과 관련된 변수를 더욱 명확하게 식별하는 데 도움을 줍니다. 또한, 주어진 데이터에서 몇 개의 요인이 적절한지를 결정해야 하는데, 이를 돕는 개념이 바로 “고유값(Eigen values)”입니다. 이에 대해서는 주요 가정을 다룬 후 다시 설명하겠습니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>요인분석</span>"
    ]
  },
  {
    "objectID": "15-Factor-Analysis.html#탐색적-요인분석",
    "href": "15-Factor-Analysis.html#탐색적-요인분석",
    "title": "15  요인분석",
    "section": "",
    "text": "15.1.1 가정 검토하기\n분석을 수행하기 전에 확인해야 할 몇 가지 가정이 있습니다. 첫 번째 가정은 구형성(sphericity)으로, 이는 데이터 내 변수들이 서로 상관관계를 가져 요인분석을 통해 요약될 가능성이 있는지를 평가하는 것입니다. Bartlett의 구형성 검정은 관찰된 상관 행렬이 영 (또는 귀무) 상관 행렬과 유의미하게 차이가 있는지를 확인합니다. 따라서 Bartlett 검정이 유의미한 경우(\\(p &lt; .05\\)), 이는 관찰된 상관 행렬이 영 상관 행렬과 유의미하게 다르며, EFA에 적합함을 의미합니다.\n두 번째 가정은 표본 적절성(sampling adequacy)이며, 이는 Kaiser-Meyer-Olkin (KMO) 표본 적절성 측도(MSA)를 사용하여 확인합니다. KMO 지수는 관찰된 변수의 분산 중 공통 분산이 차지하는 비율을 측정합니다. 부분 상관을 이용하여 단 두 개의 항목에만 부하되는 요인이 있는지 확인하며, 일반적으로 EFA에서 단 두 개의 항목에만 부하되는 요인이 다수 존재하는 것은 바람직하지 않습니다. KMO는 표본 적절성과 관련이 있으며, 부분 상관이 높은 경우에는 표본이 적절하지 않은 것으로 간주됩니다. KMO 지수가 높을수록 (\\(\\approx 1\\)) EFA가 효율적이고, 낮을수록 (\\(\\approx 0\\)) EFA가 적절하지 않습니다. KMO 값이 \\(0.5\\)보다 작으면 EFA에 적합하지 않으며, 최소한 \\(0.6\\) 이상의 KMO 값을 가져야 EFA를 수행할 수 있습니다. KMO 값이 \\(0.5\\)~\\(0.7\\)이면 적절, \\(0.7\\)~\\(0.9\\)이면 우수, \\(0.9\\)~\\(1.0\\)이면 매우 우수한 것으로 간주됩니다.\n\n\n15.1.2 EFA의 활용\nEFA가 좋은 해결책(즉, 요인 모형)을 제공했다면, 이제 새롭게 발견한 요인을 어떻게 활용할지를 결정해야 합니다. 연구자들은 심리측정 척도를 개발할 때 EFA를 자주 사용합니다. 연구자는 하나 이상의 심리적 구성 개념과 관련된 설문 문항 풀(pool)을 개발한 후, EFA를 사용하여 어떤 문항들이 함께 묶여 잠재 요인을 형성하는지를 확인합니다. 그런 다음 특정 요인을 명확하게 측정하지 못하는 문항을 제거할지를 평가합니다.2\n이 접근법과 관련하여, EFA의 또 다른 결과는 특정 요인에 부하된 변수를 결합하여 요인 점수(때로는 척도 점수라고도 함)를 생성하는 것입니다. 변수를 척도 점수로 결합하는 방법에는 두 가지 옵션이 있습니다:\n\n요인에 기여하는 각 항목의 요인 적재량에 따라 가중치를 부여하여 새로운 변수를 생성하는 방법\n요인에 기여하는 각 항목을 동일한 가중치로 결합하여 새로운 변수를 생성하는 방법\n\n첫 번째 방법에서는 각 항목이 요인과 얼마나 강하게 관련되어 있는지에 따라 결합된 척도 점수에 대한 기여도가 달라집니다. 두 번째 방법에서는 요인에 기여하는 모든 항목의 평균을 구하여 척도 점수를 생성합니다. 어느 방법을 선택할지는 연구자의 선호에 따라 달라질 수 있지만, 첫 번째 방법의 단점은 표본마다 적재량이 크게 변할 수 있다는 점입니다. 특히 행동과 보건 과학에서는 다양한 연구 및 다양한 표본에서 사용될 수 있는 복합 설문 척도를 개발하고 활용하는 것이 일반적이므로, 특정 표본의 적재량에 따라 가중치를 부여하는 것보다 모든 항목을 동일하게 취급하는 복합 측정 방법이 보다 합리적일 수 있습니다. 또한, 여러 항목의 평균을 활용하는 방법이 특정 표본에 최적화된 가중 조합을 사용하는 것보다 이해하기 쉽고 직관적입니다.\n그러나 이보다 먼저, 우리가 집중해야 할 것은 jamovi에서 EFA를 수행하는 방법입니다.\n\n\n15.1.3 jamovi에서 EFA 수행하기\nEFA를 위한 데이터를 준비해 봅시다. 국제 성격 항목 풀(http://ipip.ori.org)에서 가져온 25개의 성격 자가 보고 항목(표 Table 15.1 참조)은 Synthetic Aperture Personality Assessment (SAPA)의 웹 기반 성격 평가 프로젝트(http://sapa-project.org)의 일부로 포함되어 있습니다. 이 25개 항목은 다음의 다섯 가지 잠정적 요인으로 구성되어 있습니다.\n\n친화성 (Agreeableness)\n성실성 (Conscientiousness)\n외향성 (Extraversion)\n신경증 (Neuroticism)\n개방성 (Openness)\n\n이 항목 데이터는 6점 척도를 사용하여 수집되었습니다:\n\n매우 그렇지 않다.\n다소 그렇지 않다.\n약간 그렇지 않다.\n약간 그렇다.\n다소 그렇다.\n매우 그렇다.\n\n\\(N=250\\)명의 응답을 포함하는 샘플 데이터가 bfi_sample.csv에 있습니다. 연구자로서 우리는 이 데이터를 탐색하여 25개의 관찰된 변수가 어떠한 잠재 요인을 적절하게 측정하고 있는지를 확인하는 데 관심이 있습니다. 데이터를 열어 25개 변수가 연속형 변수로 코딩되어 있는지 확인하십시오(기술적으로는 서열 변수이지만, jamovi에서 EFA를 수행하는 경우 가중치가 적용된 요인 점수를 계산하지 않는 한 크게 문제가 되지 않습니다).\n\n\n\n\nTable 15.1. 데이터 세트 bfi_sample.csv에서 다섯 가지 잠정적 성격 요인으로 구성된 25개 관찰 변수 항목\n\n\n\n\n\n변수 이름질문 / 항목 (짧은 문구가 당신의 일반적인 행동이나 태도를 얼마나 정확하게 설명하는지 표시하세요)코딩 (R: 역코딩)\n\nA1다른 사람의 감정에 무관심하다R\n\nA2다른 사람의 안부를 묻는다\n\nA3다른 사람을 위로하는 방법을 안다\n\nA4아이들을 좋아한다\n\nA5사람들을 편안하게 만든다\n\nC1일을 철저하게 한다\n\nC2완벽할 때까지 계속한다\n\nC3계획에 따라 일을 한다\n\nC4일을 대충 한다R\n\nC5시간을 낭비한다R\n\nE1말을 많이 하지 않는다R\n\nE2다른 사람에게 다가가는 것이 어렵다R\n\nE3사람들을 사로잡는 방법을 안다\n\nE4쉽게 친구를 만든다\n\nE5주도권을 잡는다\n\nN1쉽게 화를 낸다\n\nN2쉽게 짜증을 낸다\n\nN3기분 변화가 자주 있다\n\nN4우울한 기분을 자주 느낀다\n\nN5쉽게 공황 상태에 빠진다\n\nO1아이디어가 풍부하다\n\nO2어려운 읽을거리를 피한다R\n\nO3대화를 더 높은 수준으로 이끈다\n\nO4생각하는 시간을 많이 갖는다\n\nO5어떤 주제를 깊이 파고들지 않는다R\n\n\n\n\n\n\n\njamovi에서 EFA를 수행하는 방법은 다음과 같습니다.\n\njamovi에서 ‘분석’-‘요인분석’-’탐색적 요인분석’을 선택하여 EFA 분석 창을 엽니다(Figure 15.2 참조).\n25개의 성격 질문을 선택하고 ‘변수’ 상자로 이동합니다.\n‘가정검증’을 포함한 적절한 옵션을 선택하고, 회전 ’방법’, 추출할 ‘요인 갯수’, ‘추가 결과’ 옵션을 확인합니다. Figure 15.2 에서는 예시적인 EFA에 대한 추천 옵션을 보여주고 있으며, 회전 ‘방법’ 및 추출된 ’요인 수’는 분석 중에 연구자가 최상의 결과를 찾기 위해 조정하는 것이 일반적입니다.\n\n먼저, 가정을 확인합니다(Figure 15.3 참조). (1) Bartlett의 구형성 검정이 유의미하므로 이 가정이 충족되었으며, (2) KMO 표본 적절성 측도(MSA)가 전체적으로 \\(0.81\\)로 나타나 표본 적절성이 우수함을 시사합니다. 따라서 문제없이 진행할 수 있습니다!\n\n\n\n\n\n\n\n\nFigure 15.2. jamovi의 탐색적 요인분석(EFA) 분석 창\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 15.3. 성격 설문지 데이터에 대한 jamovi의 EFA 가정 검토\n\n\n\n\n\n다음으로 확인해야 할 것은 몇 개의 요인을 사용할 것인지(또는 데이터에서 “추출할 것인지”)입니다. 이를 결정하는 세 가지 접근법이 있습니다.\n\n하나의 기준은 고유값(Eigen value)이 1보다 큰 모든 요인을 선택하는 것입니다3. 이 기준을 따르면, 우리 데이터에서는 네 개의 요인을 얻게 됩니다(직접 실행해 보고 확인해 보세요).\n\n\n스크리 플롯을 검사하는 방법도 있습니다(Figure 15.4 참조). 여기서 “변곡점”을 식별하는 것이 핵심입니다. 변곡점은 스크리 곡선의 기울기가 명확히 완만해지는 지점으로, 즉, “팔꿈치” 아래에 위치합니다. 우리 데이터에서는 다섯 개의 요인을 선택할 수 있습니다. 스크리 플롯을 해석하는 것은 어느 정도 직관이 필요한 작업입니다. Figure 15.4 에서는 요인 5에서 6으로 넘어갈 때 눈에 띄는 단계적 변화가 있지만, 다른 스크리 플롯에서는 이처럼 명확하지 않을 수도 있습니다.\n병렬 분석(parallel analysis) 기법을 사용하면, 얻어진 고유값을 무작위 데이터에서 얻어질 것으로 예상되는 고유값과 비교할 수 있습니다. 추출할 요인의 개수는 실제 데이터의 고유값이 무작위 데이터에서 나올 것으로 예상되는 고유값보다 큰 개수로 결정됩니다.\n\n\n\n\n\n\n\n\n\nFigure 15.4. jamovi EFA에서 성격 데이터의 스크리 플롯. 변곡점이 5번째 요인 이후에 나타나며 기울기가 완만해짐.\n\n\n\n\n\nFabrigar et al. (1999) 에 따르면 세 번째 접근법(병렬 분석)이 좋은 방법이지만, 실제 연구에서는 세 가지 방법을 모두 고려한 후 가장 해석이 쉽고 유용한 요인 개수를 결정하는 경우가 많습니다. 이를 “의미 기준(meaningfulness criterion)”이라고 하며, 연구자들은 위의 접근법 중 하나의 결과뿐만 아니라, 요인 개수를 1~2개 더하거나 줄인 결과도 함께 살펴보면서 가장 적절한 해석이 가능한 해를 선택합니다.\n이와 동시에 최종 해를 회전하는 가장 적절한 방법도 고려해야 합니다. 회전에는 두 가지 주요 접근법이 있습니다.\n\n직교 회전(orthogonal rotation, 예: “varimax”): 선택된 요인들이 서로 상관이 없도록 강제합니다.\n\n사각(비스듬한 각도) 회전(oblique rotation, 예: “oblimin”): 선택된 요인들이 서로 상관을 가질 수 있도록 허용합니다.\n\n심리학 및 행동과학에서 연구하는 차원들은 일반적으로 서로 완전히 독립적이라고 가정하기 어렵기 때문에, 사각 회전이 보다 타당한 방법으로 여겨집니다4.\n실제로, 사각 회전을 수행했을 때 요인들이 상당히 상관이 있는 것으로 나타난다면(양수든 음수든 0.3 이상), 예를 들어 Figure 15.5 에서 두 개의 추출된 요인 간 상관계수가 0.31인 경우, 이는 사각 회전을 선호해야 한다는 우리의 직관을 확인시켜 줍니다. 요인들이 실제로 상관되어 있다면, 사각 회전이 직교 회전보다 더 정확한 요인 추정치를 제공하며, 더 나은 단순 구조(simple structure)를 만들어 냅니다. 반면, 사각 회전의 결과 요인들 간의 상관이 거의 0에 가깝다면, 연구자는 직교 회전을 수행해도 무방합니다(이 경우 직교 회전과 사각 회전의 결과는 거의 동일하게 나올 것입니다).\n추출된 요인 사이의 상관을 확인한 결과, 최소한 하나의 상관계수가 0.3 이상이었으며(Figure 15.5), 따라서 다섯 개의 요인에 대해 사각 회전(“oblimin”)을 수행하는 것이 더 적절합니다. 또한 Figure 15.5 에서 확인할 수 있듯이, 다섯 개의 요인이 설명하는 전체 데이터 분산의 비율은 46%입니다. 요인 1은 약 10%의 분산을 설명하며, 요인 2~4는 각각 약 9%, 요인 5는 약 7%를 설명합니다. 이 결과는 다소 부족합니다. 전체 해가 데이터 분산의 더 많은 부분을 설명할 수 있었다면 더 좋았을 것입니다.\n\n\n\n\n\n\n\n\nFigure 15.5. jamovi EFA에서 다섯 개 요인 해의 요약 통계 및 요인 간 상관관계\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 15.6. jamovi EFA에서 다섯 개 요인 해의 요인 적재량\n\n\n\n\n\n모든 EFA에서 잠재적으로 관찰된 변수의 개수만큼 요인을 추출할 수 있지만, 추가하는 요인이 많을수록 설명되는 분산의 증가 폭은 점점 줄어듭니다. 만약 처음 몇 개의 요인이 원래 25개 변수의 분산을 충분히 설명한다면, 이러한 요인들이 25개 변수를 더 간결한 방식으로 대체할 수 있습니다. 이 경우, 나머지 요인들을 제거하더라도 원래의 변동성을 크게 잃지는 않습니다. 하지만 대부분의 분산을 설명하는 데 18개의 요인이 필요하다면(예를 들어), 차라리 원래의 25개 변수를 그대로 사용하는 것이 더 나을 것입니다.\nFigure 15.6 은 요인 적재량을 보여줍니다. 즉, 25개의 성격 항목이 선택된 다섯 개 요인에 얼마나 적재되는지를 나타냅니다. 적재량이 0.3 미만인 값은 숨겨져 있으며, 이는 Figure 15.2 에서 설정된 옵션을 따른 것입니다.\n요인 1, 2, 3, 4의 적재 패턴은 Table 15.1 에서 명시된 가설적 요인과 상당히 일치합니다. 다행입니다! 요인 5 또한 가설적 요인과 상당히 유사하며, “개방성(openness)”을 측정하는 다섯 개 변수 중 네 개가 요인 5에 잘 적재되었습니다. 그러나 변수 O4는 요인 5가 아닌 요인 4에 적재된 것으로 보이며(Figure 15.6), 적재량도 상대적으로 낮아 요인 5에 충분히 포함되었다고 보기 어렵습니다.\n또한, Table 15.1 에서 “R: 반대 방향 부호(reverse coding)”로 표시된 변수들은 음의 요인 적재량을 가집니다. 예를 들어, 항목 A1(“다른 사람의 감정을 신경 쓰지 않는다”)과 A2(“다른 사람의 안부를 묻는다”)를 살펴보면, A1에서 높은 점수를 받을수록 친화성이 낮음을 의미하는 반면, A2에서 높은 점수를 받을수록(그리고 다른 모든 “A” 변수를 포함하여) 친화성이 높음을 의미합니다. 따라서 A1은 다른 “A” 변수들과 음의 상관을 가지며, 이로 인해 Figure 15.6 에서 보이는 것처럼 음의 요인 적재량을 가집니다.\nFigure 15.6 에서는 각 변수의 ’고유분산 또는 고유성(uniqueness)’도 확인할 수 있습니다. 고유성은 해당 변수만의 고유한 분산 비율을 의미하며, 요인들에 의해 설명되지 않는 부분입니다5. 예를 들어, A1의 분산 중 72%는 다섯 개 잠재 요인으로 설명되지 않습니다. 반면, N1은 잠재 요인에 의해 설명되지 않는 분산이 35%로 상대적으로 낮습니다. 일반적으로 고유성이 클수록 해당 변수가 요인 모형에서 차지하는 중요도나 기여도가 낮아집니다.\n솔직히 말해서, EFA에서 이렇게 깔끔한 해가 나오는 경우는 드뭅니다. 보통은 훨씬 더 복잡한 결과가 나오며, 요인의 의미를 해석하는 것이 더 어렵습니다. 일반적으로 이렇게 명확하게 구분되는 항목 모음을 갖기는 쉽지 않습니다. 오히려, 여러 개의 잠재 요인을 반영할 것으로 추측되는 관찰 변수들이 많아서 어떤 변수가 어떤 요인에 포함될지 명확하지 않은 경우가 더 흔합니다.\n따라서, 우리는 비교적 좋은 다섯 개 요인을 얻었으며, 다만 전체적으로 설명하는 분산의 비율이 상대적으로 낮습니다. 이 해에 만족한다고 가정하고, 이 요인을 추가적인 분석에 사용하고자 한다면 어떻게 해야 할까요? 가장 간단한 방법은 각 요인에 대해 평균 점수를 계산하는 것입니다. 즉, 해당 요인에 실질적으로 적재된 각 변수의 점수를 합산한 후 변수의 개수로 나누는 것입니다(즉, 각 요인과 관련된 항목에 대한 “평균 점수”를 계산하는 방식입니다). 예를 들어, 친화성(Agreeableness) 요인의 경우, 각 응답자의 데이터에서 \\(A1 + A2 + A3 + A4 + A5\\)를 더한 후 5로 나누는 것입니다.6 본질적으로, 우리가 계산한 요인 점수는 포함된 변수/항목을 동일한 가중치러 반영합니다. 이를 jamovi에서 두 단계로 수행할 수 있습니다.\n\njamovi의 변환 변수 명령을 사용하여 변수 A1을 역코딩한 “A1R”로 다시 코딩합니다(예: \\(6 = 1\\); \\(5 = 2\\); \\(4 = 3\\); \\(3 = 4\\); \\(2 = 5\\); \\(1 = 6\\)). (Figure 15.7 참조)\n새로운 계산 변수를 계산하여 “친화성” 점수를 생성합니다. 이는 A1R, A2, A3, A4, A5의 평균을 계산하는 방식으로 이루어집니다. jamovi의 새로운 변수 계산 명령을 사용합니다(Figure 15.8 참조).\n\n\n\n\n\n\n\n\n\nFigure 15.7. jamovi 변환 명령을 사용하여 변수 재코딩\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 15.8. jamovi 계산된 변수 명령을 사용하여 새로운 척도 점수 계산\n\n\n\n\n\n또 다른 방법은 최적 가중치를 적용한 요인 점수를 생성하는 것입니다. 이를 수행하려면 ‘저장’ 옵션에서 ’요인 점수’를 체크하여 요인 점수를 데이터 세트에 저장하면 됩니다. 이렇게 하면 추출된 각 요인에 해당하는 다섯 개의 새로운 변수가(열이) 데이터에 추가됩니다(Figure 15.9 및 Figure 15.10 참조).\n\n\n\n\n\n\n\n\nFigure 15.9. 다섯 개 요인 해에 대해 ‘Bartlett’ 최적 가중 방법을 사용한 jamovi 요인 점수 옵션\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 15.10. 새롭게 생성된 다섯 개 요인 점수 변수를 보여주는 데이터 시트 보기\n\n\n\n\n\n이제 평균 점수를 기반으로 한 요인 척도(Figure 15.8) 또는 jamovi가 계산한 최적 가중 요인 점수를 사용하여 추가 분석을 수행할 수 있습니다. 선택은 여러분의 몫입니다! 예를 들어, 각 성격 척도에서 성별 차이가 있는지 확인해 볼 수도 있습니다. 우리는 평균 점수 접근법을 사용하여 친화성 점수에 대해 이 분석을 수행했으며, \\(t\\)-검정 플롯(Figure 15.11)에 따르면 남성이 여성보다 덜 친화적인 경향을 보였으나, 이 차이는 통계적으로 유의하지 않았습니다(Mann-Whitney \\(U = 5768\\), \\(p = .075\\)).\n\n\n\n\n\n\n\n\nFigure 15.11. 친화성 요인 기반 점수에서 남성과 여성 간 차이 비교\n\n\n\n\n\n\n\n\n\n\n\n탐색적 요인분석\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Personality Questionnaire’를 선택합니다.\n스프레드시트 창에서 각 변수의 이름을 더블클릭하여 각 변수의 척도유형과 데이터 유형이 제대로 설정되어 있는지 확인하고 필요하면 이를 정정합니다.\n\n\nID: 아이디, 정수\nA1에서 O5, age: 연속변수, 정수\ngender: 명명변수, 문자\n\n\n다음을 차례대로 수행하여 A1에서 O5를 사용하여 EFA를 수행해 봅니다.\n\n\n‘분석’-‘요인분석’-‘탐색적 요인분석’ 메뉴를 선택합니다.\n‘탐색적 요인분석’ 설정 창에서 다음을 수행합니다.\n\nA1부터 O5를 선택하여 ‘변수’ 상자로 이동합니다.\n‘방법’에서 ’추출’은 ’최소 잔차 값’, ’회전’은 ’Oblimin’을 선택합니다.\n’요인 갯수’는 ’Based on parallel analysis’를 선택합니다.\n’가정검증’의 ’Bartlett의 구형성 검증’과 ’KMO 구형성 검증’을 체크합니다.\n‘추가 결과’에서 ’요인 통계량’, ‘요인 상관’, ’Scree plot’을 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n\nA1 열의 척도가 역전이 되도록 역코딩하여 Figure 15.7 처럼 A1R 열을 만듭니다.\n\n\n‘데이터’에서 A1 열을 클릭한 후, ’변환’ 메뉴를 선택합니다. 그러면 ‘다중 변환 변수’ 설정 창이 상단에 나타납니다.\n‘다중 변환 변수’ 설정 창에서 이름을 A1R로 변경합니다.\n’변환 사용’에서 ’새 변환 만들기’를 선택합니다.\n’변환’의 이름을 ’역코딩’으로 설정합니다.\n’새로운 관측치 추가’를 5 번 선택한 후 Figure 15.8 처럼 6이면 1, 5 이면 2, 4이면 3, 3이면 4, 2이면 5, 나머지 경우는 6이 되도록 설정합니다.\n\n\nFigure 15.8 처럼 친화성 요인 점수를 만들어 봅니다.\n\n\n‘데이터’-‘추가’-‘다중 계산 변수’-‘추가’ 메뉴를 선택합니다. 그러면 상단에 ‘다중 계산 변수’ 설정 창이 나타납니다.\n‘다중 계산 변수’ 창에서 이름을 친화성으로 변경합니다.\n\\(f_x\\) 옆의 수식 상자에 다음을 입력합니다. MEAN(A1R, A2, A3, A4, A5)\n\n\n요인 적재량을 가중치로 하여 요인 점수를 만들어 봅시다.\n\n\n오른쪽 결과 창에서 ‘탐색적 요인분석’ 결과를 클릭합니다. 그러면 왼쪽에 ‘탐색적 요인분석’ 설정 창이 나타납니다.\nFigure 15.9 처럼 ‘저장’ 옵션을 확장하여 ’요인 점수’를 체크합니다.\n그러면 ’데이터’의 스프레드시트에서 요인 점수를 나타내는 열이 5 개 추가되었음을 확인할 수 있다.(Figure 15.10)\n\n\n친화성에 성별 차이가 있는지를 가설 검정해 봅니다.\n\n\n‘분석’-‘T-검정’-‘독립표본 T 검정’ 메뉴를 선택합니다.\n‘독립표본 T 검정’ 설정 창에서 친화성을 ‘종속변수’ 상자로, gender를 ‘집단변수’ 상자로 이동합니다.\n’가정검증’에서 ’등분산 검정’과 ’정규분포성 검정’을 체크합니다.\n정규성이 만족되지 않으므로 ’검정’에서 ’Mann-Whitney U’를 체크합니다.\n‘추가 통계’에서 ’효과 크기’, ‘기술통계’, ’기술통계 도표’를 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15.1.4 EFA 보고하기\n지금까지 탐색적 요인분석(EFA)에 대한 개요와 jamovi에서 EFA를 수행하는 방법을 설명해 드렸습니다. 그렇다면 EFA를 완료한 후에는 이를 어떻게 보고해야 할까요? EFA를 보고하는 데 있어 공식적인 표준 방식은 없으며, 분야와 연구자에 따라 작성 방식이 다를 수 있습니다. 그렇지만, 일반적으로 포함해야 할 주요 정보는 다음과 같습니다.\n\n연구하고 있는 영역의 이론적 배경과, 특히 EFA를 통해 발견하고자 하는 구성 개념에 대한 설명을 제시합니다.\n표본에 대한 설명을 포함합니다(예: 인구통계학적 정보, 표본 크기, 표집 방법).\n사용한 데이터의 유형(예: 명목형, 연속형)과 기술 통계를 설명합니다.\nEFA의 가정을 어떻게 검토했는지 설명합니다. 구형성 검정과 표본 적절성 측정에 대한 세부 사항을 보고해야 합니다.\n사용한 요인분석(FA) 추출 방법(예: ‘최소 잔차법’ 또는 ‘최대 우도법’)을 설명합니다.\n최종 해결안에서 몇 개의 요인을 추출했는지, 그리고 어떤 항목을 선택했는지를 결정하기 위해 사용한 기준과 과정을 설명합니다. EFA 과정에서 이루어진 주요 결정의 근거를 명확히 제시해야 합니다.\n사용한 회전 방법, 그 이유, 그리고 결과를 설명합니다.\n최종 요인 적재량을 표로 작성하여 결과에 보고해야 합니다. 이 표에는 각 변수의 독자성 또는 공통성이 마지막 열에 포함되어야 합니다. 요인 적재량은 항목 번호뿐만 아니라 설명적인 레이블과 함께 보고해야 합니다. 또한, 요인 사이의 상관관계도 이 표의 하단 또는 별도의 표에 포함해야 합니다.\n추출된 요인에 의미 있는 이름을 부여해야 합니다. 이전에 선택한 요인 이름을 사용할 수도 있지만, 실제 항목과 요인을 검토한 후 더 적절한 이름이 있을 수도 있으므로 이를 고려해야 합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>요인분석</span>"
    ]
  },
  {
    "objectID": "15-Factor-Analysis.html#주성분-분석",
    "href": "15-Factor-Analysis.html#주성분-분석",
    "title": "15  요인분석",
    "section": "15.2 주성분 분석",
    "text": "15.2 주성분 분석\n이전 절에서 탐색적 요인분석(EFA)이 내재된 잠재 요인을 식별하는 방식에 대해 살펴보았습니다. 또한, 특정한 상황에서는 소수의 잠재 요인을 이용하여 추가적인 통계 분석을 수행할 수 있음을 확인하였습니다.\n이러한 방식에서 EFA는 “데이터 축소(data reduction)” 기법으로 사용됩니다. EFA 계열에 속하는 또 다른 데이터 축소 기법으로 주성분 분석(Principal Component Analysis, PCA) 이 있습니다. 그러나 PCA는 내재된 잠재 요인을 식별하지 않습니다. 대신, 측정된 변수들로 이루어진 더 큰 집합으로부터 선형 결합 변수를 생성합니다.\nPCA는 변수들이 어떻게 공변하는지에 대한 가정 없이(모형 없이) 단순히 원본 데이터를 수학적으로 변환하는 기법입니다. PCA의 목표는 원본 변수들로부터 소수의 선형 결합(주성분, components)을 계산하여, 정보를 크게 손실하지 않으면서도 관측된 데이터를 요약하는 것입니다. 그러나 분석의 목표가 내재된 구조를 식별하는 것이라면, EFA를 사용하는 것이 더 적절합니다. 그리고 앞서 살펴본 바와 같이, EFA는 주성분 점수와 마찬가지로 데이터 축소 목적으로 사용할 수 있는 요인 점수를 생성합니다 (Fabrigar et al., 1999).\nPCA는 여러 가지 이유로 심리학 분야에서 오랫동안 인기가 있었습니다. 따라서 이에 대해 언급할 가치가 있습니다. 그러나 오늘날에는 데스크톱 컴퓨터의 성능이 향상됨에 따라 EFA를 수행하는 것이 PCA만큼이나 쉬워졌으며, 특히 적은 수의 요인과 변수를 다룰 때 PCA보다 편향에 덜 취약할 수 있습니다. PCA와 EFA는 개념적으로 차이가 있지만, 절차적으로는 대부분 유사하며, 표본 크기가 크고 충분한 수의 요인과 변수가 존재할 경우 PCA와 EFA의 결과는 상당히 유사할 것입니다.\njamovi에서 PCA를 수행하려면, jamovi의 기본 버튼 바에서 ‘요인분석’-’주성분 분석’을 선택하여 PCA 분석 창을 열면 됩니다. 그런 다음, 위의 [jamovi에서의 EFA 수행하기] 절차를 동일하게 따라 수행하면 됩니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>요인분석</span>"
    ]
  },
  {
    "objectID": "15-Factor-Analysis.html#확인적-요인분석",
    "href": "15-Factor-Analysis.html#확인적-요인분석",
    "title": "15  요인분석",
    "section": "15.3 확인적 요인분석",
    "text": "15.3 확인적 요인분석\n성격 문항 풀에서 신중하게 선택한 질문을 사용하여 EFA를 통해 잠재 요인을 식별하려는 우리의 시도는 상당히 성공적인 것으로 보였습니다. 성격을 측정하는 유용한 도구를 개발하기 위한 다음 단계는 원래 EFA에서 확인한 잠재 요인을 다른 표본으로 검증하는 것입니다. 우리는 이 요인들이 유지되는지, 다른 데이터에서도 그 존재를 확인할 수 있는지를 확인하고자 합니다. 이는 더 엄격한 검증 과정이며, 우리는 이를 확인적 요인분석(Confirmatory Factor Analysis, CFA)이라고 부릅니다. 예상할 수 있듯이, 사전에 명시된 잠재 요인 구조를 확인하려는 과정입니다.7\nCFA에서는 탐색적인 방식으로 데이터를 분석하는 대신, Figure 15.12 에 나타난 것처럼 사전에 구조를 설정하고 데이터가 해당 구조에 얼마나 잘 맞는지를 확인합니다. 즉, 관찰된 데이터가 사전에 설정된 모형을 얼마나 잘 확인하는지를 검증하는 분석을 수행하는 것입니다.\n성격 문항에 대한 기본적인 확인적 요인분석(CFA)은 Figure 15.12 에 나타난 것처럼 다섯 개의 잠재 요인을 설정하고, 각각을 다섯 개의 관찰된 변수로 측정하는 방식으로 이루어집니다. 각 변수는 특정한 잠재 요인을 측정하는 도구입니다. 예를 들어, A1은 잠재 요인인 친화성(Agreeableness)에 의해 예측됩니다. 그러나 A1이 친화성을 완벽하게 측정하는 것은 아니므로, 이에 대한 오차 항 \\(e\\)가 존재합니다. 다시 말해, \\(e\\)는 A1의 분산 중 친화성 요인으로 설명되지 않는 부분을 나타내며, 이를 측정 오차(measurement error)라고 합니다.\n\n\n\n\n\n\n\n\nFigure 15.12. 확인적 요인분석을 위한 성격 척도의 초기 잠재 요인 구조 사전 지정\n\n\n\n\n\n다음 단계는 우리의 모형에서 잠재 요인들이 서로 상관 관계를 가질 수 있도록 허용할지 여부를 고려하는 것입니다. 앞서 언급했듯이, 심리학 및 행동 과학에서 사용되는 구성 개념들은 종종 서로 관련되어 있으며, 우리의 성격 요인 중 일부도 서로 상관이 있을 가능성이 있습니다. 따라서 모형에서 Figure 15.12 에 나타난 양방향 화살표를 통해 이러한 잠재 요인들이 공분산을 가질 수 있도록 허용하는 것이 좋을 것 같습니다.\n동시에, 일부 오차 항들이 서로 상관 관계를 가질 필요가 있는지 여부도 고려해야 합니다. 관찰된 변수들의 하위 집합에 대해 공통된 방법론적 특성이 존재하는 경우, 이러한 변수들이 실제 잠재 요인이 아니라 방법론적 요인으로 인해 연관될 가능성이 있습니다. 이 가능성에 대해서는 이후 절에서 다시 논의할 예정이지만, 현재로서는 오차 항들 사이의 상관성을 정당화할 명확한 이유는 보이지 않습니다.\n오차 항 사이의 상관성이 없는 상태에서, 우리가 관측된 데이터와 얼마나 잘 맞는지를 검증하고자 하는 모형은 Figure 15.12 에 명시된 것과 같습니다. CFA에서는 모형에 포함된 모수만이 데이터에서 존재할 것으로 예상하며, 다른 모든 가능한 모수(계수)는 0으로 설정됩니다. 따라서 이러한 다른 매개 변수가 0이 아닐 경우(예: A1이 실제 데이터에서는 외향성 잠재 요인에 상당한 적재량이 있지만, 우리의 모형에서는 그렇지 않은 경우)에는, 관찰된 데이터에 대한 모형의 적합도가 낮아질 수 있습니다.\n좋습니다. 이제 jamovi에서 이 CFA 분석을 설정하는 방법을 살펴보겠습니다.\n\n15.3.1 jamovi에서의 CFA\nbfi_sample2.csv 파일을 열고, 25개의 변수가 서열형(또는 연속형)으로 코딩되어 있는지 확인합니다. (이번 분석에서는 두 가지 중 어느 것이든 무관합니다.) jamovi에서 CFA를 수행하려면 다음과 같이 하십시오:\n\njamovi의 기본 버튼 바에서 ’Factor - Confirmatory Factor Analysis’를 선택하여 CFA 분석 창을 엽니다 (Figure 15.13).\n5개의 A 변수를 선택하여 ‘요인’ 상자로 이동시키고, “친화성”이라는 라벨을 부여합니다.\n‘요인’ 상자에서 ‘새 요인 추가’를 눌러 새 요인을 생성하고 “성실성”이라는 라벨을 부여합니다. 그런 다음 5개의 C 변수를 선택하여 “성실성” 아래의 ’요인’ 상자로 이동시킵니다.\n또 다른 새로운 요인을 생성하고 “외향성”이라는 라벨을 부여합니다. 그런 다음 5개의 E 변수를 선택하여 “외향성” 아래의 ‘요인’ 상자로 이동시킵니다.\n또 다른 새로운 요인을 생성하고 “신경증”이라는 라벨을 부여합니다. 그런 다음 5개의 N 변수를 선택하여 “신경증” 아래의 ‘요인’ 상자로 이동시킵니다.\n또 다른 새로운 요인을 생성하고 “개방성”이라는 라벨을 부여합니다. 그런 다음 5개의 O 변수를 선택하여 “개방성” 아래의 ‘요인’ 상자로 이동시킵니다.\n기타 적절한 옵션을 확인합니다. 이번 초기 분석에서는 기본 설정값을 사용하는 것이 괜찮지만, ‘추가 결과’-‘도표’ 아래에서 “경로 모형” 옵션을 선택하면 jamovi가 Figure 15.12 와 (상당히) 유사한 다이어그램을 생성하는 것을 확인할 수 있습니다.\n\n분석을 설정한 후, jamovi 결과 창으로 이동하여 결과를 확인합니다. 가장 먼저 확인해야 할 것은 모형 적합도(model fit) (Figure 15.14)입니다. 이는 모형이 관찰된 데이터에 얼마나 잘 맞는지를 보여줍니다. 주의할 점은, 우리 모형에서는 사전에 지정된 공분산(요인 간 상관 포함)만 추정되며, 다른 모든 가능한 값은 0으로 설정된다는 것입니다.\n모형 적합도를 평가하는 방법에는 여러 가지가 있습니다. 첫 번째는 카이제곱(chi-square) 통계량으로, 값이 작을수록 모형이 데이터에 적합함을 나타냅니다. 하지만, 모형 적합도를 평가하는 카이제곱 통계량은 표본 크기에 매우 민감하여, 표본 크기가 크면 모형과 데이터 간 적절한 적합도가 있더라도 거의 항상 크고 유의미한 (\\(p &lt; .05\\)) 카이제곱 값을 생성하는 경향이 있습니다.\n따라서, 다른 방식으로도 모형 적합도를 평가해야 합니다. jamovi에서는 기본적으로 여러 지표를 제공합니다. 대표적인 지표는 비교 적합 지수(Comparative Fit Index, CFI), 터커 루이스 지수(Tucker Lewis Index, TLI), 근사 오차 제곱 평균(Root Mean Square Error of Approximation, RMSEA) 및 RMSEA의 90% 신뢰 구간입니다. 일반적인 기준은 CFI &gt; 0.9, TLI &gt; 0.9, RMSEA가 약 0.05~0.08이면 만족스러운 적합도를 나타냅니다. 좋은 적합도는 CFI &gt; 0.95, TLI &gt; 0.95, RMSEA 및 RMSEA 상한 신뢰구간이 0.05 미만인 경우입니다.\n\n\n\n\n\n\n\n\nFigure 15.13. jamovi의 CFA 분석 창\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 15.14. 우리의 CFA 모형에 대한 jamovi CFA 모형 적합도 결과\n\n\n\n\n\nFigure 15.14 를 살펴보면, 카이제곱 값이 크고 유의하게 나타났음을 알 수 있습니다. 우리 표본 크기는 너무 크지 않으므로, 이는 적합도가 좋지 않음을 시사할 수 있습니다. CFI 값은 \\(0.762\\), TLI 값은 \\(0.731\\)로, 모형과 데이터 사이의 적합도가 좋지 않음을 나타냅니다. RMSEA는 \\(0.085\\)이며, 90% 신뢰 구간은 \\(0.077\\)에서 \\(0.092\\) 사이로, 역시 좋은 적합도를 나타내지 않습니다.\n꽤 실망스럽죠? 하지만 놀라운 일은 아닙니다. 앞서 EFA를 수행했을 때(자세한 내용은 탐색적 요인분석 절 참조), 유사한 데이터에서 다섯 요인 모형이 데이터 분산의 절반 정도만 설명할 수 있었기 때문입니다.\n요인 적재량과 요인 공분산 추정치를 살펴보겠습니다 (Figure 15.15 및 Figure 15.16). 각 모수에 대한 \\(Z\\)-통계량과 \\(p\\)-값은 해당 모수가 모형에 상당한 기여를 한다는 것을 나타냅니다(즉, 0이 아닙니다). 따라서 지정된 변수-요인 경로나 요인-요인 상관관계를 제거할 이유는 없어 보입니다. 종종 표준화된 추정치가 해석하기 더 쉬우며, 이는 ‘추정값’ 옵션에서 지정할 수 있습니다. 이러한 표들은 보고서나 과학 논문에 유용하게 포함될 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 15.15. jamovi의 CFA 요인 적재량 표\n\n\n\n\n\n모형을 어떻게 개선할 수 있을까요? 하나의 방법은 몇 단계를 거슬러 올라가 우리가 사용하는 항목/측정치를 다시 고려하고 어떻게 개선하거나 변경할 수 있을지를 생각해 보는 것입니다. 또 다른 방법은 모형 적합도를 개선하기 위해 사후 수정(post hoc tweaks)을 수행하는 것입니다. 이를 수행하는 한 가지 방법은 jamovi에서 ‘추가 결과’ 옵션으로 지정할 수 있는 “수정 지수(modification indices)”를 사용하는 것입니다 (Figure 15.17).\n우리가 찾고자 하는 것은 가장 높은 수정 지수(MI) 값입니다. 그런 다음, 추가적인 항목을 모형에 포함하는 것이 이론적으로 타당한지 여부를 판단해야 합니다. 예를 들어, Figure 15.17 에서 모형에 포함되지 않은 요인 적재량 중 가장 높은 MI 값은 N4(“자주 우울함을 느낌”)가 외향성 잠재 요인에 대한 적재량으로 28.786입니다. 이는 이 경로를 모형에 추가하면 카이제곱 값이 대략 동일한 크기만큼 감소한다는 것을 의미합니다.\n그러나 우리 모형에서 이 경로를 추가하는 것은 이론적 또는 방법론적으로 타당하지 않아 보이므로 좋은 선택이 아닙니다(물론 “자주 우울함을 느낌”이 신경증과 외향성을 모두 측정한다고 설득력 있는 논리를 제시할 수 있다면 예외일 수 있습니다). 저로서는 적절한 이유를 찾을 수 없습니다. 그러나 논의를 위해, 이것이 의미가 있다고 가정하고 이 경로를 모형에 추가해 보겠습니다. CFA 분석 창(Figure 15.13 참고)으로 돌아가 N4를 외향성 요인에 추가하세요. 이제 CFA 결과가 변경됩니다(결과는 표시되지 않음). 카이제곱 값은 약 709로 감소했으며(대략 MI 크기만큼 감소), 다른 적합도 지수도 다소 향상되었습니다. 그러나 여전히 적합도가 충분히 좋지는 않습니다.\n만약 MI 값을 사용하여 모형에 새로운 매개변수를 추가하는 경우, 각 추가 후 MI 표를 다시 확인해야 합니다. MI 값은 매번 새롭게 갱신되기 때문입니다.\n\n\n\n\n\n\n\n\nFigure 15.16. jamovi의 CFA 요인 공분산 표\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 15.17. jamovi의 CFA 요인 적재량 수정 지수\n\n\n\n\n\njamovi에서는 또한 잔차 공분산 수정 지수 표를 생성합니다 (Figure 15.18). 즉, 모형 적합도를 가장 많이 향상시킬 수 있는 상관된 오류를 보여주는 표입니다. 두 개의 MI 표를 동시에 살펴보는 것이 좋으며, 가장 큰 MI를 찾아보고 해당 매개변수를 추가하는 것이 합리적인지 생각해 본 후, 가능하면 모형에 추가하세요. 그런 다음 다시 가장 큰 MI를 찾아 재계산된 결과를 확인하면 됩니다.\n\n\n\n\n\n\n\n\nFigure 15.18. jamovi에서 생성된 잔차 공분산 수정 지수\n\n\n\n\n\n이러한 방식으로 원하는 만큼 계속 진행하여 MI 값을 기반으로 모형에 매개변수를 추가하면 결국 만족할 만한 적합도를 얻을 수 있습니다. 그러나 그렇게 하는 과정에서 “괴물”을 만들어낼 가능성이 높습니다! 즉, 이론적으로 타당성이 부족하고 왜곡된 모형이 될 수 있습니다. 따라서 매우 신중해야 합니다!\n지금까지 우리는 EFA에서 얻은 요인 구조를 두 번째 표본과 CFA를 사용하여 확인해 보았습니다. 그러나 안타깝게도 EFA에서 도출한 요인 구조가 CFA에서 확인되지 않았기 때문에, 성격 척도의 개발을 다시 시작해야 할 것 같습니다.\nCFA를 수정 지수를 사용하여 조정할 수도 있었지만, 제가 생각하기에는 추가적인 요인 적재량이나 잔차 공분산을 포함할 만한 타당한 이유가 없었습니다. 그러나 때로는 잔차가 공분산(또는 상관)을 허용해야 할 이유가 존재할 수도 있으며, 이에 대한 좋은 예시는 다음 다특질 다방법 CFA 절에서 다루겠습니다. 그 전에, CFA 결과를 보고하는 방법에 대해 알아보겠습니다.\n\n\n\n\n\n\n확인적 요인분석\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ‘Personality Questionnaire’ 두 번째(CFA) 데이터를 선택합니다.\n스프레드시트 창에서 각 변수의 이름을 더블클릭하여 각 변수의 척도유형과 데이터 유형이 제대로 설정되어 있는지 확인하고 필요하면 이를 정정합니다.\n\n\nID: 아이디, 정수\nA1에서 O5, age: 연속변수, 정수\ngender: 명명변수, 문자\n\n\n‘분석’-‘요인분석’-‘확인적 요인분석’ 메뉴를 선택하면, 왼쪽에 ‘확인적 요인분석’ 설정 창이 나타납니다.\n\n5.’확인적 요인분석’ 설정 창에서 앞에서 설명한 것처럼 친화성, 성실성, 외향성, 신경증, 개방성 요인을 설정합니다.\n\n\n\n\n\n\n\n\n\n\n‘추가 결과’ 옵션을 확장하여 ’수정 지수’와 ’경로 모형’을 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n수정 지수 값이 가장 높은 외향성 -&gt; N4 경로를 모형에 추가해 봅니다.\n\n\n‘요인’ 상자에서 외향성 요인을 선택한 후, 왼편에서 N5를 선택하여 외향성 요인에 추가합니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15.3.2 CFA 보고하기\n확인적 요인분석(CFA)을 보고하는 데 있어 공식적인 표준 방식은 없으며, 분야와 연구자에 따라 다양한 방식이 사용됩니다. 그렇지만, 보고서에 포함하는 것이 일반적으로 권장되는 주요 정보들은 다음과 같습니다.\n\n가설로 설정한 모형에 대한 이론적, 실증적 근거.\n모형의 명세에 대한 완전한 설명 (예: 각 잠재 요인을 나타내는 지표 변수, 잠재 변수 사이의 공분산, 그리고 오류 항 사이의 상관 관계 등). Figure 15.12 와 같은 경로 다이어그램을 포함하는 것이 좋습니다.\n표본에 대한 설명 (예: 인구통계학적 정보, 표본 크기, 표본 추출 방법).\n사용된 데이터 유형(예: 명목형, 연속형)과 기술 통계량에 대한 설명.\n가정 검토 및 사용된 추정 방법.\n결측 데이터에 대한 설명과 해당 데이터를 어떻게 처리했는지에 대한 설명.\n모형 적합에 사용된 소프트웨어 및 버전 정보.\n모형 적합도를 평가하는 데 사용된 기준과 측정 방법.\n모형 적합도나 수정 지수를 기반으로 원래 모형에서 수정한 사항.\n모든 모수 추정값(즉, 요인 부하량, 오류 분산, 잠재 변수의 공분산)과 이에 대한 표준 오차를 표 형태로 제공.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>요인분석</span>"
    ]
  },
  {
    "objectID": "15-Factor-Analysis.html#다특질-다방법-cfa",
    "href": "15-Factor-Analysis.html#다특질-다방법-cfa",
    "title": "15  요인분석",
    "section": "15.4 다특질 다방법 CFA",
    "text": "15.4 다특질 다방법 CFA\n이 절에서는 방법 분산(method variance)이라는 개념을 살펴볼 것입니다. 방법 분산이란 서로 다른 측정 기법이나 질문이 데이터 변동성의 중요한 원천이 될 수 있다는 것입니다. 이를 위해 “귀인 양식(attributional style)”에 대한 데이터를 포함하는 또 다른 심리학적 데이터를 사용하겠습니다.\n귀인 양식 질문지(Attributional Style Questionnaire, ASQ)는 영국과 뉴질랜드의 젊은이를 대상으로 심리적 웰빙 데이터를 수집하기 위해 사용되었습니다(Hewitt et al., 2004). 연구에서는 부정적 사건에 대한 귀인 양식을 측정하였으며, 이는 사람들이 자신에게 일어나는 나쁜 일의 원인을 어떻게 습관적으로 설명하는지를 나타냅니다(Peterson & Seligman, 1984). ASQ는 귀인 양식의 세 가지 측면을 측정합니다.\n\n내재성(Internality): 개인이 나쁜 사건의 원인을 자신의 행동 때문이라고 믿는 정도입니다.\n지속성(Stability): 개인이 나쁜 사건의 원인이 시간이 지나도 변하지 않는다고 습관적으로 믿는 정도입니다.\n전반성(Globality): 개인이 특정 영역에서 발생한 나쁜 사건이 자신의 삶의 다른 영역에도 영향을 미칠 것이라고 믿는 정도입니다.\n\n이 설문지는 여섯 가지 가상의 시나리오를 포함하며, 각 시나리오에 대해 응답자는 (a) 내재성, (b) 지속성, (c) 전반성을 평가하는 질문에 답하게 됩니다. 따라서 총 문항 수는 \\(6 \\times 3 = 18\\)개입니다. 자세한 내용은 Figure 15.19 를 참고하십시오.\n\n\n\n\n\n\n\n\nFigure 15.19. 부정적 사건에 대한 귀인 양식 질문지(ASQ)\n\n\n\n\n\n연구자들은 ASQ의 18개 관찰 변수가 잠재 요인을 적절히 측정하는지를 확인하기 위해 데이터를 분석하고자 합니다.\n먼저 연구자들은 18개 변수에 대해 탐색적 요인분석(EFA)을 수행했지만(결과는 미제시), 요인을 어떻게 추출하거나 회전시키더라도 적절한 요인 해를 찾을 수 없었습니다. 즉, 귀인 양식 질문지(ASQ)에서 잠재 요인을 식별하려는 시도가 실패로 돌아갔습니다. 이러한 결과가 나온다면, 가능한 원인은 다음과 같습니다.\n\n연구의 이론적 가설이 틀렸을 가능성 (즉, 귀인 양식에는 기본적인 잠재 요인 구조가 존재하지 않을 수도 있음).\n표본이 적절하지 않을 가능성 (하지만 영국과 뉴질랜드의 젊은 성인을 대상으로 한 이 표본의 크기와 특성을 고려할 때 가능성이 낮음).\n사용한 분석 방법이 적절하지 않았을 가능성.\n\n우리는 세 번째 가능성에 주목하여 분석 방법이 적절했는지를 살펴보겠습니다.\nASQ에서는 내재성, 지속성, 전반성의 세 가지 차원을 측정하였으며, 각 차원은 여섯 개의 질문으로 평가되었습니다(Table 15.2 참고).\n그렇다면 데이터를 탐색적으로 분석하는 대신, Table 15.2 에서처럼 사전에 정해진 구조를 데이터에 적용한 후, 데이터가 이 구조에 얼마나 잘 들어맞는지를 살펴보는 방식으로 분석을 수행하면 어떨까요? 즉, 사전에 정해진 모형이 관찰된 데이터에 의해 얼마나 잘 확인되는지를 알아보기 위해 확인적 요인분석을 수행하는 것입니다.\n따라서 ASQ에 대한 기본적인 확인적 요인분석(CFA)에서는 Figure 15.24 의 열에 나타난 것처럼 세 개의 잠재 요인을 지정하고, 각각을 여섯 개의 관찰 변수가 측정하도록 설정합니다.\n\n\n\n\nTable 15.2. 내재성, 지속성, 전반성 차원별 ASQ 문항 6개\n\n\n\n\n\n내재성지속성전반성\n\nQ1aQ1bQ1c\n\nQ2aQ2bQ2c\n\nQ3aQ3bQ3c\n\nQ4aQ4bQ4c\n\nQ5aQ5bQ5c\n\nQ6aQ6bQ6c\n\n\n\n\n\n\n\n이러한 관계를 Figure 15.20 의 다이어그램처럼 나타낼 수 있습니다. 여기서 각 변수는 특정 잠재 요인을 측정하는 지표 변수입니다. 예를 들어, INT1은 내재성 요인에 의해 예측됩니다. 하지만 INT1이 내재성 요인을 완벽하게 측정하는 것은 아니므로, \\(e_1\\)이라는 오류 항이 이에 대응됩니다. 즉, \\(e_1\\)은 INT1의 분산 중 내재성 요인에 의해 설명되지 않는 부분을 나타내며, 이는 종종 “측정 오류(measurement error)”라고 불립니다.\n다음 단계는 우리 모형에서 잠재 요인들이 서로 상관을 가질 수 있도록 허용해야 하는지를 고려하는 것입니다. 앞서 언급했듯이, 심리학 및 행동과학에서는 구성개념들이 서로 연관되는 경우가 많으며, 내재성, 지속성, 전반성 또한 서로 상관되어 있을 수 있습니다. 따라서 모형에서 이러한 잠재 요인들이 공분산을 가질 수 있도록 설정해야 합니다. 이는 Figure 15.21 에 나타나 있습니다.\n\n\n\n\n\n\n\n\nFigure 15.20. ASQ에 대한 초기 잠재 요인 구조 사전 지정\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 15.21. ASQ에 대한 최종 잠재 요인 구조 사전 지정, 잠재 요인 간 상관과 CFA MTMM 모형에서 관찰 변수(INT1, STAB1, GLOB1)의 공유 방법 오류 항 상관 포함. 명확성을 위해 다른 사전 지정된 오류 항 상관은 표시되지 않음.\n\n\n\n\n\n동시에, 특정 오류 항들 사이에 상관성이 존재할 만한 체계적인 이유가 있는지도 고려해야 합니다. ASQ의 질문을 다시 떠올려 보면, 각 주요 질문(1~6)에 대해 세 개의 하위 질문(a, b, c)이 있었습니다. 예를 들어, Q1은 “취업 실패”에 관한 질문이었으며, 이는 다른 질문(Q2~Q5)과 비교했을 때 고유한 방법론적 특성을 가질 가능성이 있습니다. 아마도 취업 실패와 관련된 특정한 측면이 반영되었을 수 있습니다. 마찬가지로, Q2는 “친구를 돕지 않은 상황”에 대한 질문이었으며, 이 질문 역시 다른 질문(Q1 및 Q3~Q5)과 구별되는 방법론적 특성을 가질 수 있습니다.\n즉, ASQ에서는 여러 요인뿐만 아니라 여러 방법론적 특징도 존재합니다. 각 질문(1~6)은 약간씩 다른 “방법”을 사용하고 있지만, 각 방법은 해당 질문의 하위 질문(a, b, c)에서 공통적으로 적용됩니다. 이러한 방법론적 특성을 모형에 반영하기 위해 특정 오류 항들 사이의 상관을 설정할 수 있습니다. 예를 들어, INT1, STAB1, GLOB1에 해당하는 오류 항들은 서로 상관될 수 있도록 지정해야 합니다. 이는 Q1a, Q1b, Q1c가 공유하는 고유한 방법론적 분산을 반영하기 위함입니다. Table 1.2 를 보면, 열로 표현된 잠재 요인뿐만 아니라, 행에 속한 변수들 사이에도 측정 오류가 관련되어 있을 수 있습니다.\nFigure 15.20 에 제시된 기본적인 CFA 모형을 실제 관찰 데이터에 적용해볼 수도 있지만, 우리는 보다 정교한 모형을 개발하였습니다. 이는 Figure 15.21 의 다이어그램에 나타나 있습니다. 이러한 보다 정교한 CFA 모형을 다특질 다방법(Multi-Trait Multi-Method, MTMM) 모형이라고 하며, 우리는 이 모형을 jamovi에서 검증할 것입니다.\n\n15.4.1 jamovi에서 MTMM CFA 수행하기\nASQ.csv 파일을 열고 18개의 변수(여섯 개의 “내재성”, 여섯 개의 “안정성”, 여섯 개의 “전반성” 변수)가 연속형 변수로 지정되어 있는지 확인하십시오.\njamovi에서 MTMM CFA를 수행하려면 다음 단계를 따르십시오.\n\njamovi의 기본 버튼 바에서 ‘요인분석’-‘확인적 요인분석’를 선택하여 ’확인적 요인분석’ 창을 엽니다(Figure 15.22).\n6개의 INT 변수를 선택하여 ‘요인’ 상자로 이동시키고 “내재성”이라는 라벨을 지정하십시오.\n‘요인’ 상자에서 ‘새 요인 추가’를 하여 요인을 생성하고 “지속성”이라는 라벨을 지정하십시오. 그런 다음 6개의 STAB 변수를 선택하여 ’요인’ 상자의 “지속성” 아래에 추가하십시오.\n다시 한 번 ‘요인’ 상자에서 새 요인을 생성하고 “전반성”이라는 라벨을 지정하십시오. 그런 다음 6개의 GLOB 변수를 선택하여 ‘요인’ 상자의 “전반성” 아래에 추가하십시오.\n‘잔차 공분산’ 옵션을 열고, 사전에 설명한 잔차가 연관된 변수 쌍을 ‘잔차 공분산’ 상자로 이동시키십시오. 예를 들어, INT1과 STAB1을 선택한 후 화살표 버튼을 클릭하여 이동하십시오. 그런 다음 INT1과 GLOB1, STAB1과 GLOB1, INT2와 STAB2, INT2와 GLOB2, STAB2와 GLOB2, INT3과 STAB3 등을 같은 방식으로 추가하십시오.\n적절한 옵션을 선택하십시오. 기본값이 이 초기 분석에서는 적절합니다. 다만 ‘추가 결과’-‘도표’에서 ’경로 모형’ 옵션을 선택하면 jamovi가 Figure 15.21 과 유사한 다이어그램을 생성하며, 위에서 추가한 모든 오류 항의 상관성도 표현됩니다.\n\n\n\n\n\n\n\n\n\nFigure 15.22. jamovi의 CFA 분석 창\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 15.23. jamovi에서 수행한 CFA MTMM 모형의 적합도(Model Fit) 결과\n\n\n\n\n\n분석을 설정한 후 jamovi의 결과 창을 확인하여 분석 결과를 살펴보겠습니다. 가장 먼저 확인해야 할 것은 “모형 적합도”이며, 이는 모형이 실제 관찰된 데이터에 얼마나 잘 맞는지를 알려줍니다(Figure 15.23). 참고로, 이 모형에서는 사전 지정된 공분산만 추정되며, 나머지는 모두 0으로 설정되어 있습니다. 따라서 모형 적합도 검정에서는 사전 지정된 “자유로운” 모수들이 0이 아닌지 확인하는 동시에, 모형에서 지정하지 않은 다른 관계들이 0으로 유지될 수 있는지를 테스트하는 것입니다.\nFigure 15.23 을 보면, 카이제곱(\\(\\chi^2\\)) 값이 매우 유의한 것으로 나타났는데, 이는 큰 표본 크기(N = 2748)로 인해 예상된 결과입니다. CFI와 TLI 값이 각각 0.98로 나타나 매우 좋은 적합도를 보이고 있습니다. 또한 RMSEA 값은 0.02이며, 90% 신뢰구간이 0.02~0.02로 매우 좁은 범위입니다.\n전반적으로, 사전에 지정된 모형이 관찰된 데이터와 매우 잘 맞아 떨어지는 것으로 보이며, 이는 ASQ에 대한 MTMM 모형을 지지하는 결과입니다.\n이제 Figure 15.24 와 같이 요인 적재량과 요인 공분산 추정치를 살펴볼 수 있습니다. 일반적으로 표준화된 추정값이 해석하기 쉬우므로, ‘추정값’ 옵션에서 이를 선택하면 보다 직관적인 결과를 얻을 수 있습니다. 이러한 표는 연구 논문이나 보고서에 유용하게 포함될 수 있습니다.\n\n\n\n\n\n\n\n\nFigure 15.24. jamovi에서 수행한 CFA MTMM 모형의 요인 적재량 및 공분산 테이블\n\n\n\n\n\nFigure 15.24 를 보면, 사전에 지정된 모든 요인 적재량과 요인 공분산이 0과 유의미하게 다름을 확인할 수 있습니다. 즉, 이들 모두가 모형에 유용한 기여를 하고 있는 것으로 보입니다.\n이번 분석에서는 첫 번째 시도에서 매우 좋은 적합도를 얻을 수 있어 상당히 운이 좋았습니다!\n\n\n\n\n\n\nMTMM CFA\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ‘Attributional Style Questionnaire’ 데이터를 선택합니다.\n스프레드시트 창에서 각 변수의 이름을 더블클릭하여 각 변수의 척도유형과 데이터 유형이 제대로 설정되어 있는지 확인하고 필요하면 이를 정정합니다.\n\n\nID: 아이디, 정수\nINT1에서 GLOB6: 연속변수, 정수\n\n\n‘분석’-‘요인분석’-‘확인적 요인분석’ 메뉴를 선택하면, 왼쪽에 ‘확인적 요인분석’ 설정 창이 나타납니다.\n\n5.’확인적 요인분석’ 설정 창에서 앞에서 설명한 것처럼 내재성, 지속성, 전반성 요인을 설정합니다.\n\n\n\n\n\n\n\n\n\n\n‘추가 결과’ 옵션을 확장하여 ’경로 모형’을 체크합니다.\n‘잔차 공분산’ 옵션을 확장하여 같은 문항의 변수들의 공분산을 연결합니다. 그러면 다음과 같은 경로 모형이 나타납니다.\n\n\n\n\n\n\n\n\n\n\n\n‘추정값’ 옵션을 확장하여 ’표준화 추정값’을 체크하여 요인 부하량과 요인 공분산 추정치에 대한 표준화된 추정값을 표시하도록 합니다.",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>요인분석</span>"
    ]
  },
  {
    "objectID": "15-Factor-Analysis.html#sec-Internal-consistency-reliability-analysis",
    "href": "15-Factor-Analysis.html#sec-Internal-consistency-reliability-analysis",
    "title": "15  요인분석",
    "section": "15.5 내적 일관성 신뢰도 분석",
    "text": "15.5 내적 일관성 신뢰도 분석\nEFA와 CFA를 사용하여 초기 척도 개발 과정을 거친 후에는, 다른 표본을 사용한 CFA에서도 척도가 잘 유지되는 단계에 도달해야 합니다. 이 단계에서 또 하나의 관심사는, 관찰된 변수를 결합한 척도가 요인을 얼마나 잘 측정되는지를 확인하는 것입니다.\n심리측정학에서는 신뢰도 분석을 통해 특정 심리적 구성개념의 척도가 얼마나 일관된 측정을 하는지를 평가합니다(Section 2.3 참조). 여기서 우리가 관심을 가지는 것은 내적 일관성(internal consistency)으로, 이는 측정 척도를 구성하는 개별 항목들 사이의 일관성을 의미합니다. 예를 들어, 관찰된 항목 변수로 \\(V1, V2, V3, V4, V5\\)가 있다고 가정할 때, 이러한 항목들이 기저의 구성개념을 측정하는데 얼마나 일관성이 있는지를 나타내는 통계를 계산할 수 있습니다.\n척도의 내적 일관성을 확인하는 데 널리 사용되는 통계량 중 하나가 Cronbach의 알파(Cronbach’s alpha)입니다(Chronbach, 1951). Cronbach의 알파는 동등성을 측정하는 지표로, 동일 척도에 포함되는 서로 다른 항목이 동일한 측정 결과를 도출하는지를 평가합니다. 동등성 검사는 척도 항목을 두 그룹으로 나누고(즉, 반분하여) 두 부분의 분석 결과가 유사한지를 비교합니다. 항목을 나누는 방법은 여러 가지가 있지만, 가능한 모든 분할을 고려하면 반분 계수의 전반적 패턴을 반영하는 통계치를 도출할 수 있습니다. Cronbach의 알파(\\(\\alpha\\))는 이러한 반분 계수들의 함수입니다. 예를 들어, 특정 구성개념(예: 외향성 척도)을 측정하는 항목 집합이 \\(\\alpha = 0.80\\)을 갖는다면, 해당 척도의 오차 분산의 비율은 \\(0.20\\)입니다. 즉, \\(\\alpha = 0.80\\)인 척도는 약 20%의 오차를 포함하고 있습니다.\n그러나 여기서 중요한 점은, Cronbach의 알파는 단일차원성(unidimensionality)(한 척도가 단일 요인 또는 구성개념을 측정하는지를 나타냄)의 지표가 아니라는 것입니다. 다차원적인 개념의 척도는 각 차원별로 개별적으로 평가되지 않는 한, 알파 값이 과소 추정될 수 있습니다. 이 경우 반대로, 높은 알파 값이 반드시 단일차원성을 의미하는 것도 아닙니다. 따라서 \\(\\alpha = 0.80\\)이라고 해서 측정 대상이 80% 단일한 구성 개념이라고 단정할 수는 없습니다. 이 80%는 하나의 구성개념이 아니라 여러 개의 구성개념에 의해서 나타날 수도 있기 때문입니다. 따라서 EFA와 CFA를 먼저 수행하는 것이 유용합니다.\n또한, \\(\\alpha\\)의 또 다른 특징은 표본 특이성(sample specificity)을 갖는다는 점입니다. 즉, 이는 척도의 속성이 아니라, 척도가 사용된 표본의 속성입니다. 편향되거나 대표성이 부족한 소규모 표본에서는 큰 규모이면서 대표성이 높은 표본과는 매우 다른 \\(\\alpha\\) 값이 나올 수 있습니다. 심지어 대규모 표본 사이에도 \\(\\alpha\\) 값은 다르게 나타날 수 있습니다.\n이러한 한계점에도 불구하고 Cronbach의 \\(\\alpha\\)는 심리학에서 내적 일관성 신뢰도를 추정하는 데 널리 사용되고 있습니다. 계산, 이해, 해석이 비교적 쉽기 때문에, 새로운 환경이나 다른 모집단에 척도를 적용할 때 초기 평가 지표로 유용하게 활용될 수 있습니다.\nCronbach 알파의 대안으로 McDonald’s 오메가(McDonald’s omega, \\(\\omega\\))가 있습니다. jamovi에서도 이 통계를 제공합니다. \\(\\alpha\\)는 (a) 잔차에 상관성이 없음, (b) 항목들이 동일한 적재량을 가짐, (c) 척도가 단일차원이라는 가정을 전제로 하지만, \\(\\omega\\)는 이러한 가정을 하지 않기 때문에 보다 강건한 신뢰도 통계량입니다. 이러한 가정들이 위배되지 않는다면, \\(\\alpha\\)와 \\(\\omega\\)는 유사한 값을 갖지만, 가정이 위배될 경우에는 \\(\\omega\\)가 보다 신뢰할 수 있는 지표입니다.\n때때로 \\(\\alpha\\)나 \\(\\omega\\)의 “충분히 좋은” 값에 대한 임계값이 제시되기도 합니다. 예를 들어, \\(\\alpha = 0.70\\)이면 “허용 가능”한 신뢰도, \\(\\alpha = 0.80\\)이면 “좋은” 신뢰도를 나타낸다고 할 수 있습니다. 그러나 이는 척도가 정확히 무엇을 측정하는지에 따라 다를 수 있기 때문에, 이러한 임계값을 신중하게 해석해야 합니다. 따라서 단순히 \\(\\alpha\\)나 \\(\\omega\\)가 0.70이면 척도가 30%의 오차 분산을 포함하고 있으며, 0.80이면 20%의 오차 분산을 포함한다고 진술하는 것이 더 적절할 수 있습니다.\n그렇다면 \\(\\alpha\\) 값이 너무 높을 수도 있을까요? 그럴 가능성도 있습니다. 만약 \\(\\alpha\\) 값이 0.95를 초과한다면, 이는 항목들 간의 높은 상관을 나타내며, 측정이 지나치게 중복적인 특성을 있음을 시사합니다. 이는 측정되는 구성개념이 과도하게 좁을 위험이 있음을 의미할 수도 있습니다.\n\n15.5.1 jamovi에서 신뢰도 분석\n신뢰도 분석을 수행하기 위해 사용할 성격 데이터의 세 번째 표본이 있습니다: bfi_sample3.csv 파일입니다. 다시 한 번, 25개의 성격 항목 변수가 연속형으로 코딩되어 있는지 확인하십시오. jamovi에서 신뢰도 분석을 수행하려면 다음을 따르십시오.\n\njamovi의 메누에서 ‘요인분석’-’신뢰도 분석’을 선택하여 신뢰도 분석 창을 엽니다(Figure 15.25).\n5개의 A 변수를 선택하고 이를 ‘문항’ 상자로 이동합니다.\n“역코딩 문항” 옵션에서, “Normal Scaled Items” 상자에 있는 변수 A1을 선택한 후 “역코딩 문항” 상자로 이동합니다.\nFigure 15.25 같이 다른 적절한 옵션을 확인하십시오.\n\n\n\n\n\n\n\n\n\nFigure 15.25. jamovi의 ‘Reliability Analysis’ 창\n\n\n\n\n\n설정을 완료한 후, jamovi 결과 창을 확인하십시오. Figure 15.26 같은 결과가 표시될 것입니다. 여기에서 친화성(Agreeableness) 척도의 Cronbach의 \\(\\alpha\\) 계수가 0.70임을 알 수 있습니다. 이는 친화성 척도 점수의 약 30%가 오류 분산임을 의미합니다. 또한 McDonald’s \\(\\omega\\) 값도 제공되며, 이는 0.72로 \\(\\alpha\\) 값과 큰 차이가 없습니다.\n\n\n\n\n\n\n\n\nFigure 15.26. 친화성 요인에 대한 jamovi 신뢰도 분석 결과\n\n\n\n\n\n또한 특정 항목을 제거할 경우 \\(\\alpha\\) 또는 \\(\\omega\\) 값이 어떻게 향상될 수 있는지 확인할 수도 있습니다. 예를 들어, 항목 A1을 제거하면 \\(\\alpha\\) 값은 0.72, \\(\\omega\\) 값은 0.73으로 증가합니다. 그러나 이는 큰 증가폭이 아니므로 굳이 제거할 필요는 없을 것입니다.\n다른 척도에 대해서도 동일한 방식으로 신뢰도 분석을 수행할 수 있으며, 친화성 척도를 제외한 대부분의 척도는 유사한 신뢰도 값을 보였습니다. 그러나 개방성 척도의 경우, 척도 점수의 약 40%가 오류 분산으로 나타났습니다. 이는 다른 성격 척도에 비해 개방성이 신뢰할 만한 성격 속성 측정 도구로서 덜 일관됨을 시사합니다.\n\n\n\n\n\n\n내적 신뢰도 분석\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Personality Questionnaire’에 대한 세번째 데이터를 선택합니다.\n스프레드시트 창에서 각 변수의 이름을 더블클릭하여 각 변수의 척도유형과 데이터 유형이 제대로 설정되어 있는지 확인하고 필요하면 이를 정정합니다.\n\n\nID: 아이디, 정수\nA1에서 O5, age: 연속변수, 정수\ngender: 명명변수, 문자\n\n\n‘분석’-‘요인분석’-‘신뢰도 분석’ 메뉴를 선택합니다.\n‘신뢰도 분석’ 창에서 다음을 수행합니다.\n\n\nA로 시작되는 항목을 모두 ‘문항’ 상자로 이동합니다.\n‘역코딩 문항’을 확장하여 A1을 ’역코딩 문항’ 상자로 이동합니다.\n‘척도 통계’ 옵션을 모두 체크합니다.\n‘문항 통계값’ 옵션을 모두 체크합니다.\n\n\n\n\n\n\n\n\n\n\n\n‘신뢰도 분석’ 메뉴를 선택하여 이번에는 O로 시작하는 모든 문항의 신뢰성을 분석해 봅니다. (O2와 05를 역코딩 문항으로 설정해야 합니다.)",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>요인분석</span>"
    ]
  },
  {
    "objectID": "15-Factor-Analysis.html#요약",
    "href": "15-Factor-Analysis.html#요약",
    "title": "15  요인분석",
    "section": "15.6 요약",
    "text": "15.6 요약\n이 장에서는 요인분석 및 관련 기법을 소개하고, 데이터 집합 내 관계 패턴을 평가하는 통계 분석을 설명하였습니다. 구체적으로 다음을 다루었습니다.\n\n탐색적 요인분석 (EFA)는 데이터에서 잠재 요인을 식별하는 통계 기법입니다. 각 관측 변수는 어느 정도 잠재 요인을 반영하는 것으로 개념화되며, 이는 요인 적재량으로 나타납니다. 연구자들은 EFA를 데이터 축소 방법으로도 활용하며, 여러 관측 변수를 결합하여 새로운 요인 변수를 생성하는 데 사용하기도 합니다.\n주성분 분석 (PCA)는 엄밀히 말해 잠재 요인을 식별하는 기법이 아니라 데이터 축소 기법입니다. PCA는 단순히 관측 변수들의 선형 결합을 생성합니다.\n확인적 요인분석 (CFA)는 EFA와 달리 변수들 사이의 관계에 대한 사전 모형을 설정한 후, 이를 실제 데이터와 비교하여 모형의 적합도를 평가합니다.\n다특질 다방법 CFA (MTMM CFA)에서는 잠재 요인뿐만 아니라 방법 분산도 모형에 포함됩니다. 이는 서로 다른 방법론적 접근법이 사용되었을 경우, 방법 분산을 고려하는 것이 중요한 경우에 유용합니다.\n내적 일관성 신뢰도 분석은 특정 척도가 구성개념을 얼마나 일관되게 측정하는지에 대한 신뢰도를 평가합니다.\n\n\n\n\n\nChild, D. (1990). The essentials of factor analysis (2nd ed.). Cassell Educational.\n\n\nChronbach, L. J. (1951). Coefficient alpha and the internal structure of tests. Psychometrika, 16(3), 297–334. https://doi.org/10.1007/BF02310555\n\n\nFabrigar, L. R., Wegener, D. T., MacCallum, R. C., & Strahan, E. J. (1999). Evaluating the use of exploratory factor analysis in psychological research. Psychological Methods, 4, 272–299. https://doi.org/10.1037/1082-989X.4.3.272\n\n\nHewitt, A. K., Foxcroft, D. R., & MacDonald, J. (2004). Multitrait-multimethod confirmatory factor analysis of the attributional style questionnaire. Personality and Individual Differences, 37(7), 1483–1491. https://doi.org/10.1016/j.paid.2004.02.005\n\n\nKline, P. (1994). An easy guide to factor analysis. Routledge. https://doi.org/10.4324/9781315788135\n\n\nPeterson, C., & Seligman, M. (1984). Causal explanations as a risk factor for depression: Theory and evidence. Psychological Review, 91, 347–374. https://doi.org/10.1037/0033-295X.91.3.347",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>요인분석</span>"
    ]
  },
  {
    "objectID": "15-Factor-Analysis.html#footnotes",
    "href": "15-Factor-Analysis.html#footnotes",
    "title": "15  요인분석",
    "section": "",
    "text": "요인 적재량은 표준화된 회귀 계수처럼 해석할 수 있습니다.↩︎\n보다 고급 통계 기법으로, 이 책의 범위를 벗어나지만, 잠재 요인을 사용하여 다른 잠재 요인을 예측하는 회귀 모형이 있습니다. 이를 “구조 방정식 모형(structural equation model)”이라고 하며, 이를 위한 특정 소프트웨어와 R 패키지가 존재합니다.↩︎\n고유값은 관찰된 변수의 분산 중 한 요인이 설명하는 분산의 양을 나타냅니다. 고유값이 1보다 큰 요인은 단일 관찰 변수가 설명하는 분산보다 더 많은 분산을 설명하는 요인입니다.↩︎\n사각 회전을 적용하면 두 개의 요인 행렬이 생성됩니다. 하나는 구조 행렬(structure matrix)이고, 다른 하나는 패턴 행렬(pattern matrix)입니다. jamovi에서는 일반적으로 해석에 가장 유용한 패턴 행렬만 결과로 표시됩니다. 그러나 일부 전문가들은 두 행렬이 모두 도움이 된다고 주장합니다. 구조 행렬의 계수는 해당 변수와 요인의 관계를 나타내지만, 다른 요인들과의 관계를 고려하지 않습니다(즉, 단순 상관관계). 패턴 행렬의 계수는 다른 요인들의 영향을 통제한 상태에서 특정 요인이 변수에 미치는 고유한 영향을 보여줍니다(즉, 표준화된 부분 회귀 계수와 유사). 직교 회전을 적용한 경우에는 구조 행렬과 패턴 행렬이 동일합니다.↩︎\n요인분석에서는 때때로 “공통성(communality)”이라는 개념이 보고되는데, 이는 잠재 요인에 의해 설명되는 변수의 분산량을 의미합니다. 고유성은 (1 - 공통성)으로 계산됩니다.↩︎\n필요한 경우 일부 변수의 점수를 먼저 역코딩(음의 상관성이 있는 변수의 척도를 뒤집기)하는 것을 잊지 마세요.↩︎\n참고로, 초기 “추정” 요인들에 대한 확신이 있었다면, EFA 단계를 생략하고 바로 CFA로 진행할 수도 있었습니다. EFA를 수행한 후 CFA로 진행할지, 아니면 바로 CFA로 갈지는 연구자의 판단과 초기 모형(요인 수 및 변수)에 대한 확신 정도에 따라 달라집니다. 척도를 개발하는 초기 단계나 기본적인 잠재 구성개념을 식별하는 단계에서는 연구자들이 주로 EFA를 사용합니다. 반면, 최종 척도에 가까워질수록 또는 기존 척도를 새로운 표본에서 검증하고자 할 때는 CFA가 좋은 선택이 될 수 있습니다.↩︎",
    "crumbs": [
      "통계 기법",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>요인분석</span>"
    ]
  },
  {
    "objectID": "16-Bayesian-statistics.html",
    "href": "16-Bayesian-statistics.html",
    "title": "16  베이지안 통계학",
    "section": "",
    "text": "16.1 합리적 행위자의 확률적 추론\n베이지안 관점에서 통계적 추론은 전적으로 신념 수정과 관련되어 있습니다. 저는 세계에 대한 후보 가설들의 집합 \\(h\\)로 시작합니다. 저는 이 가설들 중 어느 것이 참인지 알지 못하지만, 어떤 가설이 그럴듯한지에 대한 신념을 가지고 있습니다. 데이터 \\(d\\)를 관찰하면, 저는 이러한 신념을 수정해야 합니다. 데이터가 가설과 일치하면, 해당 가설에 대한 신념이 강화됩니다. 데이터가 가설과 일치하지 않으면, 해당 가설에 대한 신념이 약화됩니다. 그것이 전부입니다! 이 절의 마지막 부분에서 베이지안 추론이 어떻게 작동하는지에 대한 정확한 설명을 제공할 것이지만, 먼저 핵심 개념을 소개하기 위해 간단한 예제를 살펴보겠습니다. 다음과 같은 추론 문제를 고려해 봅시다.\n이 문제에서 저는 여러분께 단 하나의 데이터만 제시했습니다 (\\(d\\) = 저는 현재 우산을 들고 있습니다), 그리고 여러분께 비가 올 것인지에 대한 신념 또는 가설을 말해 달라고 요청했습니다. 여러분은 두 가지 대안을 가지고 있습니다, \\(h\\): 오늘 비가 올 것이다 또는 그렇지 않을 것이다. 이 문제를 어떻게 해결해야 할까요?",
    "crumbs": [
      "마무리하며, 대안과 전망",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>베이지안 통계학</span>"
    ]
  },
  {
    "objectID": "16-Bayesian-statistics.html#합리적-행위자의-확률적-추론",
    "href": "16-Bayesian-statistics.html#합리적-행위자의-확률적-추론",
    "title": "16  베이지안 통계학",
    "section": "",
    "text": "저는 현재 우산을 가지고 있습니다. 여러분은 비가 올 거라 생각하십니까?\n\n\n\n16.1.1 사전 확률: 당신이 이전에 믿었던 것\n첫 번째로 해야 할 일은 제가 우산에 대해 말한 내용을 무시하고, 비에 대한 여러분의 기존 신념을 기록하는 것입니다. 이것은 매우 중요합니다. 새로운 증거(데이터)를 바탕으로 신념이 어떻게 수정되었는지 솔직하게 평가하려면, 해당 데이터가 등장하기 전에 무엇을 믿고 있었는지에 대해 언급해야 합니다! 그렇다면 오늘 비가 올 것인지에 대해 여러분은 무엇을 믿고 있었을까요? 여러분은 아마도 제가 호주에 살고 있으며, 호주의 많은 지역이 덥고 건조하다는 것을 알고 있을 것입니다. 제가 살고 있는 애들레이드시는 지중해성 기후를 가지고 있으며, 이는 남부 캘리포니아나 남유럽 또는 북아프리카와 매우 유사합니다. 저는 이 글을 1월에 쓰고 있으므로, 지금이 한여름이라는 것을 가정할 수 있습니다. 실제로, 여러분은 위키피디아2를 빠르게 검색하여 애들레이드가 1월 31일 중 평균적으로 4.4일 동안 비가 온다는 사실을 발견했을 수도 있습니다. 다른 정보를 모르더라도, 여러분은 애들레이드에서 1월에 비가 올 확률이 약 15%이고, 건조한 날일 확률이 85%라고 결론지을 수 있습니다(Table 16.1 참조). 만약 이것이 여러분이 애들레이드 강우량에 대해 실제로 믿고 있는 바라면 (그리고 제가 이를 여러분께 말해주었으므로 이제는 여러분도 그렇게 믿을 가능성이 높습니다), 여기서 제가 기술한 것이 여러분의 사전 분포(prior distribution), 즉 \\(P(h)\\)로 표현되는 것입니다.\n\n\n\n\nTable 16.1. 애들레이드에서 비가 올 가능성 – 평균 1월 강우량을 기반으로 한 기존 신념\n\n\n\n\n\n가설신념의 정도\n\n비 오는 날0.15\n\n건조한 날0.85\n\n\n\n\n\n\n\n\n\n16.1.2 가능도: 데이터 발생에 대한 이론\n추론 문제를 해결하려면 제 행동 패턴에 대한 이론이 필요합니다. 다니엘은 언제 우산을 가지고 다닐까요? 여러분은 제가 완전히 멍청하지 않으며,3 비 오는 날에만 우산을 들고 다니려고 노력한다고 추측할 수도 있습니다. 하지만, 여러분은 또한 제가 어린아이들을 키우고 있으며, 이런 종류의 일을 꽤 자주 깜빡 잊는다는 사실도 알고 있습니다. 가령, 비 오는 날에는 제가 우산을 기억할 확률이 약 30%라고 가정해 보겠습니다 (정말로 저는 이 부분에서 형편없습니다). 하지만, 맑은 날에는 제가 우산을 가지고 있을 확률이 약 5%라고 합시다. 따라서, 여러분은 이를 Table 16.2 같이 정리할 수 있습니다.\n\n\n\n\nTable 16.2. 비 오는 날과 맑은 날에 제가 우산을 들고 있을 가능성\n\n\n\n\n\n데이터데이터\n\n가설우산 있음우산 없음\n\n비 오는 날0.300.70\n\n건조한 날0.050.95\n\n\n\n\n\n\n\n이 표의 각 셀은 특정 가설 \\(h\\)가 참일 경우, 어떤 데이터 \\(d\\)가 관찰될 것인지에 대한 여러분의 신념을 설명하는 것입니다. 이러한 신념을 “조건부 확률”이라 하고, \\(P(d|h)\\)로 표현하며, “가설 \\(h\\)인 경우 데이터 \\(d\\)의 확률”이라고 할 수 있습니다. 베이지안 통계에서 가설 \\(h\\)인 경우의 데이터 \\(d\\)의 가능도(likelihood)라고 합니다.4\n\n\n16.1.3 데이터와 가설의 결합 확률\n이제 모든 요소가 준비되었습니다. 사전 확률과 가능도를 작성했으므로, 베이지안 추론을 수행하는 데 필요한 모든 정보를 갖추었습니다. 이제 문제는 이 정보를 어떻게 활용하느냐입니다. 이를 위해 사용할 수 있는 매우 간단한 방정식이 있지만, 왜 이 방정식을 사용하는지 이해하는 것이 중요하므로 기본 개념부터 차근차근 설명하겠습니다.\n확률 이론의 한 가지 규칙부터 시작해 보겠습니다. 이 규칙은 Table 7.1 에서 이미 언급했지만, 당시에는 강조하지 않았기 때문에 아마도 그냥 지나쳤을 것입니다. 이 규칙은 두 가지 사실이 동시에 참일 확률에 대한 것입니다. 예를 들어, 오늘이 비 오는 날(즉, 가설 \\(h\\)가 참임)이고 제가 우산을 가지고 있는 경우(즉, 데이터 \\(d\\)가 관찰됨)의 확률을 계산하고 싶을 수 있습니다. 가설과 데이터의 결합 확률(joint probability)은 \\(P(d,h)\\)로 표현되며, 사전 확률 \\(P(h)\\)과 가능도 \\(P(d|h)\\)를 곱하여 계산할 수 있습니다. 수식으로 표현하면 다음과 같습니다: \\[P(d,h)=P(d|h)P(h)\\]\n그렇다면, 오늘이 비 오는 날이며 제가 우산을 가지고 있을 확률은 얼마일까요? 앞서 논의한 대로, 사전 확률에 따르면 비 오는 날일 확률은 15%이고, 가능도에 따르면 제가 비 오는 날 우산을 기억할 확률은 30%입니다. 따라서 두 확률을 곱하여 다음과 같이 계산할 수 있습니다: \\[\n\\begin{split}\nP(비, 우산) & = P(우산|비) \\times P(비) \\\\\n& = 0.30 \\times 0.15 \\\\\n& = 0.045\n\\end{split}\n\\]\n다시 말해, 실제 무슨 일이 일어났는지에 대한 정보를 듣기 전에는 오늘 비가 오고 제가 우산을 가지고 있을 확률이 4.5%라고 생각할 수 있습니다. 그리고 실제로는 네 가지 가능한 상황이 존재합니다. 동일한 과정을 모든 경우에 대해 반복하면 Table 16.3 같은 결과를 얻을 수 있습니다.\n\n\n\n\nTable 16.3. 비가 오는 경우와 우산을 가지고 있는 경우의 네 가지 가능성\n\n\n\n\n\n우산 있음우산 없음\n\n비 옴0.0450.105\n\n건조함0.04250.807\n\n\n\n\n\n\n\n이 표는 네 가지 가능성 각각에 대한 정보를 포함하고 있습니다. 그러나 전체 그림을 완전히 이해하려면 행과 열의 합계를 추가하는 것이 도움이 됩니다. 그 결과는 Table 16.4 같습니다.\n\n\n\n\nTable 16.4. 비가 오는 경우와 우산을 가지고 있는 경우의 네 가지 가능성 (행 및 열 합계 포함)\n\n\n\n\n\n우산 있음우산 없음합계\n\n비 옴0.0450.1050.15\n\n건조함0.04250.8070.85\n\n합계0.08750.9121\n\n\n\n\n\n\n\n이 표는 매우 유용하므로, 각 숫자가 의미하는 바를 이해하는 것이 중요합니다. 먼저, 행 합계는 새로운 정보를 제공하지 않는다는 점을 주목해야 합니다. 예를 들어, 첫 번째 행은 우산을 가지고 있는지를 고려하지 않을 때 오늘 비가 올 확률이 15%임을 보여줍니다. 이는 당연한 결과입니다. 왜냐하면, 우리가 설정한 사전 확률이기 때문입니다.5 여기서 중요한 것은 숫자 자체가 아니라, 우리의 계산이 타당하다는 점을 확인할 수 있다는 것입니다! 이제 열 합계를 살펴보면 우리가 명확하게 언급하지 않았던 추가 정보를 제공합니다. 행 합계가 비가 올 확률을 알려주는 것과 마찬가지로, 열 합계는 제가 우산을 가지고 있을 확률을 나타냅니다. 예를 들어, 첫 번째 열은 (비오는 날일지 아닐지를 무시하고) 제가 우산을 가지고 있을 확률이 평균적으로 8.75%임을 보여줍니다. 마지막으로, 네 가지 가능한 사건을 모두 합하면 총합이 1이 됩니다. 즉, 우리가 작성한 것은 데이터와 가설의 모든 가능한 조합에 대해 정의된 올바른 확률 분포입니다.\n이 표가 매우 유용하기 때문에, 표의 각 요소가 어떤 개념에 해당하며 어떻게 표현되는지 확실히 이해하도록 하겠습니다(Table 16.5).\n\n\n\n\nTable 16.5. 비가 오는 경우와 우산을 가지고 있는 경우의 네 가지 가능성, 조건부 확률로 표현\n\n\n\n\n\n우산 있음우산 없음\n\n비 옴P(우산 있음, 비 옴)P(우산 없음, 비 옴)P(비 옴)\n\n건조함P(우산 있음, 건조함)P(우산 없음, 건조함)P(건조함)\n\nP(우산 있음)P(우산 없음)\n\n\n\n\n\n\n\n마지막으로, “적절한” 통계 표기법을 사용해 보겠습니다. 비 오는 날 문제에서 데이터는 제가 우산을 가지고 있는지 여부에 해당합니다. 그러므로 \\(d_1\\)이 제가 우산을 가지고 있는 것을 관찰하는 사건이라 하고, \\(d_2\\)는 제가 우산을 가지고 있지 않은 사건이라 합시다. 마찬가지로, \\(h_1\\)은 오늘 비가 온다는 가설이라 하고, \\(h_2\\)는 비가 오지 않는다는 가설이라 합시다. 이러한 표기법을 사용하면 표는 Table 16.6 같은 형태가 됩니다.\n\n\n\n\nTable 16.6. 비가 오는 경우와 우산을 가지고 있는 경우의 네 가지 가능성, 가설적 조건부 확률로 표현\n\n\n\n\n\n\\( d_1 \\)\\( d_2 \\)\n\n\\( h_1 \\)\\(P(h_1, d_1)\\)\\(P(h_1, d_2)\\)\\( P(h_1) \\)\n\n\\( h_2 \\)\\(P(h_2, d_1)\\)\\(P(h_2, d_2)\\)\\( P(h_2) \\)\n\n\\( P(d_1) \\)\\( P(d_2) \\)\n\n\n\n\n\n\n\n\n\n16.1.4 베이즈 규칙을 이용한 신념 업데이트\n지난 절에서 정리한 표는 비 오는 날 문제를 해결하는 데 매우 강력한 도구입니다. 왜냐하면 이 표는 네 가지 논리적 가능성을 모두 고려하고 있으며, 데이터가 주어지기 전에 각각의 가능성을 당신이 얼마나 확신하는지를 정확히 나타내고 있기 때문입니다. 이제 실제로 데이터기 주어졌을 때 우리의 신념이 어떻게 변하는지를 고려해야 합니다. 비 오는 날 문제에서 여러분은 제가 실제로 우산을 가지고 있다는 사실을 알고 있습니다. 이는 다소 놀라운 사건입니다. 우리 표에 따르면 제가 우산을 가지고 있을 확률은 단 8.75%에 불과합니다. 하지만 이는 이해할 만한 일이죠? 여름날 더운 건조한 도시에서 여성이 우산을 들고 있는 것은 꽤 드문 일이므로, 여러분도 이를 예상하지 않았을 것입니다. 그럼에도 불구하고 데이터는 그것이 사실임을 알려줍니다. 아무리 가능성이 낮다고 생각했더라도 이제는 제가 우산을 가지고 있다는 사실을 반영하여 신념을 조정해야 합니다.6 이 새로운 정보를 반영하기 위해 수정된 표는 다음과 같은 값을 가져야 합니다. (참고: Table 16.7)\n\n\n\n\nTable 16.7. 우산을 가지고 있다는 새로운 데이터를 반영한 신념 수정\n\n\n\n\n\n우산 있음우산 없음\n\n비 옴0\n\n건조함0\n\n합계10\n\n\n\n\n\n\n\n다시 말해, 주어진 사실이 “우산 없음(No-umbrella)”의 모든 가능성을 제거하므로, 제가 우산을 가지고 있지 않음을 의미하는 표의 모든 칸에 0을 넣어야 합니다. 또한, 여러분은 제가 우산을 가지고 있다는 사실을 알고 있으므로, 왼쪽 열의 합이 1이 되어야 하며, 이는 \\(P(우산) = 1\\)을 정확하게 반영해야 합니다.\n빈 칸에는 어떤 숫자를 넣어야 할까요? 다시 한 번, 수학적인 계산을 걱정하지 말고 직관적으로 생각해 봅시다. 처음 표를 작성했을 때, 두 칸의 값이 거의 동일했던 것을 기억하시나요? 우리는 “비와 우산”의 결합 확률이 4.5%, “건조한 날과 우산”의 결합 확률이 4.25%라는 것을 계산했습니다. 즉, 제가 실제로 우산을 가지고 있다고 말하기 전에, 여러분은 이 두 사건이 거의 동일한 확률을 가졌다고 생각했을 것입니다. 그리고 주어진 사실과 이 두 가능성은 모두 모순없이 양립됩니다. 그리고 이 두 가능성이 여전히 동일하게 그럴듯하다는 데 동의하실 겁니다. 따라서 최종 표에서 “비와 우산”이 “건조한 날과 우산”보다 약간 더 그럴듯하다는 사실을 유지하면서도, 표의 숫자 합이 1이 되도록 해야 합니다. 그럴려면 Table 16.8 같은 형태가 될 것입니다.\n\n\n\n\nTable 16.8. 우산을 가지고 있다는 새로운 데이터를 반영한 확률 수정\n\n\n\n\n\n우산 있음우산 없음\n\n비 옴0.5140\n\n건조함0.4860\n\n합계10\n\n\n\n\n\n\n\n이 표가 말해주는 것은, 제가 우산을 가지고 있다는 사실을 알게 된 후 여러분은 오늘이 비 오는 날일 확률을 51.4%, 그렇지 않을 확률을 48.6%로 믿는다는 것입니다. 이것이 우리가 찾던 답입니다! 즉, 제가 우산을 가지고 있다는 사실을 고려한 사후 확률(posterior probability) \\(P(h\\|d)\\)은 51.4%입니다.\n이 숫자를 어떻게 계산했을까요? 아마도 예상하셨을 것입니다. “비”의 확률이 \\(0.514\\)임을 구하기 위해 저는 “비와 우산”의 결합 확률인 \\(0.045\\)를 “우산”의 확률인 \\(0.0875\\)로 나누었습니다. 이렇게 하면 전체 합이 1이 되도록 조정하면서도, 실제 데이터와 일치하는 두 사건의 상대적인 개연성을 손상하지 않는 표를 만들 수 있습니다. 이를 통계적 용어로 표현하면, 지금까지 수행한 것은 가설과 데이터의 결합 확률 \\(P(d, h)\\)을 주변 확률(marginal probability) \\(P(d)\\)로 나눈 것입니다. 이를 식으로 표현하면 다음과 같습니다.7 \\[P(h|d)=\\frac{P(d,h)}{P(d)}\\]\n하지만 지난 절에서 언급했듯이, 결합 확률 \\(P(d, h)\\)은 사전 확률 \\(P(h)\\)와 가능도 \\(P(d|h)\\)를 곱하여 계산됩니다. 실제로 우리가 알고 있는 값은 사전 확률과 가능도이므로, 이를 다시 식에 대입하면 사후 확률을 구하는 공식이 됩니다. \\[P(h|d)=\\frac{P(d|h)P(h)}{P(d)}\\]\n이 공식이 바로 베이즈 규칙입니다. 이는 학습자가 다양한 가설의 개연성에 대한 사전 신념을 가지고 시작하며, 데이터를 통해 그 신념을 어떻게 수정해야 하는지를 설명합니다. 베이즈 패러다임에서는 모든 통계적 추론이 이 단순한 규칙에서 비롯됩니다.",
    "crumbs": [
      "마무리하며, 대안과 전망",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>베이지안 통계학</span>"
    ]
  },
  {
    "objectID": "16-Bayesian-statistics.html#베이지안-가설-검정",
    "href": "16-Bayesian-statistics.html#베이지안-가설-검정",
    "title": "16  베이지안 통계학",
    "section": "16.2 베이지안 가설 검정",
    "text": "16.2 베이지안 가설 검정\nChapter 9 에서 저는 정통적인 가설 검정 접근법을 설명하였습니다. 귀무가설 검정은 매우 복잡한 구조를 가지고 있으며, 사람들이 이해하기 어렵다고 느끼는 경우가 많기 때문에 이를 설명하는 데 한 개의 장이 필요했습니다. 반면, 베이즈 접근법을 이용한 가설 검정은 매우 간단합니다. 정통적 방법과 유사한 설정을 선택해 보겠습니다. 비교하고자 하는 두 개의 가설, 즉 귀무가설 \\(h_0\\)와 대립가설 \\(h_1\\)이 있습니다. 실험을 수행하기 전에 우리는 각 가설이 참일 확률에 대한 신념, 즉 \\(P(h)\\)을 가지고 있습니다. 실험을 실행하여 데이터 \\(d\\)를 획득합니다.\n빈도주의자 통계학과는 달리, 베이지안 통계학에서는 귀무가설이 참일 확률에 대해 이야기할 수 있습니다. 더욱이, 귀무가설의 사후 확률을 베이즈 규칙을 사용하여 계산할 수 있습니다. \\[P(h_0|d)=\\frac{P(d|h_0)P(h_0)}{P(d)}\\]\n이 공식은 데이터를 \\(d\\) 관찰한 후 귀무가설에 대해 얼마나 신뢰해야 하는지를 정확히 알려줍니다. 마찬가지로, 본질적으로 동일한 공식을 사용하여 대립가설에 대한 신념도 계산할 수 있습니다. 단순히 첨자를 변경하면 됩니다. \\[P(h_1|d)=\\frac{P(d|h_1)P(h_1)}{P(d)}\\]\n이 모든 것이 너무 간단해서 굳이 이러한 공식을 적을 필요가 있을까 싶을 정도입니다. 왜냐하면 이전 절에서 설명한 베이즈 규칙을 그대로 복사한 것이기 때문입니다.8\n\n16.2.1 베이즈 인자\n실제 분석에서는 대부분의 베이지안 데이터 분석가들이 사후 확률 \\(P(h_0|d)\\)와 \\(P(h_1|d)\\)를 직접 논의하지 않습니다. 대신, 사후 승산비(posterior odds ratio)를 이야기하는 경우가 많습니다. 이를 내기에 비유해 봅시다. 예를 들어, 귀무가설의 사후 확률이 25%이고 대립가설의 사후 확률이 75%라면, 대립가설이 귀무가설보다 세 배 더 가능성이 높다고 할 수 있습니다. 즉, 대립가설에 유리한 승산은 3:1입니다. 수학적으로, 사후 승산을 계산하는 방법은 단순히 한 사후 확률을 다른 사후 확률로 나누는 것입니다. \\[\\frac{P(h_1|d)}{P(h_0|d)}=\\frac{0.75}{0.25}=3\\]\n위의 공식을 일반적인 형태로 표현하면 다음과 같습니다. \\[\\frac{P(h_1|d)}{P(h_0|d)}=\\frac{P(d|h_1)}{P(d|h_0)} \\times \\frac{P(h_1)}{P(h_0)}\\]\n이 공식은 세 가지 중요한 요소를 포함하고 있습니다. 좌변에는 사후 승산이 있으며, 이는 데이터를 관찰한 후 귀무가설과 대립가설의 상대적 개연성을 나타냅니다. 우변에는 사전 승산(prior odds)이 있으며, 이는 데이터를 관찰하기 전에 가졌던 신념을 나타냅니다. 가운데에 있는 값이 베이즈 인자(Bayes factor)이며, 이는 데이터가 제공하는 증거의 강도를 나타냅니다 (Table 16.9).\n\n\n\n\nTable 16.9. 베이즈 인자와 사전 승산을 고려한 사후 승산\n\n\n\n\n\n\\(\\frac{P(h_1|d)}{h_0|d}\\)\\(=\\)\\(\\frac{P(d|h_1)}{d|h_0}\\)\\(\\times \\)\\(\\frac{P(h_1)}{h_0}\\)\n\n\\(\\Uparrow\\)\\(\\Uparrow\\)\\(\\Uparrow\\)\n\n사후 승산비베이즈 인자사전 승산비\n\n\n\n\n\n\n\n베이즈 인자(BF)는 베이즈 가설 검정에서 중요한 역할을 합니다. 이는 정통적 가설 검정에서 \\(p\\)-값이 수행하는 역할과 유사합니다. 베이즈 인자는 데이터가 제공하는 증거의 강도를 정량화하며, 따라서 베이즈 가설 검정을 수행할 때 일반적으로 보고하는 값이 됩니다.\n사후 승산 대신 베이즈 인자를 보고하는 이유는 연구자마다 서로 다른 사전 신념을 가질 수 있기 때문입니다. 어떤 연구자는 귀무가설이 참일 가능성이 높다고 믿을 수 있고, 다른 연구자는 반대로 생각할 수도 있습니다. 이러한 이유로, 연구자는 베이즈 인자를 보고하는 것이 더 적절합니다. 독자가 연구 결과를 읽을 때 자신의 사전 승산을 베이즈 인자와 곱하여 자신만의 사후 승산을 계산할 수 있기 때문입니다. 귀무가설과 대립가설의 가능성이 동일하다고 가정하면, 사전 승산이 1이 되어 사후 승산은 베이즈 인자와 동일해집니다.\n\n\n16.2.2 베이즈 인자 해석하기\n베이즈 인자의 가장 좋은 점 중 하나는 숫자 자체가 본질적 의미를 갖는다는 것입니다. 실험을 수행하여 베이즈 인자를 계산했을 때 그 값이 4라면, 이는 데이터가 제공하는 증거가 대립가설에 대해 4:1의 확률로 내기를 걸었다는 의미입니다.\n과학적 맥락에서 의미 있다고 여겨지는 증거의 기준을 정량화하려는 시도가 있었습니다. 가장 널리 사용되는 두 가지 기준은 Jeffreys (1961) 과 Kass & Raftery (1995) 의 것입니다. 두 가지 중에서 저는 Kass & Raftery (1995) 의 표를 선호하는데, 이 기준이 다소 보수적이기 때문입니다. 아래는 해당 표입니다(Table 16.10).\n\n\n\n\nTable 16.10. 베이즈 인자와 증거의 강도\n\n\n\n\n\n베이즈 인자해석\n\n1 - 3무시할 만한 증거\n\n3-20긍정적 증거\n\n20-150강한 증거\n\n&gt; 150매우 강한 증거\n\n\n\n\n\n\n\n솔직히 말해서, 저는 Kass & Raftery (1995) 의 기준조차도 다소 관대하다고 생각합니다. 만약 저에게 결정권이 있다면 “긍정적 증거(Postive evidence)” 범주를 “약한 증거”로 명명했을 것입니다. 개인적으로 3:1에서 20:1 범위의 베이즈 인자는 기껏해야 “약한” 또는 “보통의” 증거라고 생각합니다. 그러나 이에 대한 절대적인 규칙은 없습니다. 강한 증거와 약한 증거를 구별하는 기준은 전적으로 얼마나 보수적인 입장을 취하느냐와 연구 공동체가 어떤 발견을 “사실”로 인정하기 위해 요구하는 기준에 따라 달라집니다.\n어쨌든 위에 나열된 모든 숫자는 베이즈 인자가 1보다 클 때(즉, 증거가 대립가설을 지지할 때) 의미를 갖습니다. 그러나 베이즈 접근법이 정통적 접근법보다 좋은 실용적 장점 중 하나는 귀무가설을 지지하는 증거도 정량화할 수 있다는 것입니다. 이런 경우, 베이즈 인자는 1보다 작아집니다. 베이즈 인자가 1보다 작은 값을 보고할 수도 있지만, 저는 이것이 다소 혼란스럽다고 생각합니다. 예를 들어, 귀무가설 \\(P(d|h_0)\\) 하에서 데이터의 가능도가 0.2이고, 대립가설 \\(P(d|h_1)\\) 하에서 데이터의 가능도가 0.1이라고 가정해 봅시다. 위에서 제시한 공식을 사용하면, 베이즈 인자는 다음과 같이 계산됩니다. \\[BF=\\frac{P(d|h_1)}{P(d|h_0)}=\\frac{0.1}{0.2}=0.5\\]\n이 결과를 그대로 해석하면, 대립가설을 지지하는 증거가 0.5 대 1이라는 의미입니다. 저는 이것이 직관적으로 이해하기 어렵다고 느낍니다. 오히려 이 공식을 “뒤집어”서 귀무가설을 지지하는 증거의 크기를 보고하는 것이 훨씬 이해하기 쉽다고 생각합니다. 즉, 다음과 같이 계산합니다. \\[BF^{'}=\\frac{P(d|h_0)}{P(d|h_1)}=\\frac{0.2}{0.1}=2\\]\n그리고 우리가 보고하는 값은 귀무가설을 지지하는 2:1의 베이즈 인자입니다. 이렇게 하면 훨씬 더 직관적으로 이해할 수 있으며, 위의 표를 사용하여 해석할 수 있습니다.",
    "crumbs": [
      "마무리하며, 대안과 전망",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>베이지안 통계학</span>"
    ]
  },
  {
    "objectID": "16-Bayesian-statistics.html#왜-베이지안이-되어야-하는가",
    "href": "16-Bayesian-statistics.html#왜-베이지안이-되어야-하는가",
    "title": "16  베이지안 통계학",
    "section": "16.3 왜 베이지안이 되어야 하는가?",
    "text": "16.3 왜 베이지안이 되어야 하는가?\n지금까지 저는 베이지안 통계를 뒷받침하는 논리에만 집중해 왔습니다. 우리는 “확률을 신념의 정도로 본다”는 개념과 그것이 합리적인 행위자가 세상을 어떻게 추론해야 하는지를 의미하는 바에 대해 논의했습니다. 이제 여러분이 스스로 대답해야 할 질문은 다음과 같습니다. 통계를 어떤 방식으로 수행하고 싶으십니까? 표본 분포와 \\(p\\)-값에 의존하여 결정을 내리는 정통적 통계학자가 되고 싶으십니까? 아니면 사전 신념, 베이즈 요인 및 합리적인 신념 갱신 규칙을 사용하는 베이지안이 되고 싶으십니까? 솔직히 말씀드리면, 저는 이 질문에 대해 여러분을 대신하여 답할 수 없습니다. 궁극적으로 그것은 여러분이 옳다고 생각하는 것에 달려 있습니다. 선택은 전적으로 여러분의 몫입니다. 그렇기는 하지만, 제가 베이즈 접근법을 선호하는 이유에 대해 조금 이야기해 보겠습니다.\n\n16.3.1 통계가 여러분이 생각하는 의미 그대로를 의미하는가\n\n당신은 계속 그 단어를 사용하고 있지만, 저는 그것이 당신이 생각하는 의미라고 생각하지 않습니다.\n– 이니고 몬토야, 프린세스 브라이드9\n\n저에게 있어 베이지안 접근법의 가장 큰 장점 중 하나는 올바른 질문에 답을 한다는 점입니다. 베이지안 모형에서는 “어떤 가설이 참일 확률”을 언급하는 것이 완전히 타당하며 허용됩니다. 심지어 이 확률을 계산하려고 시도할 수도 있습니다. 궁극적으로, 우리가 원하는 것은 통계적 검정이 바로 이 정보를 제공하흔 것이 아닐까요? 실제 인간의 관점에서 보면, 통계를 수행하는 핵심 목적은 무엇이 참이고 무엇이 거짓인지를 결정하는 것입니다. 우리가 진실을 정확히 알지 못하는 경우에는, 확률 이론의 언어를 사용하여 “이론 A가 참일 확률은 80%이며, 이론 B가 참일 확률은 20%이다”라고 말해야 합니다.\n이것은 인간적 관점에서는 너무나도 당연한 것처럼 보이지만, 정통적(빈도주의자) 통계학에서는 명백히 금지되어 있습니다. 빈도주의자에게 있어 이러한 진술은 무의미합니다. 왜냐하면 “어떤 이론이 참이다”라는 사건은 반복 가능한 사건이 아니기 때문입니다. 이론은 참이거나 거짓일 뿐이며, 아무리 그렇게 말하고 싶어도 확률적 진술은 허용되지 않습니다. 저는 Section 9.5 에서 \\(p\\)-값을 귀무 가설이 참일 확률로 해석해서는 안 된다고 여러 번 경고한 바 있습니다. 거의 모든 통계학 교재에서 이 경고를 반복할 수밖에 없는 이유가 있습니다. 사람들은 간절히 이 해석이 맞기를 바라기 때문입니다. 빈도주의적 교리가 어떻든 간에, 학부생을 가르치고 데이터를 분석한 오랜 경험에 비추어 보면, 대부분의 사람들은 “어떤 가설이 참일 확률”을 의미 있는 것으로 간주하며, 그것이 우리에게 가장 중요한 정보라고 여깁니다. 이 개념은 너무나도 매력적이어서, 심지어 훈련받은 통계학자들조차도 \\(p\\)-값을 이러한 방식으로 해석하려는 실수를 저지릅니다. 예를 들어, 2013년의 공식 뉴스폴(Newspoll) 보고서에서 그들의 (빈도주의적) 데이터 분석을 해석하는 방법을 다음과 같이 설명하고 있습니다.10\n\n이 보고서 전반에서, 관련된 부분에서 통계적으로 유의한 변화가 언급되었습니다. 모든 유의성 검정은 95% 신뢰 수준을 기준으로 수행되었습니다. 이는 어떤 변화가 통계적으로 유의하다고 기록되었을 경우, 해당 변화가 실제로 발생했을 확률이 95%이며, 단순히 우연한 변동에 의한 것이 아닐 가능성이 높다는 것을 의미합니다. (강조 저자 추가)\n\n아닙니다! 이것은 \\(p &lt; .05\\)의 의미가 아닙니다. 또한 빈도주의자 통계학에서 95% 신뢰 수준이 의미하는 바도 아닙니다. 강조된 문장은 명백히 잘못되었습니다. 정통적 방법론은 “실제 변화가 발생했을 확률이 95%”라는 진술을 할 수 없습니다. 왜냐하면 이는 빈도주의자 확률을 적용할 수 있는 유형의 사건이 아니기 때문입니다. 교조적인 빈도주의자라면 이 문장을 무의미하다고 여길 것입니다. 좀 더 실용적인 빈도주의자라고 하더라도, 이는 \\(p\\)-값에 대한 잘못된 정의라고 생각할 것입니다. 정통적 통계 도구를 사용한다면, 이런 표현은 허용되지 않으며 올바르지도 않습니다.\n반면, 여러분이 베이지안이라고 가정해 보겠습니다. 강조된 문장은 \\(p\\)-값의 잘못된 정의이지만, 그것은 베이지안이 “대립 가설의 사후 확률이 95% 이상이다”라고 말할 때 의미하는 바와 거의 정확히 일치합니다. 그렇다면 이런 의문이 생깁니다. 만약 베이즈 사후 확률이 여러분이 실제로 보고하고 싶은 정보라면, 왜 굳이 정통적 방법을 사용하려고 하는 것입니까? 베이지안 주장을 하고 싶다면, 베이지안이 되어 베이지안 통계학 도구를 사용하면 될 것입니다.\n저 자신을 예로 들자면, 베이지안 관점을 채택했을 때 가장 큰 해방감을 느꼈습니다. 일단 베이지안으로 전환하고 나면, 더 이상 직관적으로 이해하기 어려운 \\(p\\)-값의 정의를 외울 필요가 없습니다. 또한 “진짜 평균이 특정 구간 내에 있을 확률이 95%이다”라고 말할 수 없는 이유를 기억할 필요도 없습니다. 단지 연구를 수행하기 전에 무엇을 믿었는지 솔직하게 밝히고, 연구를 통해 무엇을 배웠는지를 보고하면 됩니다. 듣기만 해도 좋은 접근법 같지 않습니까? 저에게 있어 베이지안 접근법의 가장 큰 매력은 바로 이것입니다. 여러분이 정말로 수행하고 싶은 분석을 하고, 데이터가 실제로 말해 주는 바를 있는 그대로 표현할 수 있습니다.\n\n\n16.3.2 믿을 수 있는 증거 기준\n\n만약 \\(p\\) 값이 0.02 미만이라면, 귀무가설이 모든 사실을 설명하지 못한다는 것을 강하게 시사합니다. 우리는 0.05에서 관습적인 기준선을 긋고, 더 작은 \\(p\\) 값이 실질적인 차이를 나타낸다고 간주하더라도 큰 오류를 범하지 않을 것입니다.\n– 로널드 피셔 경 (Fisher, 1925, p. 79)\n\n위는 현대 통계학의 정설이 된 접근법을 창시한 인물 중 한 명인 로널드 피셔 경의 말입니다. \\(p\\)-값의 본래 기능에 대해 의견을 낼 자격이 있는 사람이 있다면, 바로 피셔일 것입니다. 이 인용문은 그의 고전적인 저서 Statistical Methods for Research Workers 에서 발췌된 것으로, \\(p &lt; .05\\)일 때 귀무가설을 기각하는 것이 무엇을 의미하는지에 대해 비교적 명확하게 설명하고 있습니다.\n피셔의 견해에 따르면, 우리가 \\(p &lt; .05\\)를 “실제 효과가 존재한다”는 의미로 받아들인다면, “우리는 큰 오류를 범하지 않을 것”입니다. 이는 결코 특별한 의견이 아닙니다. 제가 경험한 바에 따르면, 대부분의 실무자는 피셔와 매우 유사한 입장을 가지고 있습니다. 본질적으로, \\(p &lt; .05\\)라는 관행은 상당히 엄격한 증거 기준으로 간주됩니다.\n과연 그럴까요? 이 질문을 탐구하는 한 가지 방법은 \\(p\\)-값을 베이즈 인자로 변환하여 비교하는 것입니다. 그러나 이는 쉬운 일이 아닙니다. 왜냐하면 \\(p\\)-값과 베이즈 인자는 근본적으로 다른 개념이며, 동일한 것을 측정하지 않기 때문입니다. 그럼에도 불구하고, 둘 사이의 관계를 분석하려는 시도가 몇 차례 있었습니다. 그 결과는 다소 놀라운 것이었습니다. 예를 들어, Johnson (2013) 은 (적어도 \\(t\\)-검정의 경우) \\(p &lt; .05\\)라는 기준이 대략 3:1에서 5:1 정도의 베이즈 인자와 대응된다고 주장합니다.\n만약 이 주장이 옳다면, 피셔의 말은 다소 과장된 것입니다. 귀무가설이 절반의 확률로 참이라고 가정할 경우(\\(H_0\\)의 사전 확률이 0.5), Johnson (2013) 의 데이터를 이용하여 \\(p &lt; .05\\)에서 귀무가설을 기각한 후의 사후 확률을 계산해 보면, 기각했을 때 약 80% 확률로 올바른 결정을 내리게 됩니다. 하지만 제 개인적인 의견으로는, 의사 결정의 20%가 잘못될 수 있는 증거 기준은 충분히 엄격하지 않습니다. 피셔의 주장과는 달리, \\(p &lt; .05\\)에서 기각하면 꽤 자주 틀릴 수 있습니다. 이는 결코 엄격한 증거 기준이 아닙니다.\n\n\n16.3.3 \\(p\\)-값은 거짓입니다.\n\n케이크는 거짓이다.\n케이크는 거짓이다.\n케이크는 거짓이다.\n케이크는 거짓이다.\n– 포털11\n\n이쯤에서 여러분은 정통 통계학 자체가 문제가 아니라, 단순히 \\(p &lt; .05\\)라는 기준이 문제라고 생각할 수도 있습니다. 어떤 의미에서는 맞는 말입니다. Johnson (2013) 이 제안하는 해결책은 “모든 사람이 이제부터 베이지안이 되어야 한다”가 아닙니다. 대신, 통계적 유의성을 판단하는 일반적인 기준을 \\(p &lt; .01\\) 수준으로 강화하는 것이 더 현명하다는 것입니다. 이는 그리 무리한 주장은 아닙니다. 하지만 제 생각에는 이 문제는 단순히 기준값을 조정하는 것으로 해결될 수 있는 것보다 더 심각한 문제입니다. 저는 대부분의(모든 것은 아니지만) 전통적인 가설 검정 방식 자체에 근본적인 결함이 있다고 봅니다. 전통적인 방법론은 인간이 실제로 연구를 수행하는 방식에 대해 너무 순진한 가정을 하고 있고, 그렇기 때문에 대부분의 \\(p\\)-값은 잘못된 값이 됩니다.\n이것이 터무니없는 주장처럼 들릴 수 있습니다. 하지만 다음과 같은 상황을 한 번 생각해 보십시오. 여러분이 정말 흥미로운 연구 가설을 세우고 이를 검증하기 위해 연구를 설계한다고 가정해 봅시다. 여러분은 매우 성실한 연구자이므로 검정력 분석을 실시하여 필요한 표본 크기를 결정한 후 연구를 진행합니다. 그런 다음 가설 검정을 수행한 결과, \\(p\\)-값이 0.072로 나왔습니다. 정말 짜증 나겠죠?\n이제 어떻게 해야 할까요? 선택지는 다음과 같습니다.\n\n효과가 없다고 결론을 내리고 이를 귀무가설 결과로 출판하려 시도한다.\n\n효과가 있을 수도 있다고 추측하며 “경계선상의 유의한(borderline significant)” 결과로서 출판하려 시도한다.\n\n포기하고 새로운 연구를 시도한다.\n\n데이터를 더 수집하여 \\(p\\)-값이 올라가거나 (하지만 되도록이면!) 내려가서 “마법의” 기준인 \\(p &lt; .05\\) 아래가 되는지 확인한다.\n\n어떤 선택을 하겠습니까? 이 질문에 대해 잠시 시간을 갖고 솔직하게 고민해 보시기 바랍니다. 하지만 너무 스트레스받을 필요는 없습니다. 어떤 선택을 하든 결국 문제에 직면하게 될 것이기 때문입니다.\n제가 저자로서, 심사위원으로서, 그리고 편집자로서 경험한 바와 다른 연구자들의 이야기를 종합하면, 각 선택지의 결과는 다음과 같습니다.\n\n옵션 1: 귀무가설 결과로 출판하려 하면 논문 게재가 어려울 것입니다. 일부 심사위원은 \\(p = .072\\)가 진정한 귀무가설을 지지하는 결과가 아니라고 주장할 것입니다. 다른 심사위원은 그것이 귀무가설 결과임을 인정하더라도, 출판할 가치가 없다고 할 것입니다. 몇몇 심사위원은 여러분 편을 들 수도 있지만, 게재 과정에서 많은 어려움을 겪을 것입니다.\n옵션 2: “경계선상의 유의한” 결과로 출판하려 시도하면, 일부 심사위원은 이것이 귀무가설을 지지하는 결과이므로 출판해서는 안 된다고 주장할 것입니다. 또 다른 심사위원들은 데이터가 모호하므로 더 많은 데이터를 수집하여 명확한 결과를 도출해야 한다고 요구할 것입니다.\n옵션 3: \\(p = .072\\)라는 애매한 결과로 인해 출판이 어려운 상황이라면, 포기하고 다른 연구를 하는 것이 유혹적일 수 있습니다. 그러나 이는 연구자로서의 경력에 치명적일 수 있습니다. 연구마다 애매한 결과가 나올 때마다 포기한다면, 결국 출판할 연구가 없을 것이고, 만약 학계에 있다면 직장을 잃을 수도 있습니다.\n옵션 4: 남은 선택지는 데이터를 더 수집하여 다시 분석하는 것입니다. 이는 합리적으로 보이지만, 이 순간부터 여러분이 계산하는 모든 \\(p\\)-값이 잘못된 값이 됩니다. 지금 이 연구에서 계산한 \\(p\\)-값뿐만 아니라, 과거에 계산한 모든 \\(p\\)-값과 미래에 계산할 모든 \\(p\\)-값도 잘못된 값이 됩니다. 다행히 아무도 이를 눈치채지 않을 것입니다. 논문은 게재될 것이고, 여러분은 거짓말을 하게 될 것입니다.\n\n잠깐만요, 뭐라고요? 어떻게 그런 일이 가능할까요? 방금 설명한 전략은 지극히 합리적인 것처럼 보이는데요. 데이터가 충분하지 않다면 더 많은 데이터를 수집하여 보다 확실한 결론을 내리는 것이 논리적으로 맞지 않나요? 대체 무엇이 문제일까요?\n솔직히 말해서, 이것은 전혀 문제가 되지 않습니다. 합리적이고, 이성적이며, 논리적인 행동입니다. 실제 연구 환경에서도 연구자들은 바로 이렇게 행동합니다. 그러나 불행하게도, Chapter 9 에서 설명한 귀무가설 검정 이론에서는 이를 금지하고 있습니다.12 그 이유는 이 이론은 분석 시에는 실험은 종료되었으며 모든 데이터가 수집되었다고 가정하기 때문입니다. 실험이 끝났다고 가정하면, 두 가지 결정만이 가능합니다. 만약 일반적으로 사용하는 \\(p &lt; .05\\) 기준을 적용한다면, 그 결정은 Table 16.11 에 나타나 있습니다.\n\n\n\n\nTable 16.11. 전통적인 귀무가설 유의성 검정(NHST)에서 \\(p &lt; .05\\) 기준 적용\n\n\n\n\n\n결과행동\n\n\\(p\\)가 .05 미만귀무가설을 기각\n\n\\(p\\)가 .05 이상귀무가설을 유지\n\n\n\n\n\n\n\n여러분이 실제로 하고 있는 것은 의사결정 과정에 세 번째 가능성을 추가하는 것입니다. 즉, 여러분은 \\(p\\)-값 자체를 실험을 계속 진행할지 여부를 결정하는 근거로 사용하고 있습니다. 그 결과, 의사결정 절차는 Table 16.12 에서 설명한 것과 같은 방식으로 바뀌게 됩니다.\n\n\n\n\nTable 16.12. 사전 검정에서 얻은 \\(p\\)-값을 기반으로 데이터 수집을 계속 진행하는 경우\n\n\n\n\n\n결과행동\n\n\\(p\\)가 .05 미만실험을 중지하고 귀무가설을 기각\n\n\\(p\\)가 .05와 .1 사이실험을 계속 수행\n\n\\(p\\)가 .1 이상실험을 중단하고 귀무가설을 유지\n\n\n\n\n\n\n\n“기본적인” 귀무가설 검정 이론은 Chapter 9 에서 설명한 것처럼, 이러한 방식으로 분석을 처리하도록 설계되지 않았습니다. 만약 여러분이 실제 연구 환경에서 “더 많은 데이터를 수집”하는 선택을 한다면, 이는 여러분이 귀무가설 검정의 규칙을 따르지 않고 있다는 의미입니다. 비록 최종적으로 귀무가설 검정과 동일한 결론에 도달하더라도, 그 과정 자체를 따르지 않았다는 점이 문제를 발생시키는 원인이 됩니다.13 여러분의 \\(p\\)-값은 허위입니다.\n더 나쁜 점은, 이러한 허위 값들이 매우 작게 나온다는 것입니다. 이 문제가 얼마나 심각한지 감을 잡기 위해, 최악의 시나리오를 가정해 보겠습니다. 여러분이 연구 예산은 매우 빠듯한 열정적인 연구자라고 가정해 보겠습니다. 위에서 설명한 문제를 전혀 신경 쓰지 않고, 두 집단을 비교하는 연구를 설계했다고 합시다. 여러분은 \\(p &lt; .05\\) 수준에서 유의한 결과를 간절히 원하지만, 데이터 수집 비용을 최소화하고 싶어 합니다. 비용 절감을 위해 데이터를 수집하는 즉시 \\(t\\)-검정을 실행합니다. 만약 \\(t\\)-검정에서 \\(p &lt; .05\\)가 나오면, 실험을 종료하고 유의한 결과를 보고합니다. 그렇지 않으면 데이터를 계속 수집합니다. 여러분은 사전에 설정한 예산 한도(N=1000)에 도달할 때까지 이 과정을 반복합니다. 실제로는 효과가 전혀 존재하지 않는다고 가정해 봅시다. 즉, 귀무가설이 참입니다. 그렇다면 여러분이 실험을 끝까지 진행하고(올바르게) 효과가 없다고 결론 내릴 확률은 얼마일까요? 이상적인 세계에서는 95%여야 합니다. 결국, \\(p &lt; .05\\) 기준의 목적은 제1종 오류(type I error) 발생 확률을 5%로 제한하는 것이므로, 이 경우 잘못된 결론을 내릴 확률은 5%여야 합니다. 그러나 현실에서는 그렇지 않습니다. 여러분은 규칙을 깨고 있습니다. 데이터를 반복적으로 검사하면서 유의한 결과를 확인하는 순간, 모든 통제 기준이 무너집니다.\n그렇다면 실제로 얼마나 심각할까요? 시뮬레이션 연구 결과는 Figure 16.1 에서 실선으로 나타나 있으며, 그 결과는 충격적일 정도로 나쁩니다.\n\n\n\n\n\n\n\n\nFigure 16.1. 실험에서 각 집단의 목표 샘플 크기 \\(N\\)이 1000일 때, 중간 확인을 서로 다른 간격으로 수행한 경우 1종 오류의 확률 - 데이터가 새롭게 추가될 때마다 중간 확인을 하고 검정을 다시 수행하면 심각한 문제가 발생할 수 있습니다. 빈도주의자 방법을 사용하는 경우, 이는 매우 잘못된 방식입니다 (파란색 원과 실선). 반면, 베이지안 방법을 사용하는 경우 상대적으로 덜 심각합니다 (초록색 삼각형과 점선). 이 시뮬레이션에서는 유의수준(alpha level)을 \\(0.05\\) (빨간색 점선)로 설정하였습니다.\n\n\n\n\n\n데이터를 매번 새로운 관측값이 추가될 때마다 “중간 확인”하면, 1종 오류를 범할 확률이 52%입니다. 이는 원래 의도된 5%보다 훨씬 큽니다. 또한 확인 간격을 줄인다고 해서 크게 개선되지 않습니다. 10번마다 또는 50번마다 확인한다고 해도 1종 오류 비율은 여전히 너무 높습니다. 각각 37% 및 29%입니다.\n비교를 위해 다음과 같은 전략을 사용했다고 가정해 보겠습니다. 데이터를 수집하기 시작합니다. 매번 새로운 관측값이 들어올 때마다 베이지안 \\(t\\)-검정을 실행하고 베이즈 인자를 확인합니다. Johnson (2013) 이 옳다고 가정하고, 베이즈 인자 3:1을 \\(p\\)-값 0.05와 대략적으로 동등한 기준으로 취급하겠습니다.14 이번에는 가설 검정을 지나치게 자주 수행하는 연구자가 다음 절차를 사용한다고 가정합니다. 베이즈 인자가 귀무가설을 지지하는 방향으로 3:1 이상이면, 실험을 중단하고 귀무가설을 유지합니다. 베이즈 인자가 대립가설을 지지하는 방향으로 3:1 이상이면, 실험을 중단하고 귀무가설을 기각합니다. 그렇지 않으면 검정을 계속 진행합니다. 이제, 앞선 경우와 마찬가지로 귀무가설이 참이라고 가정하면 어떻게 될까요? 이 시나리오에 대해서도 시뮬레이션을 수행했고, 그 결과는 Figure 16.1 의 점선으로 표시되어 있습니다. 흥미롭게도, 새로운 관측값이 들어올 때마다 확인하는 경우의 제1종 오류율은 23%으로, 기존의 정통적인 \\(t\\)-검정을 사용했을 때 얻었던 52%보다 훨씬 낮습니다. 또한, 10번마다 또는 50번마다 확인하는 경우의 오류율도 각각 11% 및 7%으로 감소합니다.\n어떤 면에서 이는 매우 주목할 만한 결과입니다. 정통적인 귀무가설 검정의 핵심 목적은 1종 오류율을 통제하는 것입니다. 반면, 베이지안 방법은 본래 이러한 목적을 위해 설계된 것이 아닙니다. 그런데도, 데이터가 들어올 때마다 가설 검정을 수행하는 “성급한” 연구자의 상황에서는 베이지안 접근법이 훨씬 더 효과적이라는 사실이 밝혀졌습니다. 심지어 베이지안 연구자들조차도 지나치게 관대한 기준이라고 생각하는 3:1조차도, \\(p &lt; .05\\) 규칙보다 훨씬 안전한 선택입니다.\n\n\n16.3.4 정말 이렇게까지 나쁠까요?\n이전 절에서 제시한 예시는 상당히 극단적인 상황입니다. 현실에서 사람들은 새로운 관측값이 추가될 때마다 가설 검정을 수행하지 않습니다. 따라서 \\(p &lt; .05\\) 임계값이 “실제로” 52%의 1종 오류율(즉, \\(p = 0.52\\))에 해당한다고 말하는 것은 공정하지 않습니다. 하지만 \\(p\\)-값이 신뢰할 만한 값이 되기를 원한다면, 완전히 다른 방식의 가설 검정을 사용하거나 엄격하게 데이터를 중간 확인하는 것을 금지하는 규칙을 따라야 한다는 사실은 변하지 않습니다. 실험을 언제 종료할지 결정하는 데 데이터를 사용해서는 안 됩니다. “경계선에 있는” \\(p\\)-값을 보고 추가 데이터를 수집하기로 결정해서도 안 됩니다. 심지어 데이터를 확인한 후에 분석 전략을 변경하는 것도 허용되지 않습니다. 반드시 이러한 규칙을 엄격하게 따라야 합니다. 그렇지 않으면 계산된 \\(p\\)-값은 의미 없는 값이 됩니다.\n정말 이 규칙들은 놀랄 만큼 엄격합니다. 몇 년 전 강의에서 학생들에게 다음과 같은 시나리오를 생각해 보도록 한 적이 있습니다. 가령, 연구를 시작할 때 \\(N = 80\\)명의 참가자를 모집할 계획이었다고 가정해 보겠습니다. 실험을 시작할 때는 규칙을 지키며 데이터를 중간에 확인하거나 검정을 수행하지 않습니다. 하지만 \\(N = 50\\)에 도달했을 때, 의지가 흔들려 데이터를 들여다보게 됩니다. 결과가 어떻게 나왔을까요? 유의한 결과를 얻었습니다! 이제, 원래 계획대로 \\(N = 80\\)까지 연구를 진행하겠다고 했지만, 지금은 더 이상 그렇게 할 필요가 없다고 생각되지 않나요? \\(N = 50\\)에서 이미 유의한 결과를 얻었으니, 데이터를 더 수집하는 것은 낭비이고 비효율적인 것처럼 보입니다. 실험을 멈추고 싶지 않으신가요? 조금이라도 말입니다? 하지만 기억하십시오. 만약 그렇게 한다면, \\(p &lt; .05\\)에서의 1종 오류율이 8%까지 급증합니다. 논문에서 \\(p &lt; .05\\)라고 보고한다면, 실제로는 \\(p &lt; .08\\)라고 말하는 것과 같습니다. 단 한 번의 “몰래 보기”가 이처럼 심각한 결과를 초래할 수 있습니다.\n이제 다음 사항을 고려해 보겠습니다. 과학 논문에는 \\(t\\)-검정, ANOVA, 회귀 분석, 카이제곱 검정 등이 가득합니다. 이 책을 쓰면서 이러한 검정을 임의로 선택한 것이 아닙니다. 이러한 네 가지 도구가 대부분의 기초 통계 교재에서 등장하는 이유는, 과학에서 가장 기본적으로 사용되는 도구이기 때문입니다. 하지만 이 도구들 중 어느 것도 “데이터 중간 확인” 문제를 해결하기 위한 보정을 포함하고 있지 않습니다. 즉, 중간에 데이터를 확인하지 않는다고 가정하고 있습니다. 그런데 이 가정은 현실적인가요? 실제로 실험이 끝나기 전에 데이터를 “몰래 본” 연구자가 얼마나 될까요? 데이터를 확인한 후에 연구를 조정한 연구자가 얼마나 있을까요? 외부적인 제약에 의해 표본 수집 절차가 엄격히 확정되어 있지 않는 한, 대부분의 연구자가 한 번쯤은 그렇게 했을 것이라고 생각합니다. 그렇다면 보고된 \\(p\\)-값이 잘못되었을 가능성이 큽니다. 더욱이, 연구자가 실제로 어떤 의사결정 과정을 거쳤는지 알 수 없기 때문에, 우리는 그들이 보고한 \\(p\\)-값이 얼마나 정확한지를 알 방법이 없습니다. 연구자가 사용한 의사결정 절차를 알지 못하면, 정확한 \\(p\\)-값을 계산할 수 없습니다. 따라서 보고된 \\(p\\)-값은 거짓이 됩니다.\n이 모든 사실을 고려할 때, 핵심 메시지는 무엇일까요? 그것은 베이지안 방법이 완벽한 해결책이라는 것이 아닙니다. 연구자가 부정행위를 저지르려고 한다면, 어떤 방법을 사용하든 이를 방지할 방법은 없습니다. 베이즈 정리는 사람들이 거짓말을 하는 것을 막을 수도 없고, 실험을 조작하는 것을 막을 수도 없습니다. 여기서 제가 강조하고 싶은 것은 이 책의 첫 번째 장(1.1 절)에서 언급했던 것과 동일한 점입니다. 우리가 통계 검정을 수행하는 이유는 우리 스스로로부터 우리를 보호하기 위해서입니다. 그리고 “데이터 중간 확인”이 문제가 되는 이유는, 정직한 연구자들에게도 너무나 큰 유혹이기 때문입니다. 통계적 추론 이론은 이 점을 반드시 고려해야 합니다. 물론, \\(p\\)-값을 옹호하는 사람들은 연구자가 올바르게 사용하지 않은 것이 문제라고 주장할 수도 있습니다. 하지만 제 생각에는 그것은 논점을 비켜간 것입니다. 연구자가 자신의 데이터를 들여다볼 가능성을 고려하지 않는 통계적 추론 이론은 가치가 없습니다. 본질적으로, 제가 말하고 싶은 요점은 다음과 같습니다.\n\n좋은 법은 나쁜 도덕에 그 기원을 둔다.\n– 암브로시우스 마크로비우스15\n\n좋은 통계 검정 규칙은 인간의 나약함을 인정해야 합니다. 우리 중 누구도 죄가 없지 않습니다. 우리 중 누구도 유혹에서 완전히 자유롭지 않습니다. 좋은 통계적 추론 체계는 실제 인간이 사용하는 경우에도 제대로 작동해야 합니다. 정통적 귀무가설 검정은 그렇지 않습니다.16",
    "crumbs": [
      "마무리하며, 대안과 전망",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>베이지안 통계학</span>"
    ]
  },
  {
    "objectID": "16-Bayesian-statistics.html#베이지안-t-검정",
    "href": "16-Bayesian-statistics.html#베이지안-t-검정",
    "title": "16  베이지안 통계학",
    "section": "16.4 베이지안 \\(t\\)-검정",
    "text": "16.4 베이지안 \\(t\\)-검정\n이 책에서 다루는 중요한 통계적 추론 문제 중 하나는 두 평균을 비교하는 것입니다. Chapter 11 에서 \\(t\\)-검정에 대해 상세히 논의된 바 있습니다. 그때를 기억하신다면, 여러 가지 버전의 \\(t\\)-검정이 있다는 것을 아실 것입니다. 본 절에서는 독립 표본 \\(t\\)-검정과 대응 표본 \\(t\\)-검정의 베이지안 버전에 대해 간략히 설명하겠습니다.\n\n16.4.1 독립 표본 \\(t\\)-검정\n가장 일반적인 형태의 \\(t\\)-검정은 독립 표본 \\(t\\)-검정이며, Chapter 11 에서 사용한 harpo.csv 데이터와 같은 경우에 자주 사용됩니다. 이 데이터에는 두 집단의 학생들이 포함되어 있으며, 하나는 Anastasia에게 수업을 받은 집단이고, 다른 하나는 Bernadette에게 수업을 받은 집단입니다. 우리가 알고 싶은 것은 이 두 집단의 학생들이 받은 성적에 차이가 있는지 여부입니다.\nChapter 11 에서 이러한 유형의 데이터를 분석하는 방법으로 jamovi에서 독립 표본 \\(t\\)-검정을 사용하는 것이며, 그 결과는 Figure 16.3 에서 볼 수 있습니다. \\(p\\)-값이 0.05보다 작게 나왔기 때문에 귀무가설을 기각하였습니다.\n그렇다면 베이지안 버전의 \\(t\\)-검정은 어떨까요? ‘독립표본 T 검정’-‘검정’ 옵션에서 ‘베이즈 계수’ 체크박스를 선택하고 ’사전’의 기본값을 그대로 사용하면, Figure 16.3 에 표시된 결과를 얻을 수 있습니다. 이 표에서 얻은 베이지안 요인 통계값은 1.75이며, 이는 대립가설을 지지하는 증거가 약 1.8:1의 비율로 존재한다는 것을 의미합니다.\n\n\n\n\n\n\n\n\nFigure 16.2. jamovi에서의 베이지안 독립 표본 \\(t\\)-검정 결과\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 16.3. 독립 표본 \\(t\\)-검정과 함께 수행한 베이지안 요인 분석\n\n\n\n\n\n다음으로 넘어가기 전에, 정통적인(빈도주의자) 검정 결과와 베이지안 검정 결과의 차이점을 강조할 필요가 있습니다. 정통적 검정에서는 유의한 결과를 얻었지만, 그 차이는 근소했습니다. 그럼에도 불구하고 많은 사람들은 \\(p = .043\\)이라는 값을 효과에 대한 꽤 강력한 증거로 받아들일 것입니다. 반면에, 베이지안 검정에서는 효과를 지지하는 확률 비율이 2:1에도 미치지 못하며, 이는 매우 약한 증거로 간주됩니다. 제 경험상, 이러한 결과는 상당히 일반적입니다. 베이지안 방법은 귀무가설을 기각하기 위해 일반적으로 더 많은 증거를 요구합니다.\n\n\n\n\n\n\n실습: 베이지안 독립표본 Student t-검정\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Harpo’를 선택합니다.\n스프레드시트에서 grade의 열이름을 더블클릭합니다. 그리고 grade의 척도유형을 ’명명척도’에서 ’연속변수’로 바꿉니다.\n‘분석’-‘T-검정’-‘독립표본 T-검정’ 메뉴를 선택합니다.\n왼편의 ‘독립표본 T-검정’ 창에서 다음을 수행합니다. 그러면 Figure 16.2 같은 결과가 나타납니다.\n\n\ngrade를 ‘종속변수’ 상자로, tutor를 ‘집단변수’ 상자로 이동합니다.\n‘검정’ 옵션에서 ’베이즈 계수’와 ’Welch’s’를 체크합니다.\n‘추가 통계’에서 ’평균 차이’와 그 아래의 ’신뢰구간’, ’효과 크기’를 체크합니다.\n‘가정검정’에서 ’동질성 검정’과 ’정규분포성 검정’, “Q-Q 도표’를 체크합니다.\n\n\n\n\n\n16.4.2 대응 표본 \\(t\\)-검정\nSection 11.6 절에서 chico.csv 데이터 세트를 다루면서, 학생들의 성적이 두 시험에서 측정되었으며, 시험 1에서 시험 2로 성적이 상승했는지 알아보는 것이 관심사였습니다. 모든 학생이 두 시험을 다 보았기 때문에 데이터를 분석하는 도구로 대응 표본 \\(t\\)-검정을 사용하였습니다. Figure 16.4 는 일반적인 대응 \\(t\\)-검정과 베이즈 인자 분석의 jamovi 결과 표를 보여줍니다. 이 시점에서는 이 출력을 어려움 없이 읽을 수 있기를 바랍니다. 데이터는 대립 가설을 지지하는 증거를 약 6000:1의 비율로 제공합니다. 우리는 귀무가설을 상당한 신뢰를 가지고 기각할 수 있을 것입니다!\n\n\n\n\n\n\n\n\nFigure 16.4. jamovi에서 수행한 대응 표본 \\(t\\)-검정과 베이즈 인자 분석 결과\n\n\n\n\n\n\n\n\n\n\n\n실습: 베이지안 대응표본 \\(t\\)-검정\n\n\n\n이 실습을 하려면 Tip 3.1 을 수행하여 lsj-data 모듈이 설치되어 있어야 합니다.\n\n‘파일’-‘열기’-’데이터 라이브러리’를 메뉴에서 선택합니다. 그러면 ’learning statistics with jamovi’라는 폴더가 보일 것입니다. 이 폴더를 선택합니다. 이미 이전 실습에서 이 폴더를 선택했으면 바로 이 폴더가 열릴 수도 있습니다.\n데이터 라이브러리 목록에서 ’Chico’를 선택합니다.\n‘분석’-‘T-검정’-‘대응표본 T 검정’ 메뉴를 선택합니다.\n왼편의 ‘대응표본 T 검정’ 설정 창에서 다음을 수행합니다.\n\n\ngrade_test2를 ‘대응 변수’ 상자로 이동합니다. 그 다음 grade_test1를 ‘대응 변수’ 상자로 이동합니다. (이 순서로 해야 grade_test2 - grade_test1을 ’평균 차이’로 계산합니다.)\n‘검정’ 옵션에서 ’베이즈 계수’를 체크합니다.\n‘추가 통계’에서 ’평균차이’와 그 아래 ’신뢰구간’, 그리고 ’효과 크기’를 체크합니다.\n’가정검증’의 모든 옵션을 체크합니다.",
    "crumbs": [
      "마무리하며, 대안과 전망",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>베이지안 통계학</span>"
    ]
  },
  {
    "objectID": "16-Bayesian-statistics.html#요약",
    "href": "16-Bayesian-statistics.html#요약",
    "title": "16  베이지안 통계학",
    "section": "16.5 요약",
    "text": "16.5 요약\n이 장의 전반부는 주로 베이지안 통계학의 이론적 기초에 초점을 맞추었습니다. 합리적 행위자의 확률적 추론 절에서 베이지안 추론이 어떻게 작동하는지에 대한 수학적 내용을 소개하였으며, 베이지안 가설 검정에 대한 매우 기본적인 개요를 제공하였습니다. 마지막으로, 제가 생각하는 왜 베이지안이 되어야 하는가?에 대해 논의하였습니다.\n그 후, 베이지안 \\(t\\)-검정을 활용하는 예제를 제시하였습니다. 베이지안 접근법에 대해 더 배우고 싶다면 참고할 만한 좋은 책들이 많이 있습니다. John Kruschke의 Doing Bayesian Data Analysis는 이 분야를 시작하기에 좋은 책이며, 이론과 실습을 적절히 혼합한 내용을 제공합니다(Kruschke, 2011). 그의 접근법은 여기에서 다룬 “베이즈 인자” 접근법과는 다소 다르므로 동일한 내용을 반복해서 학습하는 것은 아닙니다. 인지 심리학자라면 Lee & Wagenmakers (2014) 를 참고하는 것도 좋을 것입니다. 저는 이 두 권의 책이 특히 제 연구 분야에서 유용하다고 생각하여 추천하였지만, 훌륭한 책들이 많으니 찾아보시길 바랍니다!\n\n\n\n\nFisher, R. A. (1925). Statistical methods for research workers. Oliver & Boyd.\n\n\nJeffreys, H. (1961). The theory of probability (3rd ed.). Oxford. https://doi.org/10.1093/oso/9780198503682.001.0001\n\n\nJohnson, V. E. (2013). Revised standards for statistical evidence. Proceedings of the National Academy of Sciences, 48, 19313–19317. https://doi.org/10.1073/pnas.1313476110\n\n\nKass, R. E., & Raftery, A. E. (1995). Bayes factors. Journal of the American Statistical Association, 90, 773–795. https://doi.org/10.1080/01621459.1995.10476572\n\n\nKruschke, J. K. (2011). Doing Bayesian data analysis: A tutorial with R and BUGS. Academic Press.\n\n\nLee, M. D., & Wagenmakers, E.-J. (2014). Bayesian cognitive modeling: A practical course. Cambridge University Press. https://doi.org/10.1017/CBO9781139087759",
    "crumbs": [
      "마무리하며, 대안과 전망",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>베이지안 통계학</span>"
    ]
  },
  {
    "objectID": "16-Bayesian-statistics.html#footnotes",
    "href": "16-Bayesian-statistics.html#footnotes",
    "title": "16  베이지안 통계학",
    "section": "",
    "text": "https://en.wikiquote.org/wiki/David%20Hume↩︎\nhttps://en.wikipedia.org/wiki/Climate_of_Adelaide↩︎\n이는 신뢰의 문제이지만, 그냥 넘어가도록 하죠.↩︎\n이런 말을 꺼내고 싶지는 않지만, 일부 통계학자들은 여기서 “가능도”라는 단어를 사용하는 것에 대해 반대할 수도 있습니다. 문제는 “가능도”라는 단어가 빈도주의 통계에서 매우 특정한 의미를 가지며, 베이지안 통계에서의 의미와 완전히 일치하지 않는다는 점입니다. 제가 알기로는, 원래 베이지안 통계에서는 가능도에 대한 명확한 명칭이 없었고, 그래서 많은 사람들이 빈도주의 용어를 사용하게 되었습니다. 이것이 문제가 되지 않았을 수도 있지만, 베이지안이 “가능도 함수”라는 말을 사용할 때는 보통 표의 한 행을 가리키고, 빈도주의자가 같은 말을 사용할 때는 동일한 표를 가리키지만 거의 항상 열을 의미한다는 점에서 차이가 있습니다. 이 차이는 특정 맥락에서 중요할 수 있지만, 우리의 목적에서는 중요하지 않습니다.↩︎\n“사전 확률”이란 데이터를 수집하거나 사용하여 정보를 갱신하기 전에 가지고 있던 기존의 지식이나 신념을 의미합니다.↩︎\n더 정교하게 접근한다면, 제가 우산을 가지고 있다고 거짓말할 가능성도 고려할 수 있습니다. 하지만 여기서는 단순성을 유지하겠습니다.↩︎\n이 식이 사실상 이전 절의 시작에서 소개한 기본 규칙의 변형임을 알 수 있습니다. 양변에 \\(P(d)\\)를 곱하면 \\(P(d)P(h|d) = P(d, h)\\)이 되며, 이는 결합 확률을 계산하는 규칙입니다. 즉, 여기서 새로운 규칙을 소개하는 것이 아니라, 동일한 규칙을 다른 방식으로 활용하는 것입니다.↩︎\n물론, 이것은 매우 단순화한 설명입니다. 실제 베이즈 가설 검정의 모든 복잡성은 가설 \\(h\\)가 복잡하고 불명확할 때 가능도 \\(P(d|h)\\)을 어떻게 계산하는가에 달려 있습니다. 이 책에서는 이러한 복잡성에 대해 다루지 않겠지만, 이 단순한 설명이 본질적으로는 맞더라도, 실제 세계는 입문 통계학 교재에서 다룰 수 있는 것보다 훨씬 더 복잡하다는 점을 강조하고 싶습니다.↩︎\nhttps://www.imdb.com/title/tt0093779/quotes 덧붙여 말하자면, 저는 이 인용구를 빈도주의자 방법론을 비판하는 데 사용한 최초의 사람이 아닙니다. 리치 모리(Rich Morey)와 동료들이 먼저 이 아이디어를 생각해냈습니다. 하지만 저는 이 인용구가 너무나도 훌륭하다고 생각하기 때문에 부끄러움 없이 가져왔으며, 프린세스 브라이드의 대사를 인용할 기회를 놓치고 싶지 않았습니다.↩︎\nhttps://about.abc.net.au/reports-publications/appreciation-survey-summary-report-2013/↩︎\nhttps://knowyourmeme.com/memes/the-cake-is-a-lie↩︎\n완전히 솔직해지기 위해 말씀드리자면, 모든 정통 통계 검정이 이 비합리적인 가정을 따르는 것은 아닙니다. 임상 시험 등에서 가끔 사용되는 순차 분석 도구들이 있습니다. 이러한 방법은 데이터가 도착하는 대로 분석한다는 가정하에 구축되었으며, 여기서 논의하는 방식대로는 심각한 문제가 발생하지 않습니다. 그러나 순차 분석 방법은 표준적인 귀무가설 검정과는 매우 다른 방식으로 구성됩니다. 이러한 방법은 입문서에서는 거의 다루어지지 않으며, 심리학 연구 논문에서도 널리 사용되지 않습니다. 여기서 제기하는 문제는 지금까지 소개한 모든 정통 통계 검정에 적용되며, 제가 읽은 대부분의 논문에서도 동일한 문제가 발견됩니다.↩︎\n관련 문제: https://xkcd.com/1478/↩︎\n일부 독자들은 Johnson (2013) 이 \\(p = .05\\)가 3:1과 5:1 사이에 위치한다고 제안했는데, 왜 5:1이 아니라 3:1을 선택했는지 궁금할 수 있습니다. 이는 \\(p\\)-값에 대해 관대한 기준을 적용하기 위함입니다. 만약 5:1을 기준으로 선택했다면, 베이지안 접근법의 결과는 더욱 유리하게 나왔을 것입니다.↩︎\nhttps://www.quotationspage.com/quotes/Ambrosius_Macrobius/↩︎\n물론, 일부 정통적 빈도주의자들이 이 절을 읽고 불평할 것이라는 점을 알고 있습니다. 저는 멍청하지 않습니다. 순차 분석 관점을 채택하면, 정통적 체계 내에서도 이러한 오류를 피할 수 있다는 것을 잘 알고 있습니다. 또한, 중간 분석을 염두에 둔 연구 설계를 명시적으로 수행할 수도 있다는 점도 알고 있습니다. 그러므로, 한편으로는 제가 정통적 방법의 “허수아비”를 공격하고 있는 것처럼 보일 수도 있습니다. 하지만 제가 공격하고 있는 허수아비는 대다수 연구자들이 실제로 사용해 온 방식입니다. 만약 실험 심리학자들 사이에서 순차 분석 방법이 일반적인 표준이 되고, 제가 더 이상 하루에 20개씩 의심스러운 ANOVA 결과를 읽을 필요가 없어진다면, 저는 이 절을 다시 쓰고 비판의 강도를 낮출 것을 약속드립니다. 하지만 그날이 오기 전까지는, 기본적인 베이즈 인자 방법이 현재의 데이터 분석 관행 속에서 훨씬 더 견고하다는 제 주장을 유지할 것입니다. 기본적인 정통적 방법은 형편없습니다. 그리고 우리 모두 그 사실을 알고 있습니다.↩︎",
    "crumbs": [
      "마무리하며, 대안과 전망",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>베이지안 통계학</span>"
    ]
  },
  {
    "objectID": "Epilogue.html",
    "href": "Epilogue.html",
    "title": "에필로그",
    "section": "",
    "text": "더 배워나가야 할 통계학\n먼저, 이 책에 포함하지 못했지만 다루고 싶었던 몇 가지 내용을 간략히 이야기하려 합니다. 이를 통해 통계학의 세계에는 어떤 다른 개념들이 존재하는지 감을 잡을 수 있을 것입니다. 학생들이 흔히 깨닫지 못하는 사실 중 하나는 입문 통계학 강의는 말 그대로 입문 과정이라는 점입니다. 더 넓은 세계로 나아가 실제 데이터 분석을 수행하려면 학부 강의에서 배운 내용을 다양한 방식으로 확장하는 새로운 도구들을 많이 배워야 합니다. 학부에서 다루지 않았다고 해서 어떤 분석이 불가능하다고 단정 짓지 마십시오. 반대로 학부에서 배웠다고 해서 그것이 항상 올바른 방법이라고 가정하지도 마십시오. 이러한 함정에 빠지지 않도록, 여기서는 다루지 않은 다른 통계학 개념들에 대한 개요를 간략히 소개하는 것이 유용하다고 생각합니다.",
    "crumbs": [
      "에필로그"
    ]
  },
  {
    "objectID": "Epilogue.html#더-배워나가야-할-통계학",
    "href": "Epilogue.html#더-배워나가야-할-통계학",
    "title": "에필로그",
    "section": "",
    "text": "다루어진 주제에서 생략된 내용\n이 책에서 다룬 주제들만 놓고 보더라도, 향후 개정판에서 보완하고 싶은 생략된 내용이 많습니다. jamovi와 관련된 내용이 아닌 순수한 통계학적인 주제들만 한정하여, 향후 확장하고 싶은 내용을 대표적으로 몇 가지 정리하면 다음과 같습니다.\n\n다른 유형의 상관관계. 12  상관관계와 선형회귀 에서 두 가지 상관관계 분석 방법(피어슨 상관계수와 스피어만 순위 상관계수)에 대해 설명하였습니다. 이 두 방법은 두 연속형 변수 사이의 관계를 평가하는 데 적용할 수 있습니다. 하지만 변수가 둘 다 명목 척도일 경우는 어떻게 해야 할까요? 혹은 한 변수는 명목 척도이고 다른 변수는 연속형일 경우에는요? 이러한 경우에도 상관관계를 계산하는 방법(예: 다항 상관계수)이 존재하며, 향후 이를 포함하는 것이 좋을 것 같습니다.\n효과 크기에 대한 보다 상세한 설명. 전반적으로, 이 책에서 효과 크기에 대한 설명이 다소 간략하게 이루어졌다고 생각합니다. 거의 모든 경우에 하나의 효과 크기 지표(대개 가장 널리 사용되는 것)를 선택하여 설명하는 방식으로 진행했습니다. 그러나 거의 모든 검정과 모형에서 효과 크기를 측정하는 다양한 방법이 존재하며, 이에 대해 좀 더 깊이 있는 설명을 제공하고 싶습니다.\n가정이 위배될 경우의 대처 방법. 책의 여러 부분에서 검정(또는 모형)의 가정이 위배될 경우 취할 수 있는 조치에 대해 언급하였지만, 이에 대해 더 자세히 설명하는 것이 좋을 것 같습니다. 특히, 변수를 변환하여 문제를 해결하는 방법에 대해 훨씬 더 심도 있게 논의하는 것이 유익할 것입니다. 6  데이터 조작 에서 이에 대해 일부 다루긴 했지만, 논의가 충분히 상세하지 않았다고 생각합니다.\n회귀 분석에서의 상호작용 항. 14  요인분산분석 장에서 ANOVA에 상호작용 항을 포함할 수 있으며, ANOVA가 일종의 선형 회귀 모형으로 해석될 수 있다는 점을 설명하였습니다. 그러나 12  상관관계와 선형회귀 에서 회귀 분석을 설명할 때는 상호작용 항에 대해 전혀 언급하지 않았습니다. 사실 회귀 모형에서도 상호작용 항을 포함할 수 있습니다. 다만, 두 개의 연속형 예측변수의 상호작용이 의미하는 바를 정확히 파악하는 것이 조금 더 복잡하며, 이를 수행하는 방법도 여러 가지가 있습니다. 그럼에도 불구하고, 이에 대해 조금이라도 다루었더라면 좋았을 것 같습니다.\n사전 계획된 비교 방법. 14  요인분산분석 에서 언급했듯이, ANOVA를 수행할 때 항상 사후 검정(예: Tukey의 HSD)을 사용하는 것이 적절한 것은 아닙니다. 특히, 사전에 명확하고 제한된 비교를 수행하려는 계획이 있었던 경우에는 더욱 그렇습니다. 이에 대해 좀 더 자세히 다루고 싶습니다.\n다중 비교 방법. 사후 검정 및 다중 비교와 관련된 논의에서도, 몇 가지 방법만 언급하는 데 그쳤습니다. 향후에는 보다 다양한 방법을 소개하고, 기존에 다룬 방법들보다 어떤 점에서 더 적절한지에 대한 논의를 추가하고 싶습니다.\n\n\n\n책에서 다루지 않은 통계 모형\n통계학은 방대한 학문 분야입니다. 이 책에서 설명한 핵심 도구(카이제곱 검정, \\(t\\)-검정, 회귀 분석 및 ANOVA)는 일상적인 데이터 분석에서 널리 사용되는 기본 도구이며, 대부분의 입문 통계학 교재에서도 핵심적인 내용으로 다루어집니다. 하지만 이 외에도 많은 도구들이 존재합니다. 기본 통계 도구들을 넘어서는 데이터 분석 상황이 많으며, 얼마나 더 많은 방법이 있는지 감을 잡을 수 있도록 몇 가지를 소개하겠습니다.\n\n비선형 회귀 분석. 12  상관관계와 선형회귀 에서 회귀분석을 논의할 때, 회귀분석이 예측변수와 결과변수의 관계가 선형이라는 가정을 한다는 점을 설명하였습니다. 한편, 4  기술 통계량 에서 보다 간단한 문제인 상관관계를 논의할 때, 변수 사이의 비선형 관계를 평가할 수 있는 도구(예: 스피어만 상관계수)가 존재한다는 점을 살펴보았습니다. 통계학에는 비선형 회귀분석을 수행할 수 있는 여러 도구가 존재합니다. 예를 들어, 일부 비선형 회귀 모형은 예측변수와 결과변수의 관계가 단조 증가 또는 감소(예: 등간격 회귀)한다고 가정하고, 다른 모형들은 관계가 단조적이지는 않지만 매끄럽게 변화한다고 가정합니다(예: Lowess 회귀). 또 다른 모형들은 관계의 형태가 비선형이지만 이미 알려진 형태를 따른다고 가정합니다(예: 다항 회귀 분석).\n로지스틱 회귀 분석. 회귀 분석의 또 다른 변형은 결과변수가 이진형일 때 나타납니다. 예측변수는 연속형일 수도 있습니다. 예를 들어, 소셜 미디어를 연구하면서 개인의 소득, 나이 및 기타 다양한 변수들을 활용하여 해당 사람이 트위터를 사용하는지를 예측할 수 있는지를 알고 싶다고 가정해 보겠습니다. 이는 기본적으로 회귀 분석 문제이지만, 결과변수가 이진형(트위터를 사용하거나 사용하지 않음)이므로 일반적인 선형 회귀를 사용할 수 없습니다. 결과변수가 이진형이므로 잔차가 정규 분포를 따를 가능성이 없습니다. 이와 같은 상황에 적용할 수 있는 다양한 통계적 도구가 존재하며, 그중 가장 대표적인 것이 로지스틱 회귀 분석입니다.\n일반화 선형 모형(GLM, General Linear Model). 일반화 선형 모형(GLM)은 사실상 하나의 모형이 아니라 여러 모형을 포함하는 개념입니다. GLM에는 로지스틱 회귀, 선형 회귀, (일부) 비선형 회귀, ANOVA 등이 포함됩니다. GLM의 기본 아이디어는 선형 모형의 기본 개념과 유사하지만, 데이터가 정규 분포를 따르지 않을 수도 있다는 점을 허용하고, 예측변수와 결과변수의 관계가 비선형일 가능성을 고려한다는 것입니다. GLM을 활용하면 다양한 분석을 수행할 수 있으므로 익혀 두면 매우 유용합니다.\n생존 분석. 2  연구 설계에 대한 간략한 소개 에서 “차별적 탈락”에 대해 설명하면서, 연구 참가자가 무작위가 아닌 방식으로 연구를 중도 이탈하는 경향이 있음을 논의하였습니다. 당시에는 이를 방법론적 문제로 설명하였지만, 실제로는 차별적 탈락 자체가 연구의 주요 관심사가 되는 경우도 많습니다. 예를 들어, 사람들이 특정 유형의 컴퓨터 게임을 한 번의 세션에서 얼마나 오래 플레이하는지를 연구한다고 가정해 보겠습니다. 실시간 전략(RTS) 게임과 1인칭 슈팅(FPS) 게임 중 어떤 게임을 더 오래 플레이하는지 궁금할 수 있습니다. 실험실에서 참가자들에게 원하는 만큼 게임을 하도록 허용하고, 게임을 종료하면 플레이 시간을 기록한다고 가정해 보겠습니다. 하지만 윤리적 제한으로 인해 두 시간 이상 게임을 하도록 허용할 수 없다고 가정해 보겠습니다. 많은 참가자는 두 시간 이전에 게임을 그만둘 것이므로 정확한 플레이 시간을 알 수 있습니다. 그러나 일부 참가자는 두 시간 제한에 도달할 것이므로, 연구를 계속할 수 있었다면 얼마나 더 오래 플레이했을지를 알 수 없습니다. 따라서 데이터에서 매우 긴 시간대의 관측치가 체계적으로 누락됩니다. 이러한 데이터를 합리적으로 분석하는 방법이 필요하며, 생존 분석이 바로 이 문제를 해결하는 도구입니다. 생존 분석은 연구 종료로 인해 데이터의 일부가 체계적으로 누락되는 상황을 처리하도록 설계되었습니다. 이 기법은 의료 연구에서 널리 사용되며, 이 맥락에서는 말 그대로 생존을 분석하는 데 활용됩니다. 예를 들어, 특정 유형의 암 환자를 추적하면서 일부는 치료 A를 받고, 일부는 치료 B를 받는다고 가정해 보겠습니다. 연구 자금이 5년 동안만 지원되므로, 연구가 끝날 때까지 일부 환자는 생존하고, 일부 환자는 사망하게 됩니다. 이 경우, 생존 분석을 통해 어떤 치료가 더 효과적인지 판단하고, 시간이 지남에 따라 사망 위험이 어떻게 변화하는지를 분석할 수 있습니다.\n혼합 모형 (Mixed Models). 반복측정 ANOVA는 실험 단위 내에서 여러 관측값이 클러스터링된 경우에 자주 사용됩니다. 예를 들어, 개별 참가자를 여러 시간에 걸쳐 추적하는 연구에서 이를 활용할 수 있습니다. 가령 두 명의 개인을 추적하면서 시간에 따른 행복도를 측정한다고 가정해 보겠습니다. Aaron의 행복도는 10에서 시작하여 8로 감소하고, 이후 6으로 떨어집니다. 반면 Belinda의 행복도는 6에서 시작하여 8로 상승하고, 이후 10으로 증가합니다. 두 사람 모두 세 개의 시간 지점에서 평균 행복도가 8로 동일하기 때문에 반복측정 ANOVA는 이들을 동일하게 취급합니다. 하지만 이것이 올바른 접근법이 아님을 쉽게 알 수 있습니다. Aaron의 행복도는 감소하는 반면, Belinda의 행복도는 증가하고 있습니다. 시간이 지남에 따라 변할 수 있는 데이터를 분석하려면 반복측정 ANOVA보다 더 강력한 도구가 필요합니다. 이를 해결하는 도구가 바로 “혼합 모형”입니다. 혼합 모형은 개별 실험 단위(예: 개인의 행복도 변화)를 학습하는 동시에 전반적인 효과(예: 시간이 지남에 따른 소득과 행복도의 관계)도 학습할 수 있도록 설계되어 있습니다. 반복측정 ANOVA는 혼합 모형의 가장 단순한 예시일 뿐이며, 혼합 모형을 사용하면 반복측정 ANOVA로 해결할 수 없는 많은 분석을 수행할 수 있습니다.\n다차원 척도법(Multidimensional scaling). 요인분석은 “비지도 학습(unsupervised learning)” 모형의 한 예입니다. 이는 앞서 언급한 대부분의 “지도 학습(supervised learning)” 도구와 달리 변수를 예측변수와 결과변수로 나눌 수 없다는 것을 의미합니다. 회귀분석은 지도 학습이지만, 요인분석은 비지도 학습입니다. 그러나 요인분석만이 유일한 비지도 학습 모형은 아닙니다. 예를 들어, 요인분석에서는 변수 사이의 상관관계를 분석하는 데 초점을 맞춥니다. 그러나 경우에 따라서는 객체, 항목 또는 사람들 사이의 유사성이나 차이를 분석하는 것이 더 중요할 수 있습니다. 이러한 경우 사용할 수 있는 여러 도구가 있으며, 그중 가장 잘 알려진 것이 다차원 척도법(MDS)입니다. MDS의 개념은 항목들을 “기하학적”으로 표현하는 것입니다. 각 항목은 공간 속의 한 점으로 표현되며, 두 점 사이의 거리는 해당 항목들 간의 차이를 측정하는 척도가 됩니다.\n군집 분석(Clustering). 또 다른 비지도 학습 모형의 예로 군집분석과 분류가 있습니다. 군집분석은 모든 항목을 의미 있는 군집으로 구성하여 유사한 항목들이 동일한 군집에 할당되도록 하는 방법입니다. 대부분의 군집분석은 비지도 학습으로 이루어지므로, 사전에 군집에 대한 정보를 전혀 알지 못한 채 군집을 추정해야 합니다. 반면, 지도 학습인 분류의 경우, 다른 변수들을 기반으로 어떤 군집에 속하는지를 예측해야 하며, 어떤 군집에 소속되는지가 관찰 가능한 경우입니다. 로지스틱 회귀는 이러한 문제에 사용되는 대표적인 도구입니다. 그러나 어떤 군집에 소속되어 있는지 사전에 알려져 있지 않은 경우에는 다른 도구(예: K-평균 군집화(K-means clustering))를 사용해야 합니다. 또한 “반지도 군집분석(semi-supervised clustering)”이라고 불리는 방법도 있는데, 이는 일부 항목에 대해서는 어떤 군집에 속하는지가 알려져 있지만, 다른 항목에 대해서는 알지 못하는 경우를 의미합니다. 예상할 수 있듯이, 군집 분석은 매우 광범위한 주제이며, 알아두면 유용한 기술입니다.\n인과 모형(Causal models). 이 책에서 통계 모형을 사용하여 변수 사이의 인과 관계를 학습하는 방법에 대해 깊이 다루지는 않았습니다. 예를 들어, 사형 집행에서 어떤 사람이 사망하는 과정은 다음과 같은 세 가지 변수가 중요할 수 있습니다. 즉, 처형 명령이 내려졌는지 여부(변수 A), 사수가 총을 발사했는지 여부(변수 B), 그리고 사람이 총에 맞았는지 여부(변수 C)입니다. 이 세 변수는 서로 상관관계를 가지지만(예: 총이 발사될 때 사람이 총에 맞을 확률이 높아짐), 우리는 단순히 상관관계를 분석하는 것보다 더 강한 주장을 하고 싶습니다. 즉, 우리는 인과 관계를 논하고 싶습니다. 우리는 “처형 명령(A)이 사수로 하여금 발사(B)하게 하고, 그 결과 사람이 총에 맞는다(C)”라고 말할 수 있어야 합니다. 이를 방향 화살표 표기법을 사용하여 \\(A \\rightarrow B \\rightarrow C\\)로 표현할 수 있습니다. 이 “인과 사슬(causal chain)”은 다음과 같은 인과 설명과는 근본적으로 다릅니다. 사수가 먼저 총을 쏘고(B), 그 결과로 총에 맞았고(C), 이후에 처형 명령이 “사후적으로” 내려졌다고 가정할 수도 있습니다. 이는 \\(B \\rightarrow C\\) 후에 \\(B \\rightarrow A\\)가 발생하는 “공통 결과(common effect)” 모형입니다. 이 두 가지 모형이 다르다는 것을 쉽게 알 수 있습니다. 첫 번째 인과 모형에서는 처형 명령(A)을 막을 수 있었다면 처형이 발생하지 않았을 것입니다. 그러나 두 번째 모형에서는 처형 명령과 관계없이 사수가 총을 쏘았기 때문에 처형이 발생했을 것입니다. 통계학에서는 변수 사이의 인과 관계를 이해하려는 연구가 활발히 이루어지고 있으며, 여러 가지 도구를 활용하여 데이터에서 다양한 인과 모형을 검정할 수 있습니다. 심리학에서 가장 널리 사용되는 도구 중 하나는 구조 방정식 모형(SEM, Structural Equation Modelling)이며, 향후 이 책에 이러한 내용을 추가하고 싶습니다.\n\n물론, 이 목록조차도 완전하지 않습니다. 시계열 분석(time series analysis), 문항 반응 이론(item response theory), 장바구니 분석(market basket analysis), 분류 및 회귀 트리(classification and regression trees) 등 다루지 않은 주제가 많습니다. 그러나 위에서 제시한 목록은 이 책에서 다루고 싶은 주제들의 핵심을 담고 있습니다. 물론 이러한 내용을 포함하면 책의 분량이 두 배로 늘어나겠지만, 심리학 연구자들이 실무에서 필요로 하는 대부분의 기법을 다룰 수 있는 폭넓은 범위를 갖추게 될 것입니다.\n\n\n다른 추론 방법들\n이 책이 불완전한 또 다른 이유는 추론 통계를 수행하는 방법에 대해 매우 제한적이고 구식의 관점을 중심으로 다루고 있기 때문입니다. 8  표본으로 미지의 모수 추정하기 에서 불편 추정량, 표본 분포 등의 개념을 간략히 소개하였습니다. 또한, 9  가설 검정 에서는 귀무가설 유의성 검정과 \\(p\\)-값에 대한 이론을 다루었습니다. 이러한 개념들은 20세기 초부터 존재해 왔으며, 이 책에서 다루는 대부분의 도구들도 당시의 이론적 개념에 크게 의존하고 있습니다. 과학 분야에서 이루어지는 데이터 분석의 대다수가 이러한 개념에 의존하고 있기 때문에, 저는 이를 충실하게 설명할 의무가 있다고 느꼈습니다. 그러나 통계학의 이론은 이보다 훨씬 더 넓은 범위를 포함하고 있으며, 실용적인 중요성 때문에 누구나 이 개념을 알아야 하지만 현대적인 데이터 분석에서는 최선의 방법이 아닐 수도 있습니다.\n그나마 다행인 점은 이 책에서 이러한 전통적인 접근 방식을 조금이나마 넘어설 수 있었다는 것입니다. 16  베이지안 통계학 에서는 베이즈 관점을 비교적 상세하게 다루고 있지만, 전체적으로 보면 이 책은 여전히 빈도주의자 정통 이론에 크게 치우쳐 있습니다. 이 외에도 추론을 수행하는 다양한 접근 방식들이 있으며, 그중 몇 가지를 소개하겠습니다.\n\n부트스트래핑 (Bootstrapping)\n이 책에서 가설 검정을 소개할 때마다, 저는 “어떤 통계량의 표본 분포는 \\(t\\)-분포를 따른다”와 같은 주장을 자주 하였습니다. 일부 경우에는 이러한 주장을 정당화하기 위해 노력하기도 하였습니다. 예를 들어, 10  범주형 데이터 분석 에서 \\(\\chi^2\\) 검정을 설명할 때 정규 분포와 \\(\\chi^2\\) 분포의 관계(자세한 내용은 7  확률이란? 참조)를 활용하여 적합도 검정 통계량의 표본 분포가 \\(\\chi^2\\) 분포를 따른다고 가정하는 이유를 설명하였습니다.\n그러나 사실 이러한 표본 분포에 대한 가정이 종종 잘못될 수 있습니다. \\(\\chi^2\\) 검정이 대표적인 예입니다. 이 검정은 데이터의 분포에 대한 특정 가정에 기반을 두고 있으며, 이 가정은 표본 크기가 작으면 성립하지 않는다고 알려져 있습니다. 20세기 초에는 이에 대한 해결책이 거의 없었습니다. 당시의 통계학자들은 “데이터가 어떤 가정을 충족할 경우, 표본 분포는 대략적으로 어떠하다”는 수학적 결과를 발전시켰으며, 이는 당시로서 최선의 방법이었습니다. 그러나 일부 데이터 분석 상황에서는 필요한 표본 분포에 대한 수학적 해결책이 발견되지 않은 경우도 많았습니다. 따라서 20세기 후반까지는 이러한 상황에 대한 적절한 검정 방법이 존재하지 않거나 제대로 작동하지 않았습니다.\n그러나 컴퓨터 기술의 발전으로 이러한 상황이 완전히 바뀌었습니다. 복잡한 기법들도 많이 개발되었으며, 그중 가장 간단한 방법이 부트스트래핑입니다. 부트스트래핑의 기본 개념은 매우 단순합니다. (a) 귀무가설이 참이며, (b) 모집단의 분포가 실제 데이터와 상당히 유사하다는 가정 하에서 실험 결과를 여러 번 시뮬레이션 합니다. 즉, 데이터를 정규 분포 등 특정 분포로 가정하는 대신, 모집단이 표본과 동일하다고 가정하고, 이 가정이 유지될 경우 검정 통계량의 표본 분포를 컴퓨터를 이용해 시뮬레이션하는 것입니다. 물론 모집단이 표본과 완전히 동일하다고 가정하는 것은 다소 의심스러운 가정이지만, 부트스트래핑은 빠르고 간편하며 실무의 많은 데이터 분석 문제에서 매우 효과적으로 작동하는 방법입니다.\n\n\n교차 검증 (Cross-validation)\n가끔 제 통계 수업에서 학생들이 도발적인 질문을 던지곤 합니다. “왜 우리는 추론 통계를 신경 써야 하나요? 그냥 표본을 기술하면 안 되나요?” 이에 대한 대답은 보통 다음과 같습니다. “과학자로서 우리의 진정한 관심사는 과거에 관찰한 특정 표본이 아니라, 미래에 관찰할 수 있는 데이터에 대한 예측입니다.”\n통계적 추론에서 발생하는 많은 문제들은 미래의 데이터가 과거와 유사하지만 완전히 동일하지 않을 것이라는 점에서 비롯됩니다. 일반적으로 새로운 데이터는 기존 데이터와 완전히 동일하지 않으며, 우리가 하는 일은 새로운 데이터에 대해 가장 정확한 추론을 도출할 수 있는 수학적 규칙을 찾아내는 것입니다. 예를 들어, 두 개의 모형 A와 B, 그리고 오늘 수집한 데이터 \\(X\\)가 있을 때, 두 모형 중 내일 수집할 새로운 데이터 \\(Y\\)를 가장 잘 설명할 수 있는 모형을 선택하려고 합니다.\n때로는 이러한 과정을 시뮬레이션하는 것이 유용하며, 이것이 바로 교차 검증의 개념입니다. 교차 검증에서는 데이터 집합을 두 개의 부분집합 \\(X_1\\)과 \\(X_2\\)로 나누고, \\(X_1\\)을 이용해 모형을 학습한 후(예: 회귀 계수를 추정), \\(X_2\\)를 사용하여 모형의 성능을 평가합니다. 이를 통해 모형이 새로운 데이터에서도 잘 일반화될 수 있는지 평가할 수 있으며, 전체 데이터 \\(X\\)에 맞춰진 성능 평가보다 더 신뢰할 수 있는 결과를 제공합니다.\n\n\n강건 통계 (Robust statistics)\n현실은 복잡하며, 모든 것이 예상대로 작동하는 것은 아닙니다. 이는 통계에서도 마찬가지입니다. 데이터를 분석할 때 우리는 종종 예상보다 더 복잡한 문제를 마주하게 됩니다. 예를 들어, 정규 분포를 따를 것으로 가정한 변수가 실제로는 정규 분포가 아닐 수도 있으며, 선형 관계라고 가정한 변수 사이의 관계가 실제로는 비선형일 수도 있습니다. 또한, 데이터 집합에는 원래 의도했던 정보가 반영되지 않는 오류가 포함될 가능성이 높습니다.\n이 책에서 다룬 대부분의 통계 이론에서는 이러한 복잡성을 무시하였습니다. 그러나 문제를 무시한다고 해서 해결되는 것은 아닙니다. 다행히도 일부 통계 도구들은 강건(robust)하여, 데이터가 이론적 가정을 완전히 충족하지 않더라도 비교적 잘 작동합니다. 반면, 일부 도구들은 강건하지 않으며, 작은 가정 위반에도 쉽게 무너집니다. 강건 통계는 이러한 문제를 연구하는 분야로, 특정 통계량의 “붕괴점(breakdown point)” 같은 개념을 다룹니다. 즉, 데이터가 얼마나 엉망이어야 해당 통계량이 신뢰할 수 없게 되는지를 분석하는 것입니다.\n예를 들어, 평균은 중심 경향의 강건한 추정량이 아니지만, 중앙값은 강건한 추정량입니다. 제 친구 다섯 명의 나이가 34, 39, 31, 43, 그리고 4003세라고 가정해 보겠습니다. 이들의 평균 나이는 얼마일까요? 표본 평균을 사용하면 830세가 됩니다. 하지만 중앙값을 사용하면 39세가 됩니다. 엄밀히 말하면 중앙값을 모집단 평균의 추정량으로 사용하는 것은 틀린 접근 방식이지만, 실제로는 더 신뢰할 수 있는 결과를 제공합니다. 여기서 한 데이터(4003세)는 명백한 오류이며, 단순한 오타일 가능성이 큽니다. 그러나 오타가 43을 53으로 잘못 입력한 것이라면, 또는 43을 34로 잘못 입력한 것이라면 어떻게 될까요? 데이터 오류가 미묘한 경우에는 쉽게 감지할 수 없으며, 이러한 오류들은 여전히 데이터를 오염시키고 결론에 영향을 미칩니다. 강건 통계는 이러한 오염이 존재할 때도 신뢰할 수 있는 추론을 수행하는 방법을 연구하는 분야이며, 매우 흥미로운 주제입니다.\n\n\n\n기타 주제\n\n결측치 처리\n설문 조사를 진행한다고 가정해 보겠습니다. 운동과 체중에 대한 관심이 있어 데이터를 네 명에게 보냈습니다. 애덤은 운동을 많이 하고 있으며 과체중이 아니라고 응답했습니다. 브라이오니도 운동을 많이 하고 있으며 과체중이 아니라고 응답했습니다. 캐롤은 운동을 하지 않으며 과체중이라고 응답했습니다. 팀은 운동을 하지 않으며 체중에 대한 질문에는 응답하지 않았습니다. 일레인은 설문을 제출하지 않았습니다. 이제 결측된 데이터 문제를 갖게 되었습니다. 하나의 설문이 전체적으로 누락되었고, 또 다른 설문에서는 한 가지 질문이 누락되었습니다. 이를 어떻게 처리해야 할까요? 일반적으로 결측된 데이터를 무시하는 것은 안전한 방법이 아닙니다. 여기서 팀의 설문을 생각해 보겠습니다. 먼저, 그의 다른 응답을 보면 그가 애덤이나 브라이오니보다 캐롤과 더 유사하다는 것을 알 수 있습니다(둘 다 운동을 하지 않음). 따라서 그의 체중을 추측해야 한다면, 애덤이나 브라이오니보다 캐롤과 더 비슷할 것이라고 예상할 것입니다. 또한, 애덤과 팀은 남성이며, 브라이오니와 캐롤은 여성이라는 점을 감안하여 일부 조정을 할 수도 있습니다.\n이러한 추측을 통계적으로 “대체”라고 합니다. 안전하게 대체하는 것은 어렵지만 중요합니다. 특히, 결측된 데이터가 체계적인 방식으로 발생하는 경우 더욱 그렇습니다. 과체중인 사람들은 종종 공공 보건 캠페인 등으로 인해 체중에 대해 부정적으로 느끼도록 압박받습니다. 따라서 응답하지 않은 사람들이 응답한 사람들보다 과체중일 가능성이 더 높다고 의심할 이유가 있습니다. 팀의 체중을 대체하면, 표본 내 과체중인 사람의 수가 3명 중 1명(팀을 무시할 경우)에서 4명 중 2명(팀의 체중을 대체할 경우)으로 증가할 가능성이 높습니다. 이는 중요한 차이입니다. 하지만 이를 합리적으로 수행하는 것은 생각보다 더 복잡합니다. 앞서, 팀과 캐롤이 운동 여부 응답이 동일했기 때문에 팀을 캐롤과 동일하게 취급해야 한다고 제안했습니다. 그러나 이는 완전히 올바른 접근이 아닙니다. 둘 사이에는 체계적인 차이가 있습니다. 캐롤은 질문에 응답했지만, 팀은 응답하지 않았습니다. 과체중인 사람들이 사회적 압력을 받는다는 점을 고려할 때, 팀이 캐롤보다 더 과체중일 가능성이 높지 않을까요?\n물론, 팀의 체중을 단일 값으로 대체하는 것도 합리적이지 않습니다. 마치 그의 체중을 정확히 알고 있는 것처럼 행동하는 것이기 때문입니다. 대신, 여러 개의 가능한 값을 추정하는 방식(이를 다중 대체라고 합니다)을 사용하여 팀의 체중에 대한 불확실성을 반영해야 합니다. 그리고 일레인이 설문을 제출하지 않은 문제까지 고려하면 상황은 더욱 복잡해집니다. 누락된 데이터를 다루는 것은 점점 더 중요한 주제가 되고 있으며, 일부 학문 분야에서는 다중 대체와 같은 합리적인 방법을 적용하지 않으면 연구 결과를 저널에서 받아주지 않는 경우도 있다고 합니다.\n\n\n검정력 분석\n검정력 분석. 9  가설 검정 에서 검정력(즉, 효과가 실제로 존재할 경우 이를 탐지할 가능성)에 대한 개념을 논의하고, 연구의 검정력을 평가하는 데 유용한 여러 도구로 구성된 검정력 분석에 대해 언급했습니다. 검정력 분석은 연구를 계획할 때 유용할 수 있습니다(예: 필요한 표본 크기를 예상하는 데 도움을 줄 수 있음). 또한, 이미 수집한 데이터를 분석하는 데에도 중요한 역할을 합니다. 예를 들어, 유의한 결과를 얻었고 효과 크기를 추정할 수 있다고 가정해 보겠습니다. 이 정보를 사용하여 연구의 실제 검정력을 추정할 수 있습니다. 이는 특히 효과 크기가 크지 않은 경우 유용합니다. 예를 들어, \\(p &lt; .05\\)에서 귀무가설을 기각했지만 검정력 분석을 통해 연구의 검정력이 단 0.08(즉, 8%)이었다는 사실을 발견했다고 가정해 보겠습니다. 유의한 결과가 있다는 것은, 귀무가설이 사실일 경우 현재와 같은 데이터를 얻을 확률이 5%라는 의미입니다. 하지만 검정력이 낮다는 것은, 귀무가설이 거짓이고 효과 크기가 현재 추정된 것만큼 작으면, 동일한 데이터를 얻을 확률이 8%라는 것을 의미입니다. 이는 결과 해석에 있어 주의가 필요하다는 것을 시사하며, 운이 결과에 큰 영향을 미쳤을 가능성이 있음을 보여줍니다.\n\n\n이론적으로 영감을 받은 모형을 사용한 데이터 분석\n이 책에서 몇 차례 반응 시간(RT) 데이터에 대해 언급했습니다. 반응 시간 데이터란 사람이 어떤 작업을 수행하는 데 걸리는 시간을 측정하는 것입니다(예: 단순한 결정을 내리는 데 걸리는 시간). 반응 시간 데이터는 거의 항상 정규 분포를 따르지 않으며, 양의 비대칭성을 보입니다. 또한, 속도-정확도 상충관계라는 현상이 존재합니다. 즉, 결정을 너무 빠르게 내리면(RT가 짧을수록) 정확도가 낮아질 가능성이 높습니다. 따라서 실험 참가자의 의사결정 정확도와 반응 시간을 측정하면, 속도와 정확도가 서로 관련이 있음을 발견할 수 있습니다. 물론, 이보다 더 복잡한 요소들도 존재합니다. 예를 들어, 어떤 사람들은 속도와 관계없이 더 나은 결정을 내릴 수 있습니다. 또한, 속도는 인지적 과정(즉, 사고하는 데 걸리는 시간)뿐만 아니라 생리적 과정(예: 근육이 움직이는 속도)에도 영향을 받습니다.\n이러한 데이터를 분석하는 것은 복잡한 과정입니다. 하지만 심리학 문헌을 깊이 탐구하면, 사람들이 단순한 결정을 내리는 과정을 설명하는 수학적 모형(이를 “순차 표본추출 모형”이라고 합니다)이 이미 존재하며, 위에서 언급한 다양한 요소들을 고려하고 있다는 사실을 알 수 있습니다. 이러한 이론 기반 모형은 일반적인 통계 교과서에서 다루지 않습니다. 일반적인 통계 교과서는 여러 학문 분야에서 광범위하게 적용할 수 있는 표준적인 도구들을 설명합니다. 예를 들어, 분산분석은 심리학뿐만 아니라 약리학에서도 적용될 수 있는 표준 도구입니다. 그러나 순차 표본추출 모형은 그렇지 않습니다. 이는 심리학에 특화된 모형이며, 다른 분야에서는 거의 사용되지 않습니다.\n그렇다고 해서 이러한 모형이 덜 강력한 도구라는 의미는 아닙니다. 사실, 사람들이 빠르게 결정을 내려야 하는 데이터를 분석하는 경우, 반드시 순차 표본추출 모형을 사용해야 합니다. ANOVA나 회귀분석과 같은 일반적인 방법을 사용하는 것은 효과적이지 않습니다. 왜냐하면 이러한 방법들이 기반으로 하는 이론적 가정이 반응 시간 데이터와 잘 맞지 않기 때문입니다. 반면, 순차 표본추출 모형은 이러한 유형의 데이터를 분석하도록 명확하게 설계되었으며, 그 이론적 가정이 데이터와 매우 잘 부합합니다.",
    "crumbs": [
      "에필로그"
    ]
  },
  {
    "objectID": "Epilogue.html#통계-기초-학습하기와-jamovi로-배우는-통계학",
    "href": "Epilogue.html#통계-기초-학습하기와-jamovi로-배우는-통계학",
    "title": "에필로그",
    "section": "통계 기초 학습하기와 jamovi로 배우는 통계학",
    "text": "통계 기초 학습하기와 jamovi로 배우는 통계학\n방금 살펴본 목록은 상당히 길었습니다. 그리고 그 목록조차도 매우 불완전합니다. 이 책에서 다루지 않은 중요한 통계 개념이 정말 많습니다. 거의 500 페이지에 달하는 교재를 끝마친 후에도 이것이 단지 시작일 뿐이라는 이야기를 듣는 것에 다소 낙담할 수 있습니다. 특히, 지금까지 배운 내용 중 절반이 잘못되었다는 의심이 들기 시작한다면 더욱 그렇습니다. 예를 들어, 통계학 분야에는 고전적 ANOVA 모형의 사용을 강하게 반대하는 사람들이 많습니다. 그런데도 저는 ANOVA에 대해 두 개의 장이나 할애했습니다! 고전적 ANOVA는 베이지안 관점에서 비판받을 수도 있고, 강건한 통계 관점에서 비판받을 수도 있으며, 심지어는 “그냥 틀렸다”는 관점에서 공격받을 수도 있습니다. (많은 사람들이 사실은 혼합 모형을 사용해야 할 때 ANOVA를 빈번히 사용하고 있기 때문입니다.) 그렇다면, 왜 ANOVA를 배워야 할까요?\n제가 보기에는 두 가지 핵심적인 이유가 있습니다. 첫째는 순수하게 실용적인 이유입니다. 옳든 그르든, ANOVA는 널리 사용되고 있습니다. 과학 논문을 이해하려면 ANOVA를 이해해야 합니다. 둘째는 “점진적 학습”의 논리입니다. 마치 일원분산분석(one-way ANOVA)을 먼저 배운 후에 요인분산분석(factorial ANOVA)을 배우는 것이 유용한 것처럼, ANOVA를 이해하면 보다 고급 분석 기법을 배우는 데 도움이 됩니다. 실제로, 혼합 모형이 ANOVA나 회귀 분석보다 훨씬 유용하지만, ANOVA와 회귀 분석을 먼저 배우지 않고 바로 혼합 모형을 배우는 경우는 거의 없습니다. 산을 오르기 전에 기어 다니는 법부터 배워야 합니다.\n사실, 저는 이 논점을 좀 더 강조하고 싶습니다. 이 책에서 제가 반복적으로 강조한 부분이 바로 기본 개념입니다. 저는 확률 이론에 대해 많은 시간을 할애했고, 추정 이론과 가설 검정 이론도 필요 이상으로 자세히 설명했습니다. 왜 그랬을까요? 되돌아보면, 확률 분포가 무엇인지 설명하는 데 그렇게 많은 시간을 들일 필요가 있었을까요? 확률 밀도 개념을 따로 설명한 이유는 무엇일까요? 이 책의 목표가 단순히 \\(t\\)-검정이나 ANOVA를 수행하는 방법을 가르치는 것이라면, 이런 내용은 정말 불필요했던 것 아닐까요? 결국, 모든 것이 시간 낭비였던 것 아닐까요?\n저는 아니라고 확신합니다. 기초 통계 교육의 목표는 ANOVA를 가르치는 것이 아닙니다. \\(t\\)-검정, 회귀 분석, 히스토그램, \\(p\\)-값을 가르치는 것도 목표가 아닙니다. 목표는 여러분이 숙련된 데이터 분석가로 성장하는 길을 시작할 수 있도록 돕는 것입니다. 숙련된 데이터 분석가가 되려면 ANOVA, \\(t\\)-검정, 회귀 분석, 히스토그램 그 이상의 것을 할 수 있어야 합니다. 데이터에 대해 올바르게 사고하는 능력이 필요합니다. 이전 절에서 다룬 고급 통계 모형을 배울 수 있어야 하며, 그 모형들이 기반하는 이론을 이해할 수 있어야 합니다. 그리고 그러한 고급 분석 도구를 사용할 수 있는 소프트웨어를 다룰 줄 알아야 합니다. 제가 기본 개념을 강조한 이유가 바로 여기에 있습니다. 확률 이론을 이해하면 빈도주의자 분석에서 베이지안 분석으로 전환하는 것이 훨씬 쉬워집니다.\n다시 말해, 이 방식으로 통계를 배우는 가장 큰 장점은 확장성에 있습니다. 이 책은 데이터 분석의 기초만을 다루는 책임에도 불구하고, 확률 이론 등의 학습에 많은 시간을 투자합니다. 이 책은 특정 분석 기법만을 가르치는 것이 아니라, 그 과정에서 여러 가지 중요한 개념을 함께 익히도록 합니다. 만약 여러분의 목표가 최소한의 시간 내에 ANOVA를 수행하는 방법을 배우는 것이었다면, 이 책은 적절한 선택이 아니었을 것입니다. 하지만 제 생각에, 그것이 여러분의 진정한 목표는 아닙니다. 여러분은 데이터 분석을 배우고 싶어 합니다. 그리고 진정으로 데이터 분석을 배우고자 한다면, 기초 통계 교육을 통해 익힌 기술이 실제 데이터 분석에서 필요한 보다 복잡한 모형으로 자연스럽고 원활하게 확장될 수 있어야 합니다. 또한, 실제 데이터 분석가들이 사용하는 도구를 배워야 합니다. 그래야 그들이 하는 일을 여러분도 할 수 있게 됩니다.\n지금 여러분은 초보자일 수 있습니다. (혹은 이 책을 처음 시작할 때는 초보자였을 수도 있습니다). 하지만 그렇다고 해서 여러분에게 단순화된 이야기만 들려줘야 한다고 생각하지 않습니다. 저는 확률 밀도 개념을 생략하거나, 불균형 설계에서의 요인분산분석이 얼마나 복잡한지를 말하지 않는 방식으로 설명을 단순화하지 않았습니다. 또한, 저는 초보자라고 해서 실제 데이터 분석을 위한 “진정한 도구” 대신 “장난감 같은 도구”를 제공해서는 안 된다고 생각합니다. 초보자는 단순히 지식이 부족할 뿐이지, 결코 어리석지 않습니다. 여러분에게 필요한 것은 현실 세계의 데이터 분석이 얼마나 복잡한지를 감추는 것이 아닙니다. 여러분에게 필요한 것은, 현실에서 마주하게 될 데이터 분석의 복잡성을 감당할 수 있는 기술과 도구입니다.\n저는 이 책이 여러분에게 그러한 도움을 줄 수 있기를 바랍니다.\n저자의 말 - 이 책에서 인용 없이 똑똑해 보이는 내용이 있다면, 그 아이디어는 100% 다른 사람에게서 온 것입니다. 이 책은 입문서이며, 여기서 다루는 개념들은 결코 새로운 것이 아닙니다. 모든 오류는 저의 책임이지만, 좋은 내용에 대한 공은 다른 사람들에게 돌아가야 합니다. 이 책에서 유용한 개념들은 모두 다른 연구자들의 공헌에서 나온 것입니다.",
    "crumbs": [
      "에필로그"
    ]
  },
  {
    "objectID": "References.html",
    "href": "References.html",
    "title": "References",
    "section": "",
    "text": "Adair, G. (1984). The hawthorne effect: A reconsideration of the\nmethodological artifact. Journal of Applied Psychology,\n69, 334–345. https://doi.org/10.1037/0021-9010.69.2.334\n\n\nAgresti, A. (1996). An introduction to categorical data\nanalysis. Wiley. https://doi.org/10.1002/0470114754\n\n\nAgresti, A. (2002). Categorical data analysis (2nd ed.). Wiley.\nhttps://doi.org/10.1002/0471249688\n\n\nAkaike, H. (1974). A new look at the statistical model identification.\nIEEE Transactions on Automatic Control, 19, 716–723.\nhttps://doi.org/10.1109/TAC.1974.1100705\n\n\nAnscombe, F. J. (1973). Graphs in statistical analysis. American\nStatistician, 27, 17–21. https://doi.org/10.1080/00031305.1973.10478966\n\n\nBickel, P. J., Hammel, E. A., & O’Connell, J. W. (1975). Sex bias in\ngraduate admissions: Data from Berkeley. Science,\n187, 398–404. https://doi.org/10.1126/science.187.4175.398\n\n\nBox, G. E. P. (1953). Non-normality and tests on variances.\nBiometrika, 40, 318–335. https://doi.org/10.2307/2333350\n\n\nBox, G. E. P. (1976). Science and statistics. Journal of the\nAmerican Statistical Association, 71, 791–799. https://doi.org/10.1080/01621459.1976.10480949\n\n\nBox, J. F. (1987). Guinness, gosset, fisher, and small samples.\nStatistical Science, 2, 45–52. https://doi.org/10.1214/ss/1177013437\n\n\nBrown, M. B., & Forsythe, A. B. (1974). Robust tests for equality of\nvariances. Journal of the American Statistical Association,\n69, 364–367. https://doi.org/10.2307/2285659\n\n\nCampbell, D. T., & Stanley, J. C. (1963). Experimental and\nquasi-experimental designs for research. Houghton Mifflin.\n\n\nChild, D. (1990). The essentials of factor analysis (2nd ed.).\nCassell Educational.\n\n\nChronbach, L. J. (1951). Coefficient alpha and the internal structure of\ntests. Psychometrika, 16(3), 297–334. https://doi.org/10.1007/BF02310555\n\n\nCochran, W. G. (1954). The χ2 test of goodness of\nfit. The Annals of Mathematical Statistics, 23,\n315–345. https://doi.org/10.1214/aoms/1177729380\n\n\nCohen, J. (1988). Statistical power analysis for the behavioral\nsciences (2nd ed.). Lawrence Erlbaum. https://doi.org/10.4324/9780203771587\n\n\nCramer, H. (1946). Mathematical methods of statistics.\nPrinceton University Press. https://doi.org/10.1515/9781400883868\n\n\nDunn, O. J. (1961). Multiple comparisons among means. Journal of the\nAmerican Statistical Association, 56, 52–64. https://doi.org/10.1080/01621459.1961.10482090\n\n\nEllis, P. D. (2010). The essential guide to effect sizes:\nStatistical power, meta-analysis, and the interpretation of research\nresults. Cambridge University Press. https://doi.org/10.1017/CBO9780511761676\n\n\nEvans, J. St. B. T., Barston, J. L., & Pollard, P. (1983). On the\nconflict between logic and belief in syllogistic reasoning. Memory\nand Cognition, 11, 295–306. https://doi.org/10.3758/BF03196976\n\n\nEvans, M., Hastings, N., & Peacock, B. (2011). Statistical\ndistributions (3rd ed). Wiley. https://doi.org/10.1002/9780470627242\n\n\nEveritt, B. S. (1996). Making sense of statistics in psychology. A\nsecond-level course. Oxford University Press.\n\n\nFabrigar, L. R., Wegener, D. T., MacCallum, R. C., & Strahan, E. J.\n(1999). Evaluating the use of exploratory factor analysis in\npsychological research. Psychological Methods, 4,\n272–299. https://doi.org/10.1037/1082-989X.4.3.272\n\n\nFisher, R. A. (1922a). On the interpretation of χ2 from contingency\ntables, and the calculation of p. Journal of the Royal\nStatistical Society, 84, 87–94. https://doi.org/10.1111/j.2397-2335.1922.tb00768.x\n\n\nFisher, R. A. (1922b). On the mathematical foundation of theoretical\nstatistics. Philosophical Transactions of the Royal Society A,\n222, 309–368. https://doi.org/10.1098/rsta.1922.0009\n\n\nFisher, R. A. (1925). Statistical methods for research workers.\nOliver & Boyd.\n\n\nFox, J., & Weisberg, S. (2011). An R companion to\napplied regression (2nd ed.). Sage.\n\n\nGelman, A., & Stern, H. (2006). The difference between\n“significant” and “not significant” is not\nitself statistically significant. The American Statistician,\n60, 328–331. https://doi.org/10.1198/000313006X152649\n\n\nGeschwind, N. (1972). Language and the brain. Scientific\nAmerican, 226(4), 76–83. https://doi.org/10.1038/scientificamerican0472-76\n\n\nHays, W. L. (1994). Statistics (5th ed.). Harcourt Brace.\n\n\nHedges, L. V. (1981). Distribution theory for glass’s estimator of\neffect size and related estimators. Journal of Educational\nStatistics, 6, 107–128. https://doi.org/10.2307/1164588\n\n\nHedges, L. V., & Olkin, I. (1985). Statistical methods for\nmeta-analysis. Academic Press. https://doi.org/10.1016/C2009-0-03396-0\n\n\nHewitt, A. K., Foxcroft, D. R., & MacDonald, J. (2004).\nMultitrait-multimethod confirmatory factor analysis of the attributional\nstyle questionnaire. Personality and Individual Differences,\n37(7), 1483–1491. https://doi.org/10.1016/j.paid.2004.02.005\n\n\nHogg, R. V., McKean, J. V., & Craig, A. T. (2005). Introduction\nto mathematical statistics (6th ed.). Pearson.\n\n\nHolm, S. (1979). A simple sequentially rejective multiple test\nprocedure. Scandinavian Journal of Statistics, 6,\n65–70. https://doi.org/10.2307/4615733\n\n\nHróbjartsson, A., & Gøtzsche, P. (2010). Placebo interventions for\nall clinical conditions. Cochrane Database of Systematic\nReviews, 1. https://doi.org/10.1002/14651858.cd003974.pub3\n\n\nHsu, J. C. (1996). Multiple comparisons: Theory and methods.\nChapman & Hall. https://doi.org/10.1201/b15074\n\n\nIoannidis, J. P. A. (2005). Why most published research findings are\nfalse. PLoS Med, 2(8), 697–701. https://doi.org/10.1371/journal.pmed.1004085\n\n\nJeffreys, H. (1961). The theory of probability (3rd ed.).\nOxford. https://doi.org/10.1093/oso/9780198503682.001.0001\n\n\nJohnson, V. E. (2013). Revised standards for statistical evidence.\nProceedings of the National Academy of Sciences, 48,\n19313–19317. https://doi.org/10.1073/pnas.1313476110\n\n\nKahneman, D., & Tversky, A. (1973). On the psychology of prediction.\nPsychological Review, 80, 237–251. https://doi.org/10.1037/h0034747\n\n\nKass, R. E., & Raftery, A. E. (1995). Bayes factors. Journal of\nthe American Statistical Association, 90, 773–795. https://doi.org/10.1080/01621459.1995.10476572\n\n\nKeynes, J. M. (1923). A tract on monetary reform. Macmillan\n& Company.\n\n\nKline, P. (1994). An easy guide to factor analysis. Routledge.\nhttps://doi.org/10.4324/9781315788135\n\n\nKruschke, J. K. (2011). Doing Bayesian data analysis: A\ntutorial with R and BUGS. Academic Press.\n\n\nKruskal, W. H., & Wallis, W. A. (1952). Use of ranks in\none-criterion variance analysis. Journal of the American Statistical\nAssociation, 47, 583–621. https://doi.org/10.1080/01621459.1952.10483441\n\n\nKühberger, A., Fritz, A., & Scherndl, T. (2014). Publication bias in\npsychology: A diagnosis based on the correlation between effect size and\nsample size. Public Library of Science One, 9, 1–8. https://doi.org/10.1371/journal.pone.0105825\n\n\nLarntz, K. (1978). Small-sample comparisons of exact levels for\nchi-squared goodness-of-fit statistics. Journal of the American\nStatistical Association, 73, 253–263. https://doi.org/10.1080/01621459.1978.10481567\n\n\nLee, M. D., & Wagenmakers, E.-J. (2014). Bayesian cognitive\nmodeling: A practical course. Cambridge University Press. https://doi.org/10.1017/CBO9781139087759\n\n\nLehmann, E. L. (2011). Fisher, Neyman, and the creation\nof classical statistics. Springer.\n\n\nLevene, H. (1960). Robust tests for equality of variances. In Olkin, I.\nand others (Ed.), Contributions to probability and statistics:\nEssays in honor of harold hotelling (pp. 278–292). Stanford\nUniversity Press.\n\n\nMcGrath, R. E., & Meyer, G. J. (2006). When effect sizes disagree:\nThe case of r and d. Psychological Methods,\n11, 386–401. https://doi.org/10.1037/1082-989x.11.4.386\n\n\nMeehl, P. H. (1967). Theory testing in psychology and physics: A\nmethodological paradox. Philosophy of Science, 34,\n103–115. https://doi.org/10.1086/288135\n\n\nPearson, K. (1900). On the criterion that a given system of deviations\nfrom the probable in the case of a correlated system of variables is\nsuch that it can be reasonably supposed to have arisen from random\nsampling. Philosophical Magazine, 50, 157–175. https://doi.org/10.1080/14786440009463897\n\n\nPeterson, C., & Seligman, M. (1984). Causal explanations as a risk\nfactor for depression: Theory and evidence. Psychological\nReview, 91, 347–374. https://doi.org/10.1037/0033-295X.91.3.347\n\n\nPfungst, O. (1911). Clever hans (the horse of mr. Von osten): A\ncontribution to experimental animal and human psychology (C. L.\nRahn, Trans.). Henry Holt.\n\n\nRosenthal, R. (1966). Experimenter effects in behavioral\nresearch. Appleton.\n\n\nShaffer, J. P. (1995). Multiple hypothesis testing. Annual Review of\nPsychology, 46, 561–584. https://doi.org/10.1146/annurev.ps.46.020195.003021\n\n\nShapiro, S. S., & Wilk, M. B. (1965). An analysis of variance test\nfor normality (complete samples). Biometrika, 52,\n591–611. https://doi.org/10.1093/biomet/52.3-4.591\n\n\nSokal, R. R., & Rohlf, F. J. (1994). Biometry: The principles\nand practice of statistics in biological research (3rd ed.).\nFreeman.\n\n\nStevens, S. S. (1946). On the theory of scales of measurement.\nScience, 103, 677–680. https://doi.org/10.1126/science.103.2684.677\n\n\nStigler, S. M. (1986). The history of statistics. Harvard\nUniversity Press.\n\n\nStudent, A. (1908). The probable error of a mean. Biometrika,\n6, 1–2. https://doi.org/10.1093/biomet/6.1.1\n\n\nTversky, A., & Kahneman, D. (1974). Judgment under uncertainty:\nHeuristics and biases. Science, 185(4157), 1124–1131.\nhttps://doi.org/10.1126/science.185.4157.1124\n\n\nWelch, B. L. (1947). The generalization of\n“Student’s” problem when several different\npopulation variances are involved. Biometrika, 34,\n28–35. https://doi.org/10.1093/biomet/34.1-2.28\n\n\nWelch, B. L. (1951). On the comparison of several mean values: An\nalternative approach. Biometrika, 38, 330–336. https://doi.org/10.1093/biomet/38.3-4.330\n\n\nYates, F. (1934). Contingency tables involving small numbers and the\nχ2 test.\nSupplement to the Journal of the Royal Statistical Society,\n1, 217–235. https://doi.org/10.2307/2983604",
    "crumbs": [
      "References"
    ]
  }
]